<doc id="13600" url="https://en.wikipedia.org/wiki?curid=13600" title="Hipparchus">
Hipparchus

Hipparchus of Nicaea (; , "Hipparkhos";  ) was a Greek astronomer, geographer, and mathematician. He is considered the founder of trigonometry but is most famous for his incidental discovery of precession of the equinoxes.

Hipparchus was born in Nicaea, Bithynia (now İznik, Turkey), and probably died on the island of Rhodes, Greece. He is known to have been a working astronomer at least from 162 to 127 . Hipparchus is considered the greatest ancient astronomical observer and, by some, the greatest overall astronomer of antiquity. He was the first whose quantitative and accurate models for the motion of the Sun and Moon survive. For this he certainly made use of the observations and perhaps the mathematical techniques accumulated over centuries by the Babylonians and by Meton of Athens (5th century ), Timocharis, Aristyllus, Aristarchus of Samos and Eratosthenes, among others. He developed trigonometry and constructed trigonometric tables, and he solved several problems of spherical trigonometry. With his solar and lunar theories and his trigonometry, he may have been the first to develop a reliable method to predict solar eclipses. His other reputed achievements include the discovery and measurement of Earth's precession, the compilation of the first comprehensive star catalog of the western world, and possibly the invention of the astrolabe, also of the armillary sphere, which he used during the creation of much of the star catalogue.

There is a strong tradition that Hipparchus was born in Nicaea (Greek "Νίκαια"), in the ancient district of Bithynia (modern-day Iznik in province Bursa), in what today is the country Turkey. The exact dates of his life are not known, but Ptolemy attributes astronomical observations to him in the period from 147–127 , and some of these are stated as made in Rhodes; earlier observations since 162  might also have been made by him. His birth date ( ) was calculated by Delambre based on clues in his work. Hipparchus must have lived some time after 127  because he analyzed and published his observations from that year. Hipparchus obtained information from Alexandria as well as Babylon, but it is not known when or if he visited these places. He is believed to have died on the island of Rhodes, where he seems to have spent most of his later life.

It is not known what Hipparchus's economic means were nor how he supported his scientific activities. His appearance is likewise unknown: there are no contemporary portraits. In the 2nd and 3rd centuries coins were made in his honour in Bithynia that bear his name and show him with a globe; this supports the tradition that he was born there.

Relatively little of Hipparchus's direct work survives into modern times. Although he wrote at least fourteen books, only his commentary on the popular astronomical poem by Aratus was preserved by later copyists. Most of what is known about Hipparchus comes from Strabo's "Geography" and Pliny's "Natural History" in the 1st century; Ptolemy's 2nd-century "Almagest"; and additional references to him in the 4th century by Pappus and Theon of Alexandria in their commentaries on the "Almagest".

Hipparchus was amongst the first to calculate a heliocentric system, but he abandoned his work because the calculations showed the orbits were not perfectly circular as believed to be mandatory by the science of the time. Although a contemporary of Hipparchus', Seleucus of Seleucia, remained a proponent of the heliocentric model, Hipparchus' rejection of heliocentrism, supported by ideas from Aristotle, remained dominant for nearly 2000 years until Copernican heliocentrism turned the tide of the debate.

Hipparchus's only preserved work is "Τῶν Ἀράτου καὶ Εὐδόξου φαινομένων ἐξήγησις" ("Commentary on the Phaenomena of Eudoxus and Aratus"). This is a highly critical commentary in the form of two books on a popular poem by Aratus based on the work by Eudoxus. Hipparchus also made a list of his major works, which apparently mentioned about fourteen books, but which is only known from references by later authors. His famous star catalog was incorporated into the one by Ptolemy, and may be almost perfectly reconstructed by subtraction of two and two thirds degrees from the longitudes of Ptolemy's stars. The first trigonometric table was apparently compiled by Hipparchus, who is consequently now known as "the father of trigonometry".

Hipparchus was in the international news in 2005, when it was again proposed (as in 1898) that the data on the celestial globe of Hipparchus or in his star catalog may have been preserved in the only surviving large ancient celestial globe which depicts the constellations with moderate accuracy, the globe carried by the Farnese Atlas. There are a variety of mis-steps in the more ambitious 2005 paper, thus no specialists in the area accept its widely publicized speculation.

Lucio Russo has said that Plutarch, in his work "On the Face in the Moon", was reporting some physical theories that we consider to be Newtonian and that these may have come originally from Hipparchus; he goes on to say that Newton may have been influenced by them. According to one book review, both of these claims have been rejected by other scholars.

A line in Plutarch's "Table Talk" states that Hipparchus counted 103049 compound propositions that can be formed from ten simple propositions. 103049 is the tenth Schröder–Hipparchus number, which counts the number of ways of adding one or more pairs of parentheses around consecutive subsequences of two or more items in any sequence of ten symbols. This has led to speculation that Hipparchus knew about enumerative combinatorics, a field of mathematics that developed independently in modern mathematics.

Earlier Greek astronomers and mathematicians were influenced by Babylonian astronomy to some extent, for instance the period relations of the Metonic cycle and Saros cycle may have come from Babylonian sources (see "Babylonian astronomical diaries"). Hipparchus seems to have been the first to exploit Babylonian astronomical knowledge and techniques systematically. Except for Timocharis and Aristillus, he was the first Greek known to divide the circle in 360 degrees of 60 arc minutes (Eratosthenes before him used a simpler sexagesimal system dividing a circle into 60 parts). He also used the Babylonian unit "pechus" ("cubit") of about 2° or 2.5°.

Hipparchus probably compiled a list of Babylonian astronomical observations; G. J. Toomer, a historian of astronomy, has suggested that Ptolemy's knowledge of eclipse records and other Babylonian observations in the "Almagest" came from a list made by Hipparchus. Hipparchus's use of Babylonian sources has always been known in a general way, because of Ptolemy's statements. However, Franz Xaver Kugler demonstrated that the synodic and anomalistic periods that Ptolemy attributes to Hipparchus had already been used in Babylonian ephemerides, specifically the collection of texts nowadays called "System B" (sometimes attributed to Kidinnu).

Hipparchus's long draconitic lunar period (5,458 months = 5,923 lunar nodal periods) also appears a few times in Babylonian records. But the only such tablet explicitly dated is post-Hipparchus so the direction of transmission is not settled by the tablets.

Hipparchus's draconitic lunar motion cannot be solved by the lunar-four arguments that are sometimes proposed to explain his anomalistic motion. A solution that has produced the exact ratio is rejected by most historians though it uses the only anciently attested method of determining such ratios, and it automatically delivers the ratio's four-digit numerator and denominator. Hipparchus initially used ("Almagest" 6.9) his 141 BC eclipse with a Babylonian eclipse of 720 BC to find the less accurate ratio 7,160 synodic months = 7,770 draconitic months, simplified by him to 716 = 777 through division by 10. (He similarly found from the 345-year cycle the ratio 4267 synodic months = 4573 anomalistic months and divided by 17 to obtain the standard ratio 251 synodic months = 269 anomalistic months.) If he sought a longer time base for this draconitic investigation he could use his same 141 BC eclipse with a moonrise 1245 BC eclipse from Babylon, an interval of 13,645 synodic months = draconitic months ≈ anomalistic months. Dividing by produces 5458 synodic months = 5923 precisely. The obvious main objection is that the early eclipse is unattested though that is not surprising in itself and there is no consensus on whether Babylonian observations were recorded this remotely. Though Hipparchus's tables formally went back only to 747 BC, 600 years before his era, the tables were actually good back to before the eclipse in question because as only recently noted their use in reverse is no more difficult than forwards.

Hipparchus was recognized as the first mathematician known to have possessed a trigonometric table, which he needed when computing the eccentricity of the orbits of the Moon and Sun. He tabulated values for the chord function, which gives the length of the chord for each angle. He did this for a circle with a circumference of 21,600 and a radius (rounded) of 3438 units: this circle has a unit length of 1 arc minute along its perimeter. He tabulated the chords for angles with increments of 7.5°. In modern terms, the chord of an angle equals the radius times twice the sine of half of the angle, i.e.:

formula_1

He described the chord table in a work, now lost, called "Tōn en kuklō eutheiōn" ("Of Lines Inside a Circle") by Theon of Alexandria in his 4th-century commentary on the "Almagest" I.10; some claim his table may have survived in astronomical treatises in India, for instance the "Surya Siddhanta". Trigonometry was a significant innovation, because it allowed Greek astronomers to solve any triangle, and made it possible to make quantitative astronomical models and predictions using their preferred geometric techniques.

For his chord table Hipparchus must have used a better approximation for π than the one from Archimedes of between and ; perhaps he had the one later used by Ptolemy: 3;8,30 (sexagesimal) ("Almagest" VI.7); but it is not known if he computed an improved value himself.

But some scholars do not believe Āryabhaṭa's sine table has anything to do with Hipparchus's chord table which does not exist today. Some scholars do not agree with this hypothesis that Hipparchus constructed a chord table. Bo C. Klintberg states "With mathematical reconstructions and philosophical arguments I show that Toomer's 1973 paper never contained any conclusive evidence for his claims that Hipparchus had a 3438′-based chord table, and that the Indians used that table to compute their sine tables. Recalculating Toomer's reconstructions with a 3600′ radius – i.e. the radius of the chord table in Ptolemy's Almagest, expressed in 'minutes' instead of 'degrees' – generates Hipparchan-like ratios similar to those produced by a 3438′ radius. It is therefore possible that the radius of Hipparchus's chord table was 3600′, and that the Indians independently constructed their 3438′-based sine table."

Hipparchus could construct his chord table using the Pythagorean theorem and a theorem known to Archimedes. He also might have developed and used the theorem in plane geometry called Ptolemy's theorem, because it was proved by Ptolemy in his "Almagest" (I.10) (later elaborated on by Carnot).

Hipparchus was the first to show that the stereographic projection is conformal, and that it transforms circles on the sphere that do not pass through the center of projection to circles on the plane. This was the basis for the astrolabe.

Besides geometry, Hipparchus also used arithmetic techniques developed by the Chaldeans. He was one of the first Greek mathematicians to do this, and in this way expanded the techniques available to astronomers and geographers.

There are several indications that Hipparchus knew spherical trigonometry, but the first surviving text of it is that of Menelaus of Alexandria in the 1st century, who on that basis is now commonly credited with its discovery. (Previous to the finding of the proofs of Menelaus a century ago, Ptolemy was credited with the invention of spherical trigonometry.) Ptolemy later used spherical trigonometry to compute things like the rising and setting points of the ecliptic, or to take account of the lunar parallax. Hipparchus may have used a globe for these tasks, reading values off coordinate grids drawn on it, or he may have made approximations from planar geometry, or perhaps used arithmetical approximations developed by the Chaldeans. He might have used spherical trigonometry.

Aubrey Diller has shown that the clima calculations which Strabo preserved from Hipparchus were performed by spherical trigonometry with the sole accurate obliquity known to have been used by ancient astronomers, 23°40'. All thirteen clima figures agree with Diller's proposal. Further confirming his contention is the finding that the big errors in Hipparchus's longitude of Regulus and both longitudes of Spica agree to a few minutes in all three instances with a theory that he took the wrong sign for his correction for parallax when using eclipses for determining stars' positions.

Hipparchus also studied the motion of the Moon and confirmed the accurate values for two periods of its motion that Chaldean astronomers are widely presumed to have possessed before him, whatever their ultimate origin. The traditional value (from Babylonian System B) for the mean synodic month is 29 days; 31,50,8,20 (sexagesimal) = 29.5305941... days. Expressed as 29 days + 12 hours +  hours this value has been used later in the Hebrew calendar. The Chaldeans also knew that 251 synodic months ≈ 269 anomalistic months. Hipparchus used the multiple of this period by a factor of 17, because that interval is also an eclipse period, and is also close to an integer number of years (4267 moons : 4573 anomalistic periods : 4630.53 nodal periods : 4611.98 lunar orbits : 344.996 years : 344.982 solar orbits : 126,007.003 days : 126,351.985 rotations). What was so exceptional and useful about the cycle was that all 345-year-interval eclipse pairs occur slightly over 126,007 days apart within a tight range of only about ± hour, guaranteeing (after division by 4267) an estimate of the synodic month correct to one part in order of magnitude 10 million. The 345 year periodicity is why the ancients could conceive of a "mean" month and quantify it so accurately that it is even today correct to a fraction of a second of time.

Hipparchus could confirm his computations by comparing eclipses from his own time (presumably 27 January 141  and 26 November 139  according to [Toomer 1980]), with eclipses from Babylonian records 345 years earlier ("Almagest" IV.2; [A.Jones, 2001]). Already al-Biruni ("Qanun" VII.2.II) and Copernicus ("de revolutionibus" IV.4) noted that the period of 4,267 moons is actually about 5 minutes longer than the value for the eclipse period that Ptolemy attributes to Hipparchus. However, the timing methods of the Babylonians had an error of no less than 8 minutes. Modern scholars agree that Hipparchus rounded the eclipse period to the nearest hour, and used it to confirm the validity of the traditional values, rather than try to derive an improved value from his own observations. From modern ephemerides and taking account of the change in the length of the day (see ΔT) we estimate that the error in the assumed length of the synodic month was less than 0.2 seconds in the 4th century  and less than 0.1 seconds in Hipparchus's time.

It had been known for a long time that the motion of the Moon is not uniform: its speed varies. This is called its "anomaly", and it repeats with its own period; the anomalistic month. The Chaldeans took account of this arithmetically, and used a table giving the daily motion of the Moon according to the date within a long period. The Greeks however preferred to think in geometrical models of the sky. Apollonius of Perga had at the end of the 3rd century  proposed two models for lunar and planetary motion:

Hipparchus devised a geometrical method to find the parameters from three positions of the Moon, at particular phases of its anomaly. In fact, he did this separately for the eccentric and the epicycle model. Ptolemy describes the details in the "Almagest" IV.11. Hipparchus used two sets of three lunar eclipse observations, which he carefully selected to satisfy the requirements. The eccentric model he fitted to these eclipses from his Babylonian eclipse list: 22/23 December 383 , 18/19 June 382 , and 12/13 December 382 . The epicycle model he fitted to lunar eclipse observations made in Alexandria at 22 September 201 , 19 March 200 , and 11 September 200 .
The somewhat weird numbers are due to the cumbersome unit he used in his chord table according to one group of historians, who explain their reconstruction's inability to agree with these four numbers as partly due to some sloppy rounding and calculation errors by Hipparchus, for which Ptolemy criticised him (he himself made rounding errors too). A simpler alternate reconstruction agrees with all four numbers. Anyway, Hipparchus found inconsistent results; he later used the ratio of the epicycle model ( : ), which is too small (60 : 4;45 sexagesimal). Ptolemy established a ratio of 60 : . (The maximum angular deviation producible by this geometry is the arcsin of divided by 60, or about 5° 1', a figure that is sometimes therefore quoted as the equivalent of the Moon's equation of the center in the Hipparchan model.)

Before Hipparchus, Meton, Euctemon, and their pupils at Athens had made a solstice observation (i.e., timed the moment of the summer solstice) on 27 June 432  (proleptic Julian calendar). Aristarchus of Samos is said to have done so in 280 , and Hipparchus also had an observation by Archimedes. As shown in a 1991
paper, in 158 BC Hipparchus computed a very erroneous summer solstice from Callippus's calendar. He observed the summer solstice in 146 and 135  both accurate to a few hours, but observations of the moment of equinox were simpler, and he made twenty during his lifetime. Ptolemy gives an extensive discussion of Hipparchus's work on the length of the year in the "Almagest" III.1, and quotes many observations that Hipparchus made or used, spanning 162–128 . Analysis of Hipparchus's seventeen equinox observations made at Rhodes shows that the mean error in declination is positive seven arc minutes, nearly agreeing with the sum of refraction by air and Swerdlow's parallax. The random noise is two arc minutes or more nearly one arcminute if rounding is taken into account which approximately agrees with the sharpness of the eye. Ptolemy quotes an equinox timing by Hipparchus (at 24 March 146  at dawn) that differs by 5 hours from the observation made on Alexandria's large public equatorial ring that same day (at 1 hour before noon): Hipparchus may have visited Alexandria but he did not make his equinox observations there; presumably he was on Rhodes (at nearly the same geographical longitude). He could have used the equatorial ring of his armillary sphere or another equatorial ring for these observations, but Hipparchus (and Ptolemy) knew that observations with these instruments are sensitive to a precise alignment with the equator, so if he were restricted to an armillary, it would make more sense to use its meridian ring as a transit instrument. The problem with an equatorial ring (if an observer is naive enough to trust it very near dawn or dusk) is that atmospheric refraction lifts the Sun significantly above the horizon: so for a northern hemisphere observer its apparent declination is too high, which changes the observed time when the Sun crosses the equator. (Worse, the refraction decreases as the Sun rises and increases as it sets, so it may appear to move in the wrong direction with respect to the equator in the course of the day – as Ptolemy mentions. Ptolemy and Hipparchus apparently did not realize that refraction is the cause.) However, such details have doubtful relation to the data of either man, since there is no textual, scientific, or statistical ground for believing that their equinoxes were taken on an equatorial ring, which is useless for solstices in any case. Not one of two centuries of mathematical investigations of their solar errors has claimed to have traced them to the effect of refraction on use of an equatorial ring. Ptolemy claims his solar observations were on a transit instrument set in the meridian.

Recent expert translation and analysis by Anne Tihon of papyrus P. Fouad 267 A has confirmed the 1991 finding cited above that Hipparchus obtained a summer solstice in 158 BC But the papyrus makes the date 26 June, over a day earlier than the 1991 paper's conclusion for 28 June. The earlier study's §M found that Hipparchus did not adopt 26 June solstices until 146 BC when he founded the orbit of the Sun which Ptolemy later adopted. Dovetailing these data suggests Hipparchus extrapolated the 158 BC 26 June solstice from his 145 solstice 12 years later a procedure that would cause only minuscule error. The papyrus also confirmed that Hipparchus had used Callippic solar motion in 158 BC, a new finding in 1991 but not attested directly until P. Fouad 267 A. Another table on the papyrus is perhaps for sidereal motion and a third table is for Metonic tropical motion, using a previously unknown year of – days. This was presumably found by dividing the 274 years from 432 to 158 BC, into the corresponding interval of 100077 days and hours between Meton's sunrise and Hipparchus's sunset solstices.

At the end of his career, Hipparchus wrote a book called "Peri eniausíou megéthous" ("On the Length of the Year") about his results. The established value for the tropical year, introduced by Callippus in or before 330  was days. Speculating a Babylonian origin for the Callippic year is hard to defend, since Babylon did not observe solstices thus the only extant System B year length was based on Greek solstices (see below). Hipparchus's equinox observations gave varying results, but he himself points out (quoted in "Almagest" III.1(H195)) that the observation errors by himself and his predecessors may have been as large as day. He used old solstice observations, and determined a difference of about one day in about 300 years. So he set the length of the tropical year to − days (= 365.24666... days = 365 days 5 hours 55 min, which differs from the actual value (modern estimate, including earth spin acceleration) in his time of about 365.2425 days, an error of about 6 min per year, an hour per decade, 10 hours per century.

Between the solstice observation of Meton and his own, there were 297 years spanning 108,478 days. D. Rawlins noted that this implies a tropical year of 365.24579... days = 365 days;14,44,51 (sexagesimal; = 365 days + + + ) and that this exact year length has been found on one of the few Babylonian clay tablets which explicitly specifies the System B month. This is an indication that Hipparchus's work was known to Chaldeans.

Another value for the year that is attributed to Hipparchus (by the astrologer Vettius Valens in the 1st century) is 365 + + days (= 365.25347... days = 365 days 6 hours 5 min), but this may be a corruption of another value attributed to a Babylonian source: 365 + + days (= 365.25694... days = 365 days 6 hours 10 min). It is not clear if this would be a value for the sidereal year (actual value at his time (modern estimate) about 365.2565 days), but the difference with Hipparchus's value for the tropical year is consistent with his rate of precession (see below).

Before Hipparchus, astronomers knew that the lengths of the seasons are not equal. Hipparchus made observations of equinox and solstice, and according to Ptolemy ("Almagest" III.4) determined that spring (from spring equinox to summer solstice) lasted 94½ days, and summer (from summer solstice to autumn equinox) days. This is inconsistent with a premise of the Sun moving around the Earth in a circle at uniform speed. Hipparchus's solution was to place the Earth not at the center of the Sun's motion, but at some distance from the center. This model described the apparent motion of the Sun fairly well. It is known today that the planets, including the Earth, move in approximate ellipses around the Sun, but this was not discovered until Johannes Kepler published his first two laws of planetary motion in 1609. The value for the eccentricity attributed to Hipparchus by Ptolemy is that the offset is of the radius of the orbit (which is a little too large), and the direction of the apogee would be at longitude 65.5° from the vernal equinox. Hipparchus may also have used other sets of observations, which would lead to different values. One of his two eclipse trios' solar longitudes are consistent with his having initially adopted inaccurate lengths for spring and summer of and days. His other triplet of solar positions is consistent with and days, an improvement on the results ( and days) attributed to Hipparchus by Ptolemy, which a few scholars still question the authorship of. Ptolemy made no change three centuries later, and expressed lengths for the autumn and winter seasons which were already implicit (as shown, e.g., by A. Aaboe).

Hipparchus also undertook to find the distances and sizes of the Sun and the Moon. He published his results in a work of two books called "Perí megethōn kaí apostēmátōn" ("On Sizes and Distances") by Pappus in his commentary on the "Almagest" V.11; Theon of Smyrna (2nd century) mentions the work with the addition "of the Sun and Moon".

Hipparchus measured the apparent diameters of the Sun and Moon with his "diopter". Like others before and after him, he found that the Moon's size varies as it moves on its (eccentric) orbit, but he found no perceptible variation in the apparent diameter of the Sun. He found that at the "mean" distance of the Moon, the Sun and Moon had the same apparent diameter; at that distance, the Moon's diameter fits 650 times into the circle, i.e., the mean apparent diameters are = 0°33′14″.

Like others before and after him, he also noticed that the Moon has a noticeable parallax, i.e., that it appears displaced from its calculated position (compared to the Sun or stars), and the difference is greater when closer to the horizon. He knew that this is because in the then-current models the Moon circles the center of the Earth, but the observer is at the surface—the Moon, Earth and observer form a triangle with a sharp angle that changes all the time. From the size of this parallax, the distance of the Moon as measured in Earth radii can be determined. For the Sun however, there was no observable parallax (we now know that it is about 8.8", several times smaller than the resolution of the unaided eye).

In the first book, Hipparchus assumes that the parallax of the Sun is 0, as if it is at infinite distance. He then analyzed a solar eclipse, which Toomer (against the opinion of over a century of astronomers) presumes to be the eclipse of 14 March 190 . It was total in the region of the Hellespont (and in his birthplace, Nicaea); at the time Toomer proposes the Romans were preparing for war with Antiochus III in the area, and the eclipse is mentioned by Livy in his "Ab Urbe Condita Libri" VIII.2. It was also observed in Alexandria, where the Sun was reported to be obscured 4/5ths by the Moon. Alexandria and Nicaea are on the same meridian. Alexandria is at about 31° North, and the region of the Hellespont about 40° North. (It has been contended that authors like Strabo and Ptolemy had fairly decent values for these geographical positions, so Hipparchus must have known them too. However, Strabo's Hipparchus dependent latitudes for this region are at least 1° too high, and Ptolemy appears to copy them, placing Byzantium 2° high in latitude.) Hipparchus could draw a triangle formed by the two places and the Moon, and from simple geometry was able to establish a distance of the Moon, expressed in Earth radii. Because the eclipse occurred in the morning, the Moon was not in the meridian, and it has been proposed that as a consequence the distance found by Hipparchus was a lower limit. In any case, according to Pappus, Hipparchus found that the least distance is 71 (from this eclipse), and the greatest 81 Earth radii.

In the second book, Hipparchus starts from the opposite extreme assumption: he assigns a (minimum) distance to the Sun of 490 Earth radii. This would correspond to a parallax of 7′, which is apparently the greatest parallax that Hipparchus thought would not be noticed (for comparison: the typical resolution of the human eye is about 2′; Tycho Brahe made naked eye observation with an accuracy down to 1′). In this case, the shadow of the Earth is a cone rather than a cylinder as under the first assumption. Hipparchus observed (at lunar eclipses) that at the mean distance of the Moon, the diameter of the shadow cone is lunar diameters. That apparent diameter is, as he had observed, degrees. With these values and simple geometry, Hipparchus could determine the mean distance; because it was computed for a minimum distance of the Sun, it is the maximum mean distance possible for the Moon. With his value for the eccentricity of the orbit, he could compute the least and greatest distances of the Moon too. According to Pappus, he found a least distance of 62, a mean of , and consequently a greatest distance of Earth radii. With this method, as the parallax of the Sun decreases (i.e., its distance increases), the minimum limit for the mean distance is 59 Earth radii – exactly the mean distance that Ptolemy later derived.

Hipparchus thus had the problematic result that his minimum distance (from book 1) was greater than his maximum mean distance (from book 2). He was intellectually honest about this discrepancy, and probably realized that especially the first method is very sensitive to the accuracy of the observations and parameters. (In fact, modern calculations show that the size of the 189  solar eclipse at Alexandria must have been closer to ths and not the reported ths, a fraction more closely matched by the degree of totality at Alexandria of eclipses occurring in 310 and 129  which were also nearly total in the Hellespont and are thought by many to be more likely possibilities for the eclipse Hipparchus used for his computations.)

Ptolemy later measured the lunar parallax directly ("Almagest" V.13), and used the second method of Hipparchus with lunar eclipses to compute the distance of the Sun ("Almagest" V.15). He criticizes Hipparchus for making contradictory assumptions, and obtaining conflicting results ("Almagest" V.11): but apparently he failed to understand Hipparchus's strategy to establish limits consistent with the observations, rather than a single value for the distance. His results were the best so far: the actual mean distance of the Moon is 60.3 Earth radii, within his limits from Hipparchus's second book.

Theon of Smyrna wrote that according to Hipparchus, the Sun is 1,880 times the size of the Earth, and the Earth twenty-seven times the size of the Moon; apparently this refers to volumes, not diameters. From the geometry of book 2 it follows that the Sun is at 2,550 Earth radii, and the mean distance of the Moon is radii. Similarly, Cleomedes quotes Hipparchus for the sizes of the Sun and Earth as 1050:1; this leads to a mean lunar distance of 61 radii. Apparently Hipparchus later refined his computations, and derived accurate single values that he could use for predictions of solar eclipses.

See [Toomer 1974] for a more detailed discussion.

Pliny ("Naturalis Historia" II.X) tells us that Hipparchus demonstrated that lunar eclipses can occur five months apart, and solar eclipses seven months (instead of the usual six months); and the Sun can be hidden twice in thirty days, but as seen by different nations. Ptolemy discussed this a century later at length in "Almagest" VI.6. The geometry, and the limits of the positions of Sun and Moon when a solar or lunar eclipse is possible, are explained in "Almagest" VI.5. Hipparchus apparently made similar calculations. The result that two solar eclipses can occur one month apart is important, because this can not be based on observations: one is visible on the northern and the other on the southern hemisphere – as Pliny indicates – and the latter was inaccessible to the Greek.

Prediction of a solar eclipse, i.e., exactly when and where it will be visible, requires a solid lunar theory and proper treatment of the lunar parallax. Hipparchus must have been the first to be able to do this. A rigorous treatment requires spherical trigonometry, thus those who remain certain that Hipparchus lacked it must speculate that he may have made do with planar approximations. He may have discussed these things in "Perí tēs katá plátos mēniaías tēs selēnēs kinēseōs" ("On the monthly motion of the Moon in latitude"), a work mentioned in the "Suda".

Pliny also remarks that "he also discovered for what exact reason, although the shadow causing the eclipse must from sunrise onward be below the earth, it happened once in the past that the Moon was eclipsed in the west while both luminaries were visible above the earth" (translation H. Rackham (1938), Loeb Classical Library 330 p. 207). Toomer (1980) argued that this must refer to the large total lunar eclipse of 26 November 139 , when over a clean sea horizon as seen from Rhodes, the Moon was eclipsed in the northwest just after the Sun rose in the southeast. This would be the second eclipse of the 345-year interval that Hipparchus used to verify the traditional Babylonian periods: this puts a late date to the development of Hipparchus's lunar theory. We do not know what "exact reason" Hipparchus found for seeing the Moon eclipsed while apparently it was not in exact opposition to the Sun. Parallax lowers the altitude of the luminaries; refraction raises them, and from a high point of view the horizon is lowered.

Hipparchus and his predecessors used various instruments for astronomical calculations and observations, such as the gnomon, the astrolabe, and the armillary sphere.

Hipparchus is credited with the invention or improvement of several astronomical instruments, which were used for a long time for naked-eye observations. According to Synesius of Ptolemais (4th century) he made the first "astrolabion": this may have been an armillary sphere (which Ptolemy however says he constructed, in "Almagest" V.1); or the predecessor of the planar instrument called astrolabe (also mentioned by Theon of Alexandria). With an astrolabe Hipparchus was the first to be able to measure the geographical latitude and time by observing fixed stars. Previously this was done at daytime by measuring the shadow cast by a gnomon, by recording the length of the longest day of the year or with the portable instrument known as a "scaphe".

Ptolemy mentions ("Almagest" V.14) that he used a similar instrument as Hipparchus, called "dioptra", to measure the apparent diameter of the Sun and Moon. Pappus of Alexandria described it (in his commentary on the "Almagest" of that chapter), as did Proclus ("Hypotyposis" IV). It was a 4-foot rod with a scale, a sighting hole at one end, and a wedge that could be moved along the rod to exactly obscure the disk of Sun or Moon.

Hipparchus also observed solar equinoxes, which may be done with an equatorial ring: its shadow falls on itself when the Sun is on the equator (i.e., in one of the equinoctial points on the ecliptic), but the shadow falls above or below the opposite side of the ring when the Sun is south or north of the equator. Ptolemy quotes (in "Almagest" III.1 (H195)) a description by Hipparchus of an equatorial ring in Alexandria; a little further he describes two such instruments present in Alexandria in his own time.

Hipparchus applied his knowledge of spherical angles to the problem of denoting locations on the Earth's surface. Before him a grid system had been used by Dicaearchus of Messana, but Hipparchus was the first to apply mathematical rigor to the determination of the latitude and longitude of places on the Earth. Hipparchus wrote a critique in three books on the work of the geographer Eratosthenes of Cyrene (3rd century ), called "Pròs tèn 'Eratosthénous geografían" ("Against the Geography of Eratosthenes"). It is known to us from Strabo of Amaseia, who in his turn criticised Hipparchus in his own "Geografia". Hipparchus apparently made many detailed corrections to the locations and distances mentioned by Eratosthenes. It seems he did not introduce many improvements in methods, but he did propose a means to determine the geographical longitudes of different cities at lunar eclipses (Strabo "Geografia" 1 January 2012). A lunar eclipse is visible simultaneously on half of the Earth, and the difference in longitude between places can be computed from the difference in local time when the eclipse is observed. His approach would give accurate results if it were correctly carried out but the limitations of timekeeping accuracy in his era made this method impractical.

Late in his career (possibly about 135 ) Hipparchus compiled his star catalog, the original of which does not survive. He also constructed a celestial globe depicting the constellations, based on his observations. His interest in the fixed stars may have been inspired by the observation of a supernova (according to Pliny), or by his discovery of precession, according to Ptolemy, who says that Hipparchus could not reconcile his data with earlier observations made by Timocharis and Aristillus. For more information see Discovery of precession. In Raphael's painting "The School of Athens", Hipparchus is depicted holding his celestial globe, as the representative figure for astronomy.

Previously, Eudoxus of Cnidus in the 4th century  had described the stars and constellations in two books called "Phaenomena" and "Entropon". Aratus wrote a poem called "Phaenomena" or "Arateia" based on Eudoxus's work. Hipparchus wrote a commentary on the "Arateia" – his only preserved work – which contains many stellar positions and times for rising, culmination, and setting of the constellations, and these are likely to have been based on his own measurements.

Hipparchus made his measurements with an armillary sphere, and obtained the positions of at least 850 stars. It is disputed which coordinate system(s) he used. Ptolemy's catalog in the "Almagest", which is derived from Hipparchus's catalog, is given in ecliptic coordinates. However Delambre in his "Histoire de l'Astronomie Ancienne" (1817) concluded that Hipparchus knew and used the equatorial coordinate system, a conclusion challenged by Otto Neugebauer in his "A History of Ancient Mathematical Astronomy" (1975). Hipparchus seems to have used a mix of ecliptic coordinates and equatorial coordinates: in his commentary on Eudoxos he provides stars' polar distance (equivalent to the declination in the equatorial system), right ascension (equatorial), longitude (ecliptical), polar longitude (hybrid), but not celestial latitude.

As with most of his work, Hipparchus's star catalog was adopted and perhaps expanded by Ptolemy. Delambre, in 1817, cast doubt on Ptolemy's work. It was disputed whether the star catalog in the "Almagest" is due to Hipparchus, but 1976–2002 statistical and spatial analyses (by R. R. Newton, Dennis Rawlins, Gerd Grasshoff, Keith Pickering and Dennis Duke) have shown conclusively that the "Almagest" star catalog is almost entirely Hipparchan. Ptolemy has even (since Brahe, 1598) been accused by astronomers of fraud for stating ("Syntaxis", book 7, chapter 4) that he observed all 1025 stars: for almost every star he used Hipparchus's data and precessed it to his own epoch centuries later by adding 2°40′ to the longitude, using an erroneously small precession constant of 1° per century.

In any case the work started by Hipparchus has had a lasting heritage, and was much later updated by Al Sufi (964) and Copernicus (1543). Ulugh Beg reobserved all the Hipparchus stars he could see from Samarkand in 1437 to about the same accuracy as Hipparchus's. The catalog was superseded only in the late 16th century by Brahe and Wilhelm IV of Kassel via superior ruled instruments and spherical trigonometry, which improved accuracy by an order of magnitude even before the invention of the telescope. Hipparchus is considered the greatest observational astronomer from classical antiquity until Brahe.

Hipparchus is only conjectured to have ranked the apparent magnitudes of stars on a numerical scale from 1, the brightest, to 6, the faintest. Nevertheless, this system certainly precedes Ptolemy, who used it extensively about 150. This system was made more precise and extended by N. R. Pogson in 1856, who placed the magnitudes on a logarithmic scale, making magnitude 1 stars 100 times brighter than magnitude 6 stars, thus each magnitude is or 2.512 times brighter than the next faintest magnitude.

Hipparchus is generally recognized as discoverer of the precession of the equinoxes in 127 . His two books on precession, "On the Displacement of the Solsticial and Equinoctial Points" and "On the Length of the Year", are both mentioned in the "Almagest" of Claudius Ptolemy. According to Ptolemy, Hipparchus measured the longitude of Spica and Regulus and other bright stars. Comparing his measurements with data from his predecessors, Timocharis and Aristillus, he concluded that Spica had moved 2° relative to the autumnal equinox. He also compared the lengths of the tropical year (the time it takes the Sun to return to an equinox) and the sidereal year (the time it takes the Sun to return to a fixed star), and found a slight discrepancy. Hipparchus concluded that the equinoxes were moving ("precessing") through the zodiac, and that the rate of precession was not less than 1° in a century.

Hipparchus's treatise "Against the Geography of Eratosthenes" in three books is not preserved. 
Most of our knowledge of it comes from Strabo, according to whom Hipparchus thoroughly and often unfairly criticized Eratosthenes, mainly for internal contradictions and inaccuracy in determining positions of geographical localities. Hipparchus insists that a geographic map must be based only on astronomical measurements of latitudes and longitudes and triangulation for finding unknown distances. 
In geographic theory and methods Hipparchus introduced three main innovations.
He was the first to use the grade grid, to determine geographic latitude from star observations, and not only from the Sun's altitude, a method known long before him, and to suggest that geographic longitude could be determined by means of simultaneous observations of lunar eclipses in distant places. In the practical part of his work, the so-called "table of climata", Hipparchus listed latitudes for several tens of localities. In particular, he improved Eratosthenes' values for the latitudes of Athens, Sicily, and southern extremity of India. 
In calculating latitudes of climata (latitudes correlated with the length of the longest solstitial day), Hipparchus used an unexpectedly accurate value for the obliquity of the ecliptic, 23°40′ (the actual value in the second half of the 2nd century  was approximately 23°43′), whereas all other ancient authors knew only a roughly rounded value 24°, and even Ptolemy used a less accurate value, 23°51′. 
Hipparchus opposed the view generally accepted in the Hellenistic period that the Atlantic and Indian Oceans and the Caspian Sea are parts of a single ocean. At the same time he extends the limits of the oikoumene, i.e. the inhabited part of the land, up to the equator and the Arctic Circle. 
Hipparchus’ ideas found their reflection in the "Geography" of Ptolemy. In essence, Ptolemy's work is an extended attempt to realize Hipparchus’ vision of what geography ought to be.

The rather cumbersome formal name for the ESA's Hipparcos Space Astrometry Mission was High Precision Parallax Collecting Satellite; it was deliberately named in this way to give an acronym, HiPParCoS, that echoed and commemorated the name of Hipparchus. The lunar crater Hipparchus and the asteroid 4000 Hipparchus are more directly named after him.

He was inducted into the International Space Hall of Fame in 2004.

The Astronomer's Monument at the Griffith Observatory in Los Angeles, California, United States features a relief of Hipparchus as one of six of the greatest astronomers of all time and the only one from Antiquity.


Citations


General

Precession

Celestial bodies

Star catalog


</doc>
<doc id="13601" url="https://en.wikipedia.org/wiki?curid=13601" title="Hebrew (disambiguation)">
Hebrew (disambiguation)

The Hebrew language is a language native to Israel.

Hebrew may also refer to:






</doc>
<doc id="13602" url="https://en.wikipedia.org/wiki?curid=13602" title="Huldrych Zwingli">
Huldrych Zwingli

Huldrych Zwingli or Ulrich Zwingli (1 January 1484 – 11 October 1531) was a leader of the Reformation in Switzerland. Born during a time of emerging Swiss patriotism and increasing criticism of the Swiss mercenary system, he attended the University of Vienna and the University of Basel, a scholarly center of Renaissance humanism. He continued his studies while he served as a pastor in Glarus and later in Einsiedeln, where he was influenced by the writings of Erasmus.

In 1519, Zwingli became the pastor of the Grossmünster in Zürich where he began to preach ideas on reform of the Catholic Church. In his first public controversy in 1522, he attacked the custom of fasting during Lent. In his publications, he noted corruption in the ecclesiastical hierarchy, promoted clerical marriage, and attacked the use of images in places of worship. In 1525, Zwingli introduced a new communion liturgy to replace the Mass. Zwingli also clashed with the Anabaptists, which resulted in their persecution. Historians have debated whether or not he turned Zürich into a theocracy.

The Reformation spread to other parts of the Swiss Confederation, but several cantons resisted, preferring to remain Catholic. Zwingli formed an alliance of Reformed cantons which divided the Confederation along religious lines. In 1529, a war between the two sides was averted at the last moment. Meanwhile, Zwingli's ideas came to the attention of Martin Luther and other reformers. They met at the Marburg Colloquy and although they agreed on many points of doctrine, they could not reach an accord on the doctrine of the Real Presence of Christ in the Eucharist.

In 1531 Zwingli's alliance applied an unsuccessful food blockade on the Catholic cantons. The cantons responded with an attack at a moment when Zürich was ill-prepared. Zwingli died on the battlefield. His legacy lives on in the confessions, liturgy, and church orders of the Reformed churches of today.

The Swiss Confederation in Huldrych Zwingli's time consisted of thirteen states (cantons) as well as affiliated areas and common lordships. Unlike the modern state of Switzerland, which operates under a federal government, each of the thirteen cantons was nearly independent, conducting its own domestic and foreign affairs. Each canton formed its own alliances within and without the Confederation. This relative independence served as the basis for conflict during the time of the Reformation when the various cantons divided between different confessional camps. Military ambitions gained an additional impetus with the competition to acquire new territory and resources, as seen for example in the Old Zürich War of 1440–1446.

The wider political environment in Europe during the 15th and 16th centuries was also volatile. For centuries the relationship with the Confederation's powerful neighbour, France, determined the foreign policies of the Swiss. Nominally, the Confederation formed a part of the Holy Roman Empire. However, through a succession of wars culminating in the Swabian War in 1499, the Confederation had become "de facto" independent. As the two continental powers and minor regional states such as the Duchy of Milan, the Duchy of Savoy, and the Papal States competed and fought against each other, there were far-reaching political, economic, and social consequences for the Confederation. During this time the mercenary pension system became a subject of disagreement. The religious factions of Zwingli's time debated vociferously the merits of sending young Swiss men to fight in foreign wars mainly for the enrichment of the cantonal authorities.

These internal and external factors contributed to the rise of a Confederation national consciousness, in which the term "fatherland" () began to take on meaning beyond a reference to an individual canton. At the same time, Renaissance humanism, with its universal values and emphasis on scholarship (as exemplified by Erasmus (1466–1536), the "prince of humanism"), had taken root in the Confederation. Within this environment, defined by the confluence of Swiss patriotism and humanism, Zwingli was born in 1484.

Huldrych Zwingli was born on 1 January 1484 in Wildhaus, in the Toggenburg valley of Switzerland, to a family of farmers, the third child of nine. His father, Ulrich, played a leading role in the administration of the community ("Amtmann" or chief local magistrate). Zwingli's primary schooling was provided by his uncle, Bartholomew, a cleric in Weesen, where he probably met Katharina von Zimmern. At ten years old, Zwingli was sent to Basel to obtain his secondary education where he learned Latin under Magistrate Gregory Bünzli. After three years in Basel, he stayed a short time in Bern with the humanist, Henry Wölfflin. The Dominicans in Bern tried to persuade Zwingli to join their order and it is possible that he was received as a novice. However, his father and uncle disapproved of such a course and he left Bern without completing his Latin studies. He enrolled in the University of Vienna in the winter semester of 1498 but was expelled, according to the university's records. However, it is not certain that Zwingli was indeed expelled, and he re-enrolled in the summer semester of 1500; his activities in 1499 are unknown. Zwingli continued his studies in Vienna until 1502, after which he transferred to the University of Basel where he received the Master of Arts degree ("Magister") in 1506.

Zwingli was ordained in Constance, the seat of the local diocese, and he celebrated his first Mass in his hometown, Wildhaus, on 29 September 1506. As a young priest he had studied little theology, but this was not considered unusual at the time. His first ecclesiastical post was the pastorate of the town of Glarus, where he stayed for ten years. It was in Glarus, whose soldiers were used as mercenaries in Europe, that Zwingli became involved in politics. The Swiss Confederation was embroiled in various campaigns with its neighbours: the French, the Habsburgs, and the Papal States. Zwingli placed himself solidly on the side of the Roman See. In return, Pope Julius II honoured Zwingli by providing him with an annual pension. He took the role of chaplain in several campaigns in Italy, including the Battle of Novara in 1513. However, the decisive defeat of the Swiss in the Battle of Marignano caused a shift in mood in Glarus in favour of the French rather than the pope. Zwingli, the papal partisan, found himself in a difficult position and he decided to retreat to Einsiedeln in the canton of Schwyz. By this time, he had become convinced that mercenary service was immoral and that Swiss unity was indispensable for any future achievements. Some of his earliest extant writings, such as "The Ox" (1510) and "The Labyrinth" (1516), attacked the mercenary system using allegory and satire. His countrymen were presented as virtuous people within a French, imperial, and papal triangle. Zwingli stayed in Einsiedeln for two years during which he withdrew completely from politics in favour of ecclesiastical activities and personal studies.

Zwingli's time as the pastor of Glarus and Einsiedeln was characterized by inner growth and development. He perfected his Greek and he took up the study of Hebrew. His library contained over three hundred volumes from which he was able to draw upon classical, patristic, and scholastic works. He exchanged scholarly letters with a circle of Swiss humanists and began to study the writings of Erasmus. Zwingli took the opportunity to meet him while Erasmus was in Basel between August 1514 and May 1516. Zwingli's turn to relative pacifism and his focus on preaching can be traced to the influence of Erasmus.

In late 1518, the post of the "Leutpriestertum" (people's priest) of the Grossmünster at Zürich became vacant. The canons of the foundation that administered the Grossmünster recognised Zwingli's reputation as a fine preacher and writer. His connection with humanists was a decisive factor as several canons were sympathetic to Erasmian reform. In addition, his opposition to the French and to mercenary service was welcomed by Zürich politicians. On 11 December 1518, the canons elected Zwingli to become the stipendiary priest and on 27 December he moved permanently to Zürich.

On 1 January 1519, Zwingli gave his first sermon in Zürich. Deviating from the prevalent practice of basing a sermon on the Gospel lesson of a particular Sunday, Zwingli, using Erasmus' New Testament as a guide, began to read through the Gospel of Matthew, giving his interpretation during the sermon, known as the method of "lectio continua". He continued to read and interpret the book on subsequent Sundays until he reached the end and then proceeded in the same manner with the Acts of the Apostles, the New Testament epistles, and finally the Old Testament. His motives for doing this are not clear, but in his sermons he used exhortation to achieve moral and ecclesiastical improvement which were goals comparable with Erasmian reform. Sometime after 1520, Zwingli's theological model began to evolve into an idiosyncratic form that was neither Erasmian nor Lutheran. Scholars do not agree on the process of how he developed his own unique model. One view is that Zwingli was trained as an Erasmian humanist and Luther played a decisive role in changing his theology. Another view is that Zwingli did not pay much attention to Luther's theology and in fact he considered it as part of the humanist reform movement. A third view is that Zwingli was not a complete follower of Erasmus, but had diverged from him as early as 1516 and that he independently developed his theology.

Zwingli's theological stance was gradually revealed through his sermons. He attacked moral corruption and in the process he named individuals who were the targets of his denunciations. Monks were accused of indolence and high living. In 1519, Zwingli specifically rejected the veneration of saints and called for the need to distinguish between their true and fictional accounts. He cast doubts on hellfire, asserted that unbaptised children were not damned, and questioned the power of excommunication. His attack on the claim that tithing was a divine institution, however, had the greatest theological and social impact. This contradicted the immediate economic interests of the foundation. One of the elderly canons who had supported Zwingli's election, Konrad Hofmann, complained about his sermons in a letter. Some canons supported Hofmann, but the opposition never grew very large. Zwingli insisted that he was not an innovator and that the sole basis of his teachings was Scripture.

Within the diocese of Constance, Bernhardin Sanson was offering a special indulgence for contributors to the building of St Peter's in Rome. When Sanson arrived at the gates of Zürich at the end of January 1519, parishioners prompted Zwingli with questions. He responded with displeasure that the people were not being properly informed about the conditions of the indulgence and were being induced to part with their money on false pretences. This was over a year after Martin Luther published his Ninety-five theses (31 October 1517). The council of Zürich refused Sanson entry into the city. As the authorities in Rome were anxious to contain the fire started by Luther, the Bishop of Constance denied any support of Sanson and he was recalled.

In August 1519, Zürich was struck by an outbreak of the plague during which at least one in four persons died. All of those who could afford it left the city, but Zwingli remained and continued his pastoral duties. In September, he caught the disease and nearly died. He described his preparation for death in a poem, Zwingli's "Pestlied", consisting of three parts: the onset of the illness, the closeness to death, and the joy of recovery. The final verses of the first part read:

In the years following his recovery, Zwingli's opponents remained in the minority. When a vacancy occurred among the canons of the Grossmünster, Zwingli was elected to fulfill that vacancy on 29 April 1521. In becoming a canon, he became a full citizen of Zürich. He also retained his post as the people's priest of the Grossmünster.

The first public controversy regarding Zwingli's preaching broke out during the season of Lent in 1522. On the first fasting Sunday, 9 March, Zwingli and about a dozen other participants consciously transgressed the fasting rule by cutting and distributing two smoked sausages (the "Wurstessen" in Christoph Froschauer's workshop). Zwingli defended this act in a sermon which was published on 16 April, under the title "Von Erkiesen und Freiheit der Speisen" (Regarding the Choice and Freedom of Foods). He noted that no general valid rule on food can be derived from the Bible and that to transgress such a rule is not a sin. The event, which came to be referred to as the Affair of the Sausages, is considered to be the start of the Reformation in Switzerland. Even before the publication of this treatise, the diocese of Constance reacted by sending a delegation to Zürich. The city council condemned the fasting violation, but assumed responsibility over ecclesiastical matters and requested the religious authorities clarify the issue. The bishop responded on 24 May by admonishing the Grossmünster and city council and repeating the traditional position.

Following this event, Zwingli and other humanist friends petitioned the bishop on 2 July to abolish the requirement of celibacy on the clergy. Two weeks later the petition was reprinted for the public in German as "Eine freundliche Bitte und Ermahnung an die Eidgenossen" (A Friendly Petition and Admonition to the Confederates). The issue was not just an abstract problem for Zwingli, as he had secretly married a widow, Anna Reinhard, earlier in the year. Their cohabitation was well-known and their public wedding took place on 2 April 1524, three months before the birth of their first child. They would eventually have four children: Regula, William, Huldrych, and Anna. As the petition was addressed to the secular authorities, the bishop responded at the same level by notifying the Zürich government to maintain the ecclesiastical order. Other Swiss clergymen joined in Zwingli's cause which encouraged him to make his first major statement of faith, "Apologeticus Archeteles" (The First and Last Word). He defended himself against charges of inciting unrest and heresy. He denied the ecclesiastical hierarchy any right to judge on matters of church order because of its corrupted state.

The events of 1522 brought no clarification on the issues. Not only did the unrest between Zürich and the bishop continue, tensions were growing among Zürich's Confederation partners in the Swiss Diet. On 22 December, the Diet recommended that its members prohibit the new teachings, a strong indictment directed at Zürich. The city council felt obliged to take the initiative and find its own solution.

On 3 January 1523, the Zürich city council invited the clergy of the city and outlying region to a meeting to allow the factions to present their opinions. The bishop was invited to attend or to send a representative. The council would render a decision on who would be allowed to continue to proclaim their views. This meeting, the first Zürich disputation, took place on 29 January 1523.

The meeting attracted a large crowd of approximately six hundred participants. The bishop sent a delegation led by his vicar general, Johannes Fabri. Zwingli summarised his position in the "Schlussreden" (Concluding Statements or the Sixty-seven Articles). Fabri, who had not envisaged an academic disputation in the manner Zwingli had prepared for, was forbidden to discuss high theology before laymen, and simply insisted on the necessity of the ecclesiastical authority. The decision of the council was that Zwingli would be allowed to continue his preaching and that all other preachers should teach only in accordance with Scripture.

In September 1523, Leo Jud, Zwingli's closest friend and colleague and pastor of St. Peterskirche, publicly called for the removal of statues of saints and other icons. This led to demonstrations and iconoclastic activities. The city council decided to work out the matter of images in a second disputation. The essence of the mass and its sacrificial character was also included as a subject of discussion. Supporters of the mass claimed that the eucharist was a true sacrifice, while Zwingli claimed that it was a commemorative meal. As in the first disputation, an invitation was sent out to the Zürich clergy and the bishop of Constance. This time, however, the lay people of Zürich, the dioceses of Chur and Basel, the University of Basel, and the twelve members of the Confederation were also invited. About nine hundred persons attended this meeting, but neither the bishop nor the Confederation sent representatives. The disputation started on 26 October 1523 and lasted two days.

Zwingli again took the lead in the disputation. His opponent was the aforementioned canon, Konrad Hofmann, who had initially supported Zwingli's election. Also taking part was a group of young men demanding a much faster pace of reformation, who among other things pleaded for replacing infant baptism with adult baptism. This group was led by Conrad Grebel, one of the initiators of the Anabaptist movement. During the first three days of dispute, although the controversy of images and the mass were discussed, the arguments led to the question of whether the city council or the ecclesiastical government had the authority to decide on these issues. At this point, Konrad Schmid, a priest from Aargau and follower of Zwingli, made a pragmatic suggestion. As images were not yet considered to be valueless by everyone, he suggested that pastors preach on this subject under threat of punishment. He believed the opinions of the people would gradually change and the voluntary removal of images would follow. Hence, Schmid rejected the radicals and their iconoclasm, but supported Zwingli's position. In November the council passed ordinances in support of Schmid's motion. Zwingli wrote a booklet on the evangelical duties of a minister, "Kurze, christliche Einleitung" (Short Christian Introduction), and the council sent it out to the clergy and the members of the Confederation.

In December 1523, the council set a deadline of Pentecost in 1524 for a solution to the elimination of the mass and images. Zwingli gave a formal opinion in "Vorschlag wegen der Bilder und der Messe" (Proposal Concerning Images and the Mass). He did not urge an immediate, general abolition. The council decided on the orderly removal of images within Zürich, but rural congregations were granted the right to remove them based on majority vote. The decision on the mass was postponed.

Evidence of the effect of the Reformation was seen in early 1524. Candlemas was not celebrated, processions of robed clergy ceased, worshippers did not go with palms or relics on Palm Sunday to the Lindenhof, and triptychs remained covered and closed after Lent. Opposition to the changes came from Konrad Hofmann and his followers, but the council decided in favour of keeping the government mandates. When Hofmann left the city, opposition from pastors hostile to the Reformation broke down. The bishop of Constance tried to intervene in defending the mass and the veneration of images. Zwingli wrote an official response for the council and the result was the severance of all ties between the city and the diocese.

Although the council had hesitated in abolishing the mass, the decrease in the exercise of traditional piety allowed pastors to be unofficially released from the requirement of celebrating mass. As individual pastors altered their practices as each saw fit, Zwingli was prompted to address this disorganised situation by designing a communion liturgy in the German language. This was published in "Aktion oder Brauch des Nachtmahls" (Act or Custom of the Supper). Shortly before Easter, Zwingli and his closest associates requested the council to cancel the mass and to introduce the new public order of worship. On Maundy Thursday, 13 April 1525, Zwingli celebrated communion under his new liturgy. Wooden cups and plates were used to avoid any outward displays of formality. The congregation sat at set tables to emphasise the meal aspect of the sacrament. The sermon was the focal point of the service and there was no organ music or singing. The importance of the sermon in the worship service was underlined by Zwingli's proposal to limit the celebration of communion to four times a year.

For some time Zwingli had accused mendicant orders of hypocrisy and demanded their abolition in order to support the truly poor. He suggested the monasteries be changed into hospitals and welfare institutions and incorporate their wealth into a welfare fund. This was done by reorganising the foundations of the Grossmünster and Fraumünster and pensioning off remaining nuns and monks. The council secularised the church properties (Fraumünster handed over by Zwingli's acquaintance Katharina von Zimmern) and established new welfare programs for the poor. Zwingli requested permission to establish a Latin school, the "Prophezei" (Prophecy) or "Carolinum", at the Grossmünster. The council agreed and it was officially opened on 19 June 1525 with Zwingli and Jud as teachers. It served to retrain and re-educate the clergy. The Zürich Bible translation, traditionally attributed to Zwingli and printed by Christoph Froschauer, bears the mark of teamwork from the Prophecy school. Scholars have not yet attempted to clarify Zwingli's share of the work based on external and stylistic evidence.

Shortly after the second Zürich disputation, many in the radical wing of the Reformation became convinced that Zwingli was making too many concessions to the Zürich council. They rejected the role of civil government and demanded the immediate establishment of a congregation of the faithful. Conrad Grebel, the leader of the radicals and the emerging Anabaptist movement, spoke disparagingly of Zwingli in private. On 15 August 1524 the council insisted on the obligation to baptise all newborn infants. Zwingli secretly conferred with Grebel's group and late in 1524, the council called for official discussions. When talks were broken off, Zwingli published "Wer Ursache gebe zu Aufruhr" (Whoever Causes Unrest) clarifying the opposing points-of-view. On 17 January 1525 a public debate was held and the council decided in favour of Zwingli. Anyone refusing to have their children baptised was required to leave Zürich. The radicals ignored these measures and on 21 January, they met at the house of the mother of another radical leader, Felix Manz. Grebel and a third leader, George Blaurock, performed the first recorded Anabaptist adult baptisms.

On February 2, the council repeated the requirement on the baptism of all babies and some who failed to comply were arrested and fined, Manz and Blaurock among them. Zwingli and Jud interviewed them and more debates were held before the Zürich council. Meanwhile, the new teachings continued to spread to other parts of the Confederation as well as a number of Swabian towns. On 6–8 November, the last debate on the subject of baptism took place in the Grossmünster. Grebel, Manz, and Blaurock defended their cause before Zwingli, Jud, and other reformers. There was no serious exchange of views as each side would not move from their positions and the debates degenerated into an uproar, each side shouting abuse at the other.

The Zürich council decided that no compromise was possible. On 7 March 1526 it released the notorious mandate that no one shall rebaptise another under the penalty of death. Although Zwingli, technically, had nothing to do with the mandate, there is no indication that he disapproved. Felix Manz, who had sworn to leave Zürich and not to baptise any more, had deliberately returned and continued the practice. After he was arrested and tried, he was executed on 5 January 1527 by being drowned in the Limmat. He was the first Anabaptist martyr; three more were to follow, after which all others either fled or were expelled from Zürich.

On 8 April 1524, five cantons, Lucerne, Uri, Schwyz, Unterwalden, and Zug, formed an alliance, "die fünf Orte" (the Five States) to defend themselves from Zwingli's Reformation. They contacted the opponents of Martin Luther including John Eck, who had debated Luther in the Leipzig Disputation of 1519. Eck offered to dispute Zwingli and he accepted. However, they could not agree on the selection of the judging authority, the location of the debate, and the use of the Swiss Diet as a court. Because of the disagreements, Zwingli decided to boycott the disputation. On 19 May 1526, all the cantons sent delegates to Baden. Although Zürich's representatives were present, they did not participate in the sessions. Eck led the Catholic party while the reformers were represented by Johannes Oecolampadius of Basel, a theologian from Württemberg who had carried on an extensive and friendly correspondence with Zwingli. While the debate proceeded, Zwingli was kept informed of the proceedings and printed pamphlets giving his opinions. It was of little use as the Diet decided against Zwingli. He was to be banned and his writings were no longer to be distributed. Of the thirteen Confederation members, Glarus, Solothurn, Fribourg, and Appenzell as well as the Five States voted against Zwingli. Bern, Basel, Schaffhausen, and Zürich supported him.

The Baden disputation exposed a deep rift in the Confederation on matters of religion. The Reformation was now emerging in other states. The city of St Gallen, an affiliated state to the Confederation, was led by a reformed mayor, Joachim Vadian, and the city abolished the mass in 1527, just two years after Zürich. In Basel, although Zwingli had a close relationship with Oecolampadius, the government did not officially sanction any reformatory changes until 1 April 1529 when the mass was prohibited. Schaffhausen, which had closely followed Zürich's example, formally adopted the Reformation in September 1529. In the case of Bern, Berchtold Haller, the priest at St Vincent Münster, and Niklaus Manuel, the poet, painter, and politician, had campaigned for the reformed cause. But it was only after another disputation that Bern counted itself as a canton of the Reformation. Four hundred and fifty persons participated, including pastors from Bern and other cantons as well as theologians from outside the Confederation such as Martin Bucer and Wolfgang Capito from Strasbourg, Ambrosius Blarer from Constance, and Andreas Althamer from Nuremberg. Eck and Fabri refused to attend and the Catholic cantons did not send representatives. The meeting started on 6 January 1528 and lasted nearly three weeks. Zwingli assumed the main burden of defending the Reformation and he preached twice in the Münster. On 7 February 1528 the council decreed that the Reformation be established in Bern.

Even before the Bern disputation, Zwingli was canvassing for an alliance of reformed cities. Once Bern officially accepted the Reformation, a new alliance, "das Christliche Burgrecht" (the Christian Civic Union) was created. The first meetings were held in Bern between representatives of Bern, Constance, and Zürich on 5–6 January 1528. Other cities, including Basel, Biel, Mülhausen, Schaffhausen, and St Gallen, eventually joined the alliance. The Five (Catholic) States felt encircled and isolated, so they searched for outside allies. After two months of negotiations, the Five States formed "die Christliche Vereinigung" (the Christian Alliance) with Ferdinand of Austria on 22 April 1529.
Soon after the Austrian treaty was signed, a reformed preacher, Jacob Kaiser, was captured in Uznach and executed in Schwyz. This triggered a strong reaction from Zwingli; he drafted "Ratschlag über den Krieg" (Advice About the War) for the government. He outlined justifications for an attack on the Catholic states and other measures to be taken. Before Zürich could implement his plans, a delegation from Bern that included Niklaus Manuel arrived in Zürich. The delegation called on Zürich to settle the matter peacefully. Manuel added that an attack would expose Bern to further dangers as Catholic Valais and the Duchy of Savoy bordered its southern flank. He then noted, "You cannot really bring faith by means of spears and halberds." Zürich, however, decided that it would act alone, knowing that Bern would be obliged to acquiesce. War was declared on 8 June 1529. Zürich was able to raise an army of 30,000 men. The Five States were abandoned by Austria and could raise only 9,000 men. The two forces met near Kappel, but war was averted due to the intervention of Hans Aebli, a relative of Zwingli, who pleaded for an armistice.

Zwingli was obliged to state the terms of the armistice. He demanded the dissolution of the Christian Alliance; unhindered preaching by reformers in the Catholic states; prohibition of the pension system; payment of war reparations; and compensation to the children of Jacob Kaiser. Manuel was involved in the negotiations. Bern was not prepared to insist on the unhindered preaching or the prohibition of the pension system. Zürich and Bern could not agree and the Five (Catholic) States pledged only to dissolve their alliance with Austria. This was a bitter disappointment for Zwingli and it marked his decline in political influence. The first Land Peace of Kappel, "der erste Landfriede", ended the war on 24 June.

While Zwingli carried on the political work of the Swiss Reformation, he developed his theological views with his colleagues. The famous disagreement between Luther and Zwingli on the interpretation of the eucharist originated when Andreas Karlstadt, Luther's former colleague from Wittenberg, published three pamphlets on the Lord's Supper in which Karlstadt rejected the idea of a real presence in the elements. These pamphlets, published in Basel in 1524, received the approval of Oecolampadius and Zwingli. Luther rejected Karlstadt's arguments and considered Zwingli primarily to be a partisan of Karlstadt. Zwingli began to express his thoughts on the eucharist in several publications including "de Eucharistia" (On the Eucharist). He attacked the idea of the real presence and argued that the word "is" in the words of the institution—"This is my body, this is my blood"—means "signifies". Hence, the words are understood as a metaphor and Zwingli claimed that there was no real presence during the eucharist. In effect, the meal was symbolic of the Last Supper.

By spring 1527, Luther reacted strongly to Zwingli's views in the treatise "Dass Diese Worte Christi "Das ist mein Leib etc." noch fest stehen wider die Schwarmgeister" (That These Words of Christ "This is My Body etc." Still Stand Firm Against the Fanatics). The controversy continued until 1528 when efforts to build bridges between the Lutheran and the Zwinglian views began. Martin Bucer tried to mediate while Philip of Hesse, who wanted to form a political coalition of all Protestant forces, invited the two parties to Marburg to discuss their differences. This event became known as the Marburg Colloquy.

Zwingli accepted Philip's invitation fully believing that he would be able to convince Luther. By contrast, Luther did not expect anything to come out of the meeting and had to be urged by Philip to attend. Zwingli, accompanied by Oecolampadius, arrived on 28 September 1529 with Luther and Philipp Melanchthon arriving shortly thereafter. Other theologians also participated including Martin Bucer, Andreas Osiander, Johannes Brenz, and Justus Jonas. The debates were held from 1–3 October and the results were published in the fifteen "Marburg Articles". The participants were able to agree on fourteen of the articles, but the fifteenth article established the differences in their views on the presence of Christ in the eucharist. Afterwards, each side was convinced that they were the victors, but in fact the controversy was not resolved and the final result was the formation of two different Protestant confessions.

With the failure of the Marburg Colloquy and the split of the Confederation, Zwingli set his goal on an alliance with Philip of Hesse. He kept up a lively correspondence with Philip. Bern refused to participate, but after a long process, Zürich, Basel, and Strasbourg signed a mutual defence treaty with Philip in November 1530. Zwingli also personally negotiated with France's diplomatic representative, but the two sides were too far apart. France wanted to maintain good relations with the Five States. Approaches to Venice and Milan also failed.

As Zwingli was working on establishing these political alliances, Charles V, the Holy Roman Emperor, invited Protestants to the Augsburg Diet to present their views so that he could make a verdict on the issue of faith. The Lutherans presented the Augsburg Confession. Under the leadership of Martin Bucer, the cities of Strasbourg, Constance, Memmingen, and Lindau produced the Tetrapolitan Confession. This document attempted to take a middle position between the Lutherans and Zwinglians. It was too late for the "Burgrecht" cities to produce a confession of their own. Zwingli then produced his own private confession, "Fidei ratio" (Account of Faith) in which he explained his faith in twelve articles conforming to the articles of the Apostles' Creed. The tone was strongly anti-Catholic as well as anti-Lutheran. The Lutherans did not react officially, but criticised it privately. Zwingli's and Luther's old opponent, Johann Eck, counter-attacked with a publication, "Refutation of the Articles Zwingli Submitted to the Emperor".

When Philip of Hesse formed the Schmalkaldic League at the end of 1530, the four cities of the Tetrapolitan Confession joined on the basis of a Lutheran interpretation of that confession. Given the flexibility of the league's entrance requirements, Zürich, Basel, and Bern also considered joining. However, Zwingli could not reconcile the Tetrapolitan Confession with his own beliefs and wrote a harsh refusal to Bucer and Capito. This offended Philip to the point where relations with the League were severed. The "Burgrecht" cities now had no external allies to help deal with internal Confederation religious conflicts.

The peace treaty of the First Kappel War did not define the right of unhindered preaching in the Catholic states. Zwingli interpreted this to mean that preaching should be permitted, but the Five States suppressed any attempts to reform. The "Burgrecht" cities considered different means of applying pressure to the Five States. Basel and Schaffhausen preferred quiet diplomacy while Zürich wanted armed conflict. Zwingli and Jud unequivocally advocated an attack on the Five States. Bern took a middle position which eventually prevailed. In May 1531, Zürich reluctantly agreed to impose a food blockade. It failed to have any effect and in October, Bern decided to withdraw the blockade. Zürich urged its continuation and the "Burgrecht" cities began to quarrel among themselves.

On 9 October 1531, in a surprise move, the Five States declared war on Zürich. Zürich's mobilisation was slow due to internal squabbling and on 11 October, 3500 poorly deployed men encountered a Five States force nearly double their size near Kappel. Many pastors, including Zwingli, were among the soldiers. The battle lasted less than one hour and Zwingli was among the 500 casualties in the Zürich army.

Zwingli had considered himself first and foremost a soldier of Christ; second a defender of his country, the Confederation; and third a leader of his city, Zürich, where he had lived for the previous twelve years. Ironically, he died at the age of 47, not for Christ nor for the Confederation, but for Zürich. 
In Tabletalk, Luther is recorded saying: "They say that Zwingli recently died thus; if his error had prevailed, we would have perished, and our church with us. It was a judgment of God. That was always a proud people. The others, the papists, will probably also be dealt with by our Lord God."
. Erasmus wrote, "We are freed from great fear by the death of the two preachers, Zwingli and Oecolampadius, whose fate has wrought an incredible change in the mind of many. This is the wonderful hand of God on high." Oecolampadius had died on 24 November. Erasmus also wrote, "If Bellona had favoured them, it would have been all over with us."

According to Zwingli, the cornerstone of theology is the Bible. Zwingli appealed to scripture constantly in his writings. He placed its authority above other sources such as the ecumenical councils or the Church Fathers, although he did not hesitate to use other sources to support his arguments. The principles that guide Zwingli's interpretations are derived from his rationalist humanist education and his Reformed understanding of the Bible. He rejected literalist interpretations of a passage, such as those of the Anabaptists, and used synecdoche and analogies, methods he describes in "A Friendly Exegesis" (1527). Two analogies that he used quite effectively were between baptism and circumcision and between the eucharist and Passover. He also paid attention to the immediate context and attempted to understand the purpose behind it, comparing passages of scripture with each other.
Zwingli rejected the word "sacrament" in the popular usage of his time. For ordinary people, the word meant some kind of holy action of which there is inherent power to free the conscience from sin. For Zwingli, a sacrament was an initiatory ceremony or a pledge, pointing out that the word was derived from "sacramentum" meaning an oath. (However, the word is also translated "mystery".) In his early writings on baptism, he noted that baptism was an example of such a pledge. He challenged Catholics by accusing them of superstition when they ascribed the water of baptism a certain power to wash away sin. Later, in his conflict with the Anabaptists, he defended the practice of infant baptism, noting that there is no law forbidding the practice. He argued that baptism was a sign of a covenant with God, thereby replacing circumcision in the Old Testament.

Zwingli approached the eucharist in a similar manner to baptism. During the first Zürich disputation in 1523, he denied that an actual sacrifice occurred during the mass, arguing that Christ made the sacrifice only once and for all eternity. Hence, the eucharist was "a memorial of the sacrifice". Following this argument, he further developed his view, coming to the conclusion of the "signifies" interpretation for the words of the institution. He used various passages of scripture to argue against transubstantiation as well as Luther's views, the key text being John 6:63, "It is the Spirit who gives life, the flesh is of no avail". Zwingli's approach and interpretation of scripture to understand the meaning of the eucharist was one reason he could not reach a consensus with Luther.

The impact of Luther on Zwingli's theological development has long been a source of interest and discussion among Zwinglian scholars. Zwingli himself asserted vigorously his independence of Luther. The most recent studies have lent credibility to this claim, although some scholars still argue his theology was dependent upon Luther's. Zwingli appears to have read Luther's books in search of confirmation from Luther for his own views. Zwingli did, however, admire Luther greatly for the stand he took against the pope. This, more than Luther's theology, was a key influence on Zwingli's convictions as a reformer. What Zwingli considered Luther's courageous stance at the Leipzig Disputation had a decisive impact on Zwingli during his earliest years as a priest, and during this time Zwingli praised and promoted Luther's writings to support his own similar ideas. Like Luther, Zwingli was also a student and admirer of Augustine. His later writings continued to show characteristic differences from Luther such as the inclusion of non-Christians in heaven as described in "An Exposition of the Faith".

Zwingli enjoyed music and could play several instruments, including the violin, harp, flute, dulcimer and hunting horn. He would sometimes amuse the children of his congregation on his lute and was so well known for his playing that his enemies mocked him as "the evangelical lute-player and fifer". Three of Zwingli's "Lieder" or hymns have been preserved: the "Pestlied" mentioned above, an adaptation of Psalm 65 (c. 1525), and the "Kappeler Lied", which is believed to have been composed during the campaign of the first war of Kappel (1529). These songs were not meant to be sung during worship services and are not identified as hymns of the Reformation, though they were published in some 16th-century hymnals.

Zwingli criticised the practice of priestly chanting and monastic choirs. The criticism dates from 1523 when he attacked certain worship practices. His arguments are detailed in the Conclusions of 1525, in which, Conclusions 44, 45 and 46 are concerned with musical practices under the rubric of "prayer". He associated music with images and vestments, all of which he felt diverted people's attention from true spiritual worship. It is not known what he thought of the musical practices in early Lutheran churches. Zwingli, however, eliminated instrumental music from worship in the church, stating that God had not commanded it in worship. The organist of the People's Church in Zürich is recorded as weeping upon seeing the great organ broken up. Although Zwingli did not express an opinion on congregational singing, he made no effort to encourage it. Nevertheless, scholars have found that Zwingli was supportive of a role for music in the church. Gottfried W. Locher writes, "The old assertion 'Zwingli was against church singing' holds good no longer ... Zwingli's polemic is concerned exclusively with the medieval Latin choral and priestly chanting and not with the hymns of evangelical congregations or choirs". Locher goes on to say that "Zwingli freely allowed vernacular psalm or choral singing. In addition, he even seems to have striven for lively, antiphonal, unison recitative". Locher then summarizes his comments on Zwingli's view of church music as follows: "The chief thought in his conception of worship was always 'conscious attendance and understanding'—'devotion', yet with the lively participation of all concerned".

Today's Musikabteilung (literally: music departement), located in the choir of the "Predigern" church in Zürich was founded in 1971, and forms a scientific music collection of European importance. It publishes the materials entrusted to it at irregular intervals as CDs. The repertoire ranges from the early 16th-century spiritual music of Huldrych Zwingli to music of the late 20th century, published under the label "Musik aus der Zentralbibliothek Zürich".

Zwingli was a humanist and a scholar with many devoted friends and disciples. He communicated as easily with the ordinary people of his congregation as with rulers such as Philip of Hesse. His reputation as a stern, stolid reformer is counterbalanced by the fact that he had an excellent sense of humour and used satiric fables, spoofing, and puns in his writings. He was more conscious of social obligations than Luther and he genuinely believed that the masses would accept a government guided by God's word. He tirelessly promoted assistance to the poor, who he believed should be cared for by a truly Christian community.

In December 1531, the Zürich council selected Heinrich Bullinger as his successor. He immediately removed any doubts about Zwingli's orthodoxy and defended him as a prophet and a martyr. During Bullinger's rule, the confessional divisions of the Confederation were stabilised. He rallied the reformed cities and cantons and helped them to recover from the defeat at Kappel. Zwingli had instituted fundamental reforms, while Bullinger consolidated and refined them.

Scholars have found it difficult to assess Zwingli's impact on history, for several reasons. There is no consensus on the definition of "Zwinglianism"; by any definition, Zwinglianism evolved under his successor, Heinrich Bullinger; and research into Zwingli's influence on Bullinger and John Calvin is still rudimentary. Bullinger adopted most of Zwingli's points of doctrine. Like Zwingli, he summarised his theology several times, the best-known being the Second Helvetic Confession of 1566. Meanwhile, Calvin had taken over the Reformation in Geneva. Calvin differed with Zwingli on the eucharist and criticised him for regarding it as simply a metaphorical event. In 1549, however, Bullinger and Calvin succeeded in overcoming the differences in doctrine and produced the "Consensus Tigurinus" (Zürich Consensus). They declared that the eucharist was not just symbolic of the meal, but they also rejected the Lutheran position that the body and blood of Christ is in union with the elements. With this rapprochement, Calvin established his role in the Swiss Reformed Churches and eventually in the wider world.

Outside of Switzerland, no church counts Zwingli as its founder. Scholars speculate as to why Zwinglianism has not diffused more widely, even though Zwingli's theology is considered the first expression of Reformed theology. Although his name is not widely recognised, Zwingli's legacy lives on in the basic confessions of the Reformed churches of today. He is often called, after Martin Luther and John Calvin, the "Third Man of the Reformation".

Zwingli's collected works are expected to fill 21 volumes. A collection of selected works was published in 1995 by the "Zwingliverein" in collaboration with the "Theologischer Verlag Zürich" This four-volume collection contains the following works:

The complete 21-volume edition is being undertaken by the "Zwingliverein" in collaboration with the "Institut für schweizerische Reformationsgeschichte", and is projected to be organised as follows:

Vols. XIII and XIV have been published, vols. XV and XVI are under preparation. Vols. XVII to XXI are planned to cover the New Testament.

Older German / Latin editions available online include:

See also the following English translations of selected works by Zwingli:






</doc>
<doc id="13603" url="https://en.wikipedia.org/wiki?curid=13603" title="Homeschooling">
Homeschooling

Homeschooling, also known as home education is the education of children at home or a variety of other places. Home education is usually conducted by a parent or tutor or online teacher. Many families use less formal ways of educating. "Homeschooling" is the term commonly used in North America, whereas "home education" is commonly used in the United Kingdom, Europe, and in many Commonwealth countries.

Before the introduction of compulsory school attendance laws, most childhood education was done by families and local communities. In many developed countries, homeschooling is a legal alternative to public and private schools. In other nations, homeschooling remains illegal or restricted to specific conditions, as recorded by homeschooling international status and statistics.

According to the US National Center for Education Statistics, about three percent of all children in the US were homeschooled in 2011–2012 school year. The study found that 83 percent were White, 5 percent were Black, 7 percent were Hispanic, and 2 percent were Asian or Pacific Islander. As of 2016, there are about 1.7 million homeschooled students in the United States.

On average, homeschoolers score at or above the national average on standardized tests. Homeschool students have been accepted into many Ivy League universities.

For most of history and in different cultures, the education of children at home by family members was a common practice. Enlisting professional tutors was an option available only to the wealthy. Homeschooling declined in the 19th and 20th centuries with the enactment of compulsory attendance laws. But, it continued to be practiced in isolated communities. Homeschooling began a resurgence in the 1960s and 1970s with educational reformists dissatisfied with industrialized education.

The earliest public schools in modern Western culture were established during the reformation with the encouragement of Martin Luther in the German states of Gotha and Thuringia in 1524 and 1527. From the 1500s to 1800s the literacy rate increased until a majority of adults were literate; but, development of the literacy rate occurred before the implementation of compulsory attendance and universal education.

Home education and apprenticeship continued to remain the main form of education until the 1830s. However, in the 18th century, the majority of people in Europe lacked formal education. Since the early 19th century, formal classroom schooling became the most common means of schooling throughout the developed countries.

In 1647, New England provided compulsory elementary education. Regional differences in schooling existed in colonial America. In the south, farms and plantations were so widely dispersed that community schools such as those in the more compact settlements of the north were impossible. In the middle colonies, the educational situation varied when comparing New York with New England.

Most Native American tribal cultures traditionally used home education and apprenticeship to pass knowledge to children. Parents were supported by extended relatives and tribal leaders in the education of their children. The Native Americans vigorously resisted compulsory education in the United States.

In the 1960s, Rousas John Rushdoony began to advocate homeschooling, which he saw as a way to combat the secular nature of the public school system in the United States. He vigorously attacked progressive school reformers such as Horace Mann and John Dewey, and argued for the dismantling of the state's influence in education in three works: "Intellectual Schizophrenia", "The Messianic Character of American Education", and "The Philosophy of the Christian Curriculum". Rushdoony was frequently called as an expert witness by the Home School Legal Defense Association (HSLDA) in court cases. He frequently advocated the use of private schools.

During this time, American educational professionals Raymond and Dorothy Moore began to research the academic validity of the rapidly growing Early Childhood Education movement. This research included independent studies by other researchers and a review of over 8,000 studies bearing on early childhood education and the physical and mental development of children.

They asserted that formal schooling before ages 8–12 not only lacked the anticipated effectiveness, but also harmed children. The Moores published their view that formal schooling was damaging young children academically, socially, mentally, and even physiologically. The Moores presented evidence that childhood problems such as juvenile delinquency, nearsightedness, increased enrollment of students in special education classes and behavioral problems were the result of increasingly earlier enrollment of students. The Moores cited studies demonstrating that orphans who were given surrogate mothers were measurably more intelligent, with superior long-term effects – even though the mothers were "mentally retarded teenagers" – and that illiterate tribal mothers in Africa produced children who were socially and emotionally more advanced than typical western children, "by western standards of measurement".

Their primary assertion was that the bonds and emotional development made at home with parents during these years produced critical long-term results that were cut short by enrollment in schools, and could neither be replaced nor corrected in an institutional setting afterward. Recognizing a necessity for early out-of-home care for some children, particularly special needs and impoverished children and children from exceptionally inferior homes, they maintained that the vast majority of children were far better situated at home, even with mediocre parents, than with the most gifted and motivated teachers in a school setting. They described the difference as follows: "This is like saying, if you can help a child by taking him off the cold street and housing him in a warm tent, then warm tents should be provided for "all" children – when obviously most children already have even more secure housing."

The Moores embraced homeschooling after the publication of their first work, "Better Late Than Early", in 1975, and became important homeschool advocates and consultants with the publication of books such as "Home Grown Kids" (1981), and "Homeschool Burnout".

Simultaneously, other authors published books questioning the premises and efficacy of compulsory schooling, including "Deschooling Society" by Ivan Illich in 1970 and "No More Public School" by Harold Bennet in 1972.

In 1976, educator John Holt published "Instead of Education; Ways to Help People Do Things Better". In its conclusion, he called for a "Children's Underground Railroad" to help children escape compulsory schooling. In response, Holt was contacted by families from around the U.S. to tell him that they were educating their children at home. In 1977, after corresponding with a number of these families, Holt began producing "Growing Without Schooling", a newsletter dedicated to home education. Holt was nicknamed the "father of home schooling." Holt later wrote a book about homeschooling, "Teach Your Own", in 1981.

In 1980, Holt said, "I want to make it clear that I don't see homeschooling as some kind of answer to badness of schools. I think that the home is the proper base for the exploration of the world which we call learning or education. Home would be the best base no matter how good the schools were." One common theme in the homeschool philosophies of both Holt and that of the Moores is that home education should not attempt to bring the school construct into the home, or a view of education as an academic preliminary to life. They viewed home education as a natural, experiential aspect of life that occurs as the members of the family are involved with one another in daily living.

Parents commonly cite two main motivations for homeschooling their children: dissatisfaction with the local schools and the interest in increased involvement with their children's learning and development. Parental dissatisfaction with available schools typically includes concerns about the school environment, the quality of academic instruction, the curriculum, bullying, racism and lack of faith in the school's ability to cater to their children's special needs. Some parents homeschool in order to have greater control over what and how their children are taught, to cater more adequately to an individual child's aptitudes and abilities, to provide instruction from a specific religious or moral position, and to take advantage of the efficiency of one-to-one instruction and thus allow the child to spend more time on childhood activities, socializing, and non-academic learning.

Some African-American families choose homeschool as a way of increasing their children's understanding of African-American history – such as the Jim Crow laws that resulted in their ancestors being beaten, killed, or sold for learning to read – and to limit the harm caused by the unintentional and sometimes subtle systemic racism that affects most American schools.

Some parents have objections to the secular nature of public schools and homeschool in order to give their children a religious education. Use of a religious curriculum is common among these families. Recent sociological work suggests that an increasing number of parents are choosing homeschooling because of low academic quality at the local schools, or because of bullying or health problems.

Homeschooling may also be a factor in the choice of parenting style. Homeschooling can be a matter of consistency for families living in isolated rural locations, for those temporarily abroad, and for those who travel frequently. Many young athletes, actors, and musicians are taught at home to accommodate their training and practice schedules more conveniently. Homeschooling can be about mentorship and apprenticeship, in which a tutor or teacher is with the child for many years and becomes more intimately acquainted with the child. Homeschooling increased in popularity in the United States during the 2000s; the percentage of children ages 5 through 17 who were homeschooled increased from 1.7% in 1999 to 3% in 2011/12.

Homeschooling can be used a form of supplemental education and as a way of helping children learn under specific circumstances. The term may also refer to instruction in the home under the supervision of correspondence schools or umbrella schools. Some jurisdictions require adherence to an approved curriculum. A curriculum-free philosophy of homeschooling is sometimes called "unschooling", a term coined in 1977 by American educator and author John Holt in his magazine, "Growing Without Schooling". The term emphasizes the more spontaneous, less structured learning environment in which a child's interests drive his pursuit of knowledge. Some parents provide a liberal arts education using the trivium and quadrivium as the main models.

Homeschools use a wide variety of methods and materials. Families choose different educational methods, which represent a variety of educational philosophies and paradigms. Some of the methods or learning environments used include Classical education (including Trivium, Quadrivium), Charlotte Mason education, Montessori method, Theory of multiple intelligences, Unschooling, Radical Unschooling, Waldorf education, School-at-home (curriculum choices from both secular and religious publishers), A Thomas Jefferson Education, unit studies, curriculum made up from private or small publishers, apprenticeship, hands-on-learning, distance learning (both online and correspondence), dual enrollment in local schools or colleges, and curriculum provided by local schools and many others. Some of these approaches are used in private and public schools. Educational research and studies support the use of some of these methods. Unschooling, natural learning, Charlotte Mason Education, Montessori, Waldorf, apprenticeship, hands-on-learning, unit studies are supported to varying degrees by research by constructivist learning theories and situated cognition theories. Elements of these theories may be found in the other methods as well.

A student's education may be customized to support his or her learning level, style, and interests. It is not uncommon for a student to experience more than one approach as the family discovers what works best for their student. Many families use an eclectic approach, picking and choosing from various suppliers. For sources of curricula and books a study found that 78 percent utilized "a public library"; 77 percent used "a homeschooling catalog, publisher, or individual specialist"; 68 percent used "retail bookstore or another store"; 60 percent used "an education publisher that was not affiliated with homeschooling." "Approximately half" used curriculum from "a homeschooling organization", 37 percent from a "church, synagogue or other religious institution" and 23 percent from "their local public school or district." In 2003, 41 percent utilized some sort of distance learning, approximately 20 percent by "television, video or radio"; 19 percent via "The Internet, e-mail, or the World Wide Web"; and 15 percent taking a "correspondence course by mail designed specifically for homeschoolers."

Individual governmental units, e.g. states and local districts, vary in official curriculum and attendance requirements.

As a subset of homeschooling, informal learning happens outside of the classroom, but has no traditional boundaries of education. Informal learning is an everyday form of learning through participation and creation, in contrast with the traditional view of teacher-centered learning. The term is often combined with non-formal learning, and self-directed learning. Informal learning differs from traditional learning since there are no expected objectives or outcomes. From the learner's standpoint, the knowledge that they receive is not intentional. Anything from planting a garden to baking a cake or even talking to a technician at work about the installation of new software, can be considered informal learning. The individual is completing a task with different intentions, but ends up learning skills in the process. Children watching their tomato plants grow will not generate questions about photosynthesis but they will learn that their plants are growing with water and sunlight. This leads them to have a base understanding of complex scientific concepts without any background studying. The recent trend of homeschooling becoming less stigmatized has been in connection with the traditional waning of the idea that the state needs to be in primary and ultimate control over the education and upbringing of all children to create future adult citizens. This breeds an ever-growing importance on the ideas and concepts that children learn outside of the traditional classroom setting, including Informal learning.

Depending on the part of the world, informal learning can take on many different identities and has differing cultural importances. Many ways of organizing homeschooling draw on apprenticeship qualities and on non-western cultures. In some South American indigenous cultures, such as the Chillihuani community in Peru, children learn irrigation and farming technique through play, advancing them not only in their own village and society, but also in their knowledge of realistic techniques that they will need to survive. In Western culture, children use informal learning in two main ways. The first as talked about, is through hands-on experience with new material. The second is asking questions to someone who has more experience than they have (i.e. parents, elders). Children's inquisitive nature is their way of cementing the ideas they have learned through exposure informal learning. It is a more casual way of learning than traditional learning and serves the purpose of taking in information any which way they can.

All other approaches to homeschooling are subsumed under two basic categories: structured and unstructured homeschooling. Structured homeschooling includes any method or style of home education that follows a basic curriculum with articulated goals and outcomes. This style attempts to imitate the structure of the traditional school setting while personalizing the curriculum. Unstructured homeschooling is any form of home education where parents do not construct a curriculum at all. Unschooling, as it is known, attempts to teach through the child's daily experiences and focuses more on self-directed learning by the child, free of textbooks, teachers, and any formal assessment of success or failure.

In a unit study approach, multiple subjects such as math, science, history, art, and geography, are studied in relation to a single topic. Unit studies are useful for teaching multiple grades simultaneously as the difficulty level can be adjusted for each student. An extended form of unit studies, Integrated Thematic Instruction utilizes one central theme integrated throughout the curriculum so that students finish a school year with a deep understanding of a certain broad subject or idea.

All-in-one homeschooling curricula (variously known as "school-at-home", "the traditional approach", "school-in-a-box" or "The Structured Approach"), are instructionist methods of teaching in which the curriculum and homework of the student are similar or identical to those used in a public or private school. Purchased as a grade level package or separately by subject, the package may contain all of the needed books, materials, tests, answer keys, and extensive teacher guides. These materials cover the same subject areas as public schools, allowing for an easy transition into the school system. These are among the more expensive options for homeschooling, but they require minimal preparation and are easy to use. Some localities provide the same materials used at local schools to homeschoolers. The purchase of a complete curriculum and their teaching/grading service from an accredited distance learning curriculum provider may allow students to obtain an accredited high school diploma.

"Natural learning" refers to a type of learning-on-demand where children pursue knowledge based on their interests and parents take an active part in facilitating activities and experiences conducive to learning but do not rely heavily on textbooks or spend much time "teaching", looking instead for "learning moments" throughout their daily activities. Parents see their role as that of affirming through positive feedback and modeling the necessary skills, and the child's role as being responsible for asking and learning.

The term "unschooling" as coined by John Holt describes an approach in which parents do not authoritatively direct the child's education, but interact with the child following the child's own interests, leaving them free to explore and learn as their interests lead. "Unschooling" does not indicate that the child is not being educated, but that the child is not being "schooled", or educated in a rigid school-type manner. Holt asserted that children learn through the experiences of life, and he encouraged parents to live their lives with their child. Also known as interest-led or child-led learning, unschooling attempts to follow opportunities as they arise in real life, through which a child will learn without coercion. Children at school learn from 1 teacher and 2 auxiliary teachers in a classroom of approximately 30. Kids have the opportunity of dedicated education at home with a ratio of 1 to 1. An unschooled child may utilize texts or classroom instruction, but these are not considered central to education. Holt asserted that there is no specific body of knowledge that is, or should be, required of a child.

Both unschooling and natural learning advocates believe that children learn best by doing; a child may learn reading to further an interest about history or other cultures, or math skills by operating a small business or sharing in family finances. They may learn animal husbandry keeping dairy goats or meat rabbits, botany tending a kitchen garden, chemistry to understand the operation of firearms or the internal combustion engine, or politics and local history by following a zoning or historical-status dispute. While any type of homeschoolers may also use these methods, the unschooled child initiates these learning activities. The natural learner participates with parents and others in learning together.

Another prominent proponent of unschooling is John Taylor Gatto, author of Dumbing Us Down, The Exhausted School, A Different Kind of Teacher, and Weapons of Mass Instruction. Gatto argues that public education is the primary tool of "state controlled consciousness" and serves as a prime illustration of the total institution — a social system which impels obedience to the state and quells free thinking or dissent.

Autonomous learning is a school of education which sees learners as individuals who can and should be i.e. be responsible for their own learning climate.

Autonomous education helps students develop their self-consciousness, vision, practicality and freedom of discussion. These attributes serve to aid the student in his/her independent learning. However, a student must not start their autonomous learning completely on their own. It is said, that by first having interaction with someone who has more knowledge in a subject, will speed up the student's learning, and hence allow them to learn more independently.

Some degree of autonomous learning is popular with those who home educate their children. In true autonomous learning, the child usually gets to decide what projects they wish to tackle or what interests to pursue. In home education, this can be instead of or in addition to regular subjects like doing math or English.

According to Home Education UK the autonomous education philosophy emerged from the epistemology of Karl Popper in "The Myth of the Framework: In Defence of Science and Rationality", which is developed in the debates, which seek to rebut the neo-Marxist social philosophy of convergence proposed by the Frankfurt School (e.g. Theodor W. Adorno, Jürgen Habermas, Max Horkheimer).

A homeschool cooperative is a cooperative of families who homeschool their children. It provides an opportunity for children to learn from other parents who are more specialized in certain areas or subjects. Co-ops also provide social interaction. They may take lessons together or go on field trips. Some co-ops also offer events such as prom and graduation for homeschoolers.

Homeschoolers are beginning to utilize Web 2.0 as a way to simulate homeschool cooperatives online. With social networks homeschoolers can chat, discuss threads in forums, share information and tips, and even participate in online classes via blackboard systems similar to those used by colleges.

According to the Home School Legal Defense Association (HSLDA) in 2004, "Many studies over the last few years have established the academic excellence of homeschooled children." "Home Schooling Achievement", a compilation of studies published by the HSLDA, supported the academic integrity of homeschooling. This booklet summarized a 1997 study by Ray and the 1999 Rudner study. The Rudner study noted two limitations of its own research: it is not necessarily representative of all homeschoolers and it is not a comparison with other schooling methods. Among the homeschooled students who took the tests, the average homeschooled student outperformed his public school peers by 30 to 37 percentile points across all subjects. The study also indicates that public school performance gaps between minorities and genders were virtually non-existent among the homeschooled students who took the tests.

A survey of 11,739 homeschooled students conducted in 2008 found that, on average, the homeschooled students scored 37 percentile points above public school students on standardized achievement tests. This is consistent with the 1999 Rudner study. However, Rudner said that these same students in public school may have scored just as well because of the dedicated parents they had. The Ray study also found that homeschooled students who had a certified teacher as a parent scored one percentile lower than homeschooled students who did not have a certified teacher as a parent. Another nationwide descriptive study conducted by Ray contained students ranging from ages 5–18 and he found that homeschoolers scored in at least the 80th percentile on their tests.

In 2011, a quasi-experimental study was conducted that included homeschooled and traditional public students between the ages of 5 and 10. It was discovered that the majority of the homeschooled children achieved higher standardized scores compared to their counterparts. However, Martin-Chang also found that unschooling children ages 5–10 scored significantly below traditionally educated children, while academically oriented homeschooled children scored from one half grade level above to 4.5 grade levels above traditionally schooled children on standardized tests (n=37 home schooled children matched with children from the same socioeconomic and educational background).

Studies have also examined the impact of homeschooling on students' GPAs. Cogan (2010) found that homeschooled students had higher high school GPAs (3.74) and transfer GPAs (3.65) than conventional students. Snyder (2013) provided corroborating evidence that homeschoolers were outperforming their peers in the areas of standardized tests and overall GPAs. Looking beyond high school, a study by the 1990 National Home Education Research Institute (as cited by Wichers, 2001) found that at least 33% of home schooled students attended a four-year college, and 17% attended a two-year college. This same study examined the students after one year, finding that that 17% pursued higher education. Thus, the data indicates that homeschooling can also prepare students for success in higher education.

Homeschooled children may receive more individualized attention than students enrolled in traditional public schools. A 2011 study suggests that a structured environment could play a key role in homeschooler academic achievement. This means that parents were highly involved in their child's education and they were creating clear educational goals. In addition, these students were being offered organized lesson plans which are either self-made or purchased.

A study conducted by Ray (2010), indicates that the higher the level of parents' income, the more likely the homeschooled child is able to achieve academic success.

In the 1970s, Raymond and Dorothy Moore conducted four federally funded analyses of more than 8,000 early childhood studies, from which they published their original findings in "Better Late Than Early", 1975. This was followed by "School Can Wait", a repackaging of these same findings designed specifically for educational professionals. They concluded that, "where possible, children should be withheld from formal schooling until at least ages eight to ten." Their reason was that children "are not mature enough for formal school programs until their senses, coordination, neurological development and cognition are ready". They concluded that the outcome of forcing children into formal schooling is a sequence of "1) uncertainty as the child leaves the family nest early for a less secure environment, 2) puzzlement at the new pressures and restrictions of the classroom, 3) frustration because unready learning tools – senses, cognition, brain hemispheres, coordination – cannot handle the regimentation of formal lessons and the pressures they bring, 4) hyperactivity growing out of nerves and jitter, from frustration, 5) failure which quite naturally flows from the four experiences above, and 6) delinquency which is failure's twin and apparently for the same reason." According to the Moores, "early formal schooling is burning out our children. Teachers who attempt to cope with these youngsters also are burning out." Aside from academic performance, they think early formal schooling also destroys "positive sociability", encourages peer dependence, and discourages self-worth, optimism, respect for parents, and trust in peers. They believe this situation is particularly acute for boys because of their delay in maturity. The Moores cited a Smithsonian Report on the development of genius, indicating a requirement for "1) much time spent with warm, responsive parents and other adults, 2) very little time spent with peers, and 3) a great deal of free exploration under parental guidance." Their analysis suggested that children need "more of home and less of formal school", "more free exploration with... parents, and fewer limits of classroom and books", and "more old fashioned chores – children working with parents – and less attention to rivalry sports and amusements."

Along with positive school outcomes, homeschooled youth are also less likely to use and abuse illicit substances and are more likely to disapprove of using alcohol and marijuana.

There are claims that studies showing that homeschooled students do better on standardized tests do not compare with mandatory public-school testing.

By contrast, SAT and ACT tests are self-selected by homeschooled and formally schooled students alike. Some homeschoolers averaged higher scores on these college entrance tests in South Carolina. Other scores (1999 data) showed mixed results, for example showing higher levels for homeschoolers in English (homeschooled 23.4 vs national average 20.5) and reading (homeschooled 24.4 vs national average 21.4) on the ACT, but mixed scores in math (homeschooled 20.4 vs national average 20.7 on the ACT as opposed homeschooled 535 vs national average 511 on the 1999 SAT math).

Some advocates of homeschooling and educational choice counter with an input-output theory, pointing out that home educators expend only an average of $500–$600 a year on each student (not counting the cost of the parents' time), in comparison to $9,000–$10,000 (including the cost of staff time) for each public school student in the United States, which suggests home-educated students would be especially dominant on tests if afforded access to an equal commitment of tax-funded educational resources.

Many teachers and school districts oppose the idea of homeschooling. However, research has shown that homeschooled children often excel in many areas of academic endeavor. According to a study done on the homeschool movement, homeschoolers often achieve academic success and admission into elite universities. There is also evidence that most are remarkably well socialized. According to the National Home Education Research Institute president, Brian Ray, socialization is not a problem for homeschooling children, many of whom are involved in community sports, volunteer activities, book groups, or homeschool co-ops.

Using the Piers-Harris Children's Self-Concept Scale, John Taylor later found that, "while half of the conventionally schooled children scored at or below the 50th percentile (in self-concept), only 10.3% of the home-schooling children did so." He further stated that "the self-concept of home-schooling children is significantly higher statistically than that of children attending conventional school. This has implications in the areas of academic achievement and socialization which have been found to parallel self-concept. Regarding socialization, Taylor's results would mean that very few home-schooling children are socially deprived. He states that critics who speak out against homeschooling on the basis of social deprivation are actually addressing an area which favors homeschoolers.

In 2003, the National Home Education Research Institute conducted a survey of 7,300 U.S. adults who had been homeschooled (5,000 for more than seven years). Their findings included:

Opposition to homeschooling comes from some organizations of teachers and school districts. The National Education Association, a United States teachers' union and professional association, opposes homeschooling.

UC Berkeley political scientist Professor Robert Reich wrote in "The Civic Perils of Homeschooling" (2002) that homeschooling can probably result in biased students, as many homeschooling parents view the education of their children as a matter properly under their control and no one else's. A 2014 study showed that greater exposure to homeschooling was associated with more political tolerance. 

Gallup polls of American voters have shown a significant change in attitude in the last 20 years, from 73% opposed to home education in 1985 to 54% opposed in 2001. In 1988, when asked whether parents should have a right to choose homeschooling, 53 percent thought that they should, as revealed by another poll.

Homeschooling is legal in some countries. Countries with the most prevalent home education movements include Australia, Canada, New Zealand, the United Kingdom, Mexico, Chile and the United States. Some countries have highly regulated home education programs as an extension of the compulsory school system; others, such as Sweden, Germany and most European countries have outlawed it entirely. In other countries, while not restricted by law, homeschooling is not socially acceptable or considered desirable and is virtually non-existent.

Reasons for people choose to homeschool are sometimes lifestyle choices, some people choose to home educate so that they can travel and spend better time with their kids. Some children learn differently to the general crowd and can get bored or can struggle at school, where the teachers are unable to cater for the individuality of each child.

Homeschooling requires government registration, with different requirements from state to state. Some home educators prefer to be regulated, but others question whether the government has any legitimate authority to oversee the choices parents make to raise and educate their children. Curricular help is offered by the Australian Government.

Many organisations exist to help parents and teachers with home education. The HEA (Home Education Association) is one support organisation, having grown through local support networks. The HEA does not produce educational material, but offers support to families choosing to homeschool.

Homeschooling in South America has not taken hold as it has in North American countries of Canada and the United States. In 1824, Brazil permitted home education to take the place of traditional education for nearly 70 years. Many proposals were made in regards to the homeschooling regulations, but many of them were rejected. In 1990, however, The Statute of Children and Adolescents, or the Estatuto da Criança e Adolescente, prohibited homeschooling and did not recognize it as a legitimate form of education. A resurgence in the homeschooling movement, however, has encouraged congressman Lincoln Portela to introduce a new bill in 2013 that would allow children to be educated at home if parents followed state approved guidelines. The National Association of Home Education was founded in 2010 to achieve these goals. Rough estimates state that around 3,201 families are homeschooling in 2016. In 2018 the Supreme Court ruled that homeschooling was illegal, due in part to a lack of legislation regulating the practice.

Homeschooling is legal in all provinces and territories in Canada and has been for 40 years. The Ontario Education Act, for example, states in Section 21(2)(a) that "A person is excused from attendance at school if [...] the person is receiving education elsewhere". Canada is known as having some of the most comprehensive legal protections for homeschooling parents in the Americas. Some provinces have implemented policies that require parents to notify school boards of their decision to homeschool. Every province requires parents to notify the school system of their intent to withdraw their child from the public school system and to begin home education. Five of ten provinces additionally require parents to submit a detailed curriculum to the state. Seven of these provinces do not require the program to be monitored by the school board or other private school administrators, and only five provinces require routine inspection of home education. These policies, however, are not law; although Canadian legislators recognize the importance of state controls in the homeschooling environment, it is ultimately up to the parent to decide when and how to homeschool. Despite a positive environment that supports and encourages alternatives to traditional schooling, it is estimated that less than 0.5% of Canadian families were homeschooling in 2015. This number is probably inaccurate, however, as many parents do not report their decisions to homeschool.

Unlike the United States, where homeschooling is largely a consequence of religious conviction, a study of 1,600 families in 2003 found that Canadians primarily choose to homeschool out of a desire to provide better education. For those children whose parents decided to homeschool out of a desire to better education, a 2003 study found statistical significance between traditionally schooled and homeschooled students scores on standardized tests of writing, reading, and mathematics. A more recent 2011 study found that style of home education (structured versus unstructured) was a more important predictor of standardized test performance than other traditional measures, such as income and parents' educational attainment. These findings are similar to findings in U.S. research on homeschooled children and the outcomes of homeschooling.

One technique that is specifically Canadian, specifically British Columbian, is the Distributed Learning approach to home education. Distributed Learning is an online program that is directed by a teacher that meets provincial standards for education. The program draws on public and private curricula. This is distinctive to British Columbia because it is the only province that has Distributed Learning policy. It is one of the most popular forms of home education.

Homeschooling is legal in Israel, and requires acquiring a permission from the Ministry of Education. The permission involves a home visit from the person in charge of handing out the permissions, and writing a letter describing the motives, curriculum, daily routine and socialization of the children. Unschooling is legal, and the requirements are minimal. The reasons for homeschooling in Israel are very similar to those of the rest of the world, with the exception of religious motives, since religious schools are prevalent.
There is unclear information regarding the number of Homeschooling families, since not all families ask for permission, and many homeschool their children without enlisting. Estimates range between 500–1000 families.

Up until 1920, homeschooling in Germany was seen as an acceptable practice under certain circumstances. With the rise of the Weimar Republic and the Nazi regime, homeschooling was seen as an anti-nationalistic and subversive practice that could undermine children's loyalty to their country. The Reichsschulpflichtgesetz, implemented in 1938, effectively banned all homeschooling with criminal consequences for anyone found practicing. Homeschooling wouldn't become a public concept until the 1980s. In 1989, Helmut Stücher removed his children from the public school system to begin home schooling. Stücher and others who followed suit were fined, and some even lost child custody. It wasn't until the unification of Germany in 1990 that education law was reformed and homeschooling was allowed, but only under strict observation and extreme circumstances. There is no general exemption for religious or pedagogical reasons; exemptions are allowed for severe illness, children of diplomats, ad rarely for working children such as actors.

Germany has not endorsed homeschooling as other countries have. Its neighbors, Switzerland and Austria, have embraced the notion and are following similar paths as the United States and Canada.

Home education was outlawed in apartheid-era South Africa before 1994, and families were jailed for not sending their children to school. Most of the parents who were jailed have criminal records because of this. With the acceptance of the South African constitution in 1994, home education was legalised per implication. This was acknowledged with promulgation of the SA Schools Act of 1996 in which home education is accommodated in art. 51. Since home education was legalised, it has grown exponentially. According to the census count of 2011, there were about 57 000 home learners in the country, putting South Africa in the top five countries in terms of number of home learners.



</doc>
<doc id="13605" url="https://en.wikipedia.org/wiki?curid=13605" title="Heteroatom">
Heteroatom

In chemistry, a heteroatom (from Ancient Greek "heteros", "different", + "atomos", "uncut") is, strictly, any atom that is not carbon or hydrogen. 

In practice, the term is usually used more specifically, to indicate that non-carbon atoms have replaced carbon in the backbone of the molecular structure. Typical heteroatoms are nitrogen (N), oxygen (O), sulfur (S), phosphorus (P), chlorine (Cl), bromine (Br), and iodine (I), as well as the metals lithium and magnesium.

It can also be used with highly specific meanings in specialised contexts. In the description of protein structure, in particular in the Protein Data Bank file format, a heteroatom record (HETATM) describes an atom as belonging to a small molecule cofactor rather than being part of a biopolymer chain.

In the context of zeolites, the term "heteroatom" refers to partial isomorphous substitution of the typical framework atoms (silicon, aluminium, and phosphorus) by other elements such as beryllium, vanadium, and chromium. The goal is usually to adjust properties of the material (e.g., Lewis acidity) to optimize the material for a certain application (e.g., catalysis).



</doc>
<doc id="13606" url="https://en.wikipedia.org/wiki?curid=13606" title="Half-life">
Half-life

Half-life (symbol "t") is the time required for a quantity to reduce to half its initial value. The term is commonly used in nuclear physics to describe how quickly unstable atoms undergo, or how long stable atoms survive, radioactive decay. The term is also used more generally to characterize any type of exponential or non-exponential decay. For example, the medical sciences refer to the biological half-life of drugs and other chemicals in the human body. The converse of half-life is doubling time.

The original term, "half-life period", dating to Ernest Rutherford's discovery of the principle in 1907, was shortened to "half-life" in the early 1950s. Rutherford applied the principle of a radioactive element's half-life to studies of age determination of rocks by measuring the decay period of radium to lead-206.

Half-life is constant over the lifetime of an exponentially decaying quantity, and it is a characteristic unit for the exponential decay equation. The accompanying table shows the reduction of a quantity as a function of the number of half-lives elapsed.

A half-life usually describes the decay of discrete entities, such as radioactive atoms. In that case, it does not work to use the definition that states "half-life is the time required for exactly half of the entities to decay". For example, if there is just one radioactive atom, and its half-life is one second, there will "not" be "half of an atom" left after one second.

Instead, the half-life is defined in terms of probability: "Half-life is the time required for exactly half of the entities to decay "on average"". In other words, the "probability" of a radioactive atom decaying within its half-life is 50%.

For example, the image on the right is a simulation of many identical atoms undergoing radioactive decay. Note that after one half-life there are not "exactly" one-half of the atoms remaining, only "approximately", because of the random variation in the process. Nevertheless, when there are many identical atoms decaying (right boxes), the law of large numbers suggests that it is a "very good approximation" to say that half of the atoms remain after one half-life.

There are various simple exercises that demonstrate probabilistic decay, for example involving flipping coins or running a statistical computer program.

An exponential decay can be described by any of the following three equivalent formulas:
where

The three parameters , , and are all directly related in the following way:

where ln(2) is the natural logarithm of 2 (approximately 0.693).

Some quantities decay by two exponential-decay processes simultaneously. In this case, the actual half-life can be related to the half-lives "t" and "t" that the quantity would have if each of the decay processes acted in isolation:

For three or more processes, the analogous formula is:
For a proof of these formulas, see Exponential decay § Decay by two or more processes.

There is a half-life describing any exponential-decay process. For example:

The term "half-life" is almost exclusively used for decay processes that are exponential (such as radioactive decay or the other examples above), or approximately exponential (such as biological half-life discussed below). In a decay process that is not even close to exponential, the half-life will change dramatically while the decay is happening. In this situation it is generally uncommon to talk about half-life in the first place, but sometimes people will describe the decay in terms of its "first half-life", "second half-life", etc., where the first half-life is defined as the time required for decay from the initial value to 50%, the second half-life is from 50% to 25%, and so on.

A biological half-life or elimination half-life is the time it takes for a substance (drug, radioactive nuclide, or other) to lose one-half of its pharmacologic, physiologic, or radiological activity. In a medical context, the half-life may also describe the time that it takes for the concentration of a substance in blood plasma to reach one-half of its steady-state value (the "plasma half-life").

The relationship between the biological and plasma half-lives of a substance can be complex, due to factors including accumulation in tissues, active metabolites, and receptor interactions.

While a radioactive isotope decays almost perfectly according to so-called "first order kinetics" where the rate constant is a fixed number, the elimination of a substance from a living organism usually follows more complex chemical kinetics.

For example, the biological half-life of water in a human being is about 9 to 10 days, though this can be altered by behavior and various other conditions. The biological half-life of caesium in human beings is between one and four months.

The concept of a half-life has also been utilized for pesticides in plants, and certain authors maintain that pesticide risk and impact assessment models rely on and are sensitive to information describing dissipation from plants.




</doc>
<doc id="13607" url="https://en.wikipedia.org/wiki?curid=13607" title="Humus">
Humus

In soil science, humus (derived in 1790–1800 from the Latin "humus" for earth, ground) denominates the fraction of soil organic matter that is amorphous and without the "cellular cake structure characteristic of plants, micro-organisms or animals." Humus significantly affects the bulk density of soil and contributes to its retention of moisture and nutrients.

In agriculture, "humus" sometimes also is used to describe mature or natural compost extracted from a woodland or other spontaneous source for use as a soil conditioner. It is also used to describe a topsoil horizon that contains organic matter (humus type, humus form, humus profile).

Humus is the dark organic matter that forms in soil when dead plant and animal matter decays. Humus has many nutrients that improve the health of soil, nitrogen being the most important. The ratio of carbon to nitrogen (C:N) of humus is 10:1.

It is difficult to define humus precisely because it is a very complex substance which is not fully understood. Humus is different from decomposing soil organic matter. The latter looks rough and has visible remains of the original plant or animal matter. Fully humified humus, on the contrary, has a uniformly dark, spongy, and jelly-like appearance, and is amorphous; it may gradually decompose over several years or persist for millennia. It has no determinate shape, structure, or quality. However, when examined under a microscope, humus may reveal tiny plant, animal, or microbial remains that have been mechanically, but not chemically, degraded. This suggests an ambiguous boundary between humus and soil organic matter. While distinct, humus is an integral part of soil organic matter.

Microorganisms decompose a large portion of the soil organic matter into inorganic minerals that the roots of plants can absorb as nutrients. This process is termed "mineralization". In this process, nitrogen (nitrogen cycle) and the other nutrients (nutrient cycle) in the decomposed organic matter are recycled. Depending on the conditions in which the decomposition occurs, a fraction of the organic matter does not mineralize, and instead is transformed by a process called "humification" into concatenations of organic polymers. Because these organic polymers are resistant to the action of microorganisms, they are stable, and constitute "humus". This stability implies that humus integrates into the permanent structure of the soil, thereby improving it.

Humification can occur naturally in soil or artificially in the production of compost. Organic matter is humified by a combination of saprotrophic fungi, bacteria, microbes and animals such as earthworms, nematodes, protozoa, and arthropods. Plant remains, including those that animals digested and excreted, contain organic compounds: sugars, starches, proteins, carbohydrates, lignins, waxes, resins, and organic acids. Decay in the soil begins with the decomposition of sugars and starches from carbohydrates, which decompose easily as detritivores initially invade the dead plant organs, while the remaining cellulose and lignin decompose more slowly. Simple proteins, organic acids, starches, and sugars decompose rapidly, while crude proteins, fats, waxes, and resins remain relatively unchanged for longer periods of time. Lignin, which is quickly transformed by white-rot fungi, is one of the primary precursors of humus, together with by-products of microbial and animal activity. The humus produced by humification is thus a mixture of compounds and complex biological chemicals of plant, animal, or microbial origin that has many functions and benefits in soil. Some judge earthworm humus (vermicompost) to be the optimal organic manure.

Much of the humus in most soils has persisted for more than 100 years, rather than having been decomposed into CO, and can be regarded as stable; this organic matter has been protected from decomposition by microbial or enzyme action because it is hidden (occluded) inside small aggregates of soil particles, or tightly sorbed or complexed to clays. Most humus that is not protected in this way is decomposed within 10 years and can be regarded as less stable or more labile. Stable humus contributes few plant-available nutrients in soil, but it helps maintain its physical structure. A very stable form of humus is formed from the slow oxidation of soil carbon after the incorporation of finely powdered charcoal into the topsoil. This process is speculated to have been important in the formation of the very fertile Amazonian "terra preta do Indio".

Humus has a characteristic black or dark brown color and is organic due to an accumulation of organic carbon. Soil scientists use the capital letters O, A, B, C, and E to identify the master horizons, and lowercase letters for distinctions of these horizons. Most soils have three major horizons: the surface horizon (A), the subsoil (B), and the substratum (C). Some soils have an organic horizon (O) on the surface, but this horizon can also be buried. The master horizon (E) is used for subsurface horizons that have significantly lost minerals (eluviation). Bedrock, which is not soil, uses the letter R.

The importance of chemically stable humus is thought by some to be the fertility it provides to soils in both a physical and chemical sense, though some agricultural experts put a greater focus on other features of it, such as its ability to suppress disease. It helps the soil retain moisture by increasing microporosity, and encourages the formation of good soil structure. The incorporation of oxygen into large organic molecular assemblages generates many active, negatively charged sites that bind to positively charged ions (cations) of plant nutrients, making them more available to the plant by way of ion exchange. Humus allows soil organisms to feed and reproduce, and is often described as the "life-force" of the soil.




</doc>
<doc id="13609" url="https://en.wikipedia.org/wiki?curid=13609" title="Hydrogen bond">
Hydrogen bond

A hydrogen bond is a partially electrostatic force of attraction between a hydrogen (H) atom which is bound to a more electronegative atom or group, such as nitrogen (N), oxygen (O), or fluorine (F)—the hydrogen bond donor—and another adjacent atom bearing a lone pair of electrons—the hydrogen bond acceptor. Weak hydrogen bonds occur even with C-H groups as donor 

Hydrogen bonds can be intermolecular (occurring between separate molecules) or intramolecular (occurring among parts of the same molecule). Depending on the nature of the donor and acceptor atoms which constitute the bond, their geometry, and environment, the energy of a hydrogen bond can vary between 1 and 40 kcal/mol. This makes them somewhat stronger than a van der Waals interaction, and weaker than fully covalent or ionic bonds. This type of bond can occur in inorganic molecules such as water and in organic molecules like DNA and proteins.

Intermolecular hydrogen bonding is responsible for the high boiling point of water (100 °C) compared to the other group 16 hydrides that have much weaker hydrogen bonds. Intramolecular hydrogen bonding is partly responsible for the secondary and tertiary structures of proteins and nucleic acids. It also plays an important role in the structure of polymers, both synthetic and natural.

In 2011, an IUPAC Task Group recommended a modern evidence-based definition of hydrogen bonding, which was published in the IUPAC journal "Pure and Applied Chemistry". This definition specifies:

A hydrogen atom attached to a relatively electronegative atom is the hydrogen bond "donor". C-H bonds only participate in hydrogen bonding when the carbon atom is bound to electronegative substituents, as is the case in chloroform, CHCl. In a hydrogen bond, the electronegative atom not covalently attached to the hydrogen is named proton acceptor, whereas the one covalently bound to the hydrogen is named the proton donor. In the donor molecule, the H center is protic. The donor is a Lewis base. Hydrogen bonds are represented as H···Y system, where the dots represent the hydrogen bond. Liquids that display hydrogen bonding (such as water) are called associated liquids.

The hydrogen bond is often described as an electrostatic dipole-dipole interaction. However, it also has some features of covalent bonding: it is directional and strong, produces interatomic distances shorter than the sum of the van der Waals radii, and usually involves a limited number of interaction partners, which can be interpreted as a type of valence. These covalent features are more substantial when acceptors bind hydrogens from more electronegative donors.

Hydrogen bonds can vary in strength from weak (1–2 kJ mol) to strong (161.5 kJ mol in the ion ). Typical enthalpies in vapor include:
The strength of intermolecular hydrogen bonds is most often evaluated by measurements of equilibria between molecules containing donor and/or acceptor units, most often in solution. The strength of intramolecular hydrogen bonds can be studied with equilibria between conformers with and without hydrogen bonds. The most important method for the identification of hydrogen bonds also in complicated molecules is crystallography, sometimes also NMR-spectroscopy. Structural details, in particular distances between donor and acceptor which are smaller than the sum of the van der Waals radii can be taken as indication of the hydrogen bond strength.

The X−H distance is typically ≈110 pm, whereas the H···Y distance is ≈160 to 200 pm. The typical length of a hydrogen bond in water is 197 pm. The ideal bond angle depends on the nature of the hydrogen bond donor. The following hydrogen bond angles between a hydrofluoric acid donor and various acceptors have been determined experimentally:
Strong hydrogen bonds are revealed by downfield shifts in the H NMR spectrum. For example, the acidic proton in the enol tautomer of acetylacetone appears at δ15.5, which is about 10 ppm downfield of a conventional alcohol.

In the IR spectrum, hydrogen bonding shifts the X-H stretching frequency to lower energy (i.e. the vibration frequency decreases). This shift reflects a weakening of the X-H bond. Certain hydrogen bonds - improper hydrogen bonds - show a blue shift of the X-H stretching frequency and a decrease in the bond length.

Hydrogen bonding is of continuing theoretical interest. According to a modern description O:H-O integrates both the intermolecular O:H lone pair ":" nonbond and the intramolecular H-O polar-covalent bond associated with O-O repulsive coupling.

Quantum chemical calculations of the relevant interresidue potential constants (compliance constants) revealed large differences between individual H bonds of the same type. For example, the central interresidue N−H···N hydrogen bond between guanine and cytosine is much stronger in comparison to the N−H···N bond between the adenine-thymine pair.

Theoretically, the bond strength of the hydrogen bonds can be assessed using NCI index, non-covalent interactions index, which allows a visualization of these non-covalent interactions, as its name indicases, using the electron density of the system.

From interpretations of the anisotropies in the Compton profile of ordinary ice that the hydrogen bond is partly covalent. However, this interpretation was challenged.

Most generally, the hydrogen bond can be viewed as a metric-dependent electrostatic scalar field between two or more intermolecular bonds. This is slightly different from the intramolecular bound states of, for example, covalent or ionic bonds; however, hydrogen bonding is generally still a bound state phenomenon, since the interaction energy has a net negative sum. The initial theory of hydrogen bonding proposed by Linus Pauling suggested that the hydrogen bonds had a partial covalent nature. This interpretation remained controversial until NMR techniques demonstrated information transfer between hydrogen-bonded nuclei, a feat that would only be possible if the hydrogen bond contained some covalent character.

The concept of hydrogen bonding once was challenging. Linus Pauling credits T. S. Moore and T. F. Winmill with the first mention of the hydrogen bond, in 1912. Moore and Winmill used the hydrogen bond to account for the fact that trimethylammonium hydroxide is a weaker base than tetramethylammonium hydroxide. The description of hydrogen bonding in its better-known setting, water, came some years later, in 1920, from Latimer and Rodebush. In that paper, Latimer and Rodebush cite work by a fellow scientist at their laboratory, Maurice Loyal Huggins, saying, "Mr. Huggins of this laboratory in some work as yet unpublished, has used the idea of a hydrogen kernel held between two atoms as a theory in regard to certain organic compounds."

A ubiquitous example of a hydrogen bond is found between water molecules. In a discrete water molecule, there are two hydrogen atoms and one oxygen atom. Two molecules of water can form a hydrogen bond between them that is to say oxygen-hydrogen bonding; the simplest case, when only two molecules are present, is called the water dimer and is often used as a model system. When more molecules are present, as is the case with liquid water, more bonds are possible because the oxygen of one water molecule has two lone pairs of electrons, each of which can form a hydrogen bond with a hydrogen on another water molecule. This can repeat such that every water molecule is H-bonded with up to four other molecules, as shown in the figure (two through its two lone pairs, and two through its two hydrogen atoms). Hydrogen bonding strongly affects the crystal structure of ice, helping to create an open hexagonal lattice. The density of ice is less than the density of water at the same temperature; thus, the solid phase of water floats on the liquid, unlike most other substances.

Liquid water's high boiling point is due to the high number of hydrogen bonds each molecule can form, relative to its low molecular mass. Owing to the difficulty of breaking these bonds, water has a very high boiling point, melting point, and viscosity compared to otherwise similar liquids not conjoined by hydrogen bonds. Water is unique because its oxygen atom has two lone pairs and two hydrogen atoms, meaning that the total number of bonds of a water molecule is up to four.

The number of hydrogen bonds formed by a molecule of liquid water fluctuates with time and temperature. From TIP4P liquid water simulations at 25 °C, it was estimated that each water molecule participates in an average of 3.59 hydrogen bonds. At 100 °C, this number decreases to 3.24 due to the increased molecular motion and decreased density, while at 0 °C, the average number of hydrogen bonds increases to 3.69. A more recent study found a much smaller number of hydrogen bonds: 2.357 at 25 °C. The differences may be due to the use of a different method for defining and counting the hydrogen bonds.

Where the bond strengths are more equivalent, one might instead find the atoms of two interacting water molecules partitioned into two polyatomic ions of opposite charge, specifically hydroxide (OH) and hydronium (HO). (Hydronium ions are also known as "hydroxonium" ions.)

Indeed, in pure water under conditions of standard temperature and pressure, this latter formulation is applicable only rarely; on average about one in every 5.5 × 10 molecules gives up a proton to another water molecule, in accordance with the value of the dissociation constant for water under such conditions. It is a crucial part of the uniqueness of water.

Because water may form hydrogen bonds with solute proton donors and acceptors, it may competitively inhibit the formation of solute intermolecular or intramolecular hydrogen bonds. Consequently, hydrogen bonds between or within solute molecules dissolved in water are almost always unfavorable relative to hydrogen bonds between water and the donors and acceptors for hydrogen bonds on those solutes. Hydrogen bonds between water molecules have an average lifetime of 10 seconds, or 10 picoseconds.

A single hydrogen atom can participate in two hydrogen bonds, rather than one. This type of bonding is called "bifurcated" (split in two or "two-forked"). It can exist, for instance, in complex natural or synthetic organic molecules. It has been suggested that a bifurcated hydrogen atom is an essential step in water reorientation.
Acceptor-type hydrogen bonds (terminating on an oxygen's lone pairs) are more likely to form bifurcation (it is called overcoordinated oxygen, OCO) than are donor-type hydrogen bonds, beginning on the same oxygen's hydrogens.

For example, hydrogen fluoride—which has three lone pairs on the F atom but only one H atom—can form only two bonds; (ammonia has the opposite problem: three hydrogen atoms but only one lone pair).


Hydrogen bonding plays an important role in determining the three-dimensional structures and the properties adopted by many synthetic and natural proteins.

In these macromolecules, bonding between parts of the same macromolecule cause it to fold into a specific shape, which helps determine the molecule's physiological or biochemical role. For example, the double helical structure of DNA is due largely to hydrogen bonding between its base pairs (as well as pi stacking interactions), which link one complementary strand to the other and enable replication.

In the secondary structure of proteins, hydrogen bonds form between the backbone oxygens and amide hydrogens. When the spacing of the amino acid residues participating in a hydrogen bond occurs regularly between positions "i" and "i" + 4, an alpha helix is formed. When the spacing is less, between positions "i" and "i" + 3, then a 3 helix is formed. When two strands are joined by hydrogen bonds involving alternating residues on each participating strand, a beta sheet is formed. Hydrogen bonds also play a part in forming the tertiary structure of protein through interaction of R-groups. (See also protein folding).

Bifurcated H-bond systems are common in alpha-helical transmembrane proteins between the backbone amide C=O of residue "i" as the H-bond acceptor and two H-bond donors from residue "i+4": the backbone amide N-H and a side-chain hydroxyl or thiol H. The energy preference of the bifurcated H-bond hydroxyl or thiol system is -3.4 kcal/mol or -2.6 kcal/mol, respectively. This type of bifurcated H-bond provides an intrahelical H-bonding partner for polar side-chains, such as serine, threonine, and cysteine within the hydrophobic membrane environments.

The role of hydrogen bonds in protein folding has also been linked to osmolyte-induced protein stabilization. Protective osmolytes, such as trehalose and sorbitol, shift the protein folding equilibrium toward the folded state, in a concentration dependent manner. While the prevalent explanation for osmolyte action relies on excluded volume effects that are entropic in nature, recent circular dichroism (CD) experiments have shown osmolyte to act through an enthalpic effect. The molecular mechanism for their role in protein stabilization is still not well established, though several mechanisms have been proposed. Recently, computer molecular dynamics simulations suggested that osmolytes stabilize proteins by modifying the hydrogen bonds in the protein hydration layer.

Several studies have shown that hydrogen bonds play an important role for the stability between subunits in multimeric proteins. For example, a study of sorbitol dehydrogenase displayed an important hydrogen bonding network which stabilizes the tetrameric quaternary structure within the mammalian sorbitol dehydrogenase protein family.

A protein backbone hydrogen bond incompletely shielded from water attack is a dehydron. Dehydrons promote the removal of water through proteins or ligand binding. The exogenous dehydration enhances the electrostatic interaction between the amide and carbonyl groups by de-shielding their partial charges. Furthermore, the dehydration stabilizes the hydrogen bond by destabilizing the nonbonded state consisting of dehydrated isolated charges.

Wool, being a protein fibre, is held together by hydrogen bonds, causing wool to recoil when stretched. However, washing at high temperatures can permanently break the hydrogen bonds and a garment may permanently lose its shape.

Hydrogen bonds are important in the structure of cellulose and derived polymers in its many different forms in nature, such as cotton and flax.

Many polymers are strengthened by hydrogen bonds within and between the chains. Among the synthetic polymers, a well characterized example is nylon, where hydrogen bonds occur in the repeat unit and play a major role in crystallization of the material. The bonds occur between carbonyl and amine groups in the amide repeat unit. They effectively link adjacent chains, which help reinforce the material. The effect is great in aramid fibre, where hydrogen bonds stabilize the linear chains laterally. The chain axes are aligned along the fibre axis, making the fibres extremely stiff and strong.

The hydrogen-bond networks make both natural and synthetic polymers sensitive to humidity levels in the atmosphere because water molecules can diffuse into the surface and disrupt the network. Some polymers are more sensitive than others. Thus nylons are more sensitive than aramids, and nylon 6 more sensitive than nylon-11.

A symmetric hydrogen bond is a special type of hydrogen bond in which the proton is spaced exactly halfway between two identical atoms. The strength of the bond to each of those atoms is equal. It is an example of a three-center four-electron bond. This type of bond is much stronger than a "normal" hydrogen bond. The effective bond order is 0.5, so its strength is comparable to a covalent bond. It is seen in ice at high pressure, and also in the solid phase of many anhydrous acids such as hydrofluoric acid and formic acid at high pressure. It is also seen in the bifluoride ion [F−H−F].

Symmetric hydrogen bonds have been observed recently spectroscopically in formic acid at high pressure (>GPa). Each hydrogen atom forms a partial covalent bond with two atoms rather than one. Symmetric hydrogen bonds have been postulated in ice at high pressure (Ice X). Low-barrier hydrogen bonds form when the distance between two heteroatoms is very small.

The hydrogen bond can be compared with the closely related dihydrogen bond, which is also an intermolecular bonding interaction involving hydrogen atoms. These structures have been known for some time, and well characterized by crystallography; however, an understanding of their relationship to the conventional hydrogen bond, ionic bond, and covalent bond remains unclear. Generally, the hydrogen bond is characterized by a proton acceptor that is a lone pair of electrons in nonmetallic atoms (most notably in the nitrogen, and chalcogen groups). In some cases, these proton acceptors may be pi-bonds or metal complexes. In the dihydrogen bond, however, a metal hydride serves as a proton acceptor, thus forming a hydrogen-hydrogen interaction. Neutron diffraction has shown that the molecular geometry of these complexes is similar to hydrogen bonds, in that the bond length is very adaptable to the metal complex/hydrogen donor system.

The dynamics of hydrogen bond structures in water can be probed by the IR spectrum of OH stretching vibration. In the hydrogen bonding network in protic organic ionic plastic crystals (POIPCs), which are a type of phase change material exhibiting solid-solid phase transitions prior to melting, variable-temperature infrared spectroscopy can reveal the temperature dependence of hydrogen bonds and the dynamics of both the anions and the cations. The sudden weakening of hydrogen bonds during the solid-solid phase transition seems to be coupled with the onset of orientational or rotational disorder of the ions.

Hydrogen bonding is a key to the design of drugs. According to Lipinski's rule of five the majority of orally active drug tend to have between five and ten hydrogen bonds. These interactions exist between nitrogen–hydrogen and oxygen–hydrogen centers. As with many other rules of thumb, many exceptions exist.





</doc>
<doc id="13610" url="https://en.wikipedia.org/wiki?curid=13610" title="Heraldry">
Heraldry

Heraldry () is a broad term, encompassing the design, display, and study of armorial bearings (known as "armory"), as well as related disciplines, such as vexillology, together with the study of ceremony, rank, and pedigree. Armory, the best-known branch of heraldry, concerns the design and transmission of the heraldic achievement. The achievement, or armorial bearings usually includes a coat of arms on an shield, helmet, and crest, together with any accompanying devices, such as supporters, badges, heraldic banners, and mottoes.

Although the use of various devices to signify individuals and groups goes back to antiquity, both the form and use of such devices varied widely, and the concept of regular, hereditary designs, constituting the distinguishing feature of heraldry, did not develop until the High Middle Ages. It is very often fairly that the use of helmets with face guards during this period made it difficult to recognize one's commanders in the field when large armies gathered together for extended periods, necessitating the development of heraldry as a symbolic language but there is very little actual support for this view.

The beauty and pageantry of heraldic designs allowed them to survive the gradual abandonment of armour on the battlefield during the seventeenth century. Heraldry has been described poetically as "the handmaid of history", "the shorthand of history", and "the floral border in the garden of history". In modern times, individuals, public and private organizations, corporations, cities, towns, and regions use heraldry and its conventions to symbolize their heritage, achievements, and aspirations.

Various symbols have been used to represent individuals or groups for thousands of years. The earliest representations of distinct persons and regions in Egyptian art show the use of standards topped with the images or symbols of various gods, and the names of kings appear upon emblems known as serekhs, representing the king's palace, and usually topped with a falcon representing the god Horus, of whom the king was regarded as the earthly incarnation. Similar emblems and devices are found in ancient Mesopotamian art of the same period, and the precursors of heraldic beasts such as the griffin can also be found. In the Bible, the Book of Numbers refers to the standards and ensigns of the children of Israel, who were commanded to gather beneath these emblems and declare their pedigrees. The Greek and Latin writers frequently describe the shields and symbols of various heroes, and units of the Roman army were sometimes identified by distinctive markings on their shields.

Until the nineteenth century, it was common for heraldic writers to cite examples such as these, and metaphorical symbols such as the "Lion of Judah" or "Eagle of the Caesars" as evidence of the antiquity of heraldry itself; and to infer therefrom that the great figures of ancient history bore arms representing their noble status and descent. The Book of Saint Albans, compiled in 1486, declares that Christ himself was a gentleman of coat armour. But these fabulous claims have long since been dismissed as the fantasy of medieval heralds, for there is no evidence of a distinctive symbolic language akin to that of heraldry during this early period; nor do many of the shields described in antiquity bear a close resemblance to those of medieval heraldry; nor is there any evidence that specific symbols or designs were passed down from one generation to the next, representing a particular person or line of descent.

The medieval heralds also devised arms for various knights and lords from history and literature. Notable examples include the toads attributed to Pharamond, the cross and martlets of Edward the Confessor, and the various arms attributed to the Nine Worthies and the Knights of the Round Table. These too are now regarded as a fanciful invention, rather than evidence of the antiquity of heraldry.

The development of the modern heraldic language cannot be attributed to a single individual, time, or place. Although certain designs that are now considered heraldic were evidently in use during the eleventh century, most accounts and depictions of shields up to the beginning of the twelfth century contain little or no evidence of their heraldic character. For example, the Bayeux Tapestry, illustrating the Norman invasion of England in 1066, and probably commissioned about 1077, when the cathedral of Bayeux was rebuilt, depicts a number of shields of various shapes and designs, many of which are plain, while others are decorated with dragons, crosses, or other typically heraldic figures. Yet no individual is depicted twice bearing the same arms, nor are any of the descendants of the various persons depicted known to have borne devices resembling those in the tapestry.

Similarly, an account of the French knights at the court of the Byzantine emperor Alexius I at the beginning of the twelfth century describes their shields of polished metal, utterly devoid of heraldic design. A Spanish manuscript from 1109 describes both plain and decorated shields, none of which appears to have been heraldic. The Abbey of St. Denis contained a window commemorating the knights who embarked on the Second Crusade in 1147, and was probably made soon after the event; but Montfaucon's illustration of the window before it was destroyed shows no heraldic design on any of the shields.

In England, from the time of the Norman conquest, official documents had to be sealed. Beginning in the twelfth century, seals assumed a distinctly heraldic character; a number of seals dating from between 1135 and 1155 appear to show the adoption of heraldic devices in England, France, Germany, Spain, and Italy. A notable example of an early armorial seal is attached to a charter granted by Philip I, Count of Flanders, in 1164. Seals from the latter part of the eleventh and early twelfth centuries show no evidence of heraldic symbolism, but by the end of the twelfth century, seals are uniformly heraldic in nature.

One of the earliest known examples of armory as it subsequently came to be practiced can be seen on the tomb of Geoffrey Plantagenet, Count of Anjou, who died in 1151. An enamel, probably commissioned by Geoffrey's widow between 1155 and 1160, depicts him carrying a blue shield decorated with six golden lions rampant. He wears a blue helmet adorned with another lion, and his cloak is lined in vair. A medieval chronicle states that Geoffrey was given a shield of this description when he was knighted by his father-in-law, Henry I, in 1128; but this account probably dates to about 1175.

The earlier heraldic writers attributed the lions of England to William the Conqueror, but the earliest evidence of the association of lions with the English crown is a seal bearing two lions passant, used by the future King John during the lifetime of his father, Henry II, who died in 1189. Since Henry was the son of Geoffrey Plantagenet, it seems reasonable to suppose that the adoption of lions as an heraldic emblem by Henry or his sons might have been inspired by Geoffrey's shield. John's elder brother, Richard the Lionheart, who succeeded his father on the throne, is believed to have been the first to have borne the arms of three lions passant-guardant, still the arms of England, having earlier used two lions rampant combatant, which arms may also have belonged to his father. Richard is also credited with having originated the English crest of a lion statant (now statant-guardant).

The origins of heraldry are sometimes associated with the Crusades, a series of military campaigns undertaken by Christian armies from 1096 to 1487, with the goal of reconquering Jerusalem and other former Byzantine territories captured by Muslim forces during the seventh century. While there is no evidence that heraldic art originated in the course of the Crusades, there is no reason to doubt that the gathering of large armies, drawn from across Europe for a united cause, would have encouraged the adoption of armorial bearings as a means of identifying one's commanders in the field, or that it helped disseminate the principles of armory across Europe. At least two distinctive features of heraldry are generally accepted as products of the crusaders: the surcoat, an outer garment worn over the armor to protect the wearer from the heat of the sun, was often decorated with the same devices that appeared on a knight's shield. It is from this garment that the phrase "coat of arms" is derived. Also the lambrequin, or mantling, that depends from the helmet and frames the shield in modern heraldry, began as a practical covering for the helmet and the back of the neck during the Crusades, serving much the same function as the surcoat. Its slashed or scalloped edge, today rendered as billowing flourishes, is thought to have originated from hard wearing in the field, or as a means of deadening a sword blow and perhaps entangling the attacker's weapon.

The spread of armorial bearings across Europe soon gave rise to a new occupation: the herald, originally a type of messenger employed by noblemen, assumed the responsibility of learning and knowing the rank, pedigree, and heraldic devices of various knights and lords, as well as the rules and protocols governing the design and description, or "blazoning" of arms, and the precedence of their bearers. As early as the late thirteenth century, certain heralds in the employ of monarchs were given the title "King of Heralds", which eventually became "King of Arms."
In the earliest period, arms were assumed by their bearers without any need for heraldic authority. However, by the middle of the fourteenth century, the principle that only a single individual was entitled to bear a particular coat of arms was generally accepted, and disputes over the ownership of arms seems to have led to gradual establishment of heraldic authorities to regulate their use. The earliest known work of heraldic jurisprudence, "De Insigniis et Armis", was written about 1350 by Bartolus de Saxoferrato, a professor of law at the University of Padua. The most celebrated armorial dispute in English heraldry is that of "Scrope v Grosvenor" (1390), in which two different men claimed the right to bear "azure, a bend or". The continued proliferation of arms, and the number of disputes arising from different men assuming the same arms, led Henry V to issue a proclamation in 1419, forbidding all those who had not borne arms at the Battle of Agincourt from assuming arms, except by inheritance or a grant from the crown.

Beginning in the reign of Henry VIII of England, the English Kings of Arms were commanded to make "visitations", in which they traveled about the country, recording arms borne under proper authority, and requiring those who bore arms without authority either to obtain authority for them, or cease their use. Arms borne improperly were to be taken down and defaced. The first such visitation began in 1530, and the last was carried out in 1700, although no new commissions to carry out visitations were made after the accession of William III in 1689.. There is very little evidence that Scots herald ever went on visitations.

In 1484, during the reign of Richard III, the various heralds employed by the crown were incorporated into England’s College of Arms, through which all new grants of arms would eventually be issued. The college currently consists of three Kings of Arms, assisted by six Heralds, and four Pursuivants, or junior officers of arms, all under the authority of the Earl Marshal; but all of the arms granted by the college are granted by the authority of the crown. In Scotland Court of the Lord Lyon King of Arms oversees the heraldry, and holds court sessions which are an official part of Scotland’s court system.
Similar bodies regulate the granting of arms in other monarchies and several members of the Commonwealth of Nations, but in most other countries there is no heraldic authority, and no law preventing anyone from assuming whatever arms they please, provided that they do not infringe upon the arms of another.

Although heraldry originated from military necessity, it soon found itself at home in the pageantry of the medieval tournament. The opportunity for knights and lords to display their heraldic bearings in a competitive medium led to further refinements, such as the development of elaborate tournament helms, and further popularized the art of heraldry throughout Europe. Prominent burghers and corporations, including many cities and towns, assumed or obtained grants of arms, with only nominal military associations. Heraldic devices were depicted in various contexts, such as religious and funerary art, and in using a wide variety of media, including stonework, carved wood, enamel, stained glass, and embroidery.

As the rise of firearms rendered the mounted knight increasingly irrelevant on the battlefield during the sixteenth and seventeenth centuries, and the tournament faded into history, the military character of heraldry gave way to its use as a decorative art. Freed from the limitations of actual shields and the need for arms to be easily distinguished in combat, heraldic artists designed increasingly elaborate achievements, culminating in the development of "landscape heraldry", incorporating realistic depictions of landscapes, during the latter part of the eighteenth and early part of the nineteenth century. These fell out of fashion during the mid-nineteenth century, when a renewed interest in the history of armory led to the re-evaluation of earlier designs, and a new appreciation for the medieval origins of the art. Since the late nineteenth century, heraldry has focused on the use of varied lines of partition and little-used ordinaries to produce new and unique designs.

A heraldic achievement consists of a shield of arms the coat of arms, or simply coat, together with all of its accompanying elements, such as a crest, supporters, and other heraldic embellishments. The term "coat of arms" technically refers to the shield of arms itself, but the phrase is commonly used to refer to the entire achievement. The one indispensable element of a coat of arms is the shield; many ancient coats of arms consist of nothing else, but no achievement or armorial bearings exists without a coat of arms.

From a very early date, illustrations of arms were frequently embellished with helmets placed above the shields. These in turn came to be decorated with fan-shaped or sculptural crests, often incorporating elements from the shield of arms; as well as a wreath or torse, or sometimes a coronet, from which depended the lambrequin or mantling. To these elements, modern heraldry often adds a motto displayed on a ribbon, typically below the shield. The helmet is borne of right, and forms no part of a grant of arms; it may be assumed without authority by anyone entitled to bear arms, together with mantling and whatever motto the armiger may desire. The crest, however, together with the torse or coronet from which it arises, must be granted or confirmed by the relevant heraldic authority.

If the bearer is entitled to the ribbon, collar, or badge of a knightly order, it may encircle or depend from the shield. Some arms, particularly those of the nobility, are further embellished with supporters, heraldic figures standing alongside or behind the shield; often these stand on a compartment, typically a mound of earth and grass, on which other badges, symbols, or heraldic banners may be displayed. The most elaborate achievements sometimes display the entire coat of arms beneath a pavilion, an embellished tent or canopy of the type associated with the medieval tournament., though this only very very rarely found in English or Scots achievements.

The primary element of an heraldic achievement is the shield, or escutcheon, upon which the coat of arms is depicted. All of the other elements of an achievement are designed to decorate and complement these arms, but only the shield of arms is required. The shape of the shield, like many other details, is normally left to the discretion of the heraldic artist, and many different shapes have prevailed during different periods of heraldic design, and in different parts of Europe.

One shape alone is normally reserved for a specific purpose: the lozenge, a diamond-shaped escutcheon, was traditionally used to display the arms of women, on the grounds that shields, as implements of war, were inappropriate for this purpose. This distinction was not always strictly adhered to, and a general exception was usually made for sovereigns, whose arms represented an entire nation. Sometimes an oval shield, or cartouche, was substituted for the lozenge; this shape was also widely used for the arms of clerics in French, Spanish, and Italian heraldry, although it was never reserved for their use. In recent years, the use of the cartouche for women's arms has become general in Scottish heraldry, while both Scottish and Irish authorities have permitted a traditional shield under certain circumstances, and in Canadian heraldry the shield is now regularly granted.

The whole surface of the escutcheon is termed the field, which may be plain, consisting of a single tincture, or divided into multiple sections of differing tinctures by various lines of partition; and any part of the field may be "semé", or powdered with small charges. The edges and adjacent parts of the escutcheon are used to identify the placement of various heraldic charges; the upper edge, and the corresponding upper third of the shield, are referred to as the chief; the lower part is the base. The sides of the shield are known as the dexter and sinister flanks, although it is important to note that these terms are based on the point of view of the bearer of the shield, who would be standing behind it; accordingly the side which is to the bearer's right is the dexter, and the side to the bearer's left is the sinister, although to the observer, and in all heraldic illustration, the dexter is on the left side, and the sinister on the right.

The placement of various charges may also refer to a number of specific points, nine in number according to some authorities, but eleven according to others. The three most important are "fess point", located in the visual center of the shield; the "honour point", located midway between fess point and the chief; and the "nombril point", located midway between fess point and the base. The other points include "dexter chief", "center chief", and "sinister chief", running along the upper part of the shield from left to right, above the honour point; "dexter flank" and "sinister flank", on the sides approximately level with fess point; and "dexter base", "middle base", and "sinister base" along the lower part of the shield, below the nombril point.

One of the most distinctive qualities of heraldry is the use of a limited palette of colours and patterns, usually referred to as tinctures. These are divided into three categories, known as "metals", "colours", and "furs".

The metals are "or" and "argent", representing gold and silver, respectively, although in practice they are usually depicted as yellow and white. Five colours are universally recognized: "gules", or red; "sable", or black; "azure", or blue; "vert", or green; and "purpure", or purple; and most heraldic authorities also admit two additional colours, known as "sanguine" or "murrey", a dark red or mulberry colour between gules and purpure, and "tenné", an orange or dark yellow to brown colour. These last two are quite rare, and are often referred to as "stains", from the belief that they were used to represent some dishonourable act, although in fact there is no evidence that this use existed outside the imagination of the more fanciful heraldic writers. Perhaps owing to the realization that there is really no such thing as a "stain" in genuine heraldry, as well as the desire to create new and unique designs, the use of these colours for general purposes has become accepted in the twentieth and twenty-first centuries. Occasionally one meets with other colours, particularly in continental heraldry, although they are not generally regarded among the standard heraldic colours. Among these are "cendrée", or ash-colour; "brunâtre", or brown; "bleu-céleste" or "bleu de ciel", sky blue; "amaranth" or "columbine", a bright violet-red or pink colour; and "carnation", commonly used to represent flesh in French heraldry. A more recent addition is the use of "copper" as a metal in one or two Canadian coats of arms.

There are two basic types of heraldic fur, known as ermine and vair, but over the course of centuries each has developed a number of variations. Ermine represents the fur of the stoat, a type of weasel, in its white winter coat, when it is called an ermine. It consists of a white, or occasionally silver field, powdered with black figures known as "ermine spots", representing the black tip of the animal's tail. Ermine was traditionally used to line the cloaks and caps of the nobility. The shape of the heraldic ermine spot has varied considerably over time, and nowadays is typically drawn as an arrowhead surmounted by three small dots, but older forms may be employed at the artist's discretion. When the field is sable and the ermine spots argent, the same pattern is termed "ermines"; when the field is "or" rather than argent, the fur is termed "erminois"; and when the field is sable and the ermine spots "or", it is termed "pean".

Vair represents the winter coat of the red squirrel, which is blue-grey on top and white underneath. To form the linings of cloaks, the pelts were sewn together, forming an undulating, bell-shaped pattern, with interlocking light and dark rows. The heraldic fur is depicted with interlocking rows of argent and azure, although the shape of the pelts, usually referred to as "vair bells", is usually left to the artist's discretion. In the modern form, the bells are depicted with straight lines and sharp angles, and meet only at points; in the older, undulating pattern, now known as "vair ondé" or "vair ancien", the bells of each tincture are curved and joined at the base. There is no fixed rule as to whether the argent bells should be at the top or the bottom of each row. At one time vair commonly came in three sizes, and this distinction is sometimes encountered in continental heraldry; if the field contains fewer than four rows, the fur is termed "gros vair" or "beffroi"; if of six or more, it is "menu-vair", or miniver.

A common variation is "counter-vair", in which alternating rows are reversed, so that the bases of the vair bells of each tincture are joined to those of the same tincture in the row above or below. When the rows are arranged so that the bells of each tincture form vertical columns, it is termed "vair in pale"; in continental heraldry one may encounter "vair in bend", which is similar to vair in pale, but diagonal. When alternating rows are reversed as in counter-vair, and then displaced by half the width of one bell, it is termed "vair in point", or wave-vair. A form peculiar to German heraldry is "alternate vair", in which each vair bell is divided in half vertically, with half argent and half azure. All of these variations can also be depicted in the form known as "potent", in which the shape of the vair bell is replaced by a "T"-shaped figure, known as a potent from its resemblance to a crutch. Although it is really just a variation of vair, it is frequently treated as a separate fur.

When the same patterns are composed of tinctures other than argent and azure, they are termed "vairé" or "vairy" of those tinctures, rather than "vair"; "potenté" of other colours may also be found. Usually vairé will consist of one metal and one colour, but ermine or one of its variations may also be used, and vairé of four tinctures, usually two metals and two colours, is sometimes found.

Three additional furs are sometimes encountered in continental heraldry; in French and Italian heraldry one meets with "plumeté" or "plumetty", in which the field appears to be covered with feathers, and "papelonné", in which it is decorated with scales. In German heraldry one may encounter "kursch", or vair bellies, depicted as brown and furry; all of these probably originated as variations of vair.

Considerable latitude is given to the heraldic artist in depicting the heraldic tinctures; there is no fixed shade or hue to any of them.

Whenever an object is depicted as it appears in nature, rather than in one or more of the heraldic tinctures, it is termed "proper", or the colour of nature. This does not seem to have been done in the earliest heraldry, but examples are known from at least the seventeenth century. While there can be no objection to the occasional depiction of objects in this manner, the overuse of charges in their natural colours is often cited as indicative of bad heraldic practice. The much-maligned practice of landscape heraldry, which flourished in the latter part of the eighteenth and early part of the nineteenth century, made extensive use of such non-heraldic colours.

One of the most important conventions of heraldry is the so-called "rule of tincture". To provide for contrast and visibility, metals should never be placed on metals, and colours should never be placed on colours. This rule does not apply to charges which cross a division of the field, which is partly metal and partly colour; nor, strictly speaking, does it prevent a field from consisting of two metals or two colours, although this is unusual. Furs are considered amphibious, and neither metal nor colour; but in practice ermine and erminois are usually treated as metals, while ermines and pean are treated as colours. This rule is strictly adhered to in British armory, with only rare exceptions; although generally observed in continental heraldry, it is not adhered to quite as strictly. Arms which violate this rule are sometimes known as "puzzle arms", of which the most famous example is the arms of the Kingdom of Jerusalem, consisting of gold crosses on a silver field.

The field of a shield, or less often a charge or crest, is sometimes made up of a pattern of colours, or "variation". A pattern of horizontal (barwise) stripes, for example, is called "barry", while a pattern of vertical (palewise) stripes is called "paly". A pattern of diagonal stripes may be called "bendy" or "bendy sinister", depending on the direction of the stripes. Other variations include "chevrony", "gyronny" and "chequy". Wave shaped stripes are termed "undy". For further variations, these are sometimes combined to produce patterns of "barry-bendy", "paly-bendy", "lozengy" and "fusilly". Semés, or patterns of repeated charges, are also considered variations of the field. The Rule of tincture applies to all semés and variations of the field.

The field of a shield in heraldry can be divided into more than one tincture, as can the various heraldic charges. Many coats of arms consist simply of a division of the field into two contrasting tinctures. These are considered divisions of a shield, so the rule of tincture can be ignored. For example, a shield divided azure and gules would be perfectly acceptable. A line of partition may be straight or it may be varied. The variations of partition lines can be wavy, indented, embattled, engrailed, nebuly, or made into myriad other forms; see Line (heraldry).

In the early days of heraldry, very simple bold rectilinear shapes were painted on shields. These could be easily recognized at a long distance and could be easily remembered. They therefore served the main purpose of heraldry: identification. As more complicated shields came into use, these bold shapes were set apart in a separate class as the "honorable ordinaries". They act as charges and are always written first in blazon. Unless otherwise specified they extend to the edges of the field. Though ordinaries are not easily defined, they are generally described as including the cross, the fess, the pale, the bend, the chevron, the saltire, and the pall.

There is a separate class of charges called sub-ordinaries which are of a geometrical shape subordinate to the ordinary. According to Friar, they are distinguished by their order in blazon. The sub-ordinaries include the inescutcheon, the orle, the tressure, the double tressure, the bordure, the chief, the canton, the label, and flaunches.

Ordinaries may appear in parallel series, in which case blazons in English give them different names such as pallets, bars, bendlets, and chevronels. French blazon makes no such distinction between these diminutives and the ordinaries when borne singly. Unless otherwise specified an ordinary is drawn with straight lines, but each may be indented, embattled, wavy, engrailed, or otherwise have their lines varied.

A charge is any object or figure placed on a heraldic shield or on any other object of an armorial composition. Any object found in nature or technology may appear as a heraldic charge in armory. Charges can be animals, objects, or geometric shapes. Apart from the ordinaries, the most frequent charges are the cross – with its hundreds of variations – and the lion and eagle. Other common animals are stags, wild boars, martlets, and fish. Dragons, bats, unicorns, griffins, and more exotic monsters appear as charges and as supporters.

Animals are found in various stereotyped positions or "attitudes". Quadrupeds can often be found rampant (standing on the left hind foot). Another frequent position is passant, or walking, like the lions of the coat of arms of England. Eagles are almost always shown with their wings spread, or displayed. A pair of wings conjoined is called a vol.

In English heraldry the crescent, mullet, martlet, annulet, fleur-de-lis, and rose may be added to a shield to distinguish cadet branches of a family from the senior line. These cadency marks are usually shown smaller than normal charges, but it still does not follow that a shield containing such a charge belongs to a cadet branch. All of these charges occur frequently in basic undifferenced coats of arms.

To "marshal" two or more coats of arms is to combine them in one shield, to express inheritance, claims to property, or the occupation of an office. This can be done in a number of ways, of which the simplest is impalement: dividing the field "per pale" and putting one whole coat in each half. Impalement replaced the earlier dimidiation – combining the dexter half of one coat with the sinister half of another – because dimidiation can create ambiguity between, for example, a bend and a chevron. "Dexter" (from Latin "dextra", right) means to the right from the viewpoint of the bearer of the arms and "sinister" (from Latin "sinistra", left) means to the left. The dexter side is considered the side of greatest honour (see also Dexter and sinister).

A more versatile method is quartering, division of the field by both vertical and horizontal lines. This practice originated in Spain (Castile and León) after the 13th century. As the name implies, the usual number of divisions is four, but the principle has been extended to very large numbers of "quarters".

Quarters are numbered from the dexter chief (the corner nearest to the right shoulder of a man standing behind the shield), proceeding across the top row, and then across the next row and so on. When three coats are quartered, the first is repeated as the fourth; when only two coats are quartered, the second is also repeated as the third. The quarters of a personal coat of arms correspond to the ancestors from whom the bearer has inherited arms, normally in the same sequence as if the pedigree were laid out with the father's father's ... father (to as many generations as necessary) on the extreme left and the mother's mother's...mother on the extreme right. A few lineages have accumulated hundreds of quarters, though such a number is usually displayed only in documentary contexts. The Scottish and Spanish traditions resist allowing more than four quarters, preferring to subdivide one or more "grand quarters" into sub-quarters as needed.

The third common mode of marshalling is with an inescutcheon, a small shield placed in front of the main shield. In Britain this is most often an "escutcheon of pretence" indicating, in the arms of a married couple, that the wife is an heraldic heiress (i.e., she inherits a coat of arms because she has no brothers). In continental Europe an inescutcheon (sometimes called a "heart shield") usually carries the ancestral arms of a monarch or noble whose domains are represented by the quarters of the main shield.

In German heraldry, animate charges in combined coats usually turn to face the centre of the composition.

In English the word "crest" is commonly (but erroneously) used to refer to an entire heraldic achievement of armorial bearings. The technical use of the heraldic term crest refers to just one component of a complete achievement. The crest rests on top of a helmet which itself rests on the most important part of the achievement: the shield.

The modern crest has grown out of the three-dimensional figure placed on the top of the mounted knights' helms as a further means of identification. In most heraldic traditions, a woman does not display a crest, though this tradition is being relaxed in some heraldic jurisdictions, and the stall plate of Lady Marion Fraser in the Thistle Chapel in St Giles, Edinburgh, shows her coat on a lozenge but with helmet, crest, and motto.

The crest is usually found on a wreath of twisted cloth and sometimes within a coronet. Crest-coronets are generally simpler than coronets of rank, but several specialized forms exist; for example, in Canada, descendants of the United Empire Loyalists are entitled to use a Loyalist military coronet (for descendants of members of Loyalist regiments) or Loyalist civil coronet (for others).

When the helm and crest are shown, they are usually accompanied by a mantling. This was originally a cloth worn over the back of the helmet as partial protection against heating by sunlight. Today it takes the form of a stylized cloak hanging from the helmet. Typically in British heraldry, the outer surface of the mantling is of the principal colour in the shield and the inner surface is of the principal metal, though peers in the United Kingdom use standard colourings (Gules doubled Argent - Red/White) regardless of rank or the colourings of their arms. The mantling is sometimes conventionally depicted with a ragged edge, as if damaged in combat, though the edges of most are simply decorated at the emblazoner's discretion.

Clergy often refrain from displaying a helm or crest in their heraldic achievements. Members of the clergy may display appropriate headwear. This often takes the form of a small crowned, wide brimmed hat called a galero with the colours and tassels denoting rank; or, in the case of Papal coats of arms until the inauguration of Pope Benedict XVI in 2005, an elaborate triple crown known as a tiara. Benedict broke with tradition to substitute a mitre in his arms. Orthodox and Presbyterian clergy do sometimes adopt other forms of head gear to ensign their shields. In the Anglican tradition, clergy members may pass crests on to their offspring, but rarely display them on their own shields.

An armorial motto is a phrase or collection of words intended to describe the motivation or intention of the armigerous person or corporation. This can form a pun on the family name as in Thomas Nevile's motto "Ne vile velis". Mottoes are generally changed at will and do not make up an integral part of the armorial achievement. Mottoes can typically be found on a scroll under the shield. In Scottish heraldry, where the motto is granted as part of the blazon, it is usually shown on a scroll above the crest, and may not be changed at will. A motto may be in any language.

Supporters are human or animal figures or, very rarely, inanimate objects, usually placed on either side of a coat of arms as though supporting it. In many traditions, these have acquired strict guidelines for use by certain social classes. On the European continent, there are often fewer restrictions on the use of supporters. In the United Kingdom, only peers of the realm, a few baronets, senior members of orders of knighthood, and some corporate bodies are granted supporters. Often, these can have local significance or a historical link to the armiger.

If the armiger has the title of baron, hereditary knight, or higher, he may display a coronet of rank above the shield. In the United Kingdom, this is shown between the shield and helmet, though it is often above the crest in Continental heraldry.

Another addition that can be made to a coat of arms is the insignia of a baronet or of an order of knighthood. This is usually represented by a collar or similar band surrounding the shield. When the arms of a knight and his wife are shown in one achievement, the insignia of knighthood surround the husband's arms only, and the wife's arms are customarily surrounded by an ornamental garland of leaves for visual balance.

Since arms pass from parents to offspring, and there is frequently more than one child per couple, it is necessary to distinguish the arms of siblings and extended family members from the original arms as passed on from eldest son to eldest son. Over time several schemes have been used.

To "blazon" arms means to describe them using the formal language of heraldry. This language has its own vocabulary and syntax, or rules governing word order, which becomes essential for comprehension when blazoning a complex coat of arms. The verb comes from the Middle English "blasoun", itself a derivative of the French "blason" meaning "shield". The system of blazoning arms used in English-speaking countries today was developed by heraldic officers in the Middle Ages. The blazon includes a description of the arms contained within the escutcheon or shield, the crest, supporters where present, motto and other insignia. Complex rules, such as the rule of tincture, apply to the physical and artistic form of newly created arms, and a thorough understanding of these rules is essential to the art of heraldry. Though heraldic forms initially were broadly similar across Europe, several national styles had developed by the end of the Middle Ages, and artistic and blazoning styles today range from the very simple to extraordinarily complex.

The emergence of heraldry occurred across western Europe almost simultaneously in the various countries. Originally, heraldic style was very similar from country to country. Over time, heraldic tradition diverged into four broad styles: German-Nordic, Gallo-British, Latin, and Eastern. In addition it can be argued that newer national heraldic traditions, such as South African and Canadian, have emerged in the 20th century.

Coats of arms in Germany, the Nordic countries, Estonia, Latvia, Czech lands and northern Switzerland generally change very little over time. Marks of difference are very rare in this tradition as are heraldic furs. One of the most striking characteristics of German-Nordic heraldry is the treatment of the crest. Often, the same design is repeated in the shield and the crest. The use of multiple crests is also common. The crest is rarely used separately as in British heraldry, but can sometimes serve as a mark of difference between different branches of a family. Torse is optional. Heraldic courtoisie is observed: that is, charges in a composite shield (or two shields displayed together) usually turn to face the centre.

Coats consisting only of a divided field are somewhat more frequent in Germany than elsewhere.

The Low Countries were great centres of heraldry in medieval times. One of the famous armorials is the Gelre Armorial or "Wapenboek", written between 1370 and 1414.
Coats of arms in the Netherlands were not controlled by an official heraldic system like the two in the United Kingdom, nor were they used solely by noble families. Any person could develop and use a coat of arms if they wished to do so, provided they did not usurp someone else's arms, and historically, this right was enshrined in Roman Dutch law. As a result, many merchant families had coats of arms even though they were not members of the nobility. These are sometimes referred to as "burgher arms," and it is thought that most arms of this type were adopted while the Netherlands was a republic (1581–1806). This heraldic tradition was also exported to the erstwhile Dutch colonies.

Dutch heraldry is characterised by its simple and rather sober style, and in this sense, is closer to its medieval origins than the elaborate styles which developed in other heraldic traditions.

The use of cadency marks to difference arms within the same family and the use of semy fields are distinctive features of Gallo-British heraldry (in Scotland the most significant mark of cadency being the bordure, the small brisures playing a very minor role). It is common to see heraldic furs used. In the United Kingdom, the style is notably still controlled by royal officers of arms. French heraldry experienced a period of strict rules of construction under Napoleon. English and Scots heraldries make greater use of supporters than other European countries.

Furs, chevrons and five-pointed stars are more frequent in France and Britain than elsewhere.

The heraldry of southern France, Andorra, Spain, and Italy is characterized by a lack of crests, and uniquely shaped shields. Portuguese heraldry, however, does use crests. Portuguese and Spanish heraldry occasionally introduce words to the shield of arms, a practice usually avoided in British heraldry. Latin heraldry is known for extensive use of quartering, because of armorial inheritance via the male and the female lines. Moreover, Italian heraldry is dominated by the Roman Catholic Church, featuring many shields and achievements, most bearing some reference to the Church.

Trees are frequent charges in Latin arms. Charged bordures, including bordures inscribed with words, are seen often in Spain.

Eastern European heraldry is in the traditions developed in Belarus, Bulgaria, Serbia, Croatia, Hungary, Romania, Lithuania, Poland, Slovakia, Ukraine, and Russia. Eastern coats of arms are characterized by a pronounced, territorial, clan system – often, entire villages or military groups were granted the same coat of arms irrespective of family relationships. In Poland, nearly six hundred unrelated families are known to bear the same Jastrzębiec coat of arms. Marks of cadency are almost unknown, and shields are generally very simple, with only one charge. Many heraldic shields derive from ancient house marks. At the least, fifteen per cent of all Hungarian personal arms bear a severed Turk's head, referring to their wars against the Ottoman Empire.

True heraldry, as now generally understood, has its roots in medieval Europe. However, there have been other historical cultures which have used symbols and emblems to represent families or individuals, and in some cases these symbols have been adopted into Western heraldry. For example, the coat of arms of the Ottoman Empire incorporated the royal tughra as part of its crest, along with such traditional Western heraldic elements as the escutcheon and the compartment.

Ancient Greeks were among the first civilizations to use symbols consistently in order to identify a warrior, clan or a state. The first record of a shield blazon is illustrated in Aeschylus' tragedy "Seven Against Thebes". The Greek Heraldry Society is a useful source of information on Hellenic Heraldry and Byzantine etiquette.

, also , , and , are Japanese emblems used to decorate and identify an individual or family. While "mon" is an encompassing term that may refer to any such device, "kamon" and "mondokoro" refer specifically to emblems used to identify a family. An authoritative "mon" reference compiles Japan's 241 general categories of "mon" based on structural resemblance (a single "mon" may belong to multiple categories), with 5116 distinct individual "mon" (it is however well acknowledged that there exist lost or obscure "mon" that are not in this compilation).

The devices are similar to the badges and coats of arms in European heraldic tradition, which likewise are used to identify individuals and families. "Mon" are often referred to as crests in Western literature, another European heraldic device similar to the "mon" in function.

Socialist heraldry, also called communist heraldry, consists of emblems in a style typically adopted by communist states and filled with communist symbolism. Although commonly called "coats of arms", most such devices are not actually coats of arms in the traditional heraldic sense and should therefore, in a strict sense, not be called arms at all. Many communist governments purposely diverged from the traditional forms of European heraldry in order to distance themselves from the monarchies that they usually replaced, with actual coats of arms being seen as symbols of the monarchs.

The Soviet Union was the first state to use socialist heraldry, beginning at its creation in 1922. The style became more widespread after World War II, when many other communist states were established. Even a few non-socialist states have adopted the style, for various reasons—usually because communists had helped them to gain independence—but also when no apparent connection to a Communist nation exists, such as the emblem of Italy. After the fall of the Soviet Union and the other communist states in Eastern Europe in 1989–1991, this style of heraldry was often abandoned for the old heraldic practices, with many (but not all) of the new governments reinstating the traditional heraldry that was previously cast aside.

A tamga or tamgha "stamp, seal" (, Turkic: tamga) is an abstract seal or stamp used by Eurasian nomadic peoples and by cultures influenced by them. The tamga was normally the emblem of a particular tribe, clan or family. They were common among the Eurasian nomads throughout Classical Antiquity and the Middle Ages (including Alans, Mongols, Sarmatians, Scythians and Turkic peoples). Similar "tamga-like" symbols were sometimes also adopted by sedentary peoples adjacent to the Pontic-Caspian steppe both in Eastern Europe and Central Asia, such as the East Slavs, whose ancient royal symbols are sometimes referred to as "tamgas" and have similar appearance.

Unlike European coats of arms, tamgas were not always inherited, and could stand for families or clans (for example, when denoting territory, livestock, or religious items) as well as for specific individuals (such as when used for weapons, or for royal seals). One could also adopt the tamga of one's master or ruler, therefore signifying said master's patronage. Outside of denoting ownership, tamgas also possessed religious significance, and were used as talismans to protect one from curses (it was believed that, as symbols of family, tamgas embodied the power of one's heritage). Tamgas depicted geometric shapes, images of animals, items, or glyphs. As they were usually inscribed using heavy and unwieldy instruments, such as knives or brands, and on different surfaces (meaning that their appearance could vary somewhat), tamgas were always simple and stylised, and needed to be laconic and easily recognisable.

Every sultan of the Ottoman Empire had his own monogram, called the tughra, which served as a royal symbol. A coat of arms in the European heraldic sense was created in the late 19th century. Hampton Court requested from Ottoman Empire the coat of arms to be included in their collection. As the coat of arms had not been previously used in Ottoman Empire, it was designed after this request and the final design was adopted by Sultan Abdul Hamid II on April 17, 1882. It included two flags: the flag of the Ottoman Dynasty, which had a crescent and a star on red base, and the flag of the Islamic Caliph, which had three crescents on a green base.

Heraldry flourishes in the modern world; institutions, companies, and private persons continue using coats of arms as their pictorial identification. In the United Kingdom and Ireland, the English Kings of Arms, Scotland's Lord Lyon King of Arms, and the Chief Herald of Ireland continue making grants of arms. There are heraldic authorities in Canada, South Africa, Spain, and Sweden that grant or register coats of arms. In South Africa, the right to armorial bearings is also determined by Roman Dutch law, due to its origins as a 17th-century colony of the Netherlands.

Heraldic societies abound in Africa, Asia, Australasia, the Americas and Europe. Heraldry aficionados participate in the Society for Creative Anachronism, medieval revivals, micronations and other related projects. Modern armigers use heraldry to express ancestral and personal heritage as well as professional, academic, civic, and national pride. Little is left of class identification in modern heraldry, where the emphasis is more than ever on expression of identity.

Heraldry continues to build on its rich tradition in academia, government, guilds and professional associations, religious institutions, and the military. Nations and their subdivisions – provinces, states, counties, cities, etc. – continue to build on the traditions of civic heraldry. The Roman Catholic Church, Anglican churches, and other religious institutions maintain the traditions of ecclesiastical heraldry for clergy, religious orders, and schools. 

Many of these institutions have begun to employ blazons representing modern objects unknown in the medieval world. For example, some heraldic symbols issued by the United States Army Institute of Heraldry incorporate symbols such as guns, airplanes, or locomotives. Some scientific institutions incorporate symbols of modern science such as the atom or particular scientific instruments. The arms of the United Kingdom Atomic Energy Authority uses traditional heraldic symbols to depict the harnessing of atomic power. Locations with strong associations to particular industries may incorporate associated symbols. The coat of arms of Stenungsund Municipality in Sweden, pictured right, incorporates a hydrocarbon molecule, alluding to the historical significance of the petrochemical industry in the region.

Heraldry in countries with heraldic authorities continues to be regulated generally by laws granting rights to arms and recognizing possession of arms as well as protecting against their misuse. Countries without heraldic authorities usually treat coats of arms as creative property in the manner of logos, offering protection under copyright laws.




</doc>
<doc id="13611" url="https://en.wikipedia.org/wiki?curid=13611" title="Heretic (video game)">
Heretic (video game)

Heretic is a dark fantasy first-person shooter video game released in 1994. It was developed by Raven Software and published by id Software through GT Interactive. The game was released on Steam on August 3, 2007.

Using a modified version of the "Doom" engine, "Heretic" was one of the first first-person games to feature inventory manipulation and the ability to look up and down. It also introduced multiple gib objects that spawned when a character suffered a death by extreme force or heat. Previously, the character would simply crumple into a heap. The game used randomized ambient sounds and noises, such as evil laughter, chains rattling, distantly ringing bells, and water dripping in addition to the background music to further enhance the atmosphere. The music in the game was composed by Kevin Schilder. An indirect sequel, "", was released the following year. "Heretic II" was released in 1998, which served as a direct sequel continuing the story.

Three brothers (D'Sparil, Korax, and Eidolon), known as the Serpent Riders, have used their powerful magic to possess seven kings of Parthoris, turning them into mindless puppets and corrupting their armies. The Sidhe elves resist the Serpent Riders' magic. The Serpent Riders thus declared the Sidhe as heretics and waged war against them. The Sidhe are forced to take a drastic measure to sever the natural power of the kings destroying them and their armies, but at the cost of weakening the elves' power, giving the Serpent Riders an advantage to slay the elders. While the Sidhe retreat, one elf (revealed to be named Corvus in "Heretic II") sets off on a quest of vengeance against the weakest of the three Serpent Riders, D'Sparil. He travels through the "City of the Damned", the ruined capital of the Sidhe (its real name is revealed to be Silverspring in "Heretic II"), then past Hell's Maw and finally the Dome of D'Sparil.

The player must first fight through the undead hordes infesting the location where the elders performed their ritual. At its end is the gateway to Hell's Maw, guarded by the Iron Liches. After defeating them, the player must seal the portal and so prevent further infestation, but after he enters the portal guarded by the Maulotaurs, he finds himself inside D'Sparil's dome. After killing D'Sparil, Corvus ends up on a perilous journey with little hope of returning home.

The gameplay of "Heretic" is heavily derived from "Doom", with a level-based structure and an emphasis on finding the proper keys to progress. Many weapons are similar to those from "Doom"; the early weapons in particular are near-exact copies in functionality to those seen in "Doom". Raven added a number of features to "Heretic" that differentiated it from "Doom", however, notably interactive environments, such as rushing water that pushes the player along, and inventory items. In "Heretic", the player can pick up many different items to use at their discretion. These items range from health potions to the "morph ovum", which transforms enemies into chickens. One of the most notable pickups that can be found is the "Tome of Power" which acts as a secondary firing mode for certain weapons, resulting in a much more powerful projectile from each weapon, some of which change the look of the projectile entirely. "Heretic" also features an improved version of the "Doom" engine, sporting the ability to look up and down within constraints, as well as fly. However, the rendering method for looking up and down merely uses a proportional pixel-shearing effect rather than any new rendering algorithm, which distorts the view considerably when looking at high-elevation angles.

As with "Doom", "Heretic" contains various cheat codes that allow the player to be invulnerable, obtain every weapon, be able to instantly kill every monster in a particular level, and several other abilities. However, if the player uses the "all weapons and keys" cheat ("codice_1") from "Doom", a message appears warning the player against cheating and takes away all of his weapons, leaving him with only a quarterstaff. If the player uses the "god mode" cheat ("codice_2") from "Doom", the game will display a message saying "Trying to cheat, eh? Now you die!" and kills the player.

The original shareware release of "Heretic" came bundled with support for online multiplayer through the new DWANGO service.

Like "Doom", "Heretic" was developed on NeXTSTEP. John Romero helped Raven employees set up the development computers, and taught them how to use id's tools and "Doom" engine.

The original version of "Heretic" was only available through shareware registration (i.e. mail order) and contained three episodes. The retail version, "Heretic: Shadow of the Serpent Riders", was distributed by GT Interactive in 1996, and featured the original three episodes and two additional episodes: "The Ossuary", which takes the player to the shattered remains of a world conquered by the Serpent Riders several centuries ago, and "The Stagnant Demesne", where the player enters D'Sparil's birthplace. This version was the first official release of "Heretic" in Europe. A free patch was also downloadable from Raven's website to update the original "Heretic" with the content found in "Shadow of the Serpent Riders".

On January 11, 1999, the source code of the game engine used in "Heretic" was published by Raven Software under a license that granted rights to non-commercial use, and was re-released under the GNU General Public License on September 4, 2008. This resulted in ports to Linux, Amiga, Atari, and other operating systems, and updates to the game engine to utilize 3D acceleration. The shareware version of a console port for the Dreamcast was also released.

"Heretic" received mixed reviews, garnering an aggregated score of 62% on GameRankings and 78% on PC Zone. "Heretic" and "Hexen" shipped a combined total of roughly 1 million units by August 1997.

While remarking that "Heretic" is a thinly-veiled clone of "Doom", and that its being released in Europe after and with "Quake" due out shortly makes it somewhat outdated, "Maximum" nonetheless regarded it as an extremely polished and worthwhile purchase. They particularly highlighted the two additional episodes of the retail version, saying they offer a satisfying challenge even to first person shooter veterans and are largely what make the game worth buying.

In 1996, "Computer Gaming World" listed being turned into a chicken as #3 on its list of "the 15 best ways to die in computer gaming".

"Next Generation" reviewed the PC version of the game, and stated that "If you're only going to get one action game in the next couple of months, this is the one."

"Heretic" has received three sequels: "", "Hexen II", and "Heretic II". Following ZeniMax Media's acquisition of id Software, the rights to the series have been disputed between both id and Raven Software; Raven's parent company Activision holds the developing rights, while id holds the publishing rights to the first three games. Until both companies come to an agreement, neither will be able to make another installment in the series.

Further homages to the series have been made in other id Software titles; In 2009's "Wolfenstein", which Raven Software developed, "Heretic"'s Tomes of Power are collectible power-ups found throughout the game. The character Galena from "Quake Champions" wears armor bearing the icon of the Serpent Riders.



</doc>
<doc id="13612" url="https://en.wikipedia.org/wiki?curid=13612" title="Hexen: Beyond Heretic">
Hexen: Beyond Heretic

Hexen: Beyond Heretic is a dark fantasy first-person shooter video game developed by Raven Software and published by id Software through GT Interactive Software on October 30, 1995. It is the sequel to 1994's "Heretic", and the second game in Raven Software's "Serpent Riders" trilogy, which culminated with Hexen II. The title comes from the German noun , which means "witches", and/or the verb , which means "to cast a spell". Game producer John Romero stated that a third, unreleased game in this series was to be called "Hecatomb".

"Hexen: Beyond Heretic" met with highly positive reviews upon release, though the various 1997 console ports were negatively received due to issues with frame rate and controls and the aging of the game itself. Critical plaudits for the game centered on the non-linear level design and the selection of three playable characters, each offering a distinct gameplay experience.

Following the tale of D'Sparil's defeat in "Heretic", "Hexen" takes place in another realm, Cronos, which is besieged by the second of the three Serpent Riders, Korax. Three heroes set out to destroy Korax. The player assumes the role of one such hero. Throughout the course of his quest, he travels through elemental dungeons, a wilderness region, a mountainside seminary, a large castle, and finally a necropolis, before the final showdown with the Serpent Riders.

A new series feature introduced in "Hexen" is the choice of three character classes. Players may choose to play as a fighter (Baratus), a cleric (Parias), or a mage (Daedolon). Each character has unique weapons and physical characteristics, lending an additional degree of variety and replay value to the game. The Fighter relies mainly on close quarter physical attacks with weapons both mundane and magical in nature, and is tougher and faster than the other characters. The Mage uses an assortment of long-range spells, whose reach is counterbalanced by the fact that he is the most fragile and slowest moving of the classes. The Cleric arms himself with a combination of both melee and ranged capabilities, being a middle ground of sorts between the other two classes. Additionally, certain items, such as the flechette (poison gas bomb), behave differently when collected and used by each of the classes, functioning in a manner better suiting their varying approach to combat.

"Hexen" introduces "hub" levels to the series, wherein the player can travel back and forth between central hub levels and connected side levels. This is done in order to solve larger-scale puzzles that require a series of items or switches to be used. The player must traverse through a hub in order to reach a boss and advance to the next hub.

Like "Heretic", "Hexen" was developed on NeXTSTEP. "Hexen" uses a modified version of the "Doom" engine, which allows looking up and down, network play with up to eight players, and the choice of three character classes. It also popularized the "hub system" of level progression in the genre of first-person shooter games. Unlike previous games, which had relied purely on General MIDI for music, "Hexen" is also able to play tracks from a CD. The game's own CD contained a soundtrack in an audio format that was exactly the same as the MIDI soundtrack, but played through a high-quality sound module. However, the most significant improvement was the addition of wall translation, rotation, and level scripting.

"Polyobjects" are the walls that move within the game. Because the "Doom" engine uses the binary space partitioning system for rendering, it does not enable moving walls. "Hexen"s moving walls are actually one-sided lines built somewhere else on the map and rendered at the desired start spot when the level is loaded. This enables a pseudo-moving wall, but does not allow moving sectors (such as seeing the tops of moving doors). This often creates problems in sectors containing more than one node, however, explaining the relatively limited use of polyobjects.

Whereas "Doom", "Doom II", and "Heretic" rely on lines within the maps to perform simple actions, "Hexen" also allows these actions to be activated by Action Code Script (ACS). These scripts use a syntactic variant of C, thus allowing special sequencing of game actions. Programming features such as randomization, variables, and intermap script activation enable smooth hub gameplay and are responsible for most of the special effects within the game: on-screen messages, random sound effects, monster spawning, sidedef texture changes, versatile control of polyobjects, level initialization for deathmatch, and even complex environment changes such as earthquakes manipulating floor textures and heights.

On January 11, 1999, the source code for "Hexen" was released by Raven Software under a license that granted rights to non-commercial use, and was re-released under the GNU General Public License on September 4, 2008. This allowed the game to be ported to different platforms such as Linux, AmigaOS, and OS/2 (EComStation).

"Hexen" is compatible with many "Doom" source ports; "Hexen"s features are also compatible with "Doom" WADs made for source ports regardless of what game they are being played on.

The score was composed by Kevin Schilder. In contrast to "Heretic", some songs in "Hexen", in addition to MIDI versions, had higher-quality versions on CD. When playing in CD-audio mode, songs absent from CD would be replaced by some existing CD tracks.

"Hexen" was released for the Sega Saturn, PlayStation, and Nintendo 64, all released by GT Interactive during the first half of 1997. While presenting several specific differences in their respective translations of the original PC game, all of them constitute essentially the same game with no major changes to level design, plot, or overall delivery.

The PlayStation version, developed by Probe Entertainment, has the FMV scenes and Redbook audio music from the PC CD-ROM version, but no multiplayer mode. The scripting and animation is slower, enemies have only their front sprites and lack gory deaths when attacked by strong hits or weapons, and the frame rate is slower. Although all levels are present in this version and feature their correct layouts, their architecture details are somewhat simplified and there is some loss in overall lighting quality. This port is based on a beta version of the original PC version of "Hexen" as many gameplay tweaks are shared, such as the simpler level design and the Fighter's fists being weaker compared to other versions.

The Sega Saturn version, also developed by Probe, inherits most of the restrictions of the PlayStation version, such as the simplified scenery architecture and the downgraded lighting, although it does feature improvements in certain aspects. The scripting is faster, and the frame rate, while not fluid or consistent, is slightly better. The enemies still have all but their front sprites missing, but they retain their gory deaths when killed by a strong hit or weapon. This version also has hidden two-player link-up cooperative and deathmatch modes, accessible only through the unlockable cheat menu. While this port shares the FMV scenes and most of the Redbook audio music from the other CD-ROM versions, it also includes some new music tracks.

The Nintendo 64 version, developed by Software Creations, retains all of the graphical quality and scenery architecture, has a consistent frame rate, and includes high detail and smooth filtering. This version also has four-player split-screen cooperative and deathmatch modes, although they must be played in low detail mode. Due to cartridge storage limitations, the Nintendo 64 version is based on the original PC floppy version and lacks the FMV scenes and Redbook audio music introduced in the CD-ROM version, although it has new narrative introductions to the levels.

"Deathkings of the Dark Citadel" is an official expansion pack that was released for "Hexen" in 1996. It features three more hubs with a total of 20 new single player levels and six new deathmatch levels. Unlike the "Shadow of the Serpent Riders" expansion pack for "Heretic", it had to be purchased in retail stores or by mail order. This was unusual at the time, as most non-free expansion packs also included other new or revised gameplay elements. "Deathkings of the Dark Citadel", unlike "Shadow of the Serpent Riders", was not packaged with the original game, meaning that both had to be purchased separately, and the expansion would not work without already having "Hexen". This expansion pack also did not initially include nor enable any music. Music could be fully enabled by applying a patch specially released to address this issue (usually found online under the name "dkpatch").

Each of the hubs (The Blight, The Constable's Gate, and The Nave) features one secret level, and new puzzles based on the quest items from the original game (no new quest artifacts were added). Any type of enemy may spawn on the map.

The final level of the expansion, the Dark Citadel itself, is an arena-like level, which features teleporting waves of monsters and three bosses (Fighter, Cleric, and Mage clones).

"Heretic" and "Hexen" shipped a combined total of roughly 1 million units to retailers by August 1997.

Reviewing the PC version, "Maximum" remarked that "Hexen" sets itself apart from other "3D slashers" with its selection of characters and novel approach to level design, which "leads to your character choosing their path rather than being guided around a rather linear series of rooms, proving that 3D games have matured". They also commented that the gameplay is consistently intense due to the difficulty of the enemies, the variety of weapons and power-ups, and the sheer size and breadth of the levels. They gave the game 5 out of 5 stars and their "Maximum Game of the Month" award. A reviewer for "Next Generation" opined that ""Hexen" takes everything that was good about "Heretic", and makes it even better." He commented that the ability to choose between three different character classes gives the game replay value, something that had been missing from first-person shooters up until then, and though the graphics are blocky and pixelated, the "eerily lifelike" sound effects make up for it to a large extent. Like "Maximum", he praised the non-linear level design and concluded the game to be a must-have for any first-person shooter fan. Chris Hudak, citing the differing abilities of the three playable characters, called "Hexen" "Slicker, smarter and more stylish than "Doom"---with all the killing and three times the replay value."

"Computer Games Strategy Plus" named "Hexen" the best "First-Person Action" title of 1995. It was also a runner-up for "Computer Gaming World"s 1995 "Action Game of the Year" award, which ultimately went to "". The editors called it "another "Doom" bloodfest distinguished by its fantasy setting and the fact that it let you play as either a fighter, priest or mage, each with unique attributes and weapons".

The Saturn version was far less positively received. A review in "Next Generation" reasoned that, "Like oil and water, "Doom"-style games and console conversions don't mix well. Unless the programmers are willing to rewrite the graphics engine from scratch, PC ports suffer from getting cramped into too little memory and neglecting the console's native 3D hardware." The reviewer recommended Saturn owners instead try "PowerSlave" or "Ghen War", first-person shooters specifically designed for the console. Shawn Smith and Sushi-X of "Electronic Gaming Monthly" similarly said the game had not converted well from PC. Others described the Saturn port as an exact conversion, and argued the problem was simply that "Hexen" was too old a game to be released for console in 1997 without any improvements. Though they disagreed on why, most critics agreed that the Saturn version suffers from pixelated graphics, dramatic drops in frame rate, and cumbersome controls. Scary Larry of "GamePro" gave it a mixed review, summarizing that "although it doesn't live up to "PowerSlave"s standards, it's still decent fun." John Broady of "GameSpot" gave a slightly more dismal assessment: "Despite these glaring deficiencies, "Hexen" nonetheless offers enough enhancements over the standard shooter to warrant a rental, especially for fans of role-playing games who thirst for real-time action. ... But for the rest, the Saturn version of "Hexen" is a classic game of too little and too late." Rich Leadbetter of "Sega Saturn Magazine" and James Price of "Saturn Power" defended the Saturn version, commenting that while it is not outstanding, it is far superior to the Saturn version of "Doom", which was released at roughly the same time. Price was particularly enthusiastic about the link cable-enabled multiplayer mode.

The Nintendo 64 version also left most critics unimpressed. The four-player mode was praised as an unprecedented feature in console first person shooters, but the visuals were considered unacceptably poor, particularly the frame rate and the usage of the Nintendo 64's mip-mapping and anti-aliasing in a way which actually worsens the appearance of the game. As with the Saturn version, some critics opined that "Hexen" was too dated by this time to be receiving a straightforward port. Joe Fielder of "GameSpot" additionally complained of a severe bug in the save feature. In a dissenting opinion, Scary Larry concluded that "Although not as polished as "" or as fun and creepy as "Doom 64", "Hexen" gives you three characters to choose from, and the action's addicting once you get into it." He gave it higher scores than the Saturn version in every category except sound. In contrast, Matt Casamassina of "IGN" called it "A shoddy port of a PC game that wasn't so great to begin with."

The PlayStation version was still more negatively received, with critics universally razing the conversion for its poor frame rate, pixelated graphics, and sloppy platform jumping controls.



</doc>
<doc id="13613" url="https://en.wikipedia.org/wiki?curid=13613" title="Hexen II">
Hexen II

Hexen II is a dark fantasy first-person shooter (FPS) video game developed by Raven Software from 1996 to 1997, then published by id Software and distributed by Activision. It was the third game in the ""/"Heretic" series, and the last in the Serpent Riders trilogy. It was later made available on Steam on August 3, 2007. Using a modified "Quake" engine, it featured single-player and multiplayer game modes, as well as four character classes to choose from, each with different abilities. These included the "offensive" Paladin, the "defensive" Crusader, the spell-casting Necromancer, and the stealthy Assassin.

Improvements from "" and "Quake" included destructible environments, mounted weapons, and unique level up abilities. Like its predecessor, "Hexen II" also used a "hub" system. These hubs were a number of interconnected levels; changes made in one level had effects in another. Furthermore, the Tome of Power artifact made a return from "Heretic".

The gameplay of "Hexen II" is very similar to that of the original "Hexen". Instead of three classes, "Hexen II" features four: Paladin, Crusader, Assassin, and Necromancer, each with their own unique weapons and play style.

"Hexen II" also adds certain role-playing video game elements to the mix. Each character has a series of statistics which increase as they gain experience. This then causes the player character to grow in power as his or her HP and Mana increases.

Thyrion is a world that was enslaved by the Serpent Riders. The two previous games in the series documented the liberation of two other worlds, along with the death of their Serpent Rider overlords. Now, the oldest and most powerful of the three Serpent Rider brothers, Eidolon, must be defeated to free Thyrion. Eidolon is supported by his four generals, themselves a reference to the Four Horsemen of the Apocalypse. To confront each general, the player has to travel to four different continents, each possessing a distinct theme (Medieval European for Blackmarsh, Mesoamerican for Mazaera, Ancient Egyptian for Thysis, and Greco-Roman for Septimus). Then, finally, the player returns to Blackmarsh in order to confront Eidolon himself inside of his own dominion Cathedral.

What was originally supposed to be the final game in a trilogy, the sequel to Hexen was originally titled "Hecatomb" but was abandoned after John Romero left id Software in 1996. Activision, the distributor at the time, pressured Raven Software to split development of Hecatomb into two different games, Hexen II and Heretic II. Activision felt that the previous entries in the series, Heretic and Hexen, were different enough from one another that they should treat them as separate entities going forward, instead of just one final game to complete a trilogy. Only a select few ideas of Romero's from "Hecatomb" would ultimately make their way into what became Hexen II and Heretic II.

"Hexen II" was based on an enhanced version of the "Quake" engine. "Hexen II", by way of the "Quake" engine, uses OpenGL for 3D acceleration. However, due to the prevalence of 3dfx hardware at the time of release, the Windows version of the game installs an OpenGL ICD (opengl32.dll) designed specifically for 3dfx's hardware. This driver acts as a wrapper for the proprietary Glide API, and thus is only compatible with 3dfx hardware. Custom OpenGL drivers were also released by PowerVR and Rendition for running "Hexen II" with their respective (and also now defunct) products. Removal of the ICD allows the game to use the default OpenGL system library. Much of the music in this game is remixed versions of the soundtracks of "" and "Heretic" to match the hub themes.

Activision acquired the rights to publish versions of the game for the PlayStation and Sega Saturn. They considered Lobotomy Software to produce the Saturn conversion and get it released by late 1997. However neither ports were released.

A modification titled "Siege" was created and released by Raven Software in 1998 using updated QuakeWorld architecture, aptly dubbed "HexenWorld". The production concept was to eliminate a normal deathmatch environment in favor of a teamplay castle siege. The basic premise was to divide the players into two teams—attackers and defenders—with each side either assaulting or protecting the castle respectively. At the end of the time limit, whichever team controlled the crown was declared victorious. The mod featured appropriate objects used in the single-player portion of the game, namely catapults and ballistae. The classes, however, were drastically altered with new weapons and abilities, reflecting the departure from the normal deathmatch experience presented in "HexenWorld".

Following the tradition from "Heretic" and "Hexen", Raven released the source code of the "Hexen II" engine on November 10, 2000. This time the source was released under the GNU General Public License, allowing source ports to be made to different platforms like Linux and the Dreamcast.

An expansion pack called "Hexen II Mission Pack: Portal of Praevus" was released on March 31, 1998. It features new levels, new enemies and a new playable character class, The Demoness. It focuses on the attempted resurrection of the three Serpent Riders by the evil wizard Praevus, and takes place in a fifth continent, Tulku, featuring a Sino-Tibetan setting. Unlike the original game, the expansion was not published by id Software, and as such is not currently available via digital re-releases.

The expansion features new quest items, new enemies, and new weapons for the Demoness. She is the only player class to have a ranged starting weapon (similar to the Mage class in the original "Hexen"), whereas all other characters start with melee weapons. It also introduced minor enhancements to the game engine, mostly related to user interface, level scripts, particle effects (rain or snow), and 3D objects. "Portal of Praevus" also features a secret (easter egg) skill level, with respawning monsters. The only released patch for the expansion added respawning of certain items (such as health and ammo) in Nightmare mode, so that it would be slightly easier for playing.

Because of the popularity of the original "Hexen", the game was heavily anticipated. Upon its release, "Hexen II" received mixed to positive reviews. "Edge" praised the game for being different from other "Quake" engine-based games, highlighting its inventive and interactive levels, enemy variety, and artificial intelligence. The magazine also credited the game's diversity of weapons and spells for offering different combat strategies.

According to Erik Bethke, "Hexen II" was commercially unsuccessful, with sales slightly above 30,000 units.



</doc>
<doc id="13614" url="https://en.wikipedia.org/wiki?curid=13614" title="Heretic II">
Heretic II

Heretic II is a dark fantasy action-adventure game developed by Raven Software and published by Activision in 1998 continuing the story of Corvus, the main character from its predecessor, "Heretic". It is the fourth game in the Hexen/Heretic series and comes after the "Serpent Rider" trilogy.

Using a modified Quake II engine, the game features a mix of a third-person camera with a first-person shooter's action, making for a new gaming experience at the time. While progressive, this was a controversial design decision among fans of the original game, a well-known first-person shooter built on the Doom engine. The music was composed by Kevin Schilder. Gerald Brom contributed conceptual work to characters and creatures for the game. This is the only "Heretic"/"" video game that is unrelated to id Software, apart from its role as engine licenser.

"Heretic II" was later ported to Linux by Loki Software, to the Amiga by Hyperion Entertainment, and Macintosh by MacPlay.

After Corvus returns from his banishment, he finds that a mysterious plague has swept the land of Parthoris, taking the sanity of those it does not kill. Corvus, the protagonist of the first game, is forced to flee his hometown of Silverspring after the infected attack him, but not before he is infected himself. The effects of the disease are held at bay in Corvus’ case because he holds one of the Tomes of Power, but he still must find a cure before he succumbs.

His quest leads him through the city and swamps to a jungle palace, then through a desert canyon and insect hive, followed by a dark network of mines and finally to a castle on a high mountain where he finds an ancient Seraph named Morcalavin. Morcalavin is trying to reach immortality using the seven Tomes of Power, but he uses a false tome, as Corvus has one of them. This has caused Morcalavin to go insane and create the plague. During a battle between Corvus and Morcalavin, Corvus switches the false tome for his real one, curing Morcalavin’s insanity and ending the plague.

Unlike previous games in the "Heretic/Hexen" series, which were first-person shooters, players control Corvus from a camera fixed behind him in the third-person perspective. Players are able to use a combination of both melee and ranged attacks, similar to its predecessor. While there are still three weapons the player can collect that each use their own ammo, they also have the ability to use several offensive and defensive spells that draw from pools of green and blue mana, respectively. The Tome of Power is no longer an item scattered around the levels, but a defensive spell that still works in the same manner as the other games in the series by improving damage and granting weapons and offensive spells new abilities for a limited time. Melee combat is also more varied, with the ability to perform several attacks using Corvus' bladestaff and cut off the limbs of enemies, rendering them harmless. Players are also able to utilize magical shrines throughout the game that grant a variety of effects upon use, such as silver or gold armor, a temporary boost in health, a permanent enhancement to the bladestaff, etc.

The game consists of a wide variety of high fantasy medieval backdrops to Corvus's adventure. The third-person perspective and three-dimensional game environment allowed developers to introduce a wide variety of gymnastic moves, like climbing up ledges, back-flipping off walls, and pole vaulting, in a much more dynamic environment than the original game's engine could produce. Both games invite comparison with their respective game-engine namesake: the original "Heretic" was built on the "Doom" engine, and "Heretic II" was built using the "Quake II" engine, later known as id Tech 2. "Heretic II" was favorably received at release because it took a different approach to its design.

Inspired by the Tomb Raider series, Raven Software decided to make use of the Quake II engine to create a third person action game. A major step in the early development was Gerald Brom's concept art. In a month, the company had programmed the game's camera system. After Activision's approval of the game's demo, Raven Software aimed to get the full game finished by Christmas. To add to complications, they needed a software renderer to make the game playable to 16-bit users (especially in Europe). 

For the animation, the main character Corvus was provided with a backbone for realism and had a total of 1600 frames. Most of the animations were done using Softimage. The static world objects and simplified animations were done with 3D Studio Max. The engine was capable of showing up to 4,000 polygons on screen.

Following ZeniMax Media's acquisition of id Software in 2009, the rights to the series have been disputed between both id and Raven Software; Raven holds the development rights, while id holds the publishing rights to "Heretic II"'s predecessors. Until both companies come to an agreement, neither will be able to release another installment in the series.

"Heretic II" was a commercial flop. According to PC Data, its sales in the United States totaled 28,994 units by April 1999. Activision's Steve Felsen blamed this performance on the game's design: he noted that "fans of first-person shooters—the target audience for this game—stayed away due to the third-person perspective".

"Edge" praised the game for its mixture of platform and shoot 'em up action, stating that "Heretic II" is different enough to stand out from both first-person and third-person games like id Software's first-person shooters or Core Design's "Tomb Raider" games. "Heretic II" was a finalist for "Computer Gaming World"s 1998 "Best Action" award, which ultimately went to "Battlezone". The editors wrote that "Heretic II" "proved that the "Quake II" engine could work in a third-person game "and" that a spell-casting, shirtless elf could actually kick ass."



</doc>
<doc id="13615" url="https://en.wikipedia.org/wiki?curid=13615" title="Household hardware">
Household hardware

Household hardware (or simply, hardware) is equipment that can be touched or held by hand such as nuts, screws, washers, keys, locks, hinges, latches, handles, wire, chains, belts, plumbing supplies, electrical supplies, tools, utensils, cutlery and machine parts. Household hardware is typically sold in hardware stores.



</doc>
<doc id="13616" url="https://en.wikipedia.org/wiki?curid=13616" title="Howard Carter">
Howard Carter

Howard Carter (9 May 18742 March 1939) was a British archaeologist and Egyptologist who became world-famous after discovering the intact tomb (designated KV62) of the 18th Dynasty Pharaoh, Tutankhamun (colloquially known as "King Tut" and "the boy king"), in November 1922.

Howard Carter was born in Kensington on 9 May 1874, the son of Samuel John Carter, an artist, and Martha Joyce Carter (née Sands). His father trained and developed Howard's artistic talents.

Carter spent much of his childhood with relatives in the Norfolk market town of Swaffham, the birthplace of both his parents. Nearby was the mansion of the Amherst family, Didlington Hall, containing a sizable collection of Egyptian antiques, which sparked Carter's interest in that subject. In 1891 the Egypt Exploration Fund (EEF), on the prompting of Mary Cecil, sent Carter to assist an Amherst family friend, Percy Newberry, in the excavation and recording of Middle Kingdom tombs at Beni Hasan. 
Although only 17, Carter was innovative in improving the methods of copying tomb decoration. In 1892, he worked under the tutelage of Flinders Petrie for one season at Amarna, the capital founded by the pharaoh Akhenaten. From 1894 to 1899, he worked with Édouard Naville at Deir el-Bahari, where he recorded the wall reliefs in the temple of Hatshepsut.

In 1899, Carter was appointed to the position of Chief Inspector of the Egyptian Antiquities Service (EAS). He supervised a number of excavations at Thebes (now known as Luxor). In 1904, he was transferred to the Inspectorate of Lower Egypt. Carter was praised for his improvements in the protection of, and accessibility to, existing excavation sites, and his development of a grid-block system for searching for tombs. The Antiquities Service also provided funding for Carter to head his own excavation projects.

Carter resigned from the Antiquities Service in 1905 after a formal inquiry into what became known as the Saqqara Affair, a noisy confrontation between Egyptian site guards and a group of French tourists. Carter sided with the Egyptian personnel.

In 1907, after three hard years for Carter, Lord Carnarvon employed him to supervise excavations of nobles' tombs in Deir el-Bahri, near Thebes. Gaston Maspero had recommended Carter to Carnarvon as he knew he would apply modern archaeological methods and systems of recording.

In 1914, Lord Carnarvon received the concession to dig in the Valley of the Kings, Carter was again employed to lead the work. However excavations and study were soon interrupted by the First World War, Carter spending these war years working for the British Government as a diplomatic courier and translator. He enthusiastically resumed his excavation work towards the end of 1917.

By 1922, Lord Carnarvon had become dissatisfied with the lack of results after several years of finding little. He informed Carter that he had one more season of funding to make a significant find in the Valley of the Kings.

Carter returned to the Valley of Kings, and investigated a line of huts that he had abandoned a few seasons earlier. The crew cleared the huts and rock debris beneath. On 4 November 1922, their young water boy accidentally stumbled on a stone that turned out to be the top of a flight of steps cut into the bedrock. Carter had the steps partially dug out until the top of a mud-plastered doorway was found. The doorway was stamped with indistinct cartouches (oval seals with hieroglyphic writing). Carter ordered the staircase to be refilled, and sent a telegram to Carnarvon, who arrived two-and-a-half weeks later on 23 November.

On 26 November 1922, Carter made a "tiny breach in the top left hand corner" of the doorway, with Carnarvon, his daughter Lady Evelyn Herbert, and others in attendance, using a chisel that his grandmother had given him for his 17th birthday. He was able to peer in by the light of a candle and see that many of the gold and ebony treasures were still in place. He did not yet know whether it was "a tomb or merely an old cache", but he did see a promising sealed doorway between two sentinel statues. Carnarvon asked, "Can you see anything?" Carter replied with the famous words: "Yes, wonderful things!" Carter had, in fact, discovered Tutankhamun's tomb (subsequently designated KV62).

The next several months were spent cataloguing the contents of the antechamber under the "often stressful" supervision of Pierre Lacau, director general of the Department of Antiquities of Egypt. On 16 February 1923, Carter opened the sealed doorway and found that it did indeed lead to a burial chamber, and he got his first glimpse of the sarcophagus of Tutankhamun. The tomb was considered the best preserved and most intact pharaonic tomb ever found in the Valley of the Kings, and the discovery was eagerly covered by the world's press, but most of their representatives were kept in their hotels, much to their annoyance. Only H. V. Morton from "The Times" newspaper was allowed on the scene, and his vivid descriptions helped to cement Carter's reputation with the British public.

Carter's own notes and photographic evidence indicate that he, Lord Carnarvon, and Lady Evelyn Herbert entered the burial chamber in November 1922, shortly after the tomb's discovery and before the official opening.

Towards the end of February 1923 a rift between Lord Carnarvon and Carter, probably caused by a disagreement on how to manage the supervising Egyptian authorities, temporarily closed excavation. Work recommenced in early March after Lord Carnarvon apologised to Carter. Later that month Lord Carnarvon contracted blood poisoning while staying in Luxor near the tomb site. He died in Cairo on 5 April 1923. Lady Carnarvon retained her late husband's concession in the Valley of the Kings, allowing Carter to continue his work.

Carter's painstaking cataloguing of the thousands of objects in the tomb continued until 1932, most being moved to the Egyptian Museum in Cairo. There were a number of breaks in the work, including one lasting nearly a year in 1924–25, caused by to a dispute over what Carter saw as excessive control of the excavation by the Egyptian Antiquities Service. The Egyptian authorities eventually agreed that Carter should complete the tomb's clearance.

Despite being involved in the greatest archaeological find of his time, Carter received no honour from the British government. However, in 1926, Carter received the Order of the Nile, third class, from King Fuad I of Egypt.

Carter had authored a number of books on Egyptology during his career. During those years he had also been awarded an honorary degree of Doctor of Science by Yale University and honorary membership in the Real Academia de la Historia of Madrid, Spain.

After the clearance of the tomb had been completed, Carter retired from archaeology and became a part-time agent for collectors and museums, including the Cleveland Museum of Art and the Detroit Institute of Arts. In 1924 he toured Britain, as well as France, Spain and the United States, delivering a series of illustrated lectures. Those in New York City and other US cities were attended by large and enthusiastic audiences, sparking American Egyptomania.

Carter died at his London flat at 49 Albert Court, next to the Royal Albert Hall, on 2 March 1939, aged 64 from Hodgkin's Disease. Few people attended his funeral, one of them was his older brother William (b. 1863) who died in the same year. Carter is buried in Putney Vale Cemetery in London.

Probate was granted on 5 July 1939 to English Egyptologist Henry Burton and to publishing entrepreneur Bruce Sterling Ingram, Carter is described as Howard Carter of Luxor, Upper Egypt, Africa and of 49 Albert Court, Kensington Grove, Kensington, London, his estate was valued at £2002. A second grant of Probate was issued in Cairo on 1 September 1939.

His epitaph reads: ""May your spirit live, may you spend millions of years, you who love Thebes, sitting with your face to the north wind, your eyes beholding happiness"", a quotation taken from the Wishing Cup of Tutankhamun, and ""O night, spread thy wings over me as the imperishable stars"."




Carter has been portrayed in many film and television productions:




</doc>
<doc id="13617" url="https://en.wikipedia.org/wiki?curid=13617" title="History of Scotland">
History of Scotland

The recorded begins with the arrival of the Roman Empire in the 1st century, when the province of Britannia reached as far north as the Antonine Wall. North of this was Caledonia, inhabited by the "Picti", whose uprisings forced Rome's legions back to Hadrian's Wall. As Rome finally withdrew from Britain, Gaelic raiders called the "Scoti" began colonising Western Scotland and Wales. Prior to Roman times, prehistoric Scotland entered the Neolithic Era about 4000 BC, the Bronze Age about 2000 BC, and the Iron Age around 700 BC.

The Gaelic kingdom of Dál Riata was founded on the west coast of Scotland in the 6th century. In the following century, Irish missionaries introduced the previously pagan Picts to Celtic Christianity. Following England's Gregorian mission, the Pictish king Nechtan chose to abolish most Celtic practices in favour of the Roman rite, restricting Gaelic influence on his kingdom and avoiding war with Anglian Northumbria. Towards the end of the 8th century, the Viking invasions began, forcing the Picts and Gaels to cease their historic hostility to each other and to unite in the 9th century, forming the Kingdom of Scotland.

The Kingdom of Scotland was united under the House of Alpin, whose members fought among each other during frequent disputed successions. The last Alpin king, Malcolm II, died without issue in the early 11th century and the kingdom passed through his daughter's son to the House of Dunkeld or Canmore. The last Dunkeld king, Alexander III, died in 1286. He left only his infant granddaughter Margaret, Maid of Norway as heir, who died herself four years later. England, under Edward I, would take advantage of this questioned succession to launch a series of conquests, resulting in the Wars of Scottish Independence, as Scotland passed back and forth between the House of Balliol and the House of Bruce. Scotland's ultimate victory confirmed Scotland as a fully independent and sovereign kingdom.

When King David II died without issue, his nephew Robert II established the House of Stuart, which would rule Scotland uncontested for the next three centuries. James VI, Stuart king of Scotland, also inherited the throne of England in 1603, and the Stuart kings and queens ruled both independent kingdoms until the Act of Union in 1707 merged the two kingdoms into a new state, the Kingdom of Great Britain. Ruling until 1714, Queen Anne was the last Stuart monarch. Since 1714, the succession of the British monarchs of the houses of Hanover and Saxe-Coburg and Gotha (Windsor) has been due to their descent from James VI and I of the House of Stuart.

During the Scottish Enlightenment and Industrial Revolution, Scotland became one of the commercial, intellectual and industrial powerhouses of Europe. Later, its industrial decline following the Second World War was particularly acute. In recent decades Scotland has enjoyed something of a cultural and economic renaissance, fuelled in part by a resurgent financial services sector and the proceeds of North Sea oil and gas. Since the 1950s, nationalism has become a strong political topic, with serious debates on Scottish independence, and a referendum in 2014 about leaving the British Union.

People lived in Scotland for at least 8,500 years before Britain's recorded history. At times during the last interglacial period (130,000–70,000 BC) Europe had a climate warmer than today's, and early humans may have made their way to Scotland, with the possible discovery of pre-Ice Age axes on Orkney and mainland Scotland. Glaciers then scoured their way across most of Britain, and only after the ice retreated did Scotland again become habitable, around 9600 BC. Upper Paleolithic hunter-gatherer encampments formed the first known settlements, and archaeologists have dated an encampment near Biggar to around 12000 BC. Numerous other sites found around Scotland build up a picture of highly mobile boat-using people making tools from bone, stone and antlers. The oldest house for which there is evidence in Britain is the oval structure of wooden posts found at South Queensferry near the Firth of Forth, dating from the Mesolithic period, about 8240 BC. The earliest stone structures are probably the three hearths found at Jura, dated to about 6000 BC.

Neolithic farming brought permanent settlements. Evidence of these includes the well-preserved stone house at Knap of Howar on Papa Westray, dating from around 3500 BC and the village of similar houses at Skara Brae on West Mainland, Orkney from about 500 years later. The settlers introduced chambered cairn tombs from around 3500 BC, as at Maeshowe, and from about 3000 BC the many standing stones and circles such as those at Stenness on the mainland of Orkney, which date from about 3100 BC, of four stones, the tallest of which is in height. These were part of a pattern that developed in many regions across Europe at about the same time.

The creation of cairns and Megalithic monuments continued into the Bronze Age, which began in Scotland about 2000 BC. As elsewhere in Europe, hill forts were first introduced in this period, including the occupation of Eildon Hill near Melrose in the Scottish Borders, from around 1000 BC, which accommodated several hundred houses on a fortified hilltop. From the Early and Middle Bronze Age there is evidence of cellular round houses of stone, as at Jarlshof and Sumburgh on Shetland. There is also evidence of the occupation of crannogs, roundhouses partially or entirely built on artificial islands, usually in lakes, rivers and estuarine waters.

In the early Iron Age, from the seventh century BC, cellular houses began to be replaced on the northern isles by simple Atlantic roundhouses, substantial circular buildings with a dry stone construction. From about 400 BC, more complex Atlantic roundhouses began to be built, as at Howe, Orkney and Crosskirk, Caithness. The most massive constructions that date from this era are the circular broch towers, probably dating from about 200 BC. This period also saw the first wheelhouses, a roundhouse with a characteristic outer wall, within which was a circle of stone piers (bearing a resemblance to the spokes of a wheel), but these would flourish most in the era of Roman occupation. There is evidence for about 1,000 Iron Age hill forts in Scotland, most located below the Clyde-Forth line, which have suggested to some archaeologists the emergence of a society of petty rulers and warrior elites recognisable from Roman accounts.

The surviving pre-Roman accounts of Scotland originated with the Greek Pytheas of Massalia, who may have circumnavigated the British Isles of Albion (Britain) and Ierne (Ireland) sometime around 325 BC. The most northerly point of Britain was called "Orcas" (Orkney). By the time of Pliny the Elder, who died in AD 79, Roman knowledge of the geography of Scotland had extended to the "Hebudes" (The Hebrides), "Dumna" (probably the Outer Hebrides), the Caledonian Forest and the people of the Caledonii, from whom the Romans named the region north of their control Caledonia. Ptolemy, possibly drawing on earlier sources of information as well as more contemporary accounts from the Agricolan invasion, identified 18 tribes in Scotland in his "Geography", but many of the names are obscure and the geography becomes less reliable in the north and west, suggesting early Roman knowledge of these areas was confined to observations from the sea.

The Roman invasion of Britain began in earnest in AD 43, leading to the establishment of the Roman province of Britannia in the south. By the year 71, the Roman governor Quintus Petillius Cerialis had launched an invasion of what is now Scotland. In the year 78, Gnaeus Julius Agricola arrived in Britain to take up his appointment as the new governor and began a series of major incursions. He is said to have pushed his armies to the estuary of the "River Taus" (usually assumed to be the River Tay) and established forts there, including a legionary fortress at Inchtuthil. After his victory over the northern tribes at Mons Graupius in 84, a series of forts and towers were established along the Gask Ridge, which marked the boundary between the Lowland and Highland zones, probably forming the first Roman "limes" or frontier in Scotland. Agricola's successors were unable or unwilling to further subdue the far north. By the year 87, the occupation was limited to the Southern Uplands and by the end of the first century the northern limit of Roman expansion was a line drawn between the Tyne and Solway Firth. The Romans eventually withdrew to a line in what is now northern England, building the fortification known as Hadrian's Wall from coast to coast.

Around 141, the Romans undertook a reoccupation of southern Scotland, moving up to construct a new "limes" between the Firth of Forth and the Firth of Clyde, which became the Antonine Wall. The largest Roman construction inside Scotland, it is a sward-covered wall made of turf around high, with nineteen forts. It extended for . Having taken twelve years to build, the wall was overrun and abandoned soon after 160. The Romans retreated to the line of Hadrian's Wall. Roman troops penetrated far into the north of modern Scotland several more times, with at least four major campaigns. The most notable invasion was in 209 when the emperor Septimius Severus led a major force north. After the death of Severus in 210 they withdrew south to Hadrian's Wall, which would be Roman frontier until it collapsed in the 5th century. By the close of the Roman occupation of southern and central Britain in the 5th century, the Picts had emerged as the dominant force in northern Scotland, with the various Brythonic tribes the Romans had first encountered there occupying the southern half of the country. Roman influence on Scottish culture and history was not enduring.

In the centuries after the departure of the Romans from Britain, there were four groups within the borders of what is now Scotland. In the east were the Picts, with kingdoms between the river Forth and Shetland. In the late 6th century the dominant force was the Kingdom of Fortriu, whose lands were centred on Strathearn and Menteith and who raided along the eastern coast into modern England. In the west were the Gaelic (Goidelic)-speaking people of Dál Riata with their royal fortress at Dunadd in Argyll, with close links with the island of Ireland, from whom comes the name Scots. In the south was the British (Brythonic) Kingdom of Strathclyde, descendants of the peoples of the Roman influenced kingdoms of "Hen Ogledd" (Old north), often named Alt Clut, the Brythonic name for their capital at Dumbarton Rock. Finally, there were the English or "Angles", Germanic invaders who had overrun much of southern Britain and held the Kingdom of Bernicia, in the south-east. The first English king in the historical record is Ida, who is said to have obtained the throne and the kingdom about 547. Ida's grandson, Æthelfrith, united his kingdom with Deira to the south to form Northumbria around the year 604. There were changes of dynasty, and the kingdom was divided, but it was re-united under Æthelfrith's son Oswald (r. 634-42).

Scotland was largely converted to Christianity by Irish-Scots missions associated with figures such as St Columba, from the fifth to the seventh centuries. These missions tended to found monastic institutions and collegiate churches that served large areas. Partly as a result of these factors, some scholars have identified a distinctive form of Celtic Christianity, in which abbots were more significant than bishops, attitudes to clerical celibacy were more relaxed and there was some significant differences in practice with Roman Christianity, particularly the form of tonsure and the method of calculating Easter, although most of these issues had been resolved by the mid-7th century.

Conversion to Christianity may have speeded a long term process of gaelicisation of the Pictish kingdoms, which adopted Gaelic language and customs. There was also a merger of the Gaelic and Pictish crowns, although historians debate whether it was a Pictish takeover of Dál Riata, or the other way around. This culminated in the rise of Cínaed mac Ailpín (Kenneth MacAlpin) in the 840s, which brought to power the House of Alpin. In 867 AD the Vikings seized the southern half of Northumbria, forming the Kingdom of York; three years later they stormed the Britons' fortress of Dumbarton and subsequently conquered much of England except for a reduced Kingdom of Wessex, leaving the new combined Pictish and Gaelic kingdom almost encircled. When he died as king of the combined kingdom in 900, Domnall II (Donald II) was the first man to be called "rí Alban" (i.e. "King of Alba"). The term Scotia was increasingly used to describe the kingdom between North of the Forth and Clyde and eventually the entire area controlled by its kings was referred to as Scotland.
The long reign (900–942/3) of Causantín (Constantine II) is often regarded as the key to formation of the Kingdom of Alba. He was later credited with bringing Scottish Christianity into conformity with the Catholic Church. After fighting many battles, his defeat at Brunanburh was followed by his retirement as a Culdee monk at St. Andrews. The period between the accession of his successor Máel Coluim I (Malcolm I) and Máel Coluim mac Cináeda (Malcolm II) was marked by good relations with the Wessex rulers of England, intense internal dynastic disunity and relatively successful expansionary policies. In 945, Máel Coluim I annexed Strathclyde as part of a deal with King Edmund of England, where the kings of Alba had probably exercised some authority since the later 9th century, an event offset somewhat by loss of control in Moray. The reign of King Donnchad I (Duncan I) from 1034 was marred by failed military adventures, and he was defeated and killed by MacBeth, the Mormaer of Moray, who became king in 1040. MacBeth ruled for seventeen years before he was overthrown by Máel Coluim, the son of Donnchad, who some months later defeated MacBeth's step-son and successor Lulach to become King Máel Coluim III (Malcolm III).

It was Máel Coluim III, who acquired the nickname "Canmore" ("Cenn Mór", "Great Chief"), which he passed to his successors and who did most to create the Dunkeld dynasty that ruled Scotland for the following two centuries. Particularly important was his second marriage to the Anglo-Hungarian princess Margaret. This marriage, and raids on northern England, prompted William the Conqueror to invade and Máel Coluim submitted to his authority, opening up Scotland to later claims of sovereignty by English kings. When Malcolm died in 1093, his brother Domnall III (Donald III) succeeded him. However, William II of England backed Máel Coluim's son by his first marriage, Donnchad, as a pretender to the throne and he seized power. His murder within a few months saw Domnall restored with one of Máel Coluim sons by his second marriage, Edmund, as his heir. The two ruled Scotland until two of Edmund's younger brothers returned from exile in England, again with English military backing. Victorious, Edgar, the oldest of the three, became king in 1097. Shortly afterwards Edgar and the King of Norway, Magnus Barefoot concluded a treaty recognising Norwegian authority over the Western Isles. In practice Norse control of the Isles was loose, with local chiefs enjoying a high degree of independence. He was succeeded by his brother Alexander, who reigned 1107–24.
When Alexander died in 1124, the crown passed to Margaret's fourth son David I, who had spent most of his life as a Norman French baron in England. His reign saw what has been characterised as a "Davidian Revolution", by which native institutions and personnel were replaced by English and French ones, underpinning the development of later Medieval Scotland. Members of the Anglo-Norman nobility took up places in the Scottish aristocracy and he introduced a system of feudal land tenure, which produced knight service, castles and an available body of heavily armed cavalry. He created an Anglo-Norman style of court, introduced the office of justicar to oversee justice, and local offices of sheriffs to administer localities. He established the first royal burghs in Scotland, granting rights to particular settlements, which led to the development of the first true Scottish towns and helped facilitate economic development as did the introduction of the first recorded Scottish coinage. He continued a process begun by his mother and brothers helping to establish foundations that brought reform to Scottish monasticism based on those at Cluny and he played a part in organising diocese on lines closer to those in the rest of Western Europe.

These reforms were pursued under his successors and grandchildren Malcolm IV of Scotland and William I, with the crown now passing down the main line of descent through primogeniture, leading to the first of a series of minorities. The benefits of greater authority were reaped by William's son Alexander II and his son Alexander III, who pursued a policy of peace with England to expand their authority in the Highlands and Islands. By the reign of Alexander III, the Scots were in a position to annex the remainder of the western seaboard, which they did following Haakon Haakonarson's ill-fated invasion and the stalemate of the Battle of Largs with the Treaty of Perth in 1266.

The death of King Alexander III in 1286, and the death of his granddaughter and heir Margaret, Maid of Norway in 1290, left 14 rivals for succession. To prevent civil war the Scottish magnates asked Edward I of England to arbitrate, for which he extracted legal recognition that the realm of Scotland was held as a feudal dependency to the throne of England before choosing John Balliol, the man with the strongest claim, who became king in 1292. Robert Bruce, 5th Lord of Annandale, the next strongest claimant, accepted this outcome with reluctance. Over the next few years Edward I used the concessions he had gained to systematically undermine both the authority of King John and the independence of Scotland. In 1295, John, on the urgings of his chief councillors, entered into an alliance with France, known as the Auld Alliance.
In 1296, Edward invaded Scotland, deposing King John. The following year William Wallace and Andrew de Moray raised forces to resist the occupation and under their joint leadership an English army was defeated at the Battle of Stirling Bridge. For a short time Wallace ruled Scotland in the name of John Balliol as Guardian of the realm. Edward came north in person and defeated Wallace at the Battle of Falkirk in 1298. Wallace escaped but probably resigned as Guardian of Scotland. In 1305, he fell into the hands of the English, who executed him for treason despite the fact that he owed no allegiance to England.

Rivals John Comyn and Robert the Bruce, grandson of the claimant, were appointed as joint guardians in his place. On 10 February 1306, Bruce participated in the murder of Comyn, at Greyfriars Kirk in Dumfries. Less than seven weeks later, on 25 March, Bruce was crowned as King. However, Edward's forces overran the country after defeating Bruce's small army at the Battle of Methven. Despite the excommunication of Bruce and his followers by Pope Clement V, his support slowly strengthened; and by 1314 with the help of leading nobles such as Sir James Douglas and Thomas Randolph only the castles at Bothwell and Stirling remained under English control. Edward I had died in 1307. His heir Edward II moved an army north to break the siege of Stirling Castle and reassert control. Robert defeated that army at the Battle of Bannockburn in 1314, securing "de facto" independence. In 1320, the Declaration of Arbroath, a remonstrance to the Pope from the nobles of Scotland, helped convince Pope John XXII to overturn the earlier excommunication and nullify the various acts of submission by Scottish kings to English ones so that Scotland's sovereignty could be recognised by the major European dynasties. The Declaration has also been seen as one of the most important documents in the development of a Scottish national identity.

In 1326, what may have been the first full Parliament of Scotland met. The parliament had evolved from an earlier council of nobility and clergy, the "colloquium", constituted around 1235, but perhaps in 1326 representatives of the burghs — the burgh commissioners — joined them to form the Three Estates. In 1328, Edward III signed the Treaty of Edinburgh–Northampton acknowledging Scottish independence under the rule of Robert the Bruce. However, four years after Robert's death in 1329, England once more invaded on the pretext of restoring Edward Balliol, son of John Balliol, to the Scottish throne, thus starting the Second War of Independence. Despite victories at Dupplin Moor and Halidon Hill, in the face of tough Scottish resistance led by Sir Andrew Murray, the son of Wallace's comrade in arms, successive attempts to secure Balliol on the throne failed. Edward III lost interest in the fate of his protégé after the outbreak of the Hundred Years' War with France. In 1341, David II, King Robert's son and heir, was able to return from temporary exile in France. Balliol finally resigned his claim to the throne to Edward in 1356, before retiring to Yorkshire, where he died in 1364.

After David II's death, Robert II, the first of the Stewart kings, came to the throne in 1371. He was followed in 1390 by his ailing son John, who took the regnal name Robert III. During Robert III's reign (1390–1406), actual power rested largely in the hands of his brother, Robert Stewart, Duke of Albany. After the suspicious death (possibly on the orders of the Duke of Albany) of his elder son, David, Duke of Rothesay in 1402, Robert, fearful for the safety of his younger son, the future James I, sent him to France in 1406. However, the English captured him en route and he spent the next 18 years as a prisoner held for ransom. As a result, after the death of Robert III, regents ruled Scotland: first, the Duke of Albany; and later his son Murdoch. When Scotland finally paid the ransom in 1424, James, aged 32, returned with his English bride determined to assert this authority. Several of the Albany family were executed; but he succeeded in centralising control in the hands of the crown, at the cost of increasing unpopularity, and was assassinated in 1437. His son James II (reigned 1437–1460), when he came of age in 1449, continued his father's policy of weakening the great noble families, most notably taking on the powerful Black Douglas family that had come to prominence at the time of the Bruce.

In 1468, the last significant acquisition of Scottish territory occurred when James III was engaged to Margaret of Denmark, receiving the Orkney Islands and the Shetland Islands in payment of her dowry. Berwick upon Tweed was captured by England in 1482. With the death of James III in 1488 at the Battle of Sauchieburn, his successor James IV successfully ended the quasi-independent rule of the Lord of the Isles, bringing the Western Isles under effective Royal control for the first time. In 1503, he married Margaret Tudor, daughter of Henry VII of England, thus laying the foundation for the 17th century Union of the Crowns.

Scotland advanced markedly in educational terms during the 15th century with the founding of the University of St Andrews in 1413, the University of Glasgow in 1450 and the University of Aberdeen in 1495, and with the passing of the Education Act 1496, which decreed that all sons of barons and freeholders of substance should attend grammar schools. James IV's reign is often considered to have seen a flowering of Scottish culture under the influence of the European Renaissance.
In 1512, the Auld Alliance was renewed and under its terms, when the French were attacked by the English under Henry VIII, James IV invaded England in support. The invasion was stopped decisively at the Battle of Flodden Field during which the King, many of his nobles, and a large number of ordinary troops were killed, commemorated by the song "Flowers of the Forest". Once again Scotland's government lay in the hands of regents in the name of the infant James V.

James V finally managed to escape from the custody of the regents in 1528. He continued his father's policy of subduing the rebellious Highlands, Western and Northern isles and the troublesome borders. He also continued the French alliance, marrying first the French noblewoman Madeleine of Valois and then after her death Marie of Guise. James V's domestic and foreign policy successes were overshadowed by another disastrous campaign against England that led to defeat at the Battle of Solway Moss (1542). James died a short time later, a demise blamed by contemporaries on "a broken heart". The day before his death, he was brought news of the birth of an heir: a daughter, who would become Mary, Queen of Scots.

Once again, Scotland was in the hands of a regent. Within two years, the Rough Wooing began, Henry VIII's military attempt to force a marriage between Mary and his son, Edward. This took the form of border skirmishing and several English campaigns into Scotland. In 1547, after the death of Henry VIII, forces under the English regent Edward Seymour, 1st Duke of Somerset were victorious at the Battle of Pinkie Cleugh, the climax of the Rough Wooing, and followed up by the occupation of Haddington. Mary was then sent to France at the age of five, as the intended bride of the heir to the French throne. Her mother, Marie de Guise, stayed in Scotland to look after the interests of Mary — and of France — although the Earl of Arran acted officially as regent. Guise responded by calling on French troops, who helped stiffen resistance to the English occupation. By 1550, after a change of regent in England, the English withdrew from Scotland completely.

From 1554, Marie de Guise, took over the regency, and continued to advance French interests in Scotland. French cultural influence resulted in a large influx of French vocabulary into Scots. But anti-French sentiment also grew, particularly among Protestants, who saw the English as their natural allies. In 1560, Marie de Guise died, and soon after the Auld Alliance also ended, with the signing of the Treaty of Edinburgh, which provided for the removal of French and English troops from Scotland. The Scottish Reformation took place only days later when the Scottish Parliament abolished the Roman Catholic religion and outlawed the Mass.
Meanwhile, Queen Mary had been raised as a Catholic in France, and married to the Dauphin, who became king as Francis II in 1559, making her queen consort of France. When Francis died in 1560, Mary, now 19, returned to Scotland to take up the government. Despite her private religion, she did not attempt to re-impose Catholicism on her largely Protestant subjects, thus angering the chief Catholic nobles. Her six-year personal reign was marred by a series of crises, largely caused by the intrigues and rivalries of the leading nobles. The murder of her secretary, David Riccio, was followed by that of her unpopular second husband Lord Darnley, and her abduction by and marriage to the Earl of Bothwell, who was implicated in Darnley's murder. Mary and Bothwell confronted the lords at Carberry Hill and after their forces melted away, he fled and she was captured by Bothwell's rivals. Mary was imprisoned in Loch Leven Castle, and in July 1567, was forced to abdicate in favour of her infant son James VI. Mary eventually escaped and attempted to regain the throne by force. After her defeat at the Battle of Langside in 1568, she took refuge in England, leaving her young son in the hands of regents. In Scotland the regents fought a civil war on behalf of James VI against his mother's supporters. In England, Mary became a focal point for Catholic conspirators and was eventually tried for treason and executed on the orders of her kinswoman Elizabeth I.

During the 16th century, Scotland underwent a Protestant Reformation that created a predominantly Calvinist national Kirk, which became Presbyterian in outlook and severely reduced the powers of bishops. In the earlier part of the century, the teachings of first Martin Luther and then John Calvin began to influence Scotland, particularly through Scottish scholars, often training for the priesthood, who had visited Continental universities. The Lutheran preacher Patrick Hamilton was executed for heresy in St. Andrews in 1528. The execution of others, especially the Zwingli-influenced George Wishart, who was burnt at the stake on the orders of Cardinal Beaton in 1546, angered Protestants. Wishart's supporters assassinated Beaton soon after and seized St. Andrews Castle, which they held for a year before they were defeated with the help of French forces. The survivors, including chaplain John Knox, were condemned to be galley slaves in France, stoking resentment of the French and creating martyrs for the Protestant cause.

Limited toleration and the influence of exiled Scots and Protestants in other countries, led to the expansion of Protestantism, with a group of lairds declaring themselves Lords of the Congregation in 1557 and representing their interests politically. The collapse of the French alliance and English intervention in 1560 meant that a relatively small, but highly influential, group of Protestants were in a position to impose reform on the Scottish church. A confession of faith, rejecting papal jurisdiction and the mass, was adopted by Parliament in 1560, while the young Mary, Queen of Scots, was still in France.

Knox, having escaped the galleys and spent time in Geneva as a follower of Calvin, emerged as the most significant figure of the period. The Calvinism of the reformers led by Knox resulted in a settlement that adopted a Presbyterian system and rejected most of the elaborate trappings of the medieval church. The reformed Kirk gave considerable power to local lairds, who often had control over the appointment of the clergy. There were widespread, but generally orderly outbreaks of iconoclasm. At this point the majority of the population was probably still Catholic in persuasion and the Kirk found it difficult to penetrate the Highlands and Islands, but began a gradual process of conversion and consolidation that, compared with reformations elsewhere, was conducted with relatively little persecution.

Women shared in the religiosity of the day. The egalitarian and emotional aspects of Calvinism appealed to men and women alike. Historian Alasdair Raffe finds that, "Men and women were thought equally likely to be among the elect...Godly men valued the prayers and conversation of their female co-religionists, and this reciprocity made for loving marriages and close friendships between men and women." Furthermore, there was an increasingly intense relationship In the pious bonds between minister and his women parishioners. For the first time, laywomen gained numerous new religious roles,And took a prominent place in prayer societies.

In 1603, James VI King of Scots inherited the throne of the Kingdom of England, and became King James I of England, leaving Edinburgh for London, uniting England and Scotland under one monarch. The Union was a personal or dynastic union, with the Crowns remaining both distinct and separate—despite James's best efforts to create a new "imperial" throne of "Great Britain". The acquisition of the Irish crown along with the English, facilitated a process of settlement by Scots in what was historically the most troublesome area of the kingdom in Ulster, with perhaps 50,000 Scots settling in the province by the mid-17th century. James adopted a different approach to impose his authority in the western Highlands and Islands. The additional military resource that was now available, particularly the English navy, resulted in the enactment of the Statutes of Iona which compelled integration of Hebridean clan leaders with the rest of Scottish society. Attempts to found a Scottish colony in North America in Nova Scotia were largely unsuccessful, with insufficient funds and willing colonists.

Although James had tried to get the Scottish Church to accept some of the High Church Anglicanism of his southern kingdom, he met with limited success. His son and successor, Charles I, took matters further, introducing an English-style Prayer Book into the Scottish church in 1637. This resulted in anger and widespread rioting. (The story goes that it was initiated by a certain Jenny Geddes who threw a stool in St Giles Cathedral.) Representatives of various sections of Scottish society drew up the National Covenant in 1638, objecting to the King's liturgical innovations. In November of the same year matters were taken even further, when at a meeting of the General Assembly in Glasgow the Scottish bishops were formally expelled from the Church, which was then established on a full Presbyterian basis. Charles gathered a military force; but as neither side wished to push the matter to a full military conflict, a temporary settlement was concluded at Pacification of Berwick. Matters remained unresolved until 1640 when, in a renewal of hostilities, Charles's northern forces were defeated by the Scots at the Battle of Newburn to the west of Newcastle. During the course of these Bishops' Wars Charles tried to raise an army of Irish Catholics, but was forced to back down after a storm of protest in Scotland and England. The backlash from this venture provoked a rebellion in Ireland and Charles was forced to appeal to the English Parliament for funds. Parliament's demands for reform in England eventually resulted in the English Civil War. This series of civil wars that engulfed England, Ireland and Scotland in the 1640s and 1650s is known to modern historians as the Wars of the Three Kingdoms. The Covenanters meanwhile, were left governing Scotland, where they raised a large army of their own and tried to impose their religious settlement on Episcopalians and Roman Catholics in the north of the country. In England his religious policies caused similar resentment and he ruled without recourse to parliament from 1629.

As the civil wars developed, the English Parliamentarians appealed to the Scots Covenanters for military aid against the King. A Solemn League and Covenant was entered into, guaranteeing the Scottish Church settlement and promising further reform in England. Scottish troops played a major part in the defeat of Charles I, notably at the battle of Marston Moor. An army under the Earl of Leven occupied the North of England for some time.

However, not all Scots supported the Covenanter's taking arms against their King. In 1644, James Graham, 1st Marquess of Montrose attempted to raise the Highlands for the King. Few Scots would follow him, but, aided by 1,000 Irish, Highland and Islesmen troops sent by the Irish Confederates under Alasdair MacDonald (MacColla), and an instinctive genius for mobile warfare, he was stunningly successful. A Scottish Civil War began in September 1644 with his victory at battle of Tippermuir. After a series of victories over poorly trained Covenanter militias, the lowlands were at his mercy. However, at this high point, his army was reduced in size, as MacColla and the Highlanders preferred to continue the war in the north against the Campbells. Shortly after, what was left of his force was defeated at the Battle of Philiphaugh. Escaping to the north, Montrose attempted to continue the struggle with fresh troops; but in July 1646 his army was disbanded after the King surrendered to the Scots army at Newark, and the civil war came to an end.

The following year Charles, while he was being held captive in Carisbrooke Castle, entered into an agreement with moderate Scots Presbyterians. In this secret 'Engagement', the Scots promised military aid in return for the King's agreement to implement Presbyterianism in England on a three-year trial basis. The Duke of Hamilton led an invasion of England to free the King, but he was defeated by Oliver Cromwell in August 1648 at the Battle of Preston.

The execution of Charles I in 1649 was carried out in the face of objections by the Covenanter government and his son was immediately proclaimed as King Charles II in Edinburgh. Oliver Cromwell led an invasion of Scotland in 1650, and defeated the Scottish army at Dunbar and then defeated a Scottish invasion of England at Worcester on 3 September 1651 (the anniversary of his victory at Dunbar). Cromwell emerged as the leading figure in the English government and Scotland was occupied by an English force under George Monck. The country was incorporated into the Puritan-governed Commonwealth and lost its independent church government, parliament and legal system, but gained access to English markets. Various attempts were made to legitimise the union, calling representatives from the Scottish burghs and shires to negotiations and to various English parliaments, where they were always under-represented and had little opportunity for dissent. However, final ratification was delayed by Cromwell's problems with his various parliaments and the union did not become the subject of an act until 1657 (see Tender of Union).

After the death of Cromwell and the regime's collapse, Charles II was restored in 1660 and Scotland again became an independent kingdom. Scotland regained its system of law, parliament and kirk, but also the Lords of the Articles (by which the crown managed parliament), bishops and a king who did not visit the country. He ruled largely without reference to Parliament, through a series of commissioners. These began with John, Earl of Middleton and ended with the king's brother and heir, James, Duke of York (known in Scotland as the Duke of Albany). The English Navigation Acts prevented the Scots engaging in what would have been lucrative trading with England's colonies. The restoration of episcopacy was a source of trouble, particularly in the south-west of the country, an area with strong Presbyterian sympathies. Abandoning the official church, many of the inhabitants began to attend illegal field assemblies, known as conventicles. Official attempts to suppress these led to a rising in 1679, defeated by James, Duke of Monmouth, the King's illegitimate son, at the Battle of Bothwell Bridge. In the early 1680s a more intense phase of persecution began, later to be called "the Killing Time". When Charles died in 1685 and his brother, a Roman Catholic, succeeded him as James VII of Scotland (and II of England), matters came to a head.

James put Catholics in key positions in the government and attendance at conventicles was made punishable by death. He disregarded parliament, purged the Council and forced through religious toleration to Roman Catholics, alienating his Protestant subjects. It was believed that the king would be succeeded by his daughter Mary, a Protestant and the wife of William of Orange, Stadtholder of the Netherlands, but when in 1688, James produced a male heir, James Francis Edward Stuart, it was clear that his policies would outlive him. An invitation by seven leading Englishmen led William to land in England with 40,000 men, and James fled, leading to the almost bloodless "Glorious Revolution". The Estates issued a "Claim of Right" that suggested that James had forfeited the crown by his actions (in contrast to England, which relied on the legal fiction of an abdication) and offered it to William and Mary, which William accepted, along with limitations on royal power. The final settlement restored Presbyterianism and abolished the bishops who had generally supported James. However, William, who was more tolerant than the Kirk tended to be, passed acts restoring the Episcopalian clergy excluded after the Revolution.

Although William's supporters dominated the government, there remained a significant following for James, particularly in the Highlands. His cause, which became known as Jacobitism, from the Latin "(Jacobus)" for James, led to a series of risings. An initial Jacobite military attempt was led by John Graham, Viscount Dundee. His forces, almost all Highlanders, defeated William's forces at the Battle of Killiecrankie in 1689, but they took heavy losses and Dundee was slain in the fighting. Without his leadership the Jacobite army was soon defeated at the Battle of Dunkeld. In the aftermath of the Jacobite defeat on 13 February 1692, in an incident since known as the Massacre of Glencoe, 38 members of the Clan MacDonald of Glencoe were killed by members of the Earl of Argyll's Regiment of Foot, on the grounds that they had not been prompt in pledging allegiance to the new monarchs.

The closing decade of the 17th century saw the generally favourable economic conditions that had dominated since the Restoration come to an end. There was a slump in trade with the Baltic and France from 1689 to 1691, caused by French protectionism and changes in the Scottish cattle trade, followed by four years of failed harvests (1695, 1696 and 1698-9), an era known as the "seven ill years". The result was severe famine and depopulation, particularly in the north. The Parliament of Scotland of 1695 enacted proposals to help the desperate economic situation, including setting up the Bank of Scotland. The "Company of Scotland Trading to Africa and the Indies" received a charter to raise capital through public subscription.

With the dream of building a lucrative overseas colony for Scotland, the Company of Scotland invested in the Darien scheme, an ambitious plan devised by William Paterson to establish a colony on the Isthmus of Panama in the hope of establishing trade with the Far East. The Darién scheme won widespread support in Scotland as the landed gentry and the merchant class were in agreement in seeing overseas trade and colonialism as routes to upgrade Scotland's economy. Since the capital resources of the Edinburgh merchants and landholder elite were insufficient, the company appealed to middling social ranks, who responded with patriotic fervour to the call for money; the lower classes volunteered as colonists. But the English government opposed the idea: involved in the War of the Grand Alliance from 1689 to 1697 against France, it did not want to offend Spain, which claimed the territory as part of New Granada. The English investors withdrew. Returning to Edinburgh, the Company raised 400,000 pounds in a few weeks. Three small fleets with a total of 3,000 men eventually set out for Panama in 1698. The exercise proved a disaster. Poorly equipped; beset by incessant rain; under attack by the Spanish from nearby Cartagena; and refused aid by the English in the West Indies, the colonists abandoned their project in 1700. Only 1,000 survived and only one ship managed to return to Scotland.

Scotland was a poor rural, agricultural society with a population of 1.3 million in 1755. Although Scotland lost home rule, the Union allowed it to break free of a stultifying system and opened the way for the Scottish enlightenment as well as a great expansion of trade and increase in opportunity and wealth. Edinburgh economist Adam Smith concluded in 1776 that "By the union with England, the middling and inferior ranks of people in Scotland gained a complete deliverance from the power of an aristocracy which had always before oppressed them." Historian Jonathan Israel holds that the Union "proved a decisive catalyst politically and economically," by allowing ambitious Scots entry on an equal basis to a rich expanding empire and its increasing trade.

Scotland's transformation into a rich leader of modern industry came suddenly and unexpectedly in the next 150 years, following its union with England in 1707 and its integration with the advanced English and imperial economies. The transformation was led by two cities that grew rapidly after 1770. Glasgow, on the river Clyde, was the base for the tobacco and sugar trade with an emerging textile industry. Edinburgh was the administrative and intellectual centre where the Scottish Enlightenment was chiefly based.

By the start of the 18th century, a political union between Scotland and England became politically and economically attractive, promising to open up the much larger markets of England, as well as those of the growing English Empire. With economic stagnation since the late 17th century, which was particularly acute in 1704; the country depended more and more heavily on sales of cattle and linen to England, who used this to create pressure for a union. The Scottish parliament voted on 6 January 1707, by 110 to 69, to adopt the Treaty of Union. It was also a full economic union; indeed, most of its 25 articles dealt with economic arrangements for the new state known as "Great Britain". It added 45 Scots to the 513 members of the House of Commons and 16 Scots to the 190 members of the House of Lords, and ended the Scottish parliament. It also replaced the Scottish systems of currency, taxation and laws regulating trade with laws made in London. Scottish law remained separate from English law, and the religious system was not changed. England had about five times the population of Scotland at the time, and about 36 times as much wealth.

Jacobitism was revived by the unpopularity of the union. In 1708, James Francis Edward Stuart, the son of James VII, who became known as "The Old Pretender", attempted an invasion with a French fleet carrying 6,000 men, but the Royal Navy prevented it from landing troops. A more serious attempt occurred in 1715, soon after the death of Anne and the accession of the first Hanoverian king, the eldest son of Sophie, as George I of Great Britain. This rising (known as "The 'Fifteen") envisaged simultaneous uprisings in Wales, Devon, and Scotland. However, government arrests forestalled the southern ventures. In Scotland, John Erskine, Earl of Mar, nicknamed "Bobbin' John", raised the Jacobite clans but proved to be an indecisive leader and an incompetent soldier. Mar captured Perth, but let a smaller government force under the Duke of Argyll hold the Stirling plain. Part of Mar's army joined up with risings in northern England and southern Scotland, and the Jacobites fought their way into England before being defeated at the Battle of Preston, surrendering on 14 November 1715. The day before, Mar had failed to defeat Argyll at the Battle of Sheriffmuir. At this point, James belatedly landed in Scotland, but was advised that the cause was hopeless. He fled back to France. An attempted Jacobite invasion with Spanish assistance in 1719 met with little support from the clans and ended in defeat at the Battle of Glen Shiel.

In 1745, the Jacobite rising known as "The 'Forty-Five" began. Charles Edward Stuart, son of the "Old Pretender", often referred to as "Bonnie Prince Charlie" or the "Young Pretender", landed on the island of Eriskay in the Outer Hebrides. Several clans unenthusiastically joined him. At the outset he was successful, taking Edinburgh and then defeating the only government army in Scotland at the Battle of Prestonpans. The Jacobite army marched into England, took Carlisle and advanced as far as south as Derby. However, it became increasingly evident that England would not support a Roman Catholic Stuart monarch. The Jacobite leadership had a crisis of confidence and they retreated to Scotland as two English armies closed in and Hanoverian troops began to return from the continent. Charles' position in Scotland began to deteriorate as the Whig supporters rallied and regained control of Edinburgh. After an unsuccessful attempt on Stirling, he retreated north towards Inverness. He was pursued by the Duke of Cumberland and gave battle with an exhausted army at Culloden on 16 April 1746, where the Jacobite cause was crushed. Charles hid in Scotland with the aid of Highlanders until September 1746, when he escaped back to France. There were bloody reprisals against his supporters and foreign powers abandoned the Jacobite cause, with the court in exile forced to leave France. The Old Pretender died in 1760 and the Young Pretender, without legitimate issue, in 1788. When his brother, Henry, Cardinal of York, died in 1807, the Jacobite cause was at an end.

With the advent of the Union and the demise of Jacobitism, access to London and the Empire opened up very attractive career opportunities for ambitious middle-class and upper-class Scots, who seized the chance to become entrepreneurs, intellectuals, and soldiers. Thousands of Scots, mainly Lowlanders, took up positions of power in politics, civil service, the army and navy, trade, economics, colonial enterprises and other areas across the nascent British Empire. Historian Neil Davidson notes that “after 1746 there was an entirely new level of participation by Scots in political life, particularly outside Scotland”. Davidson also states that “far from being ‘peripheral’ to the British economy, Scotland – or more precisely, the Lowlands – lay at its core”. British officials especially appreciated Scottish soldiers. As the Secretary of War told Parliament in 1751, "I am for having always in our army as many Scottish soldiers as possible...because they are generally more hardy and less mutinous". The national policy of aggressively recruiting Scots for senior civilian positions stirred up resentment among Englishmen, ranging from violent diatribes by John Wilkes, to vulgar jokes and obscene cartoons in the popular press, and the haughty ridicule by intellectuals such as Samuel Johnson that was much resented by Scots. In his great "Dictionary" Johnson defined oats as, "a grain, which in England is generally given to horses, but in Scotland supports the people." To which Lord Elibank retorted, "Very true, and where will you find such men and such horses?"

Scottish politics in the late 18th century was dominated by the Whigs, with the benign management of Archibald Campbell, 3rd Duke of Argyll (1682–1761), who was in effect the "viceroy of Scotland" from the 1720s until his death in 1761. Scotland generally supported the king with enthusiasm during the American Revolution. Henry Dundas (1742–1811) dominated political affairs in the latter part of the century. Dundas put a brake on intellectual and social change through his ruthless manipulation of patronage in alliance with Prime Minister William Pitt the Younger, until he lost power in 1806.

The main unit of local government was the parish, and since it was also part of the church, the elders imposed public humiliation for what the locals considered immoral behaviour, including fornication, drunkenness, wife beating, cursing and Sabbath breaking. The main focus was on the poor and the landlords ("lairds") and gentry, and their servants, were not subject to the parish's control. The policing system weakened after 1800 and disappeared in most places by the 1850s.

The clan system of the Highlands and Islands had been seen as a challenge to the rulers of Scotland from before the 17th century. James VI's various measures to exert control included the Statutes of Iona, an attempt to force clan leaders to become integrated into the rest of Scottish society. This started a slow process of change which, by the second half of the 18th century, saw clan chiefs start to think of themselves as commercial landlords, rather than as patriarchs of their people. To their tenants, initially this meant that monetary rents replaced those paid in kind. Later, rent increases became common. In the 1710s the Dukes of Argyll started putting leases of some of their land up for auction; by 1737 this was done across the Argyll property. This commercial attitude replaced the principle of "", which included the obligation on clan chiefs to provide land for clan members. The shift of this attitude slowly spread through the Highland elite (but not among their tenants). As clan chiefs became more integrated into Scottish and British society, many of them built up large debts. It became easier to borrow against the security of a Highland estate from the 1770s onwards. As the lenders became predominantly people and organisations outside the Highlands, there was a greater willingness to foreclose if the borrower defaulted. Combined with an astounding level of financial incompetence among the Highland elite, this ultimately forced the sale of the estates of many Highland landed families over the period 1770-1850. (The greatest number of sales of whole estates was toward the end of this period.)

The Jacobite rebellion of 1745 gave a final period of importance to the ability of Highland clans to raise bodies of fighting men at short notice. With the defeat at Culloden, any enthusiasm for continued warfare disappeared and clan leaders returned to their transition to being commercial landlords. This was arguably accelerated by some of the punitive laws enacted after the rebellion. These included the Heritable Jurisdictions Act of 1746, which removed judicial roles from clan chiefs and gave them to the Scottish law courts. T. M. Devine warns against seeing a clear cause and effect relationship between the post-Culloden legislation and the collapse of clanship. He questions the basic effectiveness of the measures, quoting W. A. Speck who ascribes the pacification of the area more to "a disinclination to rebel than to the government's repressive measures." Devine points out that social change in Gaeldom did not pick up until the 1760s and 1770s, as this coincided with the increased market pressures from the industrialising and urbanising Lowlands.

41 properties belonging to rebels were forfeited to the Crown in the aftermath of the '45. The vast majority of these were sold by auction to pay creditors. 13 were retained and managed on behalf of the government between 1752 and 1784.

The changes by the Dukes of Argyll in the 1730s displaced many of the tacksmen in the area. From the 1770s onwards, this became a matter of policy throughout the Highlands. The restriction on subletting by tacksmen meant that landlords received all the rent paid by the actual farming tenants - thereby increasing their income. By the early part of the 19th century, the tacksman had become a rare component of Highland society. T. M. Devine describes "the displacement of this class as one of the clearest demonstrations of the death of the old Gaelic society." Many emigrated, leading parties of their tenants to North America. These tenants were from the better off part of Highland peasant society, and, together with the tacksmen, they took their capital and entrepreneurial energy to the New World, unwilling to participate in economic changes imposed by their landlords which often involved a loss of status for the tenant.

Agricultural improvement was introduced across the Highlands over the relatively short period of 1760-1850. The evictions involved in this became known as the Highland clearances. There was regional variation. In the east and south of the Highlands, the old townships or "", which were farmed under the run rig system were replaced by larger enclosed farms, with fewer people holding leases and proportionately more of the population working as employees on these larger farms. (This was broadly similar to the situation in the Lowlands.) In the north and west, including the Hebrides, as land was taken out of run rig, crofting communities were established. Much of this change involved establishing large pastoral sheep farms, with the old displaced tenants moving to new crofts in coastal areas or on poor quality land. Sheep farming was increasingly profitable at the end of the 18th century, so could pay substantially higher rents than the previous tenants. Particularly in the Hebrides, some crofting communities were established to work in the kelp industry. Others were engaged in fishing. Croft sizes were kept small, so that the occupiers were forced to seek employment to supplement what they could grow. This increased the number of seasonal migrant workers travelling to the Lowlands. The resulting connection with the Lowlands was highly influential on all aspects of Highland life, touching on income levels, social attitudes and language. Migrant working gave an advantage in speaking English, which came to be considered "the language of work".

In 1846 the Highland potato famine struck the crofting communities of the North and West Highlands. By 1850 the charitable relief effort was wound up, despite the continuing crop failure, and landlords, charities and the government resorted to encouraging emigration. The overall result was that almost 11,000 people were provided with "assisted passages" by their landlords between 1846 and 1856, with the greatest number travelling in 1851. A further 5,000 emigrated to Australia, through the Highland and Island Emigration Society. To this should be added an unknown, but significant number, who paid their own fares to emigrate, and a further unknown number assisted by the Colonial Land and Emigration commission. This was out of a famine-affected population of about 200,000 people. Many of those who remained became even more involved in temporary migration for work in the Lowlands, both out of necessity during the famine and having become accustomed to working away by the time the famine ceased. Much longer periods were spent out of the Highlands - often for much of the year or more. One illustration of this migrant working was the estimated 30,000 men and women from the far west of the Gaelic speaking area who travelled to the east coast fishing ports for the herring fishing season - providing labour in an industry that grew by 60% between 1854-1884.

The clearances were followed by a period of even greater emigration from the Highlands, which continued (with a brief lull for the First World War) up to the start of the Great Depression.

Historian Jonathan Israel argues that by 1750 Scotland's major cities had created an intellectual infrastructure of mutually supporting institutions, such as universities, reading societies, libraries, periodicals, museums and masonic lodges. The Scottish network was "predominantly liberal Calvinist, Newtonian, and 'design' oriented in character which played a major role in the further development of the transatlantic Enlightenment ." In France Voltaire said "we look to Scotland for all our ideas of civilization," and the Scots in turn paid close attention to French ideas. Historian Bruce Lenman says their "central achievement was a new capacity to recognize and interpret social patterns." The first major philosopher of the Scottish Enlightenment was Francis Hutcheson, who held the Chair of Philosophy at the University of Glasgow from 1729 to 1746. A moral philosopher who produced alternatives to the ideas of Thomas Hobbes, one of his major contributions to world thought was the utilitarian and consequentialist principle that virtue is that which provides, in his words, "the greatest happiness for the greatest numbers". Much of what is incorporated in the scientific method (the nature of knowledge, evidence, experience, and causation) and some modern attitudes towards the relationship between science and religion were developed by his protégés David Hume and Adam Smith. Hume became a major figure in the skeptical philosophical and empiricist traditions of philosophy. He and other Scottish Enlightenment thinkers developed what he called a 'science of man', which was expressed historically in works by authors including James Burnett, Adam Ferguson, John Millar and William Robertson, all of whom merged a scientific study of how humans behave in ancient and primitive cultures with a strong awareness of the determining forces of modernity. Modern sociology largely originated from this movement and Hume's philosophical concepts that directly influenced James Madison (and thus the US Constitution) and when popularised by Dugald Stewart, would be the basis of classical liberalism. Adam Smith published "The Wealth of Nations", often considered the first work on modern economics. It had an immediate impact on British economic policy and in the 21st century still framed discussions on globalisation and tariffs. The focus of the Scottish Enlightenment ranged from intellectual and economic matters to the specifically scientific as in the work of the physician and chemist William Cullen, the agriculturalist and economist James Anderson, chemist and physician Joseph Black, natural historian John Walker and James Hutton, the first modern geologist.

With tariffs with England now abolished, the potential for trade for Scottish merchants was considerable. However, Scotland in 1750 was still a poor rural, agricultural society with a population of 1.3 million. Some progress was visible: agriculture in the Lowlands was steadily upgraded after 1700 and standards remained high. There were the sales of linen and cattle to England, the cash flows from military service, and the tobacco trade that was dominated by Glasgow Tobacco Lords after 1740. Merchants who profited from the American trade began investing in leather, textiles, iron, coal, sugar, rope, sailcloth, glassworks, breweries, and soapworks, setting the foundations for the city's emergence as a leading industrial centre after 1815. The tobacco trade collapsed during the American Revolution (1776–83), when its sources were cut off by the British blockade of American ports. However, trade with the West Indies began to make up for the loss of the tobacco business, reflecting the British demand for sugar and the demand in the West Indies for herring and linen goods.

Linen was Scotland's premier industry in the 18th century and formed the basis for the later cotton, jute, and woollen industries. Scottish industrial policy was made by the Board of Trustees for Fisheries and Manufactures in Scotland, which sought to build an economy complementary, not competitive, with England. Since England had woollens, this meant linen. Encouraged and subsidised by the Board of Trustees so it could compete with German products, merchant entrepreneurs became dominant in all stages of linen manufacturing and built up the market share of Scottish linens, especially in the American colonial market. The British Linen Company, established in 1746, was the largest firm in the Scottish linen industry in the 18th century, exporting linen to England and America. As a joint-stock company, it had the right to raise funds through the issue of promissory notes or bonds. With its bonds functioning as bank notes, the company gradually moved into the business of lending and discounting to other linen manufacturers, and in the early 1770s banking became its main activity. It joined the established Scottish banks such as the Bank of Scotland (Edinburgh, 1695) and the Royal Bank of Scotland (Edinburgh, 1727). Glasgow would soon follow and Scotland had a flourishing financial system by the end of the century. There were over 400 branches, amounting to one office per 7,000 people, double the level in England, where banks were also more heavily regulated. Historians have emphasised that the flexibility and dynamism of the Scottish banking system contributed significantly to the rapid development of the economy in the 19th century.

German sociologist Max Weber mentioned Scottish Presbyterianism in The Protestant Ethic and the Spirit of Capitalism (1905), and many scholars in recent decades argued that "this worldly asceticism" of Calvinism was integral to Scotland's rapid economic modernisation.

In the 1690s the Presbyterian establishment purged the land of Episcopalians and heretics, and made blasphemy a capital crime. Thomas Aitkenhead, the son of an Edinburgh surgeon, aged 18, was indicted for blasphemy by order of the Privy Council for calling the New Testament "The History of the Imposter Christ"; he was hanged in 1696. Their extremism led to a reaction known as the "Moderate" cause that ultimately prevailed and opened the way for liberal thinking in the cities.

The early 18th century saw the beginnings of a fragmentation of the Church of Scotland. These fractures were prompted by issues of government and patronage, but reflected a wider division between the hard-line Evangelicals and the theologically more tolerant Moderate Party. The battle was over fears of fanaticism by the former and the promotion of Enlightenment ideas by the latter. The Patronage Act of 1712 was a major blow to the evangelicals, for it meant that local landlords could choose the minister, not the members of the congregation. Schisms erupted as the evangelicals left the main body, starting in 1733 with the First Secession headed by figures including Ebenezer Erskine. The second schism in 1761 lead to the foundation of the independent Relief Church. These churches gained strength in the Evangelical Revival of the later 18th century. A key result was the main Presbyterian church was in the hands of the Moderate faction, which provided critical support for the Enlightenment in the cities.

Long after the triumph of the Church of Scotland in the Lowlands, Highlanders and Islanders clung to an old-fashioned Christianity infused with animistic folk beliefs and practices. The remoteness of the region and the lack of a Gaelic-speaking clergy undermined the missionary efforts of the established church. The later 18th century saw some success, owing to the efforts of the SSPCK missionaries and to the disruption of traditional society. Catholicism had been reduced to the fringes of the country, particularly the Gaelic-speaking areas of the Highlands and Islands. Conditions also grew worse for Catholics after the Jacobite rebellions and Catholicism was reduced to little more than a poorly run mission. Also important was Episcopalianism, which had retained supporters through the civil wars and changes of regime in the 17th century. Since most Episcopalians had given their support to the Jacobite rebellions in the early 18th century, they also suffered a decline in fortunes.

Although Scotland increasingly adopted the English language and wider cultural norms, its literature developed a distinct national identity and began to enjoy an international reputation. Allan Ramsay (1686–1758) laid the foundations of a reawakening of interest in older Scottish literature, as well as leading the trend for pastoral poetry, helping to develop the Habbie stanza as a poetic form. James Macpherson was the first Scottish poet to gain an international reputation, claiming to have found poetry written by Ossian, he published translations that acquired international popularity, being proclaimed as a Celtic equivalent of the Classical epics. "Fingal" written in 1762 was speedily translated into many European languages, and its deep appreciation of natural beauty and the melancholy tenderness of its treatment of the ancient legend did more than any single work to bring about the Romantic movement in European, and especially in German, literature, influencing Herder and Goethe. Eventually it became clear that the poems were not direct translations from the Gaelic, but flowery adaptations made to suit the aesthetic expectations of his audience. Both the major literary figures of the following century, Robert Burns and Walter Scott, would be highly influenced by the Ossian cycle. Burns, an Ayrshire poet and lyricist, is widely regarded as the national poet of Scotland and a major figure in the Romantic movement. As well as making original compositions, Burns also collected folk songs from across Scotland, often revising or adapting them. His poem (and song) "Auld Lang Syne" is often sung at Hogmanay (the last day of the year), and "Scots Wha Hae" served for a long time as an unofficial national anthem of the country.

A legacy of the Reformation in Scotland was the aim of having a school in every parish, which was underlined by an act of the Scottish parliament in 1696 (reinforced in 1801). In rural communities this obliged local landowners (heritors) to provide a schoolhouse and pay a schoolmaster, while ministers and local presbyteries oversaw the quality of the education. The headmaster or "dominie" was often university educated and enjoyed high local prestige. The kirk schools were active in the rural lowlands but played a minor role in the Highlands, the islands, and in the fast-growing industrial towns and cities. The schools taught in English, not in Gaelic, because that language was seen as a leftover of Catholicism and was not an expression of Scottish nationalism. In cities such as Glasgow the Catholics operated their own schools, which directed their youth into clerical and middle class occupations, as well as religious vocations.

A "democratic myth" emerged in the 19th century to the effect that many a "lad of pairts" had been able to rise up through the system to take high office and that literacy was much more widespread in Scotland than in neighbouring states, particularly England. Historical research has largely undermined the myth. Kirk schools were not free, attendance was not compulsory and they generally imparted only basic literacy such as the ability to read the Bible. Poor children, starting at age 7, were done by age 8 or 9; the majority were finished by age 11 or 12. The result was widespread basic reading ability; since there was an extra fee for writing, half the people never learned to write. Scots were not significantly better educated than the English and other contemporary nations. A few talented poor boys did go to university, but usually they were helped by aristocratic or gentry sponsors. Most of them became poorly paid teachers or ministers, and none became important figures in the Scottish Enlightenment or the Industrial Revolution.

By the 18th century there were five universities in Scotland, at Edinburgh, Glasgow, St. Andrews and King's and Marischial Colleges in Aberdeen, compared with only two in England. Originally oriented to clerical and legal training, after the religious and political upheavals of the 17th century they recovered with a lecture-based curriculum that was able to embrace economics and science, offering a high quality liberal education to the sons of the nobility and gentry. It helped the universities to become major centres of medical education and to put Scotland at the forefront of Enlightenment thinking.

Scotland's transformation into a rich leader of modern industry came suddenly and unexpectedly. The population grew steadily in the 19th century, from 1,608,000 in the census of 1801 to 2,889,000 in 1851 and 4,472,000 in 1901. The economy, long based on agriculture, began to industrialise after 1790. At first the leading industry, based in the west, was the spinning and weaving of cotton. In 1861, the American Civil War suddenly cut off the supplies of raw cotton and the industry never recovered. Thanks to its many entrepreneurs and engineers, and its large stock of easily mined coal, Scotland became a world centre for engineering, shipbuilding, and locomotive construction, with steel replacing iron after 1870.

The Scottish Reform Act 1832 increased the number of Scottish MPs and significantly widened the franchise to include more of the middle classes. From this point until the end of the century, the Whigs and (after 1859) their successors the Liberal Party, managed to gain a majority of the Westminster Parliamentary seats for Scotland, although these were often outnumbered by the much larger number of English and Welsh Conservatives. The English-educated Scottish peer Lord Aberdeen (1784–1860) led a coalition government from 1852–5, but in general very few Scots held office in the government. From the mid-century there were increasing calls for Home Rule for Scotland and when the Conservative Lord Salisbury became prime minister in 1885 he responded to pressure by reviving the post of Secretary of State for Scotland, which had been in abeyance since 1746. He appointed the Duke of Richmond, a wealthy landowner who was both Chancellor of Aberdeen University and Lord Lieutenant of Banff. Towards the end of the century Prime Ministers of Scottish descent included the Tory, Peelite and Liberal William Gladstone, who held the office four times between 1868 and 1894. The first Scottish Liberal to become prime minister was the Earl of Rosebery, from 1894 to 1895, like Aberdeen before him a product of the English education system. In the later 19th century the issue of Irish Home Rule led to a split among the Liberals, with a minority breaking away to form the Liberal Unionists in 1886. The growing importance of the working classes was marked by Keir Hardie's success in the Mid Lanarkshire by-election, 1888, leading to the foundation of the Scottish Labour Party, which was absorbed into the Independent Labour Party in 1895, with Hardie as its first leader.

From about 1790 textiles became the most important industry in the west of Scotland, especially the spinning and weaving of cotton, which flourished until in 1861 the American Civil War cut off the supplies of raw cotton. The industry never recovered, but by that time Scotland had developed heavy industries based on its coal and iron resources. The invention of the hot blast for smelting iron (1828) revolutionised the Scottish iron industry. As a result, Scotland became a centre for engineering, shipbuilding and the production of locomotives. Toward the end of the 19th century, steel production largely replaced iron production. Coal mining continued to grow into the 20th century, producing the fuel to heat homes, factories and drive steam engines locomotives and steamships. By 1914, there were 1,000,000 coal miners in Scotland. The stereotype emerged early on of Scottish colliers as brutish, non-religious and socially isolated serfs; that was an exaggeration, for their life style resembled the miners everywhere, with a strong emphasis on masculinity, equalitarianism, group solidarity, and support for radical labour movements.

Britain was the world leader in the construction of railways, and their use to expand trade and coal supplies. The first successful locomotive-powered line in Scotland, between Monkland and Kirkintilloch, opened in 1831. Not only was good passenger service established by the late 1840s, but an excellent network of freight lines reduce the cost of shipping coal, and made products manufactured in Scotland competitive throughout Britain. For example, railways opened the London market to Scottish beef and milk. They enabled the Aberdeen Angus to become a cattle breed of worldwide reputation. By 1900, Scotland had 3500 miles of railway; their main economic contribution was moving supplies in and product out for heavy industry, especially coal-mining.
Scotland was already one of the most urbanised societies in Europe by 1800. The industrial belt ran across the country from southwest to northeast; by 1900 the four industrialised counties of Lanarkshire, Renfrewshire, Dunbartonshire, and Ayrshire contained 44 per cent of the population. Glasgow became one of the largest cities in the world, and known as "the Second City of the Empire" after London. Shipbuilding on Clydeside (the river Clyde through Glasgow and other points) began when the first small yards were opened in 1712 at the Scott family's shipyard at Greenock. After 1860, the Clydeside shipyards specialised in steamships made of iron (after 1870, made of steel), which rapidly replaced the wooden sailing vessels of both the merchant fleets and the battle fleets of the world. It became the world's pre-eminent shipbuilding centre. "Clydebuilt" became an industry benchmark of quality, and the river's shipyards were given contracts for warships.

The industrial developments, while they brought work and wealth, were so rapid that housing, town-planning, and provision for public health did not keep pace with them, and for a time living conditions in some of the towns and cities were notoriously bad, with overcrowding, high infant mortality, and growing rates of tuberculosis. The companies attracted rural workers, as well as immigrants from Catholic Ireland, by inexpensive company housing that was a dramatic move upward from the inner-city slums. This paternalistic policy led many owners to endorse government sponsored housing programs as well as self-help projects among the respectable working class.

While the Scottish Enlightenment is traditionally considered to have concluded toward the end of the 18th century, disproportionately large Scottish contributions to British science and letters continued for another 50 years or more, thanks to such figures as the mathematicians and physicists James Clerk Maxwell, Lord Kelvin, and the engineers and inventors James Watt and William Murdoch, whose work was critical to the technological developments of the Industrial Revolution throughout Britain.

In literature the most successful figure of the mid-nineteenth century was Walter Scott, who began as a poet and also collected and published Scottish ballads. His first prose work, Waverley in 1814, is often called the first historical novel. It launched a highly successful career that probably more than any other helped define and popularise Scottish cultural identity. In the late 19th century, a number of Scottish-born authors achieved international reputations. Robert Louis Stevenson's work included the urban Gothic novella "Strange Case of Dr Jekyll and Mr Hyde" (1886), and played a major part in developing the historical adventure in books like "Kidnapped" and "Treasure Island". Arthur Conan Doyle's "Sherlock Holmes" stories helped found the tradition of detective fiction. The "kailyard tradition" at the end of the century, brought elements of fantasy and folklore back into fashion as can be seen in the work of figures like J. M. Barrie, most famous for his creation of Peter Pan, and George MacDonald, whose works, including "Phantasies", played a major part in the creation of the fantasy genre.

Scotland also played a major part in the development of art and architecture. The Glasgow School, which developed in the late 19th century, and flourished in the early 20th century, produced a distinctive blend of influences including the Celtic Revival the Arts and Crafts Movement, and Japonisme, which found favour throughout the modern art world of continental Europe and helped define the Art Nouveau style. Among the most prominent members were the loose collective of The Four: acclaimed architect Charles Rennie Mackintosh, his wife the painter and glass artist Margaret MacDonald, her sister the artist Frances, and her husband, the artist and teacher Herbert MacNair.

This period saw a process of rehabilitation for highland culture. Tartan had already been adopted for highland regiments in the British army, which poor highlanders joined in large numbers until the end of the Napoleonic Wars in 1815, but by the 19th century it had largely been abandoned by the ordinary people. In the 1820s, as part of the Romantic revival, tartan and the kilt were adopted by members of the social elite, not just in Scotland, but across Europe, prompted by the popularity of Macpherson's Ossian cycle and then Walter Scott's Waverley novels. The world paid attention to their literary redefinition of Scottishness, as they forged an image largely based on characteristics in polar opposition to those associated with England and modernity. This new identity made it possible for Scottish culture to become integrated into a wider European and North American context, not to mention tourist sites, but it also locked in a sense of "otherness" which Scotland began to shed only in the late 20th century. Scott's "staging" of the royal Visit of King George IV to Scotland in 1822 and the king's wearing of tartan, resulted in a massive upsurge in demand for kilts and tartans that could not be met by the Scottish linen industry. The designation of individual clan tartans was largely defined in this period and became a major symbol of Scottish identity. The fashion for all things Scottish was maintained by Queen Victoria, who helped secure the identity of Scotland as a tourist resort, with Balmoral Castle in Aberdeenshire becoming a major royal residence from 1852.

Despite these changes the highlands remained very poor and traditional, with few connections to the uplift of the Scottish Enlightenment and little role in the Industrial Revolution. A handful of powerful families, typified by the dukes of Argyll, Atholl, Buccleuch, and Sutherland, owned large amounts of land and controlled local political, legal and economic affairs. Particularly after the end of the boom created by the Revolutionary and Napoleonic Wars (1790–1815), these landlords needed cash to maintain their position in London society, and had less need of soldiers. They turned to money rents, displaced farmers to raise sheep, and downplayed the traditional patriarchal relationship that had historically sustained the clans. This was exacerbated after the repeal of the Corn Laws in mid-century, when Britain adopted a free trade policy, and grain imports from America undermined the profitability of crop production. The Irish potato famine of the 1840s was caused by a plant disease that reached the Highlands in 1846, where 150,000 people faced disaster because their food supply was largely potatoes (with a little herring, oatmeal and milk). They were rescued by an effective emergency relief system that stands in dramatic contrast to the failures of relief in Ireland.

The unequal concentration of land ownership remained an emotional subject and eventually became a cornerstone of liberal radicalism. The politically powerless poor crofters embraced the popularly oriented, fervently evangelical Presbyterian revival after 1800, and the breakaway "Free Church" after 1843. This evangelical movement was led by lay preachers who themselves came from the lower strata, and whose preaching was implicitly critical of the established order. This energised the crofters and separated them from the landlords, preparing them for their successful and violent challenge to the landlords in the 1880s through the Highland Land League. Violence began on the Isle of Skye when Highland landlords cleared their lands for sheep and deer parks. It was quieted when the government stepped in passing the Crofters' Holdings (Scotland) Act, 1886 to reduce rents, guarantee fixity of tenure, and break up large estates to provide crofts for the homeless. In 1885, three Independent Crofter candidates were elected to Parliament, leading to explicit security for the Scottish smallholders; the legal right to bequeath tenancies to descendants; and creating a Crofting Commission. The Crofters as a political movement faded away by 1892, and the Liberal Party gained most of their votes.

The population of Scotland grew steadily in the 19th century, from 1,608,000 in the census of 1801 to 2,889,000 in 1851 and 4,472,000 in 1901. Even with the development of industry there were insufficient good jobs; as a result, during the period 1841–1931, about 2 million Scots emigrated to North America and Australia, and another 750,000 Scots relocated to England. Scotland lost a much higher proportion of its population than England and Wales, reaching perhaps as much as 30.2 per cent of its natural increase from the 1850s onwards. This not only limited Scotland's population increase, but meant that almost every family lost members due to emigration and, because more of them were young males, it skewed the sex and age ratios of the country.

Scots-born emigrants that played a leading role in the foundation and development of the United States included cleric and revolutionary John Witherspoon, sailor John Paul Jones, industrialist and philanthropist Andrew Carnegie, and scientist and inventor Alexander Graham Bell. In Canada they included soldier and governor of Quebec James Murray, Prime Minister John A. Macdonald and politician and social reformer Tommy Douglas. For Australia they included soldier and governor Lachlan Macquarie, governor and scientist Thomas Brisbane and Prime Minister Andrew Fisher. For New Zealand they included politician Peter Fraser and outlaw James Mckenzie. By the 21st century, there would be about as many people who were Scottish Canadians and Scottish Americans as the 5 million remaining in Scotland.

After prolonged years of struggle, in 1834 the Evangelicals gained control of the General Assembly and passed the Veto Act, which allowed congregations to reject unwanted "intrusive" presentations to livings by patrons. The following "Ten Years' Conflict" of legal and political wrangling ended in defeat for the non-intrusionists in the civil courts. The result was a schism from the church by some of the non-intrusionists led by Dr Thomas Chalmers known as the Great Disruption of 1843. Roughly a third of the clergy, mainly from the North and Highlands, formed the separate Free Church of Scotland. The evangelical Free Churches, which were more accepting of Gaelic language and culture, grew rapidly in the Highlands and Islands, appealing much more strongly than did the established church. Chalmers's ideas shaped the breakaway group. He stressed a social vision that revived and preserved Scotland's communal traditions at a time of strain on the social fabric of the country. Chalmers's idealised small equalitarian, kirk-based, self-contained communities that recognised the individuality of their members and the need for co-operation. That vision also affected the mainstream Presbyterian churches, and by the 1870s it had been assimilated by the established Church of Scotland. Chalmers's ideals demonstrated that the church was concerned with the problems of urban society, and they represented a real attempt to overcome the social fragmentation that took place in industrial towns and cities.

In the late 19th century the major debates were between fundamentalist Calvinists and theological liberals, who rejected a literal interpretation of the Bible. This resulted in a further split in the Free Church as the rigid Calvinists broke away to form the Free Presbyterian Church in 1893. There were, however, also moves towards reunion, beginning with the unification of some secessionist churches into the United Secession Church in 1820, which united with the Relief Church in 1847 to form the United Presbyterian Church, which in turn joined with the Free Church in 1900 to form the United Free Church of Scotland. The removal of legislation on lay patronage would allow the majority of the Free Church to rejoin Church of Scotland in 1929. The schisms left small denominations including the Free Presbyterians and a remnant that had not merged in 1900 as the Free Church.

Catholic Emancipation in 1829 and the influx of large numbers of Irish immigrants, particularly after the famine years of the late 1840s, principally to the growing lowland centres like Glasgow, led to a transformation in the fortunes of Catholicism. In 1878, despite opposition, a Roman Catholic ecclesiastical hierarchy was restored to the country, and Catholicism became a significant denomination within Scotland. Episcopalianism also revived in the 19th century as the issue of succession receded, becoming established as the Episcopal Church in Scotland in 1804, as an autonomous organisation in communion with the Church of England. Baptist, Congregationalist and Methodist churches had appeared in Scotland in the 18th century, but did not begin significant growth until the 19th century, partly because more radical and evangelical traditions already existed within the Church of Scotland and the free churches. From 1879 they were joined by the evangelical revivalism of the Salvation Army, which attempted to make major inroads in the growing urban centres.

Industrialisation, urbanisation and the Disruption of 1843 all undermined the tradition of parish schools. From 1830 the state began to fund buildings with grants, then from 1846 it was funding schools by direct sponsorship, and in 1872 Scotland moved to a system like that in England of state-sponsored largely free schools, run by local school boards. Overall administration was in the hands of the Scotch (later Scottish) Education Department in London. Education was now compulsory from five to thirteen and many new board schools were built. Larger urban school boards established "higher grade" (secondary) schools as a cheaper alternative to the burgh schools. The Scottish Education Department introduced a Leaving Certificate Examination in 1888 to set national standards for secondary education and in 1890 school fees were abolished, creating a state-funded national system of free basic education and common examinations.

At the beginning of the 19th century, Scottish universities had no entrance exam, students typically entered at ages of 15 or 16, attended for as little as two years, chose which lectures to attend and could leave without qualifications. After two commissions of enquiry in 1826 and 1876 and reforming acts of parliament in 1858 and 1889, the curriculum and system of graduation were reformed to meet the needs of the emerging middle classes and the professions. Entrance examinations equivalent to the School Leaving Certificate were introduced and average ages of entry rose to 17 or 18. Standard patterns of graduation in the arts curriculum offered 3-year ordinary and 4-year honours degrees and separate science faculties were able to move away from the compulsory Latin, Greek and philosophy of the old MA curriculum. The historic University of Glasgow became a leader in British higher education by providing the educational needs of youth from the urban and commercial classes, as well as the upper class. It prepared students for non-commercial careers in government, the law, medicine, education, and the ministry and a smaller group for careers in science and engineering. St Andrews pioneered the admission of women to Scottish universities, creating the Lady Licentiate in Arts (LLA), which proved highly popular. From 1892 Scottish universities could admit and graduate women and the numbers of women at Scottish universities steadily increased until the early 20th century.

The years before the First World War were the golden age of the inshore fisheries. Landings reached new heights, and Scottish catches dominated Europe's herring trade, accounting for a third of the British catch. High productivity came about thanks to the transition to more productive steam-powered boats, while the rest of Europe's fishing fleets were slower because they were still powered by sails.

In the Khaki Election of 1900, nationalist concern with the Boer War meant that the Conservatives and their Liberal Unionist allies gained a majority of Scottish seats for the first time, although the Liberals regained their ascendancy in the next election. The Unionists and Conservatives merged in 1912, usually known as the Conservatives in England and Wales, they adopted the name Unionist Party in Scotland. Scots played a major part in the leadership of UK political parties producing a Conservative Prime Minister in Arthur Balfour (1902–05) and a Liberal one in Henry Campbell-Bannerman (1905–08). Various organisations, including the Independent Labour Party, joined to make the British Labour Party in 1906, with Keir Hardie as its first chairman.

Scotland played a major role in the British effort in the First World War. It especially provided manpower, ships, machinery, food (particularly fish) and money, engaging with the conflict with some enthusiasm. Scotland's industries were directed at the war effort. For example, the Singer Clydebank sewing machine factory received over 5000 government contracts, and made 303 million artillery shells, shell components, fuses, and aeroplane parts, as well as grenades, rifle parts, and 361,000 horseshoes. Its labour force of 14,000 was about 70 percent female at war's end.

With a population of 4.8 million in 1911, Scotland sent 690,000 men to the war, of whom 74,000 died in combat or from disease, and 150,000 were seriously wounded. Scottish urban centres, with their poverty and unemployment, were favourite recruiting grounds of the regular British army, and Dundee, where the female-dominated jute industry limited male employment, had one of the highest proportion of reservists and serving soldiers than almost any other British city. Concern for their families' standard of living made men hesitate to enlist; voluntary enlistment rates went up after the government guaranteed a weekly stipend for life to the survivors of men who were killed or disabled. After the introduction of conscription from January 1916 every part of the country was affected. Occasionally Scottish troops made up large proportions of the active combatants, and suffered corresponding loses, as at the Battle of Loos, where there were three full Scots divisions and other Scottish units. Thus, although Scots were only 10 per cent of the British population, they made up 15 per cent of the national armed forces and eventually accounted for 20 per cent of the dead. Some areas, like the thinly populated Island of Lewis and Harris, suffered some of the highest proportional losses of any part of Britain. Clydeside shipyards and the nearby engineering shops were the major centres of war industry in Scotland. In Glasgow, radical agitation led to industrial and political unrest that continued after the war ended. After the end of the war in June 1919 the German fleet interned at Scapa Flow was scuttled by its German crews, to avoid its ships being taken over by the victorious allies.

A boom was created by the First World War, with the shipbuilding industry expanding by a third, but a serious depression hit the economy by 1922. The most skilled craftsmen were especially hard hit, because there were few alternative uses for their specialised skills. The main social indicators such as poor health, bad housing, and long-term mass unemployment, pointed to terminal social and economic stagnation at best, or even a downward spiral. The heavy dependence on obsolescent heavy industry and mining was a central problem, and no one offered workable solutions. The despair reflected what Finlay (1994) describes as a widespread sense of hopelessness that prepared local business and political leaders to accept a new orthodoxy of centralised government economic planning when it arrived during the Second World War.

A few industries did grow, such as chemicals and whisky, which developed a global market for premium "Scotch". However, in general the Scottish economy stagnated leading to growing unemployment and political agitation among industrial workers.

After World War I the Liberal Party began to disintegrate and Labour emerged as the party of progressive politics in Scotland, gaining a solid following among working classes of the urban lowlands. As a result, the Unionists were able to gain most of the votes of the middle classes, who now feared Bolshevik revolution, setting the social and geographical electoral pattern in Scotland that would last until the late 20th century. The fear of the left had been fuelled by the emergence of a radical movement led by militant trades unionists. John MacLean emerged as a key political figure in what became known as Red Clydeside, and in January 1919, the British Government, fearful of a revolutionary uprising, deployed tanks and soldiers in central Glasgow. Formerly a Liberal stronghold, the industrial districts switched to Labour by 1922, with a base in the Irish Catholic working class districts. Women were especially active in building neighbourhood solidarity on housing and rent issues. However, the "Reds" operated within the Labour Party and had little influence in Parliament; in the face of heavy unemployment the workers' mood changed to passive despair by the late 1920s. Scottish educated Bonar Law led a Conservative government from 1922 to 1923 and another Scot, Ramsay MacDonald, would be the Labour Party's first Prime Minister in 1924 and again from 1929 to 1935.

With all the main parties committed to the Union, new nationalist and independent political groupings began to emerge, including the National Party of Scotland in 1928 and Scottish Party in 1930. They joined to form the Scottish National Party (SNP) in 1934, with the goal of creating an independent Scotland, but it enjoyed little electoral success in the Westminster system.

As in World War I, Scapa Flow in Orkney served as an important Royal Navy base. Attacks on Scapa Flow and Rosyth gave RAF fighters their first successes downing bombers in the Firth of Forth and East Lothian. The shipyards and heavy engineering factories in Glasgow and Clydeside played a key part in the war effort, and suffered attacks from the Luftwaffe, enduring great destruction and loss of life. As transatlantic voyages involved negotiating north-west Britain, Scotland played a key part in the battle of the North Atlantic. Shetland's relative proximity to occupied Norway resulted in the Shetland Bus by which fishing boats helped Norwegians flee the Nazis, and expeditions across the North Sea to assist resistance. Significant individual contributions to the war effort by Scots included the invention of radar by Robert Watson-Watt, which was invaluable in the Battle of Britain, as was the leadership at RAF Fighter Command of Air Chief Marshal Hugh Dowding.

In World War II, Prime Minister Winston Churchill appointed Labour politician Tom Johnston as Secretary of State for Scotland in February 1941; he controlled Scottish affairs until the war ended. He launched numerous initiatives to promote Scotland, attracting businesses and new jobs through his new Scottish Council of Industry. He set up 32 committees to deal with social and economic problems, ranging from juvenile delinquency to sheep farming. He regulated rents, and set up a prototype national health service, using new hospitals set up in the expectation of large numbers of casualties from German bombing. His most successful venture was setting up a system of hydro electricity using water power in the Highlands. A long-standing supporter of the Home Rule movement, Johnston persuaded Churchill of the need to counter the nationalist threat north of the border and created a Scottish Council of State and a Council of Industry as institutions to devolve some power away from Whitehall.

In World War II, despite extensive bombing by the Luftwaffe, Scottish industry came out of the depression slump by a dramatic expansion of its industrial activity, absorbing unemployed men and many women as well. The shipyards were the centre of more activity, but many smaller industries produced the machinery needed by the British bombers, tanks and warships. Agriculture prospered, as did all sectors except for coal mining, which was operating mines near exhaustion. Real wages, adjusted for inflation, rose 25 per cent, and unemployment temporarily vanished. Increased income, and the more equal distribution of food, obtained through a tight rationing system, dramatically improved the health and nutrition; the average height of 13-year-olds in Glasgow increased by .

While emigration began to tail off in England and Wales after the First World War, it continued apace in Scotland, with 400,000 Scots, ten per cent of the population, estimated to have left the country between 1921 and 1931. The economic stagnation was only one factor; other push factors included a zest for travel and adventure, and the pull factors of better job opportunities abroad, personal networks to link into, and the basic cultural similarity of the United States, Canada, and Australia. Government subsidies for travel and relocation facilitated the decision to emigrate. Personal networks of family and friends who had gone ahead and wrote back, or sent money, prompted emigrants to retrace their paths. When the Great Depression hit in the 1930s there were no easily available jobs in the US and Canada and the numbers leaving fell to less than 50,000 a year, bringing to an end the period of mass emigrations that had opened in the mid-18th century.

In the early 20th century there was a new surge of activity in Scottish literature, influenced by modernism and resurgent nationalism, known as the Scottish Renaissance. The leading figure in the movement was Hugh MacDiarmid (the pseudonym of Christopher Murray Grieve). MacDiarmid attempted to revive the Scots language as a medium for serious literature in poetic works including "A Drunk Man Looks at the Thistle" (1936), developing a form of Synthetic Scots that combined different regional dialects and archaic terms. Other writers that emerged in this period, and are often treated as part of the movement, include the poets Edwin Muir and William Soutar, the novelists Neil Gunn, George Blake, Nan Shepherd, A. J. Cronin, Naomi Mitchison, Eric Linklater and Lewis Grassic Gibbon, and the playwright James Bridie. All were born within a fifteen-year period (1887 and 1901) and, although they cannot be described as members of a single school, they all pursued an exploration of identity, rejecting nostalgia and parochialism and engaging with social and political issues.

In the 20th century, the centre of the education system became more focused on Scotland, with the ministry of education partly moving north in 1918 and then finally having its headquarters relocated to Edinburgh in 1939. The school leaving age was raised to 14 in 1901, but despite attempts to raise it to 15 this was only made law in 1939 and then postponed because of the outbreak of war. In 1918, Roman Catholic schools were brought into the state system, but retained their distinct religious character, access to schools by priests and the requirement that school staff be acceptable to the Church.

The first half of the 20th century saw Scottish universities fall behind those in England and Europe in terms of participation and investment. The decline of traditional industries between the wars undermined recruitment. English universities increased the numbers of students registered between 1924 and 1927 by 19 per cent, but in Scotland the numbers fell, particularly among women. In the same period, while expenditure in English universities rose by 90 per cent, in Scotland the increase was less than a third of that figure.

Scotland's Scapa Flow was the main base for the Royal Navy in the 20th century. As the Cold War intensified in 1961, the United States deployed Polaris ballistic missiles, and submarines, in the Firth of Clyde's Holy Loch. Public protests from CND campaigners proved futile. The Royal Navy successfully convinced the government to allow the base because it wanted its own "Polaris"-class submarines, and it obtained them in 1963. The RN's nuclear submarine base opened four "Resolution" class Polaris submarines at the expanded Faslane Naval Base on the Gare Loch. The first patrol of a Trident-armed submarine occurred in 1994, although the US base was closed at the end of the Cold War.

After World War II, Scotland's economic situation became progressively worse due to overseas competition, inefficient industry, and industrial disputes. This only began to change in the 1970s, partly due to the discovery and development of North Sea oil and gas and partly as Scotland moved towards a more service-based economy. This period saw the emergence of the Scottish National Party and movements for both Scottish independence and more popularly devolution. However, a referendum on devolution in 1979 was unsuccessful as it did not achieve the support of 40 per cent of the electorate (despite a small majority of those who voted supporting the proposal.)

A national referendum to decide on Scottish independence was held on 18 September 2014. Voters were asked to answer either "Yes" or "No" to the question: "Should Scotland be an independent country?" 55.3% of voters answered "No" and 44.7% answered "Yes", with a voter turnout of 84.5%.

In the second half of the 20th century the Labour Party usually won most Scottish seats in the Westminster parliament, losing this dominance briefly to the Unionists in the 1950s. Support in Scotland was critical to Labour's overall electoral fortunes as without Scottish MPs it would have gained only two UK electoral victories in the 20th century (1945 and 1966). The number of Scottish seats represented by Unionists (known as Conservatives from 1965 onwards) went into steady decline from 1959 onwards, until it fell to zero in 1997. Politicians with Scottish connections continued to play a prominent part in UK political life, with Prime Ministers including the Conservatives Harold Macmillan (whose father was Scottish) from 1957 to 1963 and Alec Douglas-Home from 1963 to 1964.

The Scottish National Party gained its first seat at Westminster in 1945 and became a party of national prominence during the 1970s, achieving 11 MPs in 1974. However, a referendum on devolution in 1979 was unsuccessful as it did not achieve the necessary support of 40 per cent of the electorate (despite a small majority of those who voted supporting the proposal) and the SNP went into electoral decline during the 1980s. The introduction in 1989 by the Thatcher-led Conservative government of the Community Charge (widely known as the Poll Tax), one year before the rest of the United Kingdom, contributed to a growing movement for a return to direct Scottish control over domestic affairs. The electoral success of New Labour in 1997 was led by two Prime Ministers with Scottish connections: Tony Blair (who was brought up in Scotland) from 1997 to 2007 and Gordon Brown from 2007 to 2010, opened the way for constitutional change. On 11 September 1997, the 700th anniversary of Battle of Stirling Bridge, the Blair led Labour government again held a referendum on the issue of devolution. A positive outcome led to the establishment of a devolved Scottish Parliament in 1999. A coalition government, which would last until 2007, was formed between Labour and the Liberal Democrats, with Donald Dewar as First Minister. The new Scottish Parliament Building, adjacent to Holyrood House in Edinburgh, opened in 2004. Although not initially reaching its 1970s peak in Westminster elections, the SNP had more success in the Scottish Parliamentary elections with their system of mixed member proportional representation. It became the official opposition in 1999, a minority government in 2007 and a majority government from 2011. In 2014, the independence referendum saw voters reject independence, choosing instead to remain in the United Kingdom. In the 2015 Westminster election, the SNP won 56 out of 59 Scottish seats, making them the third largest party in Westminster.

After World War II, Scotland's economic situation became progressively worse due to overseas competition, inefficient industry, and industrial disputes. This only began to change in the 1970s, partly due to the discovery and development of North Sea oil and gas and partly as Scotland moved towards a more service-based economy. The discovery of the giant Forties oilfield in October 1970 signalled that Scotland was about to become a major oil producing nation, a view confirmed when Shell Expro discovered the giant Brent oilfield in the northern North Sea east of Shetland in 1971. Oil production started from the Argyll field (now Ardmore) in June 1975, followed by Forties in November of that year. Deindustrialisation took place rapidly in the 1970s and 1980s, as most of the traditional industries drastically shrank or were completely closed down. A new service-oriented economy emerged to replace traditional heavy industries. This included a resurgent financial services industry and the electronics manufacturing of Silicon Glen.

In the 20th century existing Christian denominations were joined by other organisations, including the Brethren and Pentecostal churches. Although some denominations thrived, after World War II there was a steady overall decline in church attendance and resulting church closures for most denominations. Talks began in the 1950s aiming at a grand merger of the main Presbyterian, Episcopal and Methodist bodies in Scotland. The talks were ended in 2003, when the General Assembly of the Church of Scotland rejected the proposals. In the 2011 census, 53.8% of the Scottish population identified as Christian (declining from 65.1% in 2001). The Church of Scotland is the largest religious grouping in Scotland, with 32.4% of the population. The Roman Catholic Church accounted for 15.9% of the population and is especially important in West Central Scotland and the Highlands. In recent years other religions have established a presence in Scotland, mainly through immigration and higher birth rates among ethnic minorities, with a small number of converts. Those with the most adherents in the 2011 census are Islam (1.4%, mainly among immigrants from South Asia), Hinduism (0.3%), Buddhism (0.2%) and Sikhism (0.2%). Other minority faiths include the Bahá'í Faith and small Neopagan groups. There are also various organisations which actively promote humanism and secularism, included within the 43.6% who either indicated no religion or did not state a religion in the 2011 census.

Although plans to raise the school leaving age to 15 in the 1940s were never ratified, increasing numbers stayed on beyond elementary education and it was eventually raised to 16 in 1973. As a result, secondary education was the major area of growth in the second half of the 20th century. New qualifications were developed to cope with changing aspirations and economics, with the Leaving Certificate being replaced by the Scottish Certificate of Education Ordinary Grade ('O-Grade') and Higher Grade ('Higher') qualifications in 1962, which became the basic entry qualification for university study. The higher education sector expanded in the second half of the 20th century, with four institutions being given university status in the 1960s (Dundee, Heriot-Watt, Stirling and Strathclyde) and five in the 1990s (Abertay, Glasgow Caledonian, Napier, Paisley and Robert Gordon). After devolution, in 1999 the new Scottish Executive set up an Education Department and an Enterprise, Transport and Lifelong Learning Department. One of the major diversions from practice in England, possible because of devolution, was the abolition of student tuition fees in 1999, instead retaining a system of means-tested student grants.

Some writers that emerged after the Second World War followed Hugh MacDiarmid by writing in Scots, including Robert Garioch and Sydney Goodsir Smith. Others demonstrated a greater interest in English language poetry, among them Norman MacCaig, George Bruce and Maurice Lindsay. George Mackay Brown from Orkney, and Iain Crichton Smith from Lewis, wrote both poetry and prose fiction shaped by their distinctive island backgrounds. The Glaswegian poet Edwin Morgan became known for translations of works from a wide range of European languages. He was also the first Scots Makar (the official national poet), appointed by the inaugural Scottish government in 2004. Many major Scottish post-war novelists, such as Muriel Spark, with "The Prime of Miss Jean Brodie" (1961) spent much or most of their lives outside Scotland, but often dealt with Scottish themes. Successful mass-market works included the action novels of Alistair MacLean, and the historical fiction of Dorothy Dunnett. A younger generation of novelists that emerged in the 1960s and 1970s included Shena Mackay, Alan Spence, Allan Massie and the work of William McIlvanney. From the 1980s Scottish literature enjoyed another major revival, particularly associated with a group of Glasgow writers focused around critic, poet and teacher Philip Hobsbaum and editor Peter Kravitz. In the 1990s major, prize winning, Scottish novels, often overtly political, that emerged from this movement included Irvine Welsh's "Trainspotting" (1993), Warner's "Morvern Callar" (1995), Gray's "Poor Things" (1992) and Kelman's "How Late It Was, How Late" (1994). Scottish crime fiction has been a major area of growth, particularly the success of Edinburgh's Ian Rankin and his Inspector Rebus novels. This period also saw the emergence of a new generation of Scottish poets that became leading figures on the UK stage, including Carol Ann Duffy, who was named as Poet Laureate in May 2009, the first woman, the first Scot and the first openly gay poet to take the post.















</doc>
<doc id="13621" url="https://en.wikipedia.org/wiki?curid=13621" title="Hadrian">
Hadrian

Hadrian (; Latin: Publius Aelius Hadrianus Augustus; 24 January 76 – 10 July 138) was Roman emperor from 117 to 138. He was born Publius Aelius Hadrianus in Italica, near Santiponce, Spain into a Hispano-Roman family. His father was of senatorial rank and was a first cousin of Emperor Trajan. He married Trajan's grand-niece Vibia Sabina early in his career, before Trajan became emperor and possibly at the behest of Trajan's wife Pompeia Plotina. Plotina and Trajan's close friend and adviser Lucius Licinius Sura were well disposed towards Hadrian. When Trajan died, his widow claimed that he had nominated Hadrian as emperor immediately before his death.

Rome's military and Senate approved Hadrian's succession, but four leading senators were unlawfully put to death soon after. They had opposed Hadrian or seemed to threaten his succession, and the senate held him responsible for it and never forgave him. He earned further disapproval among the elite by abandoning Trajan's expansionist policies and territorial gains in Mesopotamia, Assyria, Armenia, and parts of Dacia. Hadrian preferred to invest in the development of stable, defensible borders and the unification of the empire's disparate peoples. He is known for building Hadrian's Wall, which marked the northern limit of Britannia.

Hadrian energetically pursued his own Imperial ideals and personal interests. He visited almost every province of the Empire, accompanied by an Imperial retinue of specialists and administrators. He encouraged military preparedness and discipline, and he fostered, designed, or personally subsidised various civil and religious institutions and building projects. In Rome itself, he rebuilt the Pantheon and constructed the vast Temple of Venus and Roma. In Egypt, he may have rebuilt the Serapeum of Alexandria. He was an ardent admirer of Greece and sought to make Athens the cultural capital of the Empire, so he ordered the construction of many opulent temples there. His intense relationship with Greek youth Antinous and Antinous' untimely death led Hadrian to establish a widespread cult late in his reign. He suppressed the Bar Kokhba revolt in Judaea, but his reign was otherwise peaceful.

Hadrian's last years were marred by chronic illness. He saw the Bar Kokhba revolt as the failure of his panhellenic ideal. He executed two more senators for their alleged plots against him, and this provoked further resentment. His marriage to Vibia Sabina had been unhappy and childless; he adopted Antoninus Pius in 138 and nominated him as a successor, on the condition that Antoninus adopt Marcus Aurelius and Lucius Verus as his own heirs. Hadrian died the same year at Baiae, and Antoninus had him deified, despite opposition from the Senate. Edward Gibbon includes him among the Empire's "Five good emperors", a "benevolent dictator"; Hadrian's own senate found him remote and authoritarian. He has been described as enigmatic and contradictory, with a capacity for both great personal generosity and extreme cruelty and driven by insatiable curiosity, self-conceit, and ambition. Modern interest was revived largely thanks to Marguerite Yourcenar's novel "Mémoires d'Hadrien" (1951).

Hadrian was born on 24January 76, probably in Italica (near modern Seville) in the Roman province of Hispania Baetica; one Roman biographer claims he was born at Rome. He was named Publius Aelius Hadrianus. His father was Publius Aelius Hadrianus Afer, a senator of praetorian rank, born and raised in Italica but paternally linked, through many generations over several centuries, to a family from Hadria (modern Atri), an ancient town in Picenum. The family had settled in Italica soon after its founding by Scipio Africanus. Hadrian's mother was Domitia Paulina, daughter of a distinguished Hispano-Roman senatorial family from Gades (Cádiz). His only sibling was an elder sister, Aelia Domitia Paulina. Hadrian's great-nephew, Gnaeus Pedanius Fuscus Salinator, from Barcino (Barcelona) would become Hadrian's colleague as co-consul in 118. As a senator, Hadrian's father would have spent much of his time in Rome. In terms of his later career, Hadrian's most significant family connection was to Trajan, his father's first cousin, who was also of senatorial stock, and had been born and raised in Italica. Hadrian and Trajan were both considered to bein the words of Aurelius Victor"aliens", people "from the outside" ("advenae").

Hadrian's parents died in 86, when he was ten years old. He and his sister became wards of Trajan and Publius Acilius Attianus (who later became Trajan's Praetorian prefect). Hadrian was physically active, and enjoyed hunting; when he was 14, Trajan called him to Rome and arranged his further education in subjects appropriate to a young Roman aristocrat. Hadrian's enthusiasm for Greek literature and culture earned him the nickname "Graeculus" ("Greekling"). Trajan married Paulina off to the three-times consul Lucius Julius Ursus Servianus; the couple had a daughter, Julia Serviana Paulina.

Hadrian's first official post in Rome was as a judge at the Inheritance court, one among many vigintivirate offices at the lowest level of the cursus honorum ("course of honours") that could lead to higher office and a senatorial career. He then served as a military tribune, first with the LegioII "Adiutrix" in 95, then with the Legio V Macedonica. During Hadrian's second stint as tribune, the frail and aged reigning emperor Nerva adopted Trajan as his heir; Hadrian was dispatched to give Trajan the news— or most probably was one of many emissaries charged with this same commission. Then he was transferred to Legio XXII Primigenia and a third tribunate. Hadrian's three tribunates gave him some career advantage. Most scions of the older senatorial families might serve one, or at most two military tribunates as a prerequisite to higher office. When Nerva died in 98, Hadrian is said to have hastened to Trajan, to inform him ahead of the official envoy sent by the governor, Hadrian's brother-in-law and rival Lucius Julius Ursus Servianus.

In 101, Hadrian was back in Rome; he was elected quaestor, then "quaestor imperatoris Traiani", liaison officer between Emperor and the assembled Senate, to whom he read the Emperor's communiqués and speeches – which he possibly composed on the emperor's behalf. In his role as imperial ghostwriter, Hadrian took the place of the recently deceased Licinius Sura, Trajan's all-powerful friend and kingmaker. His next post was as "ab actis senatus", keeping the Senate's records. During the First Dacian War, Hadrian took the field as a member of Trajan's personal entourage, but was excused from his military post to take office in Rome as Tribune of the Plebs, in 105. After the war, he was probably elected praetor. During the Second Dacian War, Hadrian was in Trajan's personal service again, but was released to serve as legate of Legio I Minervia, then as governor of Lower Pannonia in 107, tasked with "holding back the Sarmatians".

Now in his mid-thirties, Hadrian travelled to Greece; he was granted Athenian citizenship and was appointed eponymous archon of Athens for a brief time (in 112). The Athenians awarded him a statue with an inscription in the Theater of Dionysus (IG II2 3286) offering a detailed account of his "cursus honorum" thus far. Thereafter no more is heard of him until Trajan's Parthian War. It is possible that he remained in Greece until his recall to the imperial retinue, when he joined Trajan's expedition against Parthia as a legate. When the governor of Syria was sent to deal with renewed troubles in Dacia, Hadrian was appointed his replacement, with independent command. Trajan became seriously ill, and took ship for Rome, while Hadrian remained in Syria, "de facto" general commander of the Eastern Roman army. Trajan got as far as the coastal city of Selinus, in Cilicia, and died there, on 8 August; he would be regarded as one of Rome's most admired, popular and best emperors.

Around the time of his quaestorship, in 100 or 101, Hadrian had married Trajan's seventeen or eighteen-year-old grandniece, Vibia Sabina. Trajan himself seems to have been less than enthusiastic about the marriage, and with good reason, as the couple's relationship would prove to be scandalously poor. The marriage might have been arranged by Trajan's empress, Plotina. This highly cultured, influential woman shared many of Hadrian's values and interests, including the idea of the Roman Empire as a commonwealth with an underlying Hellenic culture. If Hadrian were to be appointed Trajan's successor, Plotina and her extended family could retain their social profile and political influence after Trajan's death. Hadrian could also count on the support of his mother-in-law, Salonina Matidia, who was daughter of Trajan's beloved sister Ulpia Marciana. When Ulpia Marciana died, in 112, Trajan had her deified, and made Salonina Matidia an Augusta.

Hadrian's personal relationship with Trajan was complex, and may have been difficult. Hadrian seems to have sought influence over Trajan, or Trajan's decisions, through cultivation of the latter's boy favourites; this gave rise to some unexplained quarrel, around the time of Hadrian's marriage to Sabina. Late in Trajan's reign, Hadrian failed to achieve a senior consulship, being only suffect consul for 108; this gave him parity of status with other members of the senatorial nobility, but no particular distinction befitting an heir designate. Had Trajan wished it, he could have promoted his protege to patrician rank and its privileges, which included opportunities for a fast track to consulship without prior experience as tribune; he chose not to. While Hadrian seems to have been granted the office of Tribune of the Plebs a year or so younger than was customary, he had to leave Dacia, and Trajan, to take up the appointment; Trajan might simply have wanted him out of the way. The "Historia Augusta" describes Trajan's gift to Hadrian of a diamond ring that Trajan himself had received from Nerva, which "encouraged [Hadrian's] hopes of succeeding to the throne". While Trajan actively promoted Hadrian's advancement, he did so with caution.
Failure to nominate an heir could invite chaotic, destructive wresting of power by a succession of competing claimants – a civil war. Too early a nomination could be seen as an abdication, and reduce the chance for an orderly transmission of power. As Trajan lay dying, nursed by his wife, Plotina, and closely watched by Prefect Attianus, he could have lawfully adopted Hadrian as heir, by means of a simple deathbed wish, expressed before witnesses; but when an adoption document was eventually presented, it was signed not by Trajan but by Plotina, and was dated the day after Trajan's death. That Hadrian was still in Syria was a further irregularity, as Roman adoption law required the presence of both parties at the adoption ceremony. Rumours, doubts, and speculation attended Hadrian's adoption and succession. It has been suggested that Trajan's young manservant Phaedimus, who died very soon after Trajan, was killed (or killed himself) rather than face awkward questions. Ancient sources are divided on the legitimacy of Hadrian's adoption: Dio Cassius saw it as bogus and the "Historia Augusta" writer as genuine. An aureus minted early in Hadrian's reign represents the official position; it presents Hadrian as Trajan's "Caesar" (Trajan's heir designate).

According to the "Historia Augusta", Hadrian informed the Senate of his accession in a letter as a "fait accompli", explaining that "the unseemly haste of the troops in acclaiming him emperor was due to the belief that the state could not be without an emperor". The new emperor rewarded the legions' loyalty with the customary bonus, and the Senate endorsed the acclamation. Various public ceremonies were organized on Hadrian's behalf, celebrating his "divine election" by all the gods, whose community now included Trajan, deified at Hadrian's request.

Hadrian remained in the east for a while, suppressing the Jewish revolt that had broken out under Trajan. He relieved Judea's governor, the outstanding Moorish general Lusius Quietus, of his personal guard of Moorish auxiliaries; 
then he moved on to quell disturbances along the Danube frontier. In Rome, Hadrian's former guardian and current Praetorian Prefect, Attianus, claimed to have uncovered a conspiracy involving four leading senators, who included Lusius Quietus. There was no public trial for the four – they were tried "in absentia", hunted down and killed. Hadrian claimed that Attianus had acted on his own initiative, and rewarded him with senatorial status and consular rank; then pensioned him off, no later than 120. Hadrian assured the senate that henceforth their ancient right to prosecute and judge their own would be respected.

The reasons for these four executions remain obscure. Official recognition of Hadrian as legitimate heir may have come too late to dissuade other potential claimants. Hadrian's greatest rivals were Trajan's closest friends, the most experienced and senior members of the imperial council; any of them might have been a legitimate competitor for the imperial office ("capaces imperii"); and any of them might have supported Trajan's expansionist policies, which Hadrian intended to change. One of their number was Aulus Cornelius Palma who as a former conqueror of Arabia Nabatea would have retained a stake in the East. The "Historia Augusta" describes Palma and a third executed senator, Lucius Publilius Celsus (consul for the second time in 113), as Hadrian's personal enemies, who had spoken in public against him. The fourth was Gaius Avidius Nigrinus, an ex-consul, intellectual, friend of Pliny the Younger and (briefly) Governor of Dacia at the start of Hadrian's reign. He was probably Hadrian's chief rival for the throne; a senator of highest rank, breeding, and connections; according to the "Historia Augusta", Hadrian had considered making Nigrinus his heir apparent, before deciding to get rid of him.

Soon after, in 125, Hadrian appointed Marcius Turbo as his Praetorian Prefect. Turbo was his close friend, a leading figure of the equestrian order, a senior court judge and a procurator. As Hadrian also forbade equestrians to try cases against senators, the Senate retained full legal authority over its members; it also remained the highest court of appeal, and formal appeals to the emperor regarding its decisions were forbidden. If this was an attempt to repair the damage done by Attianus, with or without Hadrian's full knowledge, it was not enough; Hadrian's reputation and relationship with his Senate were iredeemably soured, for the rest of his reign. Some sources describe Hadrian's occasional recourse to a network of informers, the "frumentarii" to discreetly investigate persons of high social standing, including senators and his close friends.

Hadrian was to spend more than half his reign outside Italy. Whereas previous emperors had, for the most part, relied on the reports of their imperial representatives around the Empire, Hadrian wished to see things for himself. Previous emperors had often left Rome for long periods, but mostly to go to war, returning once the conflict was settled. Hadrian's near-incessant travels may represent a calculated break with traditions and attitudes in which the empire was a purely Roman hegemony. Hadrian sought to include provincials in a commonwealth of civilized peoples and a common Hellenic culture under Roman supervision. He supported the creation of provincial towns (municipia), semi-autonomous urban communities with their own customs and laws, rather than the imposition of new Roman colonies with Roman constitutions.

A cosmopolitan, ecumenical intent is evident in coin issues of Hadrian's later reign, showing the emperor "raising up" the personifications of various provinces. Aelius Aristides would later write that Hadrian "extended over his subjects a protecting hand, raising them as one helps fallen men on their feet". All this did not go well with Roman traditionalists. The self-indulgent emperor Nero had enjoyed a prolonged and peaceful tour of Greece, and had been criticised by the Roman elite for abandoning his fundamental responsibilities as emperor. In the eastern provinces, and to some extent in the west, Nero had enjoyed popular support; claims of his imminent return or rebirth emerged almost immediately after his death. Hadrian may have consciously exploited these positive, popular connections during his own travels. In the "Historia Augusta", Hadrian is described as "a little too much Greek", too cosmopolitan for a Roman emperor.

Prior to Hadrian's arrival in Britannia, the province had suffered a major rebellion, from 119 to 121. Inscriptions tell of an "expeditio Britannica" that involved major troop movements, including the dispatch of a detachment (vexillatio), comprising some 3,000 soldiers. Fronto writes about military losses in Britannia at the time. Coin legends of 119–120 attest that Pompeius Falco was sent to restore order. In 122 Hadrian initiated the construction of a wall, "to separate Romans from barbarians". The idea that the wall was built in order to deal with an actual threat or its resurgence, however, is probable but nevertheless conjectural. A general desire to cease the Empire's extension may have been the determining motive. Reduction of defense costs may also have played a role, as the Wall deterred attacks on Roman territory at a lower cost than a massed border army, and controlled cross-border trade and immigration. A shrine was erected in York to Brittania as the divine personification of Britain; coins were struck, bearing her image, identified as . By the end of 122, Hadrian had concluded his visit to Britannia. He never saw the finished wall that bears his name.

Hadrian appears to have continued through southern Gaul. At Nemausus, he may have overseen the building of a basilica dedicated to his patroness Plotina, who had recently died in Rome and had been deified at Hadrian's request. At around this time, Hadrian dismissed his secretary "ab epistulis", the biographer Suetonius, for "excessive familiarity" towards the empress. Marcius Turbo's colleague as Praetorian Prefect, Gaius Septicius Clarus, was dismissed for the same alleged reason, perhaps a pretext to remove him from office. Hadrian spent the winter of 122/123 at Tarraco, in Spain, where he restored the Temple of Augustus.

In 123, Hadrian crossed the Mediterranean to Mauretania, where he personally led a minor campaign against local rebels. The visit was cut short by reports of war preparations by Parthia; Hadrian quickly headed eastwards. At some point, he visited Cyrene, where he personally funded the training of young men from well-bred families for the Roman military. Cyrene had benefited earlier (in 119) from his restoration of public buildings destroyed during the earlier Jewish revolt.

When Hadrian arrived on the Euphrates, he personally negotiated a settlement with the Parthian King Osroes I, inspected the Roman defences, then set off westwards, along the Black Sea coast. He probably wintered in Nicomedia, the main city of Bithynia. Nicomedia had been hit by an earthquake only shortly before his stay; Hadrian provided funds for its rebuilding, and was acclaimed as restorer of the province.

It is possible that Hadrian visited Claudiopolis and saw the beautiful Antinous, a young man of humble birth who became Hadrian's beloved. Literary and epigraphic sources say nothing on when or where they met; depictions of Antinous show him aged 20 or so, shortly before his death in 130. In 123 he would most likely have been a youth of 13 or 14. It is also possible that Antinous was sent to Rome to be trained as a page to serve the emperor and only gradually rose to the status of imperial favourite. The actual history of their relationship is mostly unknown.

With or without Antinous, Hadrian travelled through Anatolia. Various traditions suggest his presence at particular locations, and allege his foundation of a city within Mysia, Hadrianutherae, after a successful boar hunt. At about this time, plans to complete the Temple of Zeus in Cyzicus, begun by the kings of Pergamon, were put into practice. The temple received a colossal statue of Hadrian. Cyzicus, Pergamon, Smyrna, Ephesus and Sardes were promoted as regional centres for the Imperial cult ("neocoros").

Hadrian arrived in Greece during the autumn of 124, and participated in the Eleusinian Mysteries. He had a particular commitment to Athens, which had previously granted him citizenship and an archonate; at the Athenians' request, he revised their constitution – among other things, he added a new phyle (tribe), which was named after him. Hadrian combined active, hands-on interventions with cautious restraint. He refused to intervene in a local dispute between producers of olive oil and the Athenian Assembly and Council, who had imposed production quotas on oil producers; yet he granted an imperial subsidy for the Athenian grain supply. Hadrian created two foundations, to fund Athens' public games, festivals and competitions if no citizen proved wealthy or willing enough to sponsor them as a Gymnasiarch or Agonothetes. Generally Hadrian preferred that Greek notables, including priests of the Imperial cult, focus on more durable provisions, such as aqueducts and public fountains ("nymphaea"). Athens was given two such fountains; another was given to Argos.

During the winter he toured the Peloponnese. His exact route is uncertain, but it took in Epidaurus; Pausanias describes temples built there by Hadrian, and his statue – in heroic nudity – erected by its citizens in thanks to their "restorer". Antinous and Hadrian may have already been lovers at this time; Hadrian showed particular generosity to Mantinea, which shared ancient, mythic, politically useful links with Antinous' home at Bithynia. He restored Mantinea's Temple of Poseidon Hippios, and according to Pausanias, restored the city's original, classical name. It had been renamed Antigoneia since Hellenistic times, after the Macedonian King Antigonus III Doson. Hadrian also rebuilt the ancient shrines of Abae and Megara, and the Heraion of Argos.

During his tour of the Peloponnese, Hadrian persuaded the Spartan grandee Eurycles Herculanus – leader of the Euryclid family that had ruled Sparta since Augustus' day – to enter the Senate, alongside the Athenian grandee Herodes Atticus the Elder. The two aristocrats would be the first from "Old Greece" to enter the Roman Senate, as representatives of the two "great powers" of the Classical Age. This was an important step in overcoming Greek notables' reluctance to take part in Roman political life. In March 125, Hadrian presided at the Athenian festival of Dionysia, wearing Athenian dress. The Temple of Olympian Zeus had been under construction for more than five centuries; Hadrian committed the vast resources at his command to ensure that the job would be finished. He also organised the planning and construction of a particularly challenging and ambitious aqueduct to bring water to the Athenian Agora.

On his return to Italy, Hadrian made a detour to Sicily. Coins celebrate him as the restorer of the island. Back in Rome, he saw the rebuilt Pantheon, and his completed villa at nearby Tibur, among the Sabine Hills. In early March 127 Hadrian set off on a tour of Italy; his route has been reconstructed through the evidence of his gifts and donations. He restored the shrine of Cupra in Cupra Maritima, and improved the drainage of the Fucine lake. Less welcome than such largesse was his decision in 127 to divide Italy into four regions under imperial legates with consular rank, acting as governors. They were given jurisdiction over all of Italy, excluding Rome itself, therefore shifting Italian cases from the courts of Rome. Having Italy effectively reduced to the status of a group of mere provinces did not go down well with the Roman Senate, and the innovation did not long outlive Hadrian's reign.

Hadrian fell ill around this time; whatever the nature of his illness, it did not stop him from setting off in the spring of 128 to visit Africa. His arrival coincided with the good omen of rain, which ended a drought. Along with his usual role as benefactor and restorer, he found time to inspect the troops; his speech to them survives. Hadrian returned to Italy in the summer of 128 but his stay was brief, as he set off on another tour that would last three years.

In September 128, Hadrian attended the Eleusinian mysteries again. This time his visit to Greece seems to have concentrated on Athens and Sparta – the two ancient rivals for dominance of Greece. Hadrian had played with the idea of focusing his Greek revival around the Amphictyonic League based in Delphi, but by now he had decided on something far grander. His new Panhellenion was going to be a council that would bring Greek cities together. Having set in motion the preparations – deciding whose claim to be a Greek city was genuine would take time – Hadrian set off for Ephesus. From Greece, Hadrian proceeded by way of Asia to Egypt, probably conveyed across the Aegean with his entourage by an Ephesian merchant, Lucius Erastus. Hadrian later sent a letter to the Council of Ephesus, supporting Erastus as a worthy candidate for town councillor and offering to pay the requisite fee.

Hadrian arrived in Egypt before the Egyptian New Year on 29 August 130. He opened his stay in Egypt by restoring Pompey the Great's tomb at Pelusium, offering sacrifice to him as a hero and composing an epigraph for the tomb. As Pompey was universally acknowledged as responsible for establishing Rome's power in the east, this restoration was probably linked to a need to reaffirm Roman Eastern hegemony, following social unrest there during Trajan's late reign. Hadrian and Antinous held a lion hunt in the Libyan desert; a poem on the subject by the Greek Pankrates is the earliest evidence that they travelled together.

While Hadrian and his entourage were sailing on the Nile, Antinous drowned. The exact circumstances surrounding his death are unknown, and accident, suicide, murder and religious sacrifice have all been postulated. "Historia Augusta" offers the following account:
Hadrian founded the city of Antinopolis in Antinous' honour on 30 October 130. He then continued down the Nile to Thebes, where his visit to the Colossi of Memnon on 20 and 21 November was commemorated by four epigrams inscribed by Julia Balbilla, which still survive. After that, he headed north, reaching the Fayyum at the beginning of December.

Hadrian's movements after his journey down the Nile are uncertain. Whether or not he returned to Rome, he travelled in the East during 130/131, to organise and inaugurate his new Panhellenion, which was to be focused on the Athenian Temple to Olympian Zeus. As local conflicts had led to the failure of the previous scheme for an Hellenic association centered on Delphi, Hadrian decided instead for a grand league of all Greek cities. Successful applications for membership involved mythologised or fabricated claims to Greek origins, and affirmations of loyalty to Imperial Rome, to satisfy Hadrian's personal, idealised notions of Hellenism. Hadrian saw himself as protector of Greek culture and the "liberties" of Greece – in this case, urban self-government. It allowed Hadrian to appear as the fictive heir to Pericles, who supposedly had convened a previous Panhellenic Congress – such a Congress is mentioned only in Pericles' biography by Plutarch, who respected Rome's Imperial order.

Epigraphical evidence suggests that the prospect of applying to the Panhellenion held little attraction to the wealthier, Hellenised cities of Asia Minor, which were jealous of Athenian and European Greek preeminence within Hadrian's scheme. Hadrian's notion of Hellenism was narrow and deliberately archaising; he defined "Greekness" in terms of classical roots, rather than a broader, Hellenistic culture. Some cities with a dubious claim to Greekness, however – such as Side – were acknowledged as fully Hellenic. The German sociologist Georg Simmel remarked that the Panhellenion was based on "games, commemorations, preservation of an ideal, an entirely non-political Hellenism".

Hadrian bestowed honorific titles on many regional centres. Palmyra received a state visit and was given the civic name Hadriana Palmyra. Hadrian also bestowed honours on various Palmyrene magnates, among them one Soados, who had done much to protect Palmyrene trade between the Roman Empire and Parthia.

Hadrian had spent the winter of 131–32 in Athens, where he dedicated the now-completed Temple of Olympian Zeus, At some time in 132, he headed East, to Judaea.

In Roman Judaea Hadrian visited Jerusalem, which was still in ruins after the First Roman–Jewish War of 66–73. He may have planned to rebuild Jerusalem as a Roman colony – as Vespasian had done with Caesarea Maritima – with various honorific and fiscal privileges. The non-Roman population would have no obligation to participate in Roman religious rituals, but were expected to support the Roman imperial order; this is attested in Caesarea, where some Jews served in the Roman army during both the 66 and 132 rebellions. It has been speculated that Hadrian intended to assimilate the Jewish Temple to the traditional Roman civic-religious Imperial cult; such assimilations had long been commonplace practise in Greece and in other provinces, and on the whole, had been successful. The neighbouring Samaritans had already integrated their religious rites with Hellenistic ones. Strict Jewish monotheism proved more resistant to Imperial cajoling, and then to Imperial demands. A massive anti-Hellenistic and anti-Roman Jewish uprising broke out, led by Simon bar Kokhba. The Roman governor Tineius (Tynius) Rufus asked for an army to crush the resistance; bar Kokhba punished any Jew who refused to join his ranks. According to Justin Martyr and Eusebius, that had to do mostly with Christian converts, who opposed bar Kokhba's messianic claims.

A tradition based on the "Historia Augusta" suggests that the revolt was spurred by Hadrian's abolition of circumcision ("brit milah"); which as a Hellenist he viewed as mutilation. The scholar Peter Schäfer maintains that there is no evidence for this claim, given the notoriously problematical nature of the "Historia Augusta" as a source, the "tomfoolery" shown by the writer in the relevant passage, and the fact that contemporary Roman legislation on "genital mutilation" seems to address the general issue of castration of slaves by their masters. Other issues could have contributed to the outbreak; a heavy-handed, culturally insensitive Roman administration; tensions between the landless poor and incoming Roman colonists privileged with land-grants; and a strong undercurrent of messianism, predicated on Jeremiah's prophecy that the Temple would be rebuilt seventy years after its destruction, as the First Temple had been after the Babylonian exile.
Given the fragmentary nature of the existing evidence, it is impossible to ascertain an exact date for the beginning of the uprising, but it is probable that it began in-between summer and fall 132. The Romans were overwhelmed by the organised ferocity of the uprising. Hadrian called his general Sextus Julius Severus from Britain, and brought troops in from as far as the Danube. Roman losses were heavy; an entire legion or its numeric equivalent of around 4,000. Hadrian's report on the war to the Roman Senate omitted the customary salutation, "If you and your children are in health, it is well; I and the legions are in health." The rebellion was quashed by 135. According to Cassius Dio, Roman war operations in Judea left some 580,000 Jews dead, and 50 fortified towns and 985 villages razed. An unknown proportion of the population was enslaved. Beitar, a fortified city southwest of Jerusalem, fell after a three and a half year siege. The extent of punitive measures against the Jewish population remains a matter of debate.

Hadrian erased the province's name from the Roman map, renaming it Syria Palaestina. He renamed Jerusalem Aelia Capitolina after himself and Jupiter Capitolinus, and had it rebuilt in Greek style. According to Epiphanius, Hadrian appointed Aquila from Sinope in Pontus as "overseer of the work of building the city", since he was related to him by marriage. Hadrian is said to have placed the city's main Forum at the junction of the main Cardo and Decumanus Maximus, now the location for the (smaller) Muristan. After the suppression of the Jewish revolt, Hadrian provided the Samaritans with a temple, dedicated to Zeus Hypsistos ("Highest Zeus") on Mount Gerizim. The bloody repression of the revolt ended Jewish political independence from the Roman Imperial order.

Inscriptions make it clear that in 133 Hadrian took to the field with his armies against the rebels. He then returned to Rome, probably in that year and almost certainly – judging from inscriptions – via Illyricum.

Hadrian spent the final years of his life at Rome. In 134, he took an Imperial salutation for the end of the Second Jewish War (which was not actually concluded until the following year). Commemorations and achievement awards were kept to a minimum, as Hadrian came to see the war "as a cruel and sudden disappointment to his aspirations" towards a cosmopolitan empire.

The Empress Sabina died, probably in 136, after an unhappy marriage with which Hadrian had coped as a political necessity. The "Historia Augusta" biography states that Hadrian himself declared that his wife's "ill-temper and irritability" would be reason enough for a divorce, were he a private citizen. That gave credence, after Sabina's death, to the common belief that Hadrian had her poisoned. In keeping with well-established Imperial propriety, Sabina – who had been made an "Augusta" sometime around 128 – was deified not long after her death.

Hadrian's marriage to Sabina had been childless. Suffering from poor health, Hadrian turned to the problem of the succession. In 136 he adopted one of the ordinary consuls of that year, Lucius Ceionius Commodus, who as an emperor-in waiting took the name Lucius Aelius Caesar. He was the son-in-law of Gaius Avidius Nigrinus, one of the "four consulars" executed in 118, but was himself in delicate health, apparently with a reputation more "of a voluptuous, well educated great lord than that of a leader". Various modern attempts have been made to explain Hadrian's choice: Jerome Carcopino proposes that Aelius was Hadrian's natural son. It has also been speculated that his adoption was Hadrian's belated attempt to reconcile with one of the most important of the four senatorial families whose leading members had been executed soon after Hadrian's succession. Aelius acquitted himself honourably as joint governor of Pannonia Superior and Pannonia Inferior; he held a further consulship in 137, but died on 1 January 138.

Hadrian next adopted Titus Aurelius Fulvus Boionius Arrius Antoninus (the future emperor Antoninus Pius), who had served Hadrian as one of the five imperial legates of Italy, and as proconsul of Asia. In the interests of dynastic stability, Hadrian required that Antoninus adopt both Lucius Ceionius Commodus (son of the deceased Aelius Caesar) and Marcus Annius Verus (grandson of an influential senator of the same name who had been Hadrian's close friend); Annius was already betrothed to Aelius Caesar's daughter Ceionia Fabia. It may not have been Hadrian, but rather Antoninus Pius – Annius Verus's uncle – who supported Annius Verus' advancement; the latter's divorce of Ceionia Fabia and subsequent marriage to Antoninus' daughter Annia Faustina points in the same direction. When he eventually became Emperor, Marcus Aurelius would co-opt Ceionius Commodus as his co-Emperor, under the name of Lucius Verus, on his own initiative.

Hadrian's last few years were marked by conflict and unhappiness. His adoption of Aelius Caesar proved unpopular, not least with Hadrian's brother-in-law Lucius Julius Ursus Servianus and Servianus's grandson Gnaeus Pedanius Fuscus Salinator. Servianus, though now far too old, had stood in the line of succession at the beginning of Hadrian's reign; Fuscus is said to have had designs on the imperial power for himself. In 137 he may have attempted a coup in which his grandfather was implicated; Hadrian ordered that both be put to death. Servianus is reported to have prayed before his execution that Hadrian would "long for death but be unable to die". During his final, protracted illness, Hadrian was prevented from suicide on several occasions.

Hadrian died in the year 138 on the 10th of July, in his villa at Baiae at the age of 62. Dio Cassius and the "Historia Augusta" record details of his failing health. He had reigned for 21 years, the longest since Tiberius, and the fourth longest in the Principate, after Augustus, Hadrian's successor Antoninus Pius, and Tiberius.

He was buried first at Puteoli, near Baiae, on an estate that had once belonged to Cicero. Soon after, his remains were transferred to Rome and buried in the Gardens of Domitia, close by the almost-complete mausoleum. Upon completion of the Tomb of Hadrian in Rome in 139 by his successor Antoninus Pius, his body was cremated, and his ashes were placed there together with those of his wife Vibia Sabina and his first adopted son, Lucius Aelius, who also died in 138. The Senate had been reluctant to grant Hadrian divine honours; but Antoninus persuaded them by threatening to refuse the position of Emperor. Hadrian was given a temple on the Campus Martius, ornamented with reliefs representing the provinces. The Senate awarded Antoninus the title of "Pius", in recognition of his filial piety in pressing for the deification of his adoptive father. At the same time, perhaps in reflection of the senate's ill will towards Hadrian, commemorative coinage honouring his consecration was kept to a minimum.

Most of Hadrian's military activities were consistent with his ideology of Empire as a community of mutual interest and support. He focused on protection from external and internal threats; on "raising up" existing provinces, rather than the aggressive acquisition of wealth and territory through subjugation of "foreign" peoples that had characterised the early Empire. Hadrian's policy shift was part of a trend towards the slowing down of the empire's expansion, such expansion being not closed after him (the Empire greatest extent being achieved only during the Severan dynasty), but a significant step in this direction, given the empire's overstretching. While the empire as a whole benefited from this, military careerists resented the loss of opportunities.
The 4th-century historian Aurelius Victor saw Hadrian's withdrawal from Trajan's territorial gains in Mesopotamia as a jealous belittlement of Trajan's achievements ("Traiani gloriae invidens"). More likely, an expansionist policy was no longer sustainable; the Empire had lost two legions, the Legio XXII Deiotariana and the "lost legion" IX Hispania, possibly destroyed in a late Trajanic uprising by the Brigantes in Britain. Trajan himself may have thought his gains in Mesopotamia indefensible, and abandoned them shortly before his death. Hadrian granted parts of Dacia to the Roxolani Sarmatians; their king Rasparaganus received Roman citizenship, client king status, and possibly an increased subsidy. Hadrian's presence on the Dacian front at this time is mere conjecture, but Dacia was included in his coin series with allegories of the provinces. A controlled, partial withdrawal of troops from the Dacian plains would have been less costly than maintaining several Roman cavalry units and a supporting network of fortifications.

Hadrian retained control over Osroene through the client king Parthamaspates, who had once served as Trajan's client king of Parthia; and around 121, Hadrian negotiated a peace treaty with the now-independent Parthia. Late in his reign (135), the Alani attacked Roman Cappadocia with the covert support of Pharasmanes, king of Caucasian Iberia. The attack was repulsed by Hadrian's governor, the historian Arrian, who subsequently installed a Roman "adviser" in Iberia. Arrian kept Hadrian well-informed on matters related to the Black Sea and the Caucasus. Between 131 and 132 he sent Hadrian a lengthy letter ("Periplus of the Euxine") on a maritime trip around the Black Sea, intended to offer relevant information in case a Roman intervention was needed.

Hadrian also developed permanent fortifications and military posts along the empire's borders ("limites", sl. "limes") to support his policy of stability, peace and preparedness. This helped keep the military usefully occupied in times of peace; his Wall across Britania was built by ordinary troops. A series of mostly wooden fortifications, forts, outposts and watchtowers strengthened the Danube and Rhine borders. Troops practised intensive, regular drill routines. Although his coins showed military images almost as often as peaceful ones, Hadrian's policy was peace through strength, even threat, with an emphasis on "disciplina" (discipline), which was the subject of two monetary series. Cassius Dio praised Hadrian's emphasis on "spit and polish" as cause for the generally peaceful character of his reign. Fronto expressed other opinions on the subject. In his view, Hadrian preferred war games to actual war, and enjoyed "giving eloquent speeches to the armies" – like the inscribed series of addresses he made while on an inspection tour, during 128, at the new headquarters of Legio III Augusta in Lambaesis

Faced with a shortage of legionary recruits from Italy and other Romanised provinces, Hadrian systematised the use of less costly "numeri" – ethnic non-citizen troops with special weapons, such as Eastern mounted archers – in low-intensity, mobile defensive tasks such as dealing with border infiltrators and skirmishers. Hadrian is also credited with introducing units of heavy cavalry (cataphracts) into the Roman army. Fronto later blamed Hadrian for declining standards in the Roman army of his own time.

Hadrian enacted, through the jurist Salvius Julianus, the first attempt to codify Roman law. This was the Perpetual Edict, according to which the legal actions of praetors became fixed statutes, and as such could no longer be subjected to personal interpretation or change by any magistrate other than the Emperor. At the same time, following a procedure initiated by Domitian, Hadrian made the Emperor's legal advisory board, the "consilia principis" ("council of the princeps") into a permanent body, staffed by salaried legal aides. Its members were mostly drawn from the equestrian class, replacing the earlier freedmen of the Imperial household. This innovation marked the superseding of surviving Republican institutions by an openly autocratic political system. The reformed bureaucracy was supposed to exercise administrative functions independently of traditional magistracies; objectively it did not detract from the Senate's position. The new civil servants were free men and as such supposed to act on behalf of the interests of the "Crown", not of the Emperor as an individual. However, the Senate never accepted the loss of its prestige caused by the emergence of a new aristocracy alongside it, placing more strain on the already troubled relationship between the Senate and the Emperor.

Hadrian codified the customary legal privileges of the wealthiest, most influential or highest status citizens (described as "splendidiores personae" or "honestiores"), who held a traditional right to pay fines when found guilty of relatively minor, non-treasonous offences. Low ranking persons – "alii" ("the others"), including low-ranking citizens – were "humiliores" who for the same offences could be subject to extreme physical punishments, including forced labour in the mines or in public works, as a form of fixed-term servitude. While Republican citizenship had carried at least notional equality under law, and the right to justice, offences in Imperial courts were judged and punished according to the relative prestige, rank, reputation and moral worth of both parties; senatorial courts were apt to be lenient when trying one of their peers, and to deal very harshly with offences committed against one of their number by low ranking citizens or non-citizens. For treason (maiestas) beheading was the worst punishment that the law could inflict on "honestiores"; the "humiliores" might suffer crucifixion, burning, or condemnation to the beasts in the arena.

A great number of Roman citizens maintained a precarious social and economic advantage at the lower end of the hierarchy. Hadrian found it necessary to clarify that decurions, the usually middle-class, elected local officials responsible for running the ordinary, everyday official business of the provinces, counted as "honestiores"; so did soldiers, veterans and their families, as far as civil law was concerned; by implication, all others, including freedmen and slaves, counted as "humiliores". Like most Romans, Hadrian seems to have accepted slavery as morally correct, an expression of the same natural order that rewarded "the best men" with wealth, power and respect. When confronted by a crowd demanding the freeing of a popular slave charioteer, Hadrian replied that he could not free a slave belonging to another person. However, he limited the punishments that slaves could suffer; they could be lawfully tortured to provide evidence, but they could not be lawfully killed unless guilty of a capital offence. Masters were also forbidden to sell slaves to a gladiator trainer (lanista) or to a procurer, except as legally justified punishment. Hadrian also forbade torture of free defendants and witnesses. He abolished ergastula, private prisons for slaves in which kidnapped free men had sometimes been illegally detained.

Hadrian issued a general rescript, imposing a ban on castration, performed on freedman or slave, voluntarily or not, on pain of death for both the performer and the patient. Under the "Lex Cornelia de Sicaris et Veneficis", castration was placed on a par with conspiracy to murder, and punished accordingly. Notwithstanding his philhellenism, Hadrian was also a traditionalist. He enforced dress-standards among the "honestiores"; senators and knights were expected to wear the toga when in public. He imposed strict separation between the sexes in theaters and public baths; to discourage idleness, the latter were not allowed to open until 2.00 in the afternoon, "except for medical reasons".

One of Hadrian's immediate duties on accession was to seek senatorial consent for the apotheosis of his predecessor, Trajan, and any members of Trajan's family to whom he owed a debt of gratitude. Matidia Augusta, Hadrian's mother-in-law, died in December 119, and was duly deified. Hadrian may have stopped at Nemausus during his return from Britannia, to oversee the completion or foundation of a basilica dedicated to his patroness Plotina. She had recently died in Rome and had been deified at Hadrian's request.

As Emperor, Hadrian was also Rome's pontifex maximus, responsible for all religious affairs and the proper functioning of official religious institutions throughout the empire. His Hispano-Roman origins and marked pro-Hellenism shifted the focus of the official imperial cult, from Rome to the Provinces. While his standard coin issues still identified him with the traditional "genius populi Romani", other issues stressed his personal identification with "Hercules Gaditanus" (Hercules of Gades), and Rome's imperial protection of Greek civilisation. He promoted Sagalassos in Greek Pisidia as the Empire's leading Imperial cult centre; his exclusively Greek "Panhellenion" extolled Athens as the spiritual centre of Greek culture.

Hadrian added several Imperial cult centres to the existing roster, particularly in Greece, where traditional intercity rivalries were commonplace. Cities promoted as Imperial cult centres drew Imperial sponsorship of festivals and sacred games, attracted tourism, trade and private investment. Local worthies and sponsors were encouraged to seek self-publicity as cult officials under the aegis of Roman rule, and to foster reverence for Imperial authority. Hadrian's rebuilding of long-established religious centres would have further underlined his respect for the glories of classical Greece – something well in line with contemporary antiquarian tastes. During Hadrian's third and last trip to the Greek East, there seems to have been an upwelling of religious fervour, focused on Hadrian himself. He was given personal cult as a deity, monuments and civic homage, according to the religious syncretism at the time. He may have had the great Serapeum of Alexandria rebuilt, following damage sustained in 116, during the Kitos War.

In 136, just two years before his death, Hadrian dedicated his Temple of Venus and Roma. It was built on land he had set aside for the purpose in 121, formerly the site of Nero's Golden House. The temple was the largest in Rome, and was built in an Hellenising style, more Greek than Roman. The temple's dedication and statuary associated the worship of the traditional Roman goddess Venus, divine ancestress and protector of the Roman people, with the worship of the goddess Roma – herself a Greek invention, hitherto worshiped only in the provinces – to emphasise the universal nature of the empire.

Hadrian had Antinous deified as Osiris-Antinous by an Egyptian priest at the ancient Temple of Ramesses II, very near the place of his death. Hadrian dedicated a new temple-city complex there, built in a Graeco-Roman style, and named it Antinopolis. It was a proper Greek polis; it was granted an Imperially subsidised alimentary scheme similar to Trajan's alimenta, and its citizens were allowed intermarriage with members of the native population, without loss of citizen-status. Hadrian thus identified an existing native cult (to Osiris) with Roman rule. The cult of Antinous was to become very popular in the Greek-speaking world, and also found support in the West. In Hadrian's villa, statues of the Tyrannicides, with a bearded Aristogeiton and a clean-shaven Harmodios, linked his favourite to the classical tradition of Greek love. In the west, Antinous was identified with the Celtic sun-god Belenos.

Hadrian was criticized for the open intensity of his grief at Antinous's death, particularly as he had delayed the apotheosis of his own sister Paulina after her death. Nevertheless, his recreation of the deceased youth as a cult-figure found little opposition. Though not a subject of the state-sponsored, official Roman imperial cult, Antinous offered a common focus for the emperor and his subjects, emphasizing their sense of community. Medals were struck with his effigy, and statues erected to him in all parts of the empire, in all kinds of garb, including Egyptian dress. Temples were built for his worship in Bithynia and Mantineia in Arcadia. In Athens, festivals were celebrated in his honour and oracles delivered in his name. As an "international" cult figure, Antinous had an enduring fame, far outlasting Hadrian's reign. Local coins with his effigy were still being struck during Caracalla's reign, and he was invoked in a poem to celebrate the accession of Diocletian.

Hadrian continued Trajan's policy on Christians; they should not be sought out, and should only be prosecuted for specific offences, such as refusal to swear oaths. In a rescript addressed to the proconsul of Asia, Minutius Fundanus, and preserved by Justin Martyr, Hadrian laid down that accusers of Christians had to bear the burden of proof for their denunciations or be punished for "calumnia" (defamation).

Hadrian had an abiding and enthusiastic interest in art, architecture and public works. Rome's Pantheon (temple "to all the gods"), originally built by Agrippa and destroyed by fire in 80, was partly restored under Trajan and completed under Hadrian in the domed form it retains to this day. Hadrian's Villa at Tibur (Tivoli) provides the greatest Roman equivalent of an Alexandrian garden, complete with domed Serapeum, recreating a sacred landscape. An anecdote from Cassius Dio's history suggests Hadrian had a high opinion of his own architectural tastes and talents, and took their rejection as a personal offense: at some time before his reign, his predecessor Trajan was discussing an architectural problem with Apollodorus of Damascus – architect and designer of Trajan's Forum, the Column commemorating his Dacian conquest, and his bridge across the Danube – when Hadrian interrupted to offer his advice. Apollodorus gave him a scathing response: "Be off, and draw your gourds [a sarcastic reference to the domes which Hadrian apparently liked to draw]. You don't understand any of these matters". Dio claims that once Hadrian became emperor, he showed Apollodorus drawings of the gigantic Temple of Venus and Roma, implying that great buildings could be created without his help. When Apollodorus pointed out the building's various insoluble problems and faults, Hadrian was enraged, sent him into exile and later put him to death on trumped up charges.

Hadrian wrote poetry in both Latin and Greek; one of the few surviving examples is a Latin poem he reportedly composed on his deathbed (see below). Some of his Greek productions found their way into the Palatine Anthology. He also wrote an autobiography, which "Historia Augusta" says was published under the name of Hadrian's freedman Phlegon of Tralles. It was not, apparently, a work of great length or revelation, but designed to scotch various rumours or explain Hadrian's most controversial actions. It is possible that this autobiography had the form of a series of open letters to Antoninus Pius.

Hadrian was a passionate hunter from a young age. In northwest Asia, he founded and dedicated a city to commemorate a she-bear he killed. It is documented that in Egypt he and his beloved Antinous killed a lion. In Rome, eight reliefs featuring Hadrian in different stages of hunting decorate a building that began as a monument celebrating a kill.

Hadrian's philhellenism may have been one reason for his adoption, like Nero before him, of the beard as suited to Roman imperial dignity; Dio of Prusa had equated the growth of the beard with the Hellenic ethos. Hadrian's beard may also have served to conceal his natural facial blemishes. All emperors before him (except Nero) had been clean-shaven; emperors who came after him until Constantine the Great were bearded and this imperial fashion was revived again by Phocas at the beginning of the 7th century.

Hadrian was familiar with the rival philosophers Epictetus and Favorinus, and with their works. During his first stay in Greece, before he became emperor, he attended lectures by Epictetus at Nicopolis. Shortly before the death of Plotina, Hadrian had granted her wish that the leadership of the Epicurean School in Athens be open to a non-Roman candidate.

During Hadrian's time as Tribune of the Plebs, omens and portents supposedly announced his future imperial condition. According to the "Historia Augusta", Hadrian had a great interest in astrology and divination and had been told of his future accession to the Empire by a grand-uncle who was himself a skilled astrologer.

According to the "Historia Augusta", Hadrian composed the following poem shortly before his death:

The poem has enjoyed remarkable popularity, but uneven critical acclaim. According to Aelius Spartianus, the alleged author of Hadrian's biography in the "Historia Augusta", Hadrian "wrote also similar poems in Greek, not much better than this one". T. S. Eliot's poem "Animula" may have been inspired by Hadrian's, though the relationship is not unambiguous.

Hadrian has been described as the most versatile of all Roman emperors, who "adroitly concealed a mind envious, melancholy, hedonistic, and excessive with respect to his own ostentation; he simulated restraint, affability, clemency, and conversely disguised the ardor for fame with which he burned." His successor Marcus Aurelius, in his "Meditations", lists those to whom he owes a debt of gratitude; Hadrian is conspicuously absent. Hadrian's tense, authoritarian relationship with his senate was acknowledged a generation after his death by Fronto, himself a senator, who wrote in one of his letters to Marcus Aurelius that "I praised the deified Hadrian, your grandfather, in the senate on a number of occasions with great enthusiasm, and I did this willingly, too [...] But, if it can be said – respectfully acknowledging your devotion towards your grandfather – I wanted to appease and assuage Hadrian as I would Mars Gradivus or Dis Pater, rather than to love him." Fronto adds, in another letter, that he kept some friendships, during Hadrian's reign, "under the risk of my life" ("cum periculo capitis"). Hadrian underscored the autocratic character of his reign by counting his "dies imperii" from the day of his acclamation by the armies, rather than the senate, and legislating by frequent use of imperial decrees to bypass the Senate's approval. The veiled antagonism between Hadrian and the Senate never grew to overt confrontation as had happened during the reigns of overtly "bad" emperors, because Hadrian knew how to remain aloof and avoid an open clash. That Hadrian spent half of his reign away from Rome in constant travel probably helped to mitigate the worst of this permanently strained relationship.

In 1503, Niccolò Machiavelli, though an avowed republican, esteemed Hadrian as an ideal "princeps", one of Rome's Five Good Emperors. Friedrich Schiller called Hadrian "the Empire's first servant". Edward Gibbon admired his "vast and active genius" and his "equity and moderation", and considered Hadrian's era as part of the "happiest era of human history". In Ronald Syme's view, Hadrian "was a Führer, a Duce, a Caudillo". According to Syme, Tacitus' description of the rise and accession of Tiberius is a disguised account of Hadrian's authoritarian Principate. According, again, to Syme, Tacitus' Annals would be a work of contemporary history, written "during Hadrian's reign and hating it".

While the balance of ancient literary opinion almost invariably compares Hadrian unfavourably to his predecessor, modern historians have sought to examine his motives, purposes and the consequences of his actions and policies. For M.A. Levi, a summing-up of Hadrian's policies should stress the ecumenical character of the Empire, his development of an alternate bureaucracy disconnected from the Senate and adapted to the needs of an "enlightened" autocracy, and his overall defensive strategy; this would qualify him as a grand Roman political reformer, creator of an openly absolute monarchy to replace a sham senatorial republic. Robin Lane Fox credits Hadrian as creator of a unified Greco-Roman cultural tradition, and as the end of this same tradition; Hadrian's attempted "restoration" of Classical culture within a non-democratic Empire drained it of substantive meaning, or, in Fox's words, "kill[ed] it with kindness".

In Hadrian's time, there was already a well established convention that one could not write a contemporary Roman imperial history for fear of contradicting what the emperors wanted to say, read or hear about themselves. As an earlier Latin source, Fronto's correspondence and works attest to Hadrian's character and the internal politics of his rule. Greek authors such as Philostratus and Pausanias wrote shortly after Hadrian's reign, but confined their scope to the general historical framework that shaped Hadrian's decisions, especially those relating the Greek-speaking world, Greek cities and notables. Pausanias especially wrote a lot in praise of Hadrian's benefactions to Greece in general and Athens in particular. Political histories of Hadrian's reign come mostly from later sources, some of them written centuries after the reign itself. The early 3rd-century "Roman History" by Cassius Dio, written in Greek, gave a general account of Hadrian's reign, but the original is lost, and what survives, aside from some fragments, is a brief, Byzantine-era abridgment by the 11th-century monk Xiphilinius, who focused on Hadrian's religious interests, the Bar Kokhba war, and little else—mostly on Hadrian's moral qualities and his fraught relationship with the Senate. The principal source for Hadrian's life and reign is therefore in Latin: one of several late 4th-century imperial biographies, collectively known as the "Historia Augusta". The collection as a whole is notorious for its unreliability ("a mish mash of actual fact, cloak and dagger, sword and sandal, with a sprinkling of "Ubu Roi""), but most modern historians consider its account of Hadrian to be relatively free of outright fictions, and probably based on sound historical sources, principally one of a lost series of imperial biographies by the prominent 3rd-century senator Marius Maximus, who covered the reigns of Nerva through to Elagabalus.

The first modern historian to produce a chronological account of Hadrian's life, supplementing the written sources with other epigraphical, numismatic, and archaeological evidence, was the German 19th-century medievalist Ferdinand Gregorovius. A 1907 biography by Weber, a German nationalist and later Nazi Party supporter, incorporates the same archaeological evidence to produce an account of Hadrian, and especially his Bar Kokhba war, that has been described as ideologically loaded. Epigraphical studies in the post-war period help support alternate views of Hadrian. Anthony Birley's 1997 biography of Hadrian sums up and reflects these developments in Hadrian historiography.

Inscriptions:





</doc>
<doc id="13623" url="https://en.wikipedia.org/wiki?curid=13623" title="Herman Melville">
Herman Melville

Herman Melville (August 1, 1819 – September 28, 1891) was an American novelist, short story writer, and poet of the American Renaissance period. Among his best known works are "Typee" (1846), a romantic account of his experiences of Polynesian life, and his whaling novel "Moby-Dick" (1851).

Melville was born in New York City, the third child of a merchant who dealt in French dry goods and his wife. Years as a common sailor from 1839 to 1844 were the basis of his early writings. His first book was "Typee" (1846), a highly romanticized account of his life among Polynesians. It became such a best-seller that he wrote the sequel "Omoo" (1847). These successes gave him the financial basis to marry Elizabeth Shaw, daughter of a prominent Boston family, but the success proved hard to sustain. His first novel that was not based on his own experiences was "Mardi" (1849), a sea narrative that develops into a philosophical allegory—but it was not well received. He received warmer reviews for "Redburn" (1849), a story of life on a merchant ship, and his 1850 description of the harsh life aboard a man-of-war in "White-Jacket", but they did not provide financial security.

"Moby-Dick" (1851), although now considered one of the great American novels, was not well received, and critics scorned his psychological novel, "" (1852). From 1853 to 1856, Melville published short fiction in magazines, most notably "Bartleby, the Scrivener" (1853), "The Encantadas" (1854), and "Benito Cereno" (1855). These and three other stories were collected in 1856 as "The Piazza Tales". In 1857, he traveled to England and then toured the Near East. "The Confidence-Man" (1857) was the last prose work that he published. He moved to New York to take a position as Customs Inspector and turned to poetry. "Battle-Pieces and Aspects of the War" (1866) was his poetic reflection on the moral questions of the American Civil War.

In 1867, his oldest child Malcolm died at home from a self-inflicted gunshot. "Clarel: A Poem and Pilgrimage in the Holy Land" was published in 1876, a metaphysical epic. In 1886, his son Stanwix died, and Melville retired. During his last years, he privately published two volumes of poetry, left one volume unpublished, and returned to prose of the sea. The novella "Billy Budd" was left unfinished at his death but was published in 1924. Melville's death from cardiovascular disease in 1891 subdued a reviving interest in his work. The 1919 centennial of his birth became the starting point of the "Melville Revival". Critics discovered his work, scholars explored his life; his major novels and stories have come to be considered world classics, and his poetry has gradually gained respect.

Born Herman Melvill in New York City on August 1, 1819, to Allan Melvill (1782–1832) and Maria (Gansevoort) Melvill (1791–1872) into a family of Dutch extraction. Herman was the third of eight children. His siblings, who played important roles in his career as well as in his emotional life, were Gansevoort (1815–1846); Helen Maria (1817–1888); Augusta (1821–1876); Allan (1823–1872); Catherine (1825–1905); Frances Priscilla (1827–1885); and Thomas (1830–1884), who eventually became a governor of Sailors Snug Harbor. Part of a well-established and colorful Boston family, Melville's father spent much time out of New York and in Europe as a commission merchant and an importer of French dry goods.
Both of Melville's grandfathers were heroes of the Revolutionary War. Major Thomas Melvill (1751–1832) had taken part in the Boston Tea Party, and his maternal grandfather, General Peter Gansevoort (1749–1812), was famous for having commanded the defense of Fort Stanwix in New York in 1777. Melville found satisfaction in his "double revolutionary descent." Major Melvill sent his son Allan (Herman's father) not to college but to France at the turn of the nineteenth century, where he spent two years in Paris and learned to speak and write French fluently. He subscribed to his father's Unitarianism. In 1814, Allan married Maria Gansevoort, who was committed to the Dutch Reformed version of the Calvinist creed of her family. The severe Protestantism of the Gansevoort's tradition ensured that she knew her Bible well, in English as well as in Dutch, the language she had grown up speaking with her parents.

Almost three weeks after his birth, on August 19, Herman Melville was baptized at home by a minister of the South Reformed Dutch Church. During the 1820s, Melville lived a privileged, opulent life, in a household with three or more servants at a time. At four-year intervals, the family would move to more spacious and elegant quarters, finally settling on Broadway in 1828. Allan Melvill lived beyond his means and on large sums he borrowed from both his father and his wife's widowed mother. His wife's opinion of his financial conduct is unknown. Biographer Hershel Parker suggests Maria "thought her mother's money was infinite and that she was entitled to much of her portion now, while she had small children." How well, biographer Delbanco adds, the parents managed to hide the truth from their children is "impossible to know."

In 1830, Maria's family finally lost patience and their support came to a halt, at which point Allan's total debt to both families exceeded $20,000 (roughly equivalent to $518,000 in 2018 dollars). The felicity of Melville's early childhood, biographer Newton Arvin writes, depended not so much on wealth as on the "exceptionally tender and affectionate spirit in all the family relationships, especially in the immediate circle." Arvin describes Allan as "a man of real sensibility and a particularly warm and loving father," while Maria was "warmly maternal, simple, robust, and affectionately devoted to her husband and her brood."

Melville's education began when he was five, around the time the Melvills moved to a newly built house at 33 Bleecker Street in Manhattan. In 1826, the same year that Melville contracted scarlet fever, Allan Melvill, who sent both Gansevoort and Herman to the New York Male High School, described Melville in a letter to Peter Gansevoort Jr. as "very backwards in speech & somewhat slow in comprehension." His older brother Gansevoort appeared to be the brightest of the children, but soon Melville's development increased its pace. "You will be as much surprised as myself to know," Allan wrote Peter Gansevoort Jr., "that Herman proved the best Speaker in the introductory Department, at the examination of the High School, he has made rapid progress during the 2 last quarters." In 1829, both Gansevoort and Herman were transferred to Columbia Grammar & Preparatory School, and Herman enrolled in the English Department on September 28. "Herman I think is making more progress than formerly," Allan wrote in May 1830 to Major Melvill, "& without being a bright Scholar, he maintains a respectable standing, & would proceed further, if he could only be induced to study more—being a most amiable & innocent child, I cannot find it in my heart to coerce him."

Emotionally unstable and behind on paying the rent for the house on Broadway, the father Allan tried to recover from his setbacks by moving his family to Albany in 1830 and going into the fur business. Herman attended the Albany Academy from October 1830 to October 1831, where he took the standard preparatory course, studying reading and spelling; penmanship; arithmetic; English grammar; geography; natural history; universal, Greek, Roman and English history; classical biography; and Jewish antiquities. It is unknown why he left the Academy in October 1831; Parker suggests that by then "even the tiny tuition fee seemed too much to pay." His brothers Gansevoort and Allan continued their attendance a few months longer, Gansevoort until March the next year. "The ubiquitous classical references in Melville's published writings," as Melville scholar Merton Sealts observed, "suggest that his study of ancient history, biography, and literature during his school days left a lasting impression on both his thought and his art, as did his almost encyclopedic knowledge of both the Old and the New Testaments."

In December, Melville's father returned from New York City by steamboat, but ice forced him to travel the last seventy miles for two days and two nights in an open horse carriage at two degrees below zero (Fahrenheit), with the result that he developed a cold. In early January, he began to show "signs of delirium," and his situation grew worse until he—in the words of his wife—"by reason of severe suffering was deprive'd of his Intellect." Two months before reaching fifty, Allan Melvill died on January 28, 1832. As Melville was no longer attending school, he must have witnessed these scenes: twenty years later he described such a death in the death of Pierre's father in "Pierre".

The death of Allan caused many major shifts in the family's material (and spiritual) circumstances. One result was the greater influence of his mother's religious beliefs. Maria sought consolation in her faith and in April was admitted as a member of the First Reformed Dutch Church. Herman's saturation in orthodox Calvinism is for Arvin "surely the most decisive intellectual and spiritual influence of his early life."

Two months after his father's death, Gansevoort entered the cap and fur business. Uncle Peter Gansevoort, a director of the New York State Bank, got Herman a job as clerk for $150 a year. Biographers cite a passage from "Redburn" when trying to answer what Herman must have felt then: "I had learned to think much and bitterly before my time," the narrator remarks, adding, "I must not think of those delightful days, before my father became a bankrupt ... and we removed from the city; for when I think of those days, something rises up in my throat and almost strangles me." Arvin argues Melville was forced to reckon with the "tormented psychology, of the decayed patrician."

When Melville's paternal grandfather died on September 16, 1832, Maria and her children discovered he had borrowed more than his share of his inheritance, meaning Maria received only $20. His paternal grandmother died almost exactly seven months later. Melville did his job well at the bank; though he was only fourteen in 1834, the bank considered him competent enough to be sent to Schenectady on an errand. Not much else is known from this period, except that he was very fond of drawing. The visual arts became a lifelong interest.

Around May 1834, the Melvilles moved to another house in Albany, a three-story brick house. That same month a fire destroyed Gansevoort's skin-preparing factory, which left him with personnel he could neither employ nor afford. Instead he pulled Melville out of the bank to man the cap and fur store. (Biographer Andrew Delbanco says that Gansevoort was doing so well he could hire his younger brother until a fire broke out in 1835, destroying both factory and the store.)

In 1835, while still working in the store, Melville enrolled in Albany Classical School, perhaps using Maria's part of the proceeds from the sale of the estate of his maternal grandmother in March 1835. In September of the following year Herman was back in Albany Academy in the Latin course. He also participated in debating societies, in an apparent effort to make up as much as he could for his missed years of schooling. In this period he read Shakespeare—at least "Macbeth", whose witch scenes gave him the chance to teasingly scare his sisters. In March 1837, he was again withdrawn from Albany Academy.

Gansevoort served as a role model and support for Melville in many ways throughout his life, at this time particularly in forming a self-directed educational plan. In early 1834 Gansevoort had become a member of Albany's Young Men's Association for Mutual Improvement, and in January 1835 Melville joined. Gansevoort also had copies of John Todd's "Index Rerum", a blank register for indexing remarkable passages from books one had read for easy retrieval. Among the sample entries was "Pequot, beautiful description of the war with," with a short title reference to the place in Benjamin Trumbull's "A Complete History of Connecticut" (1797 or 1818) where the description could be found. The two surviving volumes of Gansevoort's are the best evidence for Melville's reading in this period. Gansevoort's entries include books Melville used for "Moby-Dick" and "Clarel", such as "Parsees—of India—an excellent description of their character, & religion & an account of their descent—East India Sketch Book p. 21." Other entries are on Panther, the pirate's cabin, and storm at sea from James Fenimore Cooper's "The Red Rover", Saint-Saba.

The Panic of 1837 forced Gansevoort to file for bankruptcy in April. Uncle Thomas Jr. had not paid taxes on the farm, so he left Pittsfield secretly; he settled in Galena, Illinois. In June Maria told the younger children they must leave Albany for somewhere cheaper. Gansevoort began studying law in New York City while Herman managed the farm. However, that summer Herman decided to become a schoolteacher. He succeeded in getting a position at Sikes District School near Lenox, Massachusetts, where he taught some 30 students of many ages, including his own.

The semester over, he returned to his mother in 1838. In February he was elected president of the Philo Logos Society, which Peter Gansevoort invited to move into Stanwix Hall for no rent. In the "Albany Microscope" in March, Melville published two polemical letters about issues in vogue in the debating societies whose subjects are now obscure. Leon Howard and Hershel Parker suggest that the real issue was the youthful desire to have his rhetorical skills publicly recognized. In May the Melvilles moved to a rented house in Lansingburgh, almost 12 miles north of Albany. Nothing is known about what Melville did or where he went for several months after he finished teaching at Sikes. On November 12, five days after arriving in Lansingburgh, Melville paid for a term at Lansingburgh Academy to study surveying and engineering. In an April 1839 letter recommending Herman for a job in the Engineer Department of the Erie Canal, Peter Gansevoort says his nephew "possesses the ambition to make himself useful in a business which he desires to make his profession," but no job resulted.

Just weeks after this failure, Melville's first known published essay appeared. Using the initials "L.A.V.", Herman contributed "Fragments from a Writing Desk" to the weekly newspaper "Democratic Press and Lansingburgh Advertiser", which printed it in two installments, the first on May 4. According to Merton Sealts, his use of heavy-handed allusions reveals familiarity with the work of William Shakespeare, John Milton, Walter Scott, Richard Brinsley Sheridan, Edmund Burke, Samuel Taylor Coleridge, Lord Byron, and Thomas Moore. Parker calls the piece "characteristic Melvillean mood-stuff" and considers its style "excessive enough [...] to indulge his extravagances and just enough overdone to allow him to deny that he was taking his style seriously." For Delbanco, the style is "overheated in the manner of Poe, with sexually charged echoes of Byron and "The Arabian Nights.""

On May 31, 1839, Gansevoort, then living in New York City, wrote that he was sure Herman could get a job on a whaler or merchant vessel. The next day, he signed aboard the merchant ship "St. Lawrence" as a "boy" (a green hand), which cruised from New York to Liverpool; he arrived back in New York October 1. "Redburn: His First Voyage" (1849) draws on his experiences in this journey. Melville resumed teaching, now at Greenbush, New York, but left after one term because he had not been paid. In the summer of 1840 he and his friend James Murdock Fly went to Galena, Illinois to see if his Uncle Thomas could help them find work. On this trip it is possible that Herman went up the Mississippi, where he may well have witnessed scenes of frontier life he later used in his books. Unsuccessful, he and his friend returned home in autumn, very likely by way of St. Louis and up the Ohio River.

Probably inspired by his reading of Richard Henry Dana, Jr.'s new book "Two Years Before the Mast," and by Jeremiah N. Reynolds's account in the May 1839 issue of "The Knickerbocker" magazine of the hunt for a great white sperm whale named Mocha Dick, Melville and Gansevoort traveled to New Bedford, where Melville signed up for a whaling voyage aboard a new ship, the "Acushnet". Built in 1840, the ship measured some 104 feet in length, almost 28 feet in breadth, and almost 14 feet in depth. She measured slightly less than 360 tons, had two decks and three masts, but no galleries. Melville signed a contract on Christmas Day with the ship's agent as a "green hand" for 1/175th of whatever profits the voyage would yield. On Sunday the 27th the brothers heard the Reverend Enoch Mudge preach at the Seamen's Bethel on Johnny-Cake Hill, where white marble cenotaphs on the walls memorialized local sailors who had died at sea, often in battle with whales. When he signed the crew list the next day he was advanced $84.

On January 3, 1841, the "Acushnet" set sail. Melville slept with some twenty others in the forecastle; Captain Valentine Pease, the mates, and the skilled men slept aft. Whales were found near The Bahamas, and in March 150 barrels of oil were sent home from Rio de Janeiro. Cutting in and trying-out (boiling) a single whale took some three days, and a whale yielded approximately one barrel of oil per foot of length and per ton of weight (the average whale weighed 40 to 60 tons). The oil was kept on deck for a day to cool off, and was then stowed down; scrubbing the deck completed the labor. An average voyage meant that some forty whales were killed to yield some 1600 barrels of oil.

On April 15, the "Acushnet" sailed around Cape Horn, and traveled to the South Pacific, where the crew sighted whales without catching any. Then up the coast of Chile to the region of Selkirk Island and on 7 May, near Juan Fernández Islands, she had 160 barrels. On June 23 the ship anchored for the first time since Rio, in Santa Harbor. The cruising grounds the "Acushnet" was sailing attracted much traffic, and Captain Pease not only paused to visit other whalers, but at times hunted in company with them. From July 23 into August the "Acushnet" regularly gammed with the "Lima" from Nantucket, and Melville met William Henry Chase, the son of Owen Chase, who gave him a copy of his father's account of his adventures aboard the "Essex". Ten years later Melville wrote in his other copy of the book: "The reading of this wondrous story upon the landless sea, & close to the very latitude of the shipwreck had a surprising effect upon me."

On September 25 the ship reported 600 barrels of oil to another whaler, and in October 700 barrels. On October 24 the "Acushnet" crossed the equator to the north, and six or seven days later arrived at the Galápagos Islands. This short visit would be the basis for "The Encantadas". On November 2, the Acushnet and three other American whalers were hunting together near the Galápagos Islands; Melville later exaggerated that number in Sketch Fourth of "The Encantadas". From November 19 to 25 the ship anchored at Chatham's Isle, and on December 2 reached the coast of Peru and anchored at Tombez near Paita, with 570 barrels of oil on board. On December 27 the "Acushnet" sighted Cape Blanco, off Ecuador, Point St. Elena was sighted the next day, and on January 6, 1842 the ship approached the Galápagos Islands from the southeast. From February 13 to 7 May, seven sightings of sperm whales were recorded but none killed. From early May to early June the "Acushnet" gammed several times with the "Columbus" of New Bedford, which also took letters from Melville's ship; the two ships were in the same area just south of the Equator. On June 16 she carried 750 barrels, and sent home 200 on the "Herald the Second". On June 23, the "Acushnet" reached the Marquesas Islands, and anchored at Nuku Hiva.

A time of some emotional turbulence for Melville ensued over the next summer months. On July 9, 1842, Melville and his shipmate Richard Tobias Greene jumped ship at Nukahiva Bay and ventured into the mountains to avoid capture. Melville's first book, Typee (1845), is loosely based on his stay in or near the Taipi Valley. Scholarly research starting in the 1930s and extending into the twenty-first century has increasingly shown that much if not all of this account was either taken from Melville's readings or exaggerated to dramatize a contrast between idyllic native culture and Western civilization. On August 9, Melville boarded the Australian whaler "Lucy Ann", bound for Tahiti, where on arrival he took part in a mutiny and was briefly jailed in the native "Calabooza Beretanee". In October, he and crew mate John B. Troy escaped Tahiti for Eimeo. He then spent a month as beachcomber and island rover ("omoo" in Tahitian), eventually crossing over to Moorea. He drew on these experiences for "Omoo", the sequel to "Typee" In November, he signed articles on the Nantucket whaler "Charles & Henry" for a six-month cruise (November 1842 − April 1843), and was discharged at Lahaina, Maui in the Hawaiian Islands in May 1843.

After four months of working several jobs, including as a clerk, he joined the US Navy initially as one of the crew of the frigate as an ordinary seaman on August 20. During the next year, the homeward bound ship visited the Marquesas Islands, Tahiti, and Valparaiso, and then, from summer to fall 1844, Mazatlan, Lima, and Rio de Janeiro, before reaching Boston on October 3. Melville was discharged on October 14. This navy experience is used in "White-Jacket" (1850) Melville's fifth book. Melville's wander-years created what biographer Arvin calls "a settled hatred of external authority, a lust for personal freedom" and a "growing and intensifying sense of his own exceptionalness as a person," along with "the resentful sense that circumstance and mankind together had already imposed their will upon him in a series of injurious ways." Scholar Milder believes the encounter with the wide ocean, where he was seemingly abandoned by God, led Melville to experience a "metaphysical estrangement" and influenced his social views in two ways: first that he belonged to the genteel classes but sympathized with the "disinherited commons" he had been placed among; second that experiencing the cultures of Polynesia let him view the West from an outsider's perspective.

Upon his return, Melville regaled his family and friends with his adventurous tales and romantic experiences, and they urged him to put them into writing. Melville completed "Typee", his first book, in the summer of 1845 while living in Troy. His brother Gansevoort found a publisher for it in London, where it was published in February 1846 by John Murray and became an overnight bestseller, then in New York on March 17 by Wiley & Putnam. Inspired by his adventures in the Marquesas, the book was far from a reliable autobiographical account.

Melville extended the period his narrator spent on the island to three months more than he himself did, made it appear that he understood the native language, and incorporated material from source books he had assembled. Scholar Robert Milder calls "Typee" "an appealing mixture of adventure, anecdote, ethnography, and social criticism presented with a genial latitudinarianism that gave novelty to a South Sea idyll at once erotically suggestive and romantically chaste."

An unsigned review in the "Salem Advertiser", actually written by Nathaniel Hawthorne, called the book a "skilfully managed" narrative, "lightly but vigorously written" by an author with "that freedom of view ... which renders him tolerant of codes of morals that may be little in accordance with our own." The depictions of the "native girls are voluptuously colored, yet not more so than the exigencies of the subject appear to require." Pleased but slightly bemused by the adulation of his new public, Melville later complained in a letter to Nathaniel Hawthorne that he would "go down to posterity ... as a ‘man who lived among the cannibals'!" The book brought Melville into contact with his friend Greene again, Toby in the book, who wrote to the newspapers confirming Melville's account. The two corresponded until 1863, and sustained a bond for life: in his final years Melville "traced and successfully located his old friend."

In March 1847, "Omoo", a sequel to "Typee", was published by Murray in London, and in May by Harper in New York. "Omoo" is "a slighter but more professional book," according to Milder. "Typee" and "Omoo" gave Melville overnight renown as a writer and adventurer, and he often entertained by telling stories to his admirers. As the writer and editor Nathaniel Parker Willis wrote, "With his cigar and his Spanish eyes, he "talks" Typee and Omoo, just as you find the flow of his delightful mind on paper." In 1847 Melville tried unsuccessfully to find a "government job" in Washington.
In June 1847, Melville and Elizabeth Knapp Shaw were engaged, after knowing each other for approximately three months. A brief courtship, yet Melville had already asked her father for her hand in March but was at first turned down. Lizzie's father was Lemuel Shaw, the Chief Justice of the Massachusetts Supreme Judicial Court. Arvin describes Lemuel Shaw as a man "of an almost childlike tenderness of heart and gentleness of feeling." He had been an intimate friend of Melville's father Allan, and had fallen in love with Allan's sister Nancy. The Judge would have married her had she not died early. His grief was such that for many years he did not marry, and his friendship with the Melvilles continued after Allan's death. His wife Elizabeth died when she gave birth to their first daughter, who was named Elizabeth in remembrance of her mother. Elizabeth was raised by her grandmother and the Irish nurse. Arvin suggests that Melville's interest in Elizabeth may have been stimulated by "his need of Judge Shaw's paternal presence." They were married on August 4, 1847. As Lizzie wrote a relative, "My marriage was very unexpected, and scarcely thought of until about two months before it actually took place." She wanted to be married in church, "but we all thought if it were to get about previously that 'Typee' was to be seen on such a day, a great crowd might rush out of mere curiosity to see 'the author' who would have no personal interest in us whatsoever, and make it very unpleasant for us both." Because of Melville's celebrity status a private wedding ceremony took place at home. The couple honeymooned in Canada, and traveled to Montreal. They settled in a house on Fourth Avenue in New York City (now called Madison Avenue).

According to scholars Joyce Deveau Kennedy and Frederick James Kennedy, Lizzie brought the following qualities to their marriage: a sense of religious obligation in marriage, an intent to make a home with Melville regardless of place, a willingness to please her husband by performing such "tasks of drudgery" as mending stockings, an ability to hide her agitation, and a desire "to shield Melville from unpleasantness." The Kennedys conclude their assessment with:

Biographer Robertson-Lorant's cites "Lizzie's adventurous spirit and abundant energy," and she suggests that "her pluck and good humor might have been what attracted Melville to her, and vice versa." An example of such good humor appears in a letter about her not yet used to being married: "It seems sometimes exactly as if I were here for a "visit". The illusion is quite dispelled however when Herman stalks into my room without even the ceremony of knocking, bringing me perhaps a button to sew on, or some equally romantic occupation."

In March 1848, "Mardi" was published by Richard Bentley in London, and in April by Harper in New York. Nathaniel Hawthorne thought it a rich book, he told Evert Augustus Duyckinck, a friend of Melville's, "with depths here and there that compel a man to swim for his life." According to Robert Milder, the book began as another South Sea story but, as he wrote, Melville left that genre behind, first in favor of "a romance of the narrator Taji and the lost maiden Yillah," and then "to an allegorical voyage of the philosopher Babbalanja and his companions through the imaginary archipelago of Mardi," On February 16, 1849, the Melvilles' first child, Malcolm, was born.

In October 1849, "Redburn" was published by Bentley in London, and in November by Harper in New York. The bankruptcy and death of Allan Melville, and Melville's own youthful humiliations surface in this "story of outward adaptation and inner impairment." Biographer Robertson-Lorant regards the work as a deliberate attempt for popular appeal: "Melville modeled each episode almost systematically on every genre that was popular with some group of antebellum readers," combining elements of "the picaresque novel, the travelogue, the nautical adventure, the sentimental novel, the sensational French romance, the gothic thriller, temperance tracts, urban reform literature, and the English pastoral." In January 1850, another novel "White-Jacket" was published by Bentley in London, and in March by Harper in New York.

Although not yet personally acquainted with Melville, Nathaniel Hawthorne and his family moved to a small red farmhouse near Lenox, Massachusetts, at the end of March 1850. In early May 1850 Melville wrote to fellow sea author Richard Henry Dana Jr. a letter that contains what is the earliest surviving mention of the writing of "Moby-Dick", saying he was already "half way" done. In June he described the book to his English publisher as "a romance of adventure, founded upon certain wild legends in the Southern Sperm Whale Fisheries," and promised it would be done by the fall. The manuscript has not survived, so it is impossible to know its state at this juncture. Over the next several months, Melville radically transformed his initial plan, conceiving what Delbanco has described as "the most ambitious book ever conceived by an American writer."

From August 4 to 12, 1850, the Melvilles and their neighbor Sarah Morewood, Evert Duyckinck, Oliver Wendell Holmes, and other literary figures from New York and Boston, came to Pittsfield to enjoy a period of social parties, picnics, dinners, and the like. On August 5, Nathaniel Hawthorne and his publisher James T. Fields joined the group, while Hawthorne's wife stayed at home to look after the children. As the men took a stroll through Ice Glen, someone noticed that Hawthorne and Melville were absent, and the group went looking for the two, who were at last found "deep in conversation." Melville had just read Hawthorne's short story collection "Mosses from an Old Manse" with interest. The following day, the group visited the Hawthornes, who since May had been living in nearby Lenox. "I liked Melville so much," Hawthorne wrote to his friend Horatio Bridge, "that I have asked him to spend a few days with me," an uncharacteristic move for a man so attached to his work that he would not suffer overnight guests to keep him from it. The following days, Melville wrote the essay "Hawthorne and His Mosses," a review of Hawthorne's "Mosses from an Old Manse" that appeared in two installments, on August 17 and 24, in "The Literary World". Melville wrote that these stories revealed a dark side to Hawthorne, "shrouded in blackness, ten times black".

Later that summer, Melville received a package from Duyckinck with a letter asking him to forward it to Hawthorne. When he delivered the package to Hawthorne, he did not know it contained his last three books. Hawthorne read them, as he wrote to Duyckinck on August 29, "with a progressive appreciation of their author." He thought Melville in "Redburn" and "White-Jacket" put the reality "more unflinchingly" before his reader than any writer, and he thought "Mardi" was "a rich book, with depths here and there that compel a man to swim for his life. It is so good that one scarcely pardons the writer for not having brooded long over it, so as to make it a great deal better." In September 1850, Melville borrowed three thousand dollars from his father-in-law Lemuel Shaw to buy a 160-acre farm in Pittsfield. Melville called his new home Arrowhead because of the arrowheads that were dug up around the property during planting season.

That winter, Melville on an impulse paid Hawthorne a visit, only to discover he was "not in the mood for company" as he was finishing "The House of the Seven Gables". Hawthorne's wife Sophia entertained him while he waited for Hawthorne to come down for supper, and gave him copies of "Twice-Told Tales" and, for Malcolm, "The Grandfather's Chair". Melville invited them to visit Arrowhead some time in the next two weeks, and when Sophia agreed, he looked forward to "discussing the Universe with a bottle of brandy & cigars" with Hawthorne. A few days later Sophia notified the Melvilles that Hawthorne could not stop working on his new book for more than one day, and Melville felt moved to repeat his invitation: "Your bed is already made, & the wood marked for your fire." Eventually Melville visited the Hawthornes again, and the next day Hawthorne surprised him by arriving at Arrowhead with his daughter Una. According to Robertson-Lorant, "The handsome Hawthorne made quite an impression on the Melville women, especially Augusta, who was a great fan of his books." They spent the day mostly "smoking and talking metaphysics."

In Robertson-Lorant's assessment of the friendship, Melville was "infatuated with Hawthorne's intellect, captivated by his artistry, and charmed by his elusive personality," and though the two writers were "drawn together in an undeniable sympathy of soul and intellect, the friendship meant something different to each of them," with Hawthorne offering Melville "the kind of intellectual stimulation he needed." They may have been "natural allies and friends," yet they were also "fifteen years apart in age and temperamentally quite different," and Hawthorne "found Melville's manic intensity exhausting at times." Melville wrote ten letters to Hawthorne, "all of them effusive, profound, deeply affectionate." Melville was inspired and encouraged by his new relationship with Hawthorne during the period that he was writing "Moby-Dick." He dedicated this new novel to Hawthorne, though their friendship was to wane only a short time later. Melville dedicated the work in 1851 to Hawthorne with a short dedication: "In token of my admiration for his genius, this book is inscribed to Nathaniel Hawthorne."

On October 18, 1851, "The Whale" was published in Britain in three volumes, and on November 14 "Moby-Dick" appeared in the United States as a single volume. In between these dates, on October 22, 1851, the Melvilles' second child, Stanwix, was born. On December 1 Hawthorne wrote a letter of appraisal to Duyckinck, prompted in part by his disagreement with the review in "Literary World": "What a book Melville has written! It gives me an idea of much greater power than his preceding ones. It hardly seemed to me that the review of it, in the "Literary World", did justice to its best points." In early December 1852, Melville visited the Hawthornes in Concord, and discussed the idea of the "Agatha" story which he had pitched to Hawthorne. This was the last known contact between the two writers before Melville visited Hawthorne in Liverpool four years later.

Melville had high hopes that his next book would please the public and restore his finances. In April 1851 he wrote to his British publisher, Richard Bentley, that his new book, "possessing unquestionable novelty" is "as I believe, very much more calculated for popularity than anything you have yet published of mine—being a regular romance, with a mysterious plot to it & stirring passions at work, and withall, representing a new & elevated aspect of American life..." In fact,
"" was heavily psychological, though drawing on the conventions of the romance, and difficult in style. It was not well received. The New York "Day Book" on September 8, 1852, published a venomous attack headlined "HERMAN MELVILLE CRAZY." The item, offered as a news story, reported,
On May 22, 1853, Elizabeth (Bessie) was born, the Melvilles' third child and first daughter, and on or about that day Herman finished work on "Isle of the Cross"—one relative wrote that 'The Isle of the Cross' is almost a twin sister of the little one ..." Herman traveled to New York to discuss it with his publisher, but later wrote that Harper & Brothers was "prevented" from publishing his manuscript, presumed to be "Isle of the Cross", which has been lost.

Finding it difficult to find a publisher for his follow-up novel to the commercial and critical failure of "Pierre", "Israel Potter", the narrative of a Revolutionary War veteran, was first serialized in "Putnam's Monthly Magazine" in 1853. From November 1853 to 1856, Melville published fourteen tales and sketches in "Putnam's" and "Harper"'s magazines. In December 1855 he proposed to Dix & Edwards, the new owners of "Putnam's", that they publish a selection of the short fiction titled "Benito Cereno and Other Sketches". The collection would eventually be named after a new introductory story Melville had written for it, "The Piazza," and was published as "The Piazza Tales", with five previously published stories, including "Bartleby, the Scrivener" and "Benito Cereno." On March 2, 1855, Frances (Fanny) was born, the Melvilles' fourth child. In this period his book "Israel Potter" was published.

The writing of "The Confidence-Man" put great strain on Melville, leading Sam Shaw, a nephew of Lizzie, to write to his uncle Lemuel Shaw, "Herman I hope has had no more of those ugly attacks"—a reference to what Robertson-Lorant calls "the bouts of rheumatism and sciatica that plagued Melville." Melville's father-in-law apparently shared his daughter's "great anxiety about him" when he wrote a letter to a cousin, in which he described Melville's working habits: "When he is deeply engaged in one of his literary works, he confines him[self] to hard study many hours in the day, with little or no exercise, & this specially in winter for a great many days together. He probably thus overworks himself & brings on severe nervous affections." Shaw advanced Melville $1,500 from Lizzie's inheritance to travel four or five months in Europe and the Holy Land.

From October 11, 1856, to May 20, 1857, Melville made a six-month Grand Tour of the British Isles and the Mediterranean. While in England, in November he spent three days with Hawthorne, who had taken an embassy position there. At the seaside village of Southport, amid the sand dunes where they had stopped to smoke cigars, they had a conversation which Hawthorne later described in his journal:
Melville's subsequent visit to the Holy Land inspired his epic poem "Clarel." On April 1, 1857, Melville published his last full-length novel, "The Confidence-Man". This novel, subtitled "His Masquerade", has won general acclaim in modern times as a complex and mysterious exploration of issues of fraud and honesty, identity and masquerade. But, when it was published, it received reviews ranging from the bewildered to the denunciatory.

To repair his faltering finances, Melville was advised by friends to enter what had proven to be, at least for others, a remunerative field: public lecturing. From late 1857 to 1860, he embarked upon three lecture tours, and spoke at lyceums, chiefly on Roman statuary and sightseeing in Rome. Melville's lectures, which mocked the pseudo-intellectualism of lyceum culture, were panned by contemporary audiences.

On May 30, 1860, Melville boarded the clipper "Meteor" for California, with his brother Thomas at the helm. After a shaky trip around Cape Horn Melville returned alone to New York via Panama in November. Turning to poetry, he submitted a collection of verse to a publisher in 1860, but it was not accepted. In 1861 he shook hands with Abraham Lincoln. In 1862, Melville met with a road accident which left him seriously injured. He also suffered from rheumatism. In 1863, he bought his brother's house at 104 East 26th Street in New York City and moved there. Allan, his brother, for his part bought Arrowhead. On March 30, his father-in-law died.

In 1864, Melville and Allan paid a visit to the Virginia battlefields of the American Civil War. After the end of the war, he published "Battle Pieces and Aspects of the War" (1866), a collection of 72 poems that has been described as "a polyphonic verse journal of the conflict". It was generally ignored by reviewers, who gave him at best patronizingly favorable reviews. The volume did not sell well; of the Harper & Bros. printing of 1200 copies, only 525 had been sold ten years later. Uneven as a collection of individual poems, "its achievement lies in the interplay of voices and moods throughout which Melville patterns a shared historical experience into formative myth".

In 1866, Melville's wife and her relatives used their influence to obtain a position for him as customs inspector for the City of New York, a humble but adequately paying appointment. He held the post for 19 years and won the reputation of being the only honest employee in a notoriously corrupt institution. Unbeknownst to him, his modest position and income "were protected throughout the periodic turmoil of political reappointments by a customs official who never spoke to Melville but admired his writings: future US president Chester A. Arthur". In 1867 his oldest son Malcolm shot himself, perhaps accidentally, and died at home at the age of 18. Some psychologists believe it was a suicide.

The job came as a relief for his family, because he would be out of the house for much of the day. Melville suffered from unpredictable mood swings, habitually "bullying his servants, wife, and children." As Robertson-Lorant's writes, "Like the tyrannical captains he had portrayed in his novels, Melville probably provoked rebellious feelings in his 'crew' by the capricious way he ruled the home, especially when he was drinking." Nervous exhaustion and physical pain rendered him short-tempered, made worse by his drinking. Robertson-Lorant takes the different ways one can look at Melville in this period to their extremes:

In May 1867, Sam Shaw contacted Lizzie's minister Henry Bellows asking assistance with his "sister's case", which "has been a cause of anxiety to all of us for years past." A wife then could not leave her husband without losing all claims to the children, so Bellows suggested Lizzie be kidnapped and brought to Boston. Shaw suspected that Lizzie would not agree to such melodramatic scheme. He thought up a different scheme, in which Lizzie would visit Boston and friends would inform Herman she would not come back. To get a divorce, she would then have to bring charges against Melville, believing her husband to be insane.

Though Melville's professional writing career had ended, he remained dedicated to his writing. He bought books on poetry, landscape, art, and engraving. He had a Rembrandt mezzotint framed in his New York residence. In 1872 his brother Allan died, as did his mother, aged eighty-two. Melville devoted years to "his autumnal masterpiece," an 18,000-line epic poem titled " Clarel: A Poem and a Pilgrimage", inspired by his 1856 trip to the Holy Land. It is among the longest single poems in American literature. The title character is a young American student of divinity who travels to Jerusalem to renew his faith. One of the central characters, Rolfe, is similar to Melville in his younger days, a seeker and adventurer, while the reclusive Vine is loosely based on Hawthorne, who had died twelve years before. A bequest from his uncle, Peter Gansevoort, paid for publication in 1876, but epic-length verse-narrative was considered quite obscure even in his own time. The book had an initial printing of 350 copies, but sales failed miserably, and the unsold copies were burned when Melville was unable to afford to buy them at cost. The critic Lewis Mumford found a copy in the New York Public Library in 1925 "with its pages uncut"—in other words, it had sat there unread for 50 years.

In 1884, Mrs. Melville received a legacy, which enabled her to allow Melville a monthly sum of $25 to spend on books and prints. While Melville had his steady customs job, he no longer showed signs of depression, which recurred after the death of his second son. On February 23, 1886, Stanwix Melville died in San Francisco at age 36. Melville retired on December 31, 1885, after several of his wife's relatives died and left the couple more legacies which Mrs. Melville administered with skill and good fortune. In 1889 Melville became a member of the New York Society Library.

As English readers, pursuing the vogue for sea stories represented by such writers as G. A. Henty, rediscovered Melville's novels in the late nineteenth century, the author had a modest revival of popularity in England, though not in the United States. He wrote a series of poems, with prose head notes, inspired by his early experiences at sea. He published them in two collections, each issued in a tiny edition of 25 copies for his relatives and friends. Of these, scholar Robert Milder calls "John Marr and Other Poems" (1888), "the finest of his late verse collections". The second privately printed volume is "Timoleon" (1891).

Intrigued by one of these poems, Melville began to rework the headnote, expanding it first as a short story and eventually as a novella. He worked on it on and off for several years, but when he died in September 1891, the piece was unfinished. Also left unpublished were another volume of poetry, "Weeds and Wildings", and a sketch, "Daniel Orme." To "Billy Budd", his widow added notes and edited it, but the manuscript was not discovered until 1919, by Raymond Weaver, his first biographer. He worked at transcribing and editing a full text, which he published in 1924 as "Billy Budd, Sailor." It was an immediate critical success in England and soon one in the United States. The authoritative version was published in 1962, after two scholars studied the papers for several years. In 1951 it was adapted as a stage play on Broadway, and as an opera by English composer Benjamin Britten with assistance on the libretto by E. M. Forster. In 1961 Peter Ustinov released a movie based on the stage play and starring Terence Stamp titled "Billy Budd (film)".

Melville died at his home in New York City early on the morning of September 28, 1891, at age 72. The doctor listed "cardiac dilation" on the death certificate. He was interred in the Woodlawn Cemetery in The Bronx, New York City. A common story recounts that his "The New York Times" obituary called him ""Henry" Melville," implying that he was unknown and unappreciated at his time of death, but the story is not true. A later article was published on October 6 in the same paper, referring to him as "the late Hiram Melville," but this appears to have been a typesetting error.

Melville's writing style shows enormous changes throughout the years as well as consistencies. In the words of Arvin, Melville's development "had been abnormally postponed, and when it came, it came with a rush and a force that had the menace of quick exhaustion in it." As early a juvenile piece as "Fragments from a Writing Desk" from 1839, scholar Sealts points out, already shows "a number of elements that anticipate Melville's later writing, especially his characteristic habit of abundant literary allusion". "Typee" and "Omoo" were documentary adventures that called for a division of the narrative in short chapters. Such compact organization bears the risk of fragmentation when applied to a lengthy work such as "Mardi", but with "Redburn" and "White Jacket," Melville turned the short chapter into an instrument of form and concentration.

A number of chapters of "Moby-Dick" are no longer than two pages in standard editions, and an extreme example is Chapter 122, consisting of a single paragraph of 36 words (including the thrice-repeated "Um, um, um.") The skillful handling of chapters in "Moby-Dick" is one of the most fully developed Melvillean signatures, and is a measure of "his manner of mastery as a writer". Individual chapters have become "a touchstone for appreciation of Melville's art and for explanation" of his themes. In contrast, the chapters in "Pierre", called Books, are divided into short numbered sections, seemingly an "odd formal compromise" between Melville's natural length and his purpose to write a regular romance that called for longer chapters. As satirical elements were introduced, the chapter arrangement restores "some degree of organization and pace from the chaos". The usual chapter unit then reappears for "Israel Potter", "The Confidence-Man" and even "Clarel", but only becomes "a vital part in the whole creative achievement" again in the juxtaposition of accents and of topics in "Billy Budd".

Newton Arvin points out that only superficially the books after "Mardi" seem as if Melville's writing went back to the vein of his first two books. In reality, his movement "was not a retrograde but a spiral one", and while "Redburn" and "White-Jacket" may lack the spontaneous, youthful charm of his first two books, they are "denser in substance, richer in feeling, tauter, more complex, more connotative in texture and imagery." The rhythm of the prose in "Omoo" "achieves little more than easiness; the language is almost neutral and without idiosyncrasy", yet "Redburn" shows a "gain in rhythmical variety and intricacy, in sharpness of diction, in syntactical resource, in painterly bravura and the fusing of image and emotion into a unity of strangeness, beauty and dread".

Melville's early works were "increasingly baroque" in style, and with "Moby-Dick" Melville's vocabulary had grown superabundant. Bezanson calls it an "immensely varied style". According to critic Warner Berthoff, three characteristic uses of language can be recognized. First, the exaggerated repetition of words, as in the series "pitiable," "pity," "pitied," and "piteous" (Ch. 81, "The Pequod Meets the Virgin"). A second typical device is the use of unusual adjective-noun combinations, as in "concentrating brow" and "immaculate manliness" (Ch. 26, "Knights and Squires"). A third characteristic is the presence of a participial modifier to emphasize and to reinforce the already established expectations of the reader, as the words "preluding" and "foreshadowing" ("so still and subdued and yet somehow preluding was all the scene ...," "In this foreshadowing interval ...").

After his use of hyphenated compounds in "Pierre", Melville's writing gives Berthoff the impression of becoming less exploratory and less provocative in his choices of words and phrases. Instead of providing a lead "into possible meanings and openings-out of the material in hand," the vocabulary now served "to crystallize governing impressions," the diction no longer attracted attention to itself, except as an effort at exact definition. The language, Berthoff continues, reflects a "controlling intelligence, of right judgment and completed understanding". The sense of free inquiry and exploration which infused his earlier writing and accounted for its "rare force and expansiveness," tended to give way to "static enumeration." For Berthoff, added "seriousness of consideration" came at the cost of losing "pace and momentum". The verbal music and kinetic energy of "Moby-Dick" seem "relatively muted, even withheld" in the later works.

Melville's paragraphing in his best work Berthoff considers to be the virtuous result of "compactness of form and free assembling of unanticipated further data", such as when the mysterious sperm whale is compared with Exodus's invisibility of God's face in the final paragraph of Chapter 86 ("The Tail"). Over time Melville's paragraphs became shorter as his sentences grew longer, until he arrived at the "one-sentence paragraphing characteristic of his later prose." Berthoff points to the opening chapter of "The Confidence-Man" for an example, as it counts fifteen paragraphs, seven of which consist of only one elaborate sentence, and four that have only two sentences. The use of similar technique in "Billy Budd" contributes in large part, Berthoff says, to its "remarkable narrative economy".

In Nathalia Wright's view, Melville's sentences generally have a looseness of structure, easy to use for devices as catalogue and allusion, parallel and refrain, proverb and allegory. The length of his clauses may vary greatly, but the "torterous" writing in "Pierre" and "The Confidence-Man" is there to convey feeling, not thought. Unlike Henry James, who was an innovator of sentence ordering to render the subtlest nuances in thought, Melville made few such innovations. His domain is the mainstream of English prose, with its rhythm and simplicity influenced by the King James Bible. Another important characteristic of Melville's writing style is in its echoes and overtones. Melville's imitation of certain distinct styles is responsible for this. His three most important sources, in order, are the Bible, Shakespeare, and Milton. Scholar Nathalia Wright has identified three stylistic categories of Biblical influence. Direct quotation from any of the sources is slight; only one sixth of his Biblical allusions can be qualified as such.

First, far more unmarked than acknowledged quotations occur, some favorites even numerous times throughout his whole body of work, taking on the nature of refrains. Examples of this idiom are the injunctions to be 'as wise as serpents and as harmless as doves,' 'death on a pale horse,' 'the man of sorrows', the 'many mansions of heaven;' proverbs 'as the hairs on our heads are numbered,' 'pride goes before a fall,' 'the wages of sin is death;' adverbs and pronouns as 'verily, whoso, forasmuch as; phrases as come to pass, children's children, the fat of the land, vanity of vanities, outer darkness, the apple of his eye, Ancient of Days, the rose of Sharon.' Second, there are paraphrases of individual and combined verses. Redburn's "Thou shalt not lay stripes upon these Roman citizens" makes use of language of the Ten Commandments in Ex.20, and Pierre's inquiry of Lucy: "Loveth she me with the love past all understanding?" combines John 21:15–17 and Philippians 4:7 Third, certain Hebraisms are used, such as a succession of genitives ("all the waves of the billows of the seas of the boisterous mob"), the cognate accusative ("I dreamed a dream," "Liverpool was created with the Creation"), and the parallel ("Closer home does it go than a rammer; and fighting with steel is a play without ever an interlude"). A passage from "Redburn" shows how all these different ways of alluding interlock and result in a fabric texture of Biblical language, though there is very little direct quotation:

In addition to this, Melville successfully imitates three Biblical strains: he sustains the apocalyptic for a whole chapter of "Mardi;" the prophetic strain is expressed in "Moby-Dick", most notably in Father Mapple's sermon; and the tradition of the Psalms is imitated at length in "The Confidence-Man".

Melville owned an edition of Shakespeare's works by 1849, and his reading of it greatly influenced the style of his next book, "Moby-Dick" (1851). The critic F. O. Matthiessen found that the language of Shakespeare far surpasses other influences upon the book, in that it inspired Melville to discover his own full strength. On almost every page, debts to Shakespeare can be discovered. The "mere sounds, full of Leviathanism, but signifying nothing" at the end of "Cetology" (Ch.32) echo the famous phrase in "Macbeth:" "Told by an idiot, full of sound and fury/ Signifying nothing." Ahab's first extended speech to the crew, in the "Quarter-Deck" (Ch.36) is practically blank verse and so is Ahab's soliloquy at the beginning of "Sunset" (Ch.37):'I leave a white and turbid wake;/ Pale waters, paler cheeks, where'er I sail./ The envious billows sidelong swell to whelm/ My track; let them; but first I pass.' Through Shakespeare, Melville infused "Moby-Dick" with a power of expression he had not previously possessed. Reading Shakespeare had been "a catalytic agent" for Melville, one that transformed his writing from merely reporting to "the expression of profound natural forces." The extent to which Melville assimilated Shakespeare is evident in the description of Ahab, Matthiessen continues, which ends in language that seems Shakespearean yet is no imitation: 'Oh, Ahab! what shall be grand in thee, it must needs be plucked from the skies and dived for in the deep, and featured in the unbodied air!' The imaginative richness of the final phrase seems particularly Shakespearean, "but its two key words appear only once each in the plays...and to neither of these usages is Melville indebted for his fresh combination." Melville's diction depended upon no source, and his prose is not based on anybody else's verse but on an awareness of "speech rhythm".

Melville's mastering of Shakespeare, Matthiessen finds, supplied him with verbal resources that enabled him to create dramatic language through three essential techniques. First, the use of verbs of action creates a sense of movement and meaning. The effective tension caused by the contrast of "thou launchest navies of full-freighted worlds" and "there's that in here that still remains indifferent" in "The Candles" (Ch. 119) makes the last clause lead to a "compulsion to strike the breast," which suggests "how thoroughly the drama has come to inhere in the words;" Second, Melville took advantage of the Shakespearean energy of verbal compounds, as in "full-freighted". Third, Melville employed the device of making one part of speech act as another – for example, 'earthquake' as an adjective, or turning an adjective into a noun, as in "placeless".

Melville's style, in Nathalia Wright's analysis, seamlessly flows over into theme, because all these borrowings have an artistic purpose, which is to suggest an appearance "larger and more significant than life" for characters and themes that are in fact unremarkable. The allusions suggest that beyond the world of appearances another world exists, one that influences this world, and where ultimate truth can be found. Moreover, the ancient background thus suggested for Melville's narratives – ancient allusions being next in number to the Biblical ones – invests them with a sense of timelessness.

Melville was not financially successful as a writer, having earned just over $10,000 for his writing during his lifetime. His popularity declined dramatically after his success with travelogues based on voyages to the South Seas and his stories based on misadventures in the merchant marine and navy. By 1876, all of his books were out of print. He was viewed as a minor figure in American literature in the later years of his life and during the years after his death.

The "Melville Revival" of the late 1910s and 1920s brought about a reassessment of his work. The centennial of his birth was in 1919. Carl Van Doren's 1917 article on Melville in a standard history of American literature was the start of renewed appreciation. Van Doren also encouraged Raymond Weaver, who wrote the author's first full-length biography, "Herman Melville: Mariner and Mystic" (1921). Discovering the unfinished manuscript of "Billy Budd", among papers shown to him by Melville's granddaughter, Weaver edited it and published it in a new collected edition of Melville's works. Other works that helped fan the flames for Melville were Carl Van Doren's "The American Novel" (1921), D. H. Lawrence's "Studies in Classic American Literature" (1923), Carl Van Vechten's essay in "The Double Dealer" (1922), and Lewis Mumford's biography, "Herman Melville: A Study of His Life and Vision" (1929).
Starting in the mid-1930s, the Yale University scholar Stanley Thomas Williams supervised more than a dozen dissertations on Melville that were eventually published as books. Where the first wave of Melville scholars focused on psychology, Williams' students were prominent in establishing Melville Studies as an academic field concerned with texts and manuscripts, tracing Melville's influences and borrowings (even plagiarism), and exploring archives and local publications. Jay Leyda, known for his work in film, spent more than a decade in archives and small-town libraries gathering documents and records for a day by day record, published as "Melville Log" (1951). Sparked by Leyda, the second phase of the Melville Revival emphasized research rather than accepting Melville's early books as reliable accounts.

The postwar scholars tended to think that Weaver, Harvard psychologist Henry Murray, and Mumford favored Freudian interpretations which read Melville's fiction too literally as autobiography; exaggerated his suffering in the family; and inferred a homosexual attachment to Hawthorne. They saw a different arc to Melville's writing career. The first biographers saw a tragic withdrawal after the cold critical reception for his prose works and largely dismissed his poetry. A new view emerged of Melville's turn to poetry as a conscious choice that placed him among the most important American poets.

Other post-war studies, however, continued the broad imaginative and interpretive style. Charles Olson's "Call Me Ishmael" (1947) presented Ahab as a Shakespearean tragic hero, and Newton Arvin's critical biography, "Herman Melville" (1950) won the National Book Award for non-fiction in 1951. Hershel Parker published his two volume "Herman Melville: A Biography", in 1996 and 2002, based on extensive original research and his involvement as editor of the Northwestern-Newberry Melville edition. 

In the 1960s, Northwestern University Press, in alliance with the Newberry Library and the Modern Language Association, organized a project to edit and published reliable critical texts of Melville's complete works, including unpublished poems, journals, and correspondence. The aim of the editors was to present a text "as close as possible to the author's intention as surviving evidence permits". The volumes have extensive appendices, including textual variants from each of the editions published in Melville's lifetime, an historical note on the publishing history and critical reception, and related documents. In many cases, it was not possible to establish a "definitive text", but the edition supplies all evidence available at the time. Because the texts were prepared with financial support from the United States Department of Education, no royalties are charged, and they have been widely reprinted.

In 1945, The Melville Society was founded, a non-profit organisation dedicated to the study of Melville's life and works. Between 1969 and 2003 it published 125 issues of "Melville Society Extracts," which are now freely available on the society's website. Since 1999 it publishes "Leviathan: A Journal of Melville Studies", currently three issues a year, published by Johns Hopkins University Press.

Melville did not publish poetry until late in life, and his reputation as a poet was not high until late in the 20th century.

Melville, says recent literary critic Lawrence Buell, "is justly said to be nineteenth-century America's leading poet after Whitman and Dickinson, yet his poetry remains largely unread even by many Melvillians." True, Buell concedes, even more than most Victorian poets, Melville turned to poetry as an "instrument of meditation rather than for the sake of melody or linguistic play." It is also true that he turned from fiction to poetry late in life. Yet he wrote twice as much poetry as Dickinson and probably as many lines as Whitman, and he wrote distinguished poetry for a quarter of a century, twice as long as his career publishing prose narratives. The three novels of the 1850s which Melville worked on most seriously to present his philosophical explorations, "Moby-Dick", "Pierre", and "The Confidence Man", seem to make the step to philosophical poetry a natural one rather than simply a consequence of commercial failure.

In 2000, the Melville scholar Elizabeth Renker wrote "a sea change in the reception of the poems is incipient." Some critics now place him as the first modernist poet in the United States; others assert that his work more strongly suggests what today would be a postmodern view. Henry Chapin wrote in an introduction to "John Marr and Other Sailors (1888)", a collection of Melville's late poetry, "Melville's loveable freshness of personality is everywhere in evidence, in the voice of a true poet." The poet and novelist Robert Penn Warren was a leading champion of Melville as a great American poet. Warren issued a selection of Melville's poetry prefaced by an admiring critical essay. The poetry critic Helen Vendler remarked of "Clarel" : "What it cost Melville to write this poem makes us pause, reading it. Alone, it is enough to win him, as a poet, what he called 'the belated funeral flower of fame.'"

Melville's writings did not attract the attention of women's studies scholars of the 1970s and 1980s, though his preference for sea-going tales that involved almost only males has been of interest to scholars in men's studies and especially gay and queer studies. Melville was remarkably open in his exploration of sexuality of all sorts. For example, Alvin Sandberg claimed that the short story "The Paradise of Bachelors and the Tartarus of Maids" offers "an exploration of impotency, a portrayal of a man retreating to an all-male childhood to avoid confrontation with sexual manhood," from which the narrator engages in "congenial" digressions in heterogeneity. In line with this view, Warren Rosenberg argues the homosocial "Paradise of Bachelors" is shown to be "superficial and sterile."

David Harley Serlin observes in the second half of Melville's diptych, "The Tartarus of Maids", the narrator gives voice to the oppressed women he observes:

Issues of sexuality have been observed in other works as well. Rosenberg notes Taji, in "Mardi", and the protagonist in "Pierre" "think they are saving young 'maidens in distress' (Yillah and Isabel) out of the purest of reasons but both are also conscious of a lurking sexual motive". When Taji kills the old priest holding Yillah captive, he says,

In "Pierre," the motive of the protagonist's sacrifice for Isabel is admitted: "womanly beauty and not womanly ugliness invited him to champion the right." Rosenberg argues,

Rosenberg says that Melville fully explores the theme of sexuality in his major epic poem, "Clarel". When the narrator is separated from Ruth, with whom he has fallen in love, he is free to explore other sexual (and religious) possibilities before deciding at the end of the poem to participate in the ritualistic order represented by marriage. In the course of the poem, "he considers every form of sexual orientation – celibacy, homosexuality, hedonism, and heterosexuality – raising the same kinds of questions as when he considers Islam or Democracy."

Some passages and sections of Melville's works demonstrate his willingness to address all forms of sexuality, including the homoerotic, in his works. Commonly noted examples from "Moby-Dick" are the "marriage bed" episode involving Ishmael and Queequeg, which is interpreted as male bonding; and the "Squeeze of the Hand" chapter, describing the camaraderie of sailors' extracting spermaceti from a dead whale. Rosenberg notes that critics say that "Ahab's pursuit of the whale, which they suggest can be associated with the feminine in its shape, mystery, and in its naturalness, represents the ultimate fusion of the epistemological and sexual quest." In addition, he notes that Billy Budd's physical attractiveness is described in quasi-feminine terms: "As the Handsome Sailor, Billy Budd's position aboard the seventy-four was something analogous to that of a rustic beauty transplanted from the provinces and brought into competition with the highborn dames of the court."

Since the late 20th century, "Billy Budd" has become a central text in the field of legal scholarship known as law and literature. In the novel, Billy, a handsome and popular young sailor, is impressed from the merchant vessel "Rights of Man" to serve aboard H.M.S. "Bellipotent" in the late 1790s, during the war between Revolutionary France and Great Britain. He excites the enmity and hatred of the ship's master-at-arms, John Claggart. Claggart brings phony charges against Billy, accusing him of mutiny and other crimes, and the Captain, the Honorable Edward Fairfax Vere, brings them together for an informal inquiry. At this encounter, Billy is frustrated by his stammer, which prevents him from speaking, and strikes Claggart. The blow catches Claggart squarely on the forehead and, after a gasp or two, the master-at-arms dies.

Vere immediately convenes a court-martial, at which, after serving as sole witness and as Billy's "de facto" counsel, Vere urges the court to convict and sentence Billy to death. The trial is recounted in chapter 21, the longest chapter in the book. It has become the focus of scholarly controversy; was Captain Vere a good man trapped by bad law, or did he deliberately distort and misrepresent the applicable law to condemn Billy to death?

As early as 1839, in the juvenile sketch "Fragments from a Writing Desk," Melville explores a problem which would reappear in the short stories "Bartleby" (1853) and "Benito Cereno" (1855): the impossibility to find common ground for mutual communication. The sketch centers on the protagonist and a mute lady, leading scholar Sealts to observe: "Melville's deep concern with expression and communication evidently began early in his career."

According to scholar Nathalia Wright, Melville's characters are all preoccupied by the same intense, superhuman and eternal quest for "the absolute amidst its relative manifestations," an enterprise central to the Melville canon: "All Melville's plots describe this pursuit, and all his themes represent the delicate and shifting relationship between its truth and its illusion." It is not clear, however, what the moral and metaphysical implications of this quest are, because Melville did not distinguish between these two aspects. Throughout his life Melville struggled with and gave shape to the same set of epistemological doubts and the metaphysical issues these doubts engendered. An obsession for the limits of knowledge led to the question of God's existence and nature, the indifference of the universe, and the problem of evil.

In 1985, the New York City Herman Melville Society gathered at 104 East 26th Street to dedicate the intersection of Park Avenue south and 26th Street as Herman Melville Square. This is the street where Melville lived from 1863 to 1891 and where, among other works, he wrote "Billy Budd".

Melville's house in Lansingburgh, New York, currently (2018) houses the Lansingburgh Historical Society. In 2010, a species of extinct giant sperm whale, "Livyatan melvillei", was named in honor of Melville. The paleontologists who discovered the fossil were fans of "Moby-Dick" and dedicated their discovery to the author. Melville Hall, the Commissioned Officer's Club at the United States Merchant Marine Academy, in Kings Point, New York is named in his honor.

On August 1, 1984, as part of the Literary Arts Series, The United States Postal Service isued a 20 Cent commemorative stamp to honor Herman Melville. The setting for the first day of issue was the Whaling Museum in New Bedford, Massachusetts.





</doc>
<doc id="13624" url="https://en.wikipedia.org/wiki?curid=13624" title="High fidelity">
High fidelity

High fidelity (often shortened to hi-fi or hifi) is a term used by listeners, audiophiles and home audio enthusiasts to refer to high-quality reproduction of sound. This is in contrast to the lower quality sound produced by inexpensive audio equipment, or the inferior quality of sound reproduction that can be heard in recordings made until the late 1940s.

Ideally, high-fidelity equipment has inaudible noise and distortion, and a flat (neutral, uncolored) frequency response within the human hearing range.

Bell Laboratories began experimenting with a range of recording techniques in the early 1930s. Performances by Leopold Stokowski and the Philadelphia Orchestra were recorded in 1931 and 1932 using telephone lines between the Academy of Music in Philadelphia and the Bell labs in New Jersey. Some multitrack recordings were made on optical sound film, which led to new advances used primarily by MGM (as early as 1937) and 20th Century-Fox Film Corporation (as early as 1941). RCA Victor began recording performances by several orchestras using optical sound around 1941, resulting in higher-fidelity masters for 78-rpm discs. During the 1930s, Avery Fisher, an amateur violinist, began experimenting with audio design and acoustics. He wanted to make a radio that would sound like he was listening to a live orchestra—that would achieve high fidelity to the original sound. After World War II, Harry F. Olson conducted an experiment whereby test subjects listened to a live orchestra through a hidden variable acoustic filter. The results proved that listeners preferred high fidelity reproduction, once the noise and distortion introduced by early sound equipment was removed.

Beginning in 1948, several innovations created the conditions that made for major improvements of home-audio quality possible:


In the 1950s, audio manufacturers employed the phrase "high fidelity" as a marketing term to describe records and equipment intended to provide faithful sound reproduction. While some consumers simply interpreted "high fidelity" as fancy and expensive equipment, many found the difference in quality between "hi-fi" and the then standard AM radios and 78 rpm records readily apparent and bought 33⅓ LPs such as RCA's New Orthophonics and London's ffrr (Full Frequency Range Recording, a UK Decca system); and high-fidelity phonographs. Audiophiles paid attention to technical characteristics and bought individual components, such as separate turntables, radio tuners, preamplifiers, power amplifiers and loudspeakers. Some enthusiasts even assembled their own loudspeaker systems. In the 1950s, "hi-fi" became a generic term for home sound equipment, to some extent displacing "phonograph" and "record player".

In the late 1950s and early 1960s, the development of the Westrex single-groove stereophonic record cutterhead led to the next wave of home-audio improvement, and in common parlance "stereo" displaced "hi-fi". Records were now played on "a stereo". In the world of the audiophile, however, the concept of "high fidelity" continued to refer to the goal of highly accurate sound reproduction and to the technological resources available for approaching that goal. This period is regarded as the "Golden Age of Hi-Fi", when vacuum tube equipment manufacturers of the time produced many models considered endearing by modern audiophiles, and just before solid state (transistorized) equipment was introduced to the market, subsequently replacing tube equipment as the mainstream technology.

A popular type of system for reproducing music beginning in the 1970s was the integrated music centre—which combined a phonograph turntable, AM-FM radio tuner, tape player, preamplifier, and power amplifier in one package, often sold with its own separate, detachable or integrated speakers. These systems advertised their simplicity. The consumer did not have to select and assemble individual components, or be familiar with impedance and power ratings. Purists generally avoid referring to these systems as high fidelity, though some are capable of very good quality sound reproduction. Audiophiles in the 1970s and 1980s preferred to buy each component separately. That way, they could choose models of each component with the specifications that they desired. In the 1980s, a number of audiophile magazines became available, offering reviews of components and articles on how to choose and test speakers, amplifiers and other components.

Listening tests are used by hi-fi manufacturers, audiophile magazines and audio engineering researchers and scientists. If a listening test is done in such a way that the listener who is assessing the sound quality of a component or recording can see the components that are being used for the test (e.g., the same musical piece listened to through a tube power amplifier and a solid state amplifier), then it is possible that the listener's pre-existing biases towards or against certain components or brands could affect their judgment. To respond to this issue, researchers began to use blind tests, in which the researchers can see the components being tested, but the listeners undergoing the experiments can't. In a double-blind experiment, neither the listeners nor the researchers know who belongs to the control group and the experimental group, or which type of audio component is being used for which listening sample. Only after all the data has been recorded (and in some cases, analyzed) do the researchers learn which components or recordings were preferred by the listeners. A commonly used variant of this test is the ABX test. A subject is presented with two known samples (sample "A", the reference, and sample "B", an alternative), and one unknown sample "X," for three samples total. "X" is randomly selected from "A" and "B", and the subject identifies "X" as being either "A" or "B". Although there is no way to prove that a certain methodology is transparent, a properly conducted double-blind test can prove that a method is "not" transparent.

Scientific double-blind tests are sometimes used as part of attempts to ascertain whether certain audio components (such as expensive, exotic cables) have any subjectively perceivable effect on sound quality. Data gleaned from these double-blind tests is not accepted by some "audiophile" magazines such as "Stereophile" and "The Absolute Sound" in their evaluations of audio equipment. John Atkinson, current editor of "Stereophile", stated (in a 2005 July editorial named "Blind Tests & Bus Stops") that he once purchased a solid-state amplifier, the Quad 405, in 1978 after seeing the results from blind tests, but came to realize months later that "the magic was gone" until he replaced it with a tube amp. Robert Harley of "The Absolute Sound" wrote, in a 2008 editorial (on Issue 183), that: "...blind listening tests fundamentally distort the listening process and are worthless in determining the audibility of a certain phenomenon."

Doug Schneider, editor of the online Soundstage network, refuted this position with two editorials in 2009. He stated: "Blind tests are at the core of the decades' worth of research into loudspeaker design done at Canada's National Research Council (NRC). The NRC researchers knew that for their result to be credible within the scientific community and to have the most meaningful results, they had to eliminate bias, and blind testing was the only way to do so." Many Canadian companies such as Axiom, Energy, Mirage, Paradigm, PSB and Revel use blind testing extensively in designing their loudspeakers. Audio professional Dr. Sean Olive of Harman International shares this view.

Stereophonic sound provided a partial solution to the problem of creating the illusion of live orchestral performers by creating a phantom middle channel when the listener sits exactly in the middle of the two front loudspeakers. When the listener moves slightly to the side, however, this phantom channel disappears or is greatly reduced. An attempt to provide for the reproduction of the reverberation was tried in the 1970s through quadraphonic sound but, again, the technology at that time was insufficient for the task. Consumers did not want to pay the additional costs and space required for the marginal improvements in realism. With the rise in popularity of home theater, however, multi-channel playback systems became affordable, and many consumers were willing to tolerate the six to eight channels required in a home theater. The advances made in signal processors to synthesize an approximation of a good concert hall can now provide a somewhat more realistic illusion of listening in a concert hall.

In addition to spatial realism, the playback of music must be subjectively free from noise, such as hiss or hum, to achieve realism. The compact disc (CD) provides about 90 decibels of dynamic range, which exceeds the 80 dB dynamic range of music as normally perceived in a concert hall. Audio equipment must be able to reproduce frequencies high enough and low enough to be realistic. The human hearing range, for healthy young persons, is 20 Hz to 20,000 Hz.

"Integrated", "mini", or "lifestyle" systems (also known by the older terms "music centre" or "midi system") contain one or more sources such as a CD player, a tuner, or a cassette deck together with a preamplifier and a power amplifier in one box. Although some high-end manufacturers do produce integrated systems, such products are generally disparaged by audiophiles, who prefer to build a system from "separates" (or "components"), often with each item from a different manufacturer specialising in a particular component. This provides the most flexibility for piece-by-piece upgrades and repairs.

For slightly less flexibility in upgrades, a preamplifier and a power amplifier in one box is called an "integrated amplifier"; with a tuner, it is a "receiver". A monophonic power amplifier, which is called a "monoblock", is often used for powering a subwoofer. Other modules in the system may include components like cartridges, tonearms, hi-fi turntables, Digital Media Players, digital audio players, DVD players that play a wide variety of discs including CDs, CD recorders, MiniDisc recorders, hi-fi videocassette recorders (VCRs) and reel-to-reel tape recorders. Signal modification equipment can include equalizers and signal processors.

This modularity allows the enthusiast to spend as little or as much as they want on a component that suits their specific needs. In a system built from separates, sometimes a failure on one component still allows partial use of the rest of the system. A repair of an integrated system, though, means complete lack of use of the system. Another advantage of modularity is the ability to spend money on only a few core components at first and then later add additional components to the system. Some of the disadvantages of this approach are increased cost, complexity, and space required for the components.

In the 2000s, modern hi-fi equipment can include signal sources such as digital audio tape (DAT), digital audio broadcasting (DAB) or HD Radio tuners. Some modern hi-fi equipment can be digitally connected using fibre optic TOSLINK cables, universal serial bus (USB) ports (including one to play digital audio files), or Wi-Fi support. Another modern component is the "music server" consisting of one or more computer hard drives that hold music in the form of computer files. When the music is stored in an audio file format that is lossless such as FLAC, Monkey's Audio or WMA Lossless, the computer playback of recorded audio can serve as an audiophile-quality source for a hi-fi system.




</doc>
<doc id="13625" url="https://en.wikipedia.org/wiki?curid=13625" title="Holden">
Holden

Holden, formerly known as General Motors-Holden, is an Australian automobile importer and former automobile manufacturer with its headquarters in Port Melbourne, Victoria. The company was founded in 1856 as a saddlery manufacturer in South Australia. In 1908 it moved into the automotive field, becoming a subsidiary of the United States-based General Motors (GM) in 1931, when the company was renamed General Motors-Holden's Ltd. It was renamed Holden Ltd in 1998, and General Motors-Holden in 2005.

Holden sells the remaining stock of the locally produced range of Commodore vehicles, and imported GM models. Holden has offered badge engineered models in sharing arrangements with Chevrolet, Isuzu, Nissan, Opel, Suzuki, Toyota and Vauxhall Motors. In 2013, the vehicle lineup consisted of models from GM Korea, GM Thailand, GM in the US, and the self-developed Commodore, Caprice, and Ute. Holden also distributed the European Opel brand in Australia in 2012 until its Australian demise in mid-2013, and briefly the American Cadillac brand in 2009 until the brand's full launch was delayed indefinitely.

From 1994 to 2017, all Australian-built Holden vehicles were manufactured in Elizabeth, South Australia, and engines were produced at the Fishermans Bend plant in Melbourne. Historically, production or assembly plants were operated in all mainland states of Australia. The consolidation of final assembly at Elizabeth was completed in 1988, but some assembly operations continued at Dandenong until 1994.

General Motors assembly plants were operated in New Zealand from 1926 until 1990 by General Motors New Zealand Limited in an earlier and quite separate operation from Holden in Australia. Although Holden's involvement in exports has fluctuated since the 1950s, the declining sales of large cars in Australia led the company to look to international markets to increase profitability. From 2010 Holden incurred losses due to the strong Australian dollar, and reductions of government grants and subsidies. This led to the announcement on 11 December 2013 that Holden would cease vehicle and engine production by the end of 2017.

On 20 October 2017, the last existing vehicle plant located in Elizabeth, South Australia was closed. Holden continues solely as an importer of vehicles.

In 1852, James Alexander Holden emigrated to South Australia from Walsall, England and in 1856 established "J.A. Holden & Co", a saddlery business in Adelaide. In 1879 J A Holden’s eldest son Henry James (HJ) Holden, became a partner and effectively managed the company. In 1885, German-born H. A. Frost joined the business as a junior partner and J.A. Holden & Co became "Holden & Frost Ltd". Edward Holden, James' grandson, joined the firm in 1905 with an interest in automobiles. From there, the firm evolved through various partnerships and, in 1908, Holden & Frost moved into the business of minor repairs to car upholstery. The company began re-body older chassis using motor bodies produced by F T Hack and Co from 1914. Holden & Frost mounted the body, painted and trimmed it. The company began to produce complete motorcycle sidecar bodies after 1913. After 1917, wartime trade restrictions led the company to start full-scale production of vehicle body shells. H.J. Holden founded a new company in late 1917, and registered "Holden's Motor Body Builders Ltd" (HMBB) on 25 February 1919 specialising in car bodies and using the former F T Hack & Co facility at 400 King William Street in Adelaide before erecting a large 4 story factory on the site.

By 1923, HMBB were producing 12,000 units per year. During this time, HMBB assembled bodies for Ford Motor Company of Australia until its Geelong plant was completed. From 1924, HMBB became the exclusive supplier of car bodies for GM in Australia, with manufacturing taking place at the new Woodville plant. These bodies were made to suit a number of chassis imported from manufacturers such as Chevrolet and Dodge. In 1926 General Motors (Australia) was established with assembly plants at Newstead, Queensland; Marrickville, New South Wales; City Road, Melbourne; Birkenhead, South Australia; and Cottesloe, Western Australia using bodies produced by Holden Motor Body Builders and imported complete knock down (CKD) chassis. In 1930 alone, the still independent Woodville plant built bodies for Austin, Chrysler, DeSoto, Morris, Hillman, Humber, Hupmobile and Willys-Overland as well GM cars. The last of this line of business was the assembly of Hillman Minx sedans in 1948. The Great Depression led to a substantial downturn in production by Holden, from 34,000 units annually in 1930 to just 1,651 units one year later. In 1931 General Motors purchased Holden Motor Body Builders and merged it with General Motors (Australia) Pty Ltd to form General Motors-Holden's Ltd (GM-H). Throughout the 1920s Holden also supplied tramcars to the Melbourne & Metropolitan Tramways Board, of which several examples have been preserved in both Australia and New Zealand.

Holden's second full-scale car factory, located in Fishermans Bend (Port Melbourne), was completed in 1936, with construction beginning in 1939 on a new plant in Pagewood, New South Wales. However, World War II delayed car production with efforts shifted to the construction of vehicle bodies, field guns, aircraft and engines. Before the war ended, the Australian Government took steps to encourage an Australian automotive industry. Both GM and Ford provided studies to the Australian Government outlining the production of the first Australian-designed car. Ford's proposal was the government's first choice, but required substantial financial assistance. GM's study was ultimately chosen because of its low level of government intervention. After the war, Holden returned to producing vehicle bodies, this time for Buick, Chevrolet, Pontiac and Vauxhall. The Oldsmobile Ace was also produced from 1946 to 1948.

From here, Holden continued to pursue the goal of producing an Australian car. This involved compromise with GM, as Holden's managing director, Laurence Hartnett, favoured development of a local design, while GM preferred to see an American design as the basis for "Australia's Own Car". In the end, the design was based on a previously rejected post-war Chevrolet proposal. The Holden was launched in 1948, creating long waiting lists extending through 1949 and beyond. The name "Holden" was chosen in honour of Sir Edward Holden, the company's first chairman and grandson of J.A. Holden. Other names considered were "GeM", "Austral", "Melba", "Woomerah", "Boomerang", "Emu" and "Canbra", a phonetic spelling of Canberra. Although officially designated "48-215", the car was marketed simply as the "Holden". The unofficial usage of the name "FX" originated within Holden, referring to the updated suspension on the 48-215 of 1953.

During the 1950s, Holden dominated the Australian car market. GM invested heavily in production capacity, which allowed the company to meet increased post-war demand for motor cars. Less expensive four-cylinder cars did not offer Holden's ability to deal with rugged rural areas. 48-215 sedans were produced in parallel with the 50-2106 coupé utility from 1951; the latter was known colloquially as the "ute" and became ubiquitous in Australian rural areas as the workhorse of choice. Production of both the utility and sedan continued with minor changes until 1953, when they were replaced by the facelifted FJ model, introducing a third panel van body style. The FJ was the first major change to the Holden since its 1948 introduction. Over time it gained iconic status and remains one of Australia's most recognisable automotive symbols. A new horizontally slatted grille dominated the front-end of the FJ, which received various other trim and minor mechanical revisions. In 1954 Holden began exporting the FJ to New Zealand. Although little changed from the 48-215, marketing campaigns and price cuts kept FJ sales steady until a completely redesigned model was launched. At the 2005 Australian International Motor Show in Sydney, Holden paid homage to the FJ with the Efijy concept car.

Holden's next model, the FE, launched in 1956; offered in a new station wagon body style dubbed "Station Sedan" in the company's sales literature. In the same year Holden commenced exports to Malaya, Thailand and North Borneo. Strong sales continued in Australia, and Holden achieved a market share of more than 50 percent in 1958 with the revised FC model. This was the first Holden to be tested on the new "Holden Proving Ground" based in Lang Lang, Victoria. 1957 saw Holden's export markets grow to 17 countries, with new additions including Indonesia, Hong Kong, Singapore, Fiji, Sudan, the East Africa region and South Africa. Indonesian market cars were assembled locally by P.T. Udatin. The opening of the Dandenong, Victoria, production facility in 1956 brought further jobs; by 1959 Holden employed 19,000 workers country-wide. In 1959 complete knock down assembly began in South Africa and Indonesia.

In 1960, Holden introduced its third major new model, the FB. The car's style was inspired by 1950s Chevrolets, with tailfins and a wrap-around windshield with "dog leg" A-pillars. By the time it was introduced, many considered the appearance dated. Much of the motoring industry at the time noted that the adopted style did not translate well to the more compact Holden. The FB became the first Holden that was adapted for left-hand-drive markets, enhancing its export potential, and as such was exported to New Caledonia, New Hebrides, the Philippines, and Hawaii.
In 1960, Ford unveiled the new Falcon in Australia, only months after its introduction in the United States. To Holden's advantage, the Falcon was not durable, particularly in the front suspension, making it ill-suited for Australian conditions. In response to the Falcon, Holden introduced the facelifted EK series in 1961; the new model featured two-tone paintwork and optional "Hydramatic" automatic transmission. A restyled EJ series came in 1962, debuting the new luxury oriented Premier model. The EH update came a year later bringing the new "Red" motor, providing better performance than the previous "Grey" motor. The HD series of 1965 saw the introduction of the "Powerglide" automatic transmission. At the same time, an "X2" performance option with a more powerful version of the six-cylinder engine was made available. In 1966, the HR was introduced, including changes in the form of new front and rear styling and higher-capacity engines. More significantly, the HR fitted standard front seat belts; Holden thus became the first Australian automaker to provide the safety device as standard equipment across all models. This coincided with the completion of the production plant in Acacia Ridge, Queensland. By 1963, Holden was exporting cars to Africa, the Middle East, South-East Asia, the Pacific Islands, and the Caribbean.

Holden began assembling the compact HA series Vauxhall Viva in 1964. This was superseded by the Holden Torana in 1967, a development of the Viva ending Vauxhall production in Australia. Holden offered the LC, a Torana with new styling, in 1969 with the availability of Holden's six-cylinder engine. In the development days, the six-cylinder Torana was reserved for motor racing, but research had shown that there was a business case for such a model. The LC Torana was the first application of Holden's new three-speed "Tri-Matic" automatic transmission. This was the result of Holden's A$16.5 million transformation of the Woodville, South Australia factory for its production.
Holden's association with the manufacture of Chevrolets and Pontiacs ended in 1968, coinciding with the year of Holden's next major new model, the HK . This included Holden's first V8 engine, a Chevrolet engine imported from Canada. Models based on the HK series included an extended-length prestige model, the Brougham, and a two-door coupé, the Monaro. The mainstream Holden Special was rebranded the Kingswood, and the basic fleet model, the Standard, became the Belmont. On 3 March 1969 Alexander Rhea, managing director of General Motors-Holden's at the time, was joined by press photographers and the Federal Minister of Shipping and Transport, Ian Sinclair as the two men drove the two millionth Holden, an HK Brougham off the production line. This came just over half a decade since the one millionth car, an EJ Premier sedan rolled off the Dandenong line on 25 October 1962. Following the Chevrolet V8 fitted to the HK, the first Australian-designed and mass-produced V8, the Holden V8 engine debuted in the Hurricane concept of 1969 before fitment to facelifted HT model. This was available in two capacities: and . Late in HT production, use of the new "Tri-Matic" automatic transmission, first seen in the LC Torana was phased in as "Powerglide" stock was exhausted, but Holden's official line was that the HG of 1971 was the first full-size Holden to receive it.
Despite the arrival of serious competitors—namely, the Ford Falcon, Chrysler Valiant, and Japanese cars—in the 1960s, Holden's locally produced large six- and eight-cylinder cars remained Australia's top-selling vehicles. Sales were boosted by exporting the Kingswood sedan, station wagon, and utility body styles to Indonesia, Trinidad and Tobago, Pakistan, the Philippines, and South Africa in complete knock down form.

Holden launched the new HQ series in 1971. At this time, the company was producing all of its passenger cars in Australia, and every model was of Australian design; however, by the end of the decade, Holden was producing cars based on overseas designs. The HQ was thoroughly re-engineered, featuring a perimeter frame and semi-monocoque (unibody) construction. Other firsts included an all-coil suspension and an extended wheelbase for station wagons, while the utilities and panel vans retained the traditional coil/leaf suspension configuration. The series included the new prestige Statesman brand, which also had a longer wheelbase, replacing the Brougham. The Statesman remains noteworthy because it was not marketed as a "Holden", but rather a "Statesman".

The HQ framework led to a new generation of two-door Monaros, and, despite the introduction of the similar sized competitors, the HQ range became the top-selling Holden of all time, with 485,650 units sold in three years. 14,558 units were exported and 72,290 CKD kits were constructed. The HQ series was facelifted in 1974 with the introduction of the HJ, heralding new front panel styling and a revised rear fascia. This new bodywork was to remain, albeit with minor upgrades through the HX and HZ series. Detuned engines adhering to government emission standards were brought in with the HX series, whilst the HZ brought considerably improved road handling and comfort with the introduction of "Radial Tuned Suspension" (RTS). As a result of GM's toying with the Wankel rotary engine, as used by Mazda of Japan, an export agreement was initiated in 1975. This involved Holden exporting with powertrains, HJ, and later, HX series Premiers as the Mazda Roadpacer AP. Mazda then fitted these cars with the "13B" rotary engine and three-speed automatic transmission. Production ended in 1977, after just 840 units sold.

During the 1970s, Holden ran an advertising jingle "Football, Meat Pies, Kangaroos and Holden cars", based on the "Baseball, Hot Dogs, Apple Pies and Chevrolet" jingle used by Chevrolet in the United States. Also, development of the Torana continued in with the larger mid-sized LH series released in 1974, offered only as a four-door sedan. The LH Torana was one of the few cars worldwide engineered to accommodate four-, six-and eight-cylinder engines. This trend continued until Holden introduced the Sunbird in 1976; essentially the four-cylinder Torana with a new name. Designated LX, both the Sunbird and Torana introduced a three-door hatchback variant. A final UC update appeared in 1978. During its production run, the Torana achieved legendary racing success in Australia, achieving victories at the Mount Panorama Circuit in Bathurst, New South Wales.

In 1975, Holden introduced the compact Gemini, the Australian version of the "T-car", based on the Opel Kadett C. The Gemini was an overseas design developed jointly with Isuzu, GM's Japanese affiliate; and was powered by a 1.6-litre four-cylinder engine. Fast becoming a popular car, the Gemini rapidly attained sales leadership in its class, and the nameplate lived on until 1987.

Holden's most popular car to date, the Commodore, was introduced in 1978 as the VB. The new family car was loosely based on the Opel Rekord E body shell, but with the front from the Opel Senator grafted to accommodate the larger Holden six-cylinder and V8 engines. Initially, the Commodore maintained Holden's sales leadership in Australia. However, some of the compromises resulting from the adoption of a design intended for another market hampered the car's acceptance. In particular, it was narrower than its predecessor and its Falcon rival, making it less comfortable for three rear-seat passengers. With the abandonment of left-hand drive markets, Holden exported almost 100,000 Commodores to markets such as New Zealand, Thailand, Hong Kong, Malaysia, Indonesia, Malta and Singapore.

Holden discontinued the Torana in 1979 and the Sunbird in 1980. After the 1978 introduction of the Commodore, the Torana became the "in-between" car, surrounded by the smaller and more economical Gemini and the larger, more sophisticated Commodore. The closest successor to the Torana was the Camira, released in 1982 as Australia's version of GM's medium-sized "J-car".
The 1980s were challenging for Holden and the Australian automotive industry. The Australian Government tried to revive the industry with the Button car plan, which encouraged car makers to focus on producing fewer models at higher, more economical volumes, and to export cars. The decade opened with the shut-down of the Pagewood, New South Wales production plant and introduction of the light commercial Rodeo, sourced from Isuzu in Japan. The Rodeo was available in both two- and four-wheel drive chassis cab models with a choice of petrol and diesel powerplants. The range was updated in 1988 with the TF series, based on the Isuzu TF. Other cars sourced from Isuzu during the 1980s were the four-wheel drive Jackaroo (1981), the Shuttle (1982) van and the Piazza (1986) three-door sports hatchback. The second generation Holden Gemini from 1985 was also based on an Isuzu design, although, its manufacture was undertaken in Australia.

While GM Australia's commercial vehicle range had originally been mostly based on Bedford products, these had gradually been replaced by Isuzu products. This process began in the 1970s and by 1982 Holden's commercial vehicle arm no longer offered any Bedford products.

The new Holden WB commercial vehicles and the Statesman WB limousines were introduced in 1980. However, the designs, based on the HQ and updated HJ, HX and HZ models from the 1970s were less competitive than similar models in Ford's lineup. Thus, Holden abandoned those vehicle classes altogether in 1984. Sales of the Commodore also fell, with the effects of the 1979 energy crisis lessening, and for the first time the Commodore lost ground to the Ford Falcon. Sales in other segments also suffered when competition from Ford intensified, and other Australian manufacturers: Mitsubishi, Nissan and Toyota gained market share. When released in 1982, the Camira initially generated good sales, which later declined because buyers considered the 1.6-litre engine underpowered, and the car's build and ride quality below-average. The Camira lasted just seven years, and contributed to Holden's accumulated losses of over A$500 million by the mid-1980s.

In 1984, Holden introduced the VK Commodore, with significant styling changes from the previous VH. The Commodore was next updated in 1986 as the VL, which had new front and rear styling. Controversially, the VL was powered by the 3.0-litre Nissan "RB30" six-cylinder engine and had a Nissan-built, electronically controlled four-speed automatic transmission. Holden even went to court in 1984 to stop local motoring magazine Wheels from reporting on the matter. The engine change was necessitated by the legal requirement that all new cars sold in Australia after 1986 had to consume unleaded petrol. Because it was unfeasible to convert the existing six-cylinder engine to run on unleaded fuel, the Nissan engine was chosen as the best engine available. However, changing exchange rates doubled the cost of the engine and transmission over the life of the VL. The decision to opt for a Japanese-made transmission led to the closure of the Woodville, South Australia assembly plant. Confident by the apparent sign of turnaround, GM paid off Holden's mounted losses of A$780 million on 19 December 1986. At GM headquarters' request, Holden was then reorganised and recapitalised, separating the engine and car manufacturing divisions in the process. This involved the splitting of Holden into "Holden's Motor Company" (HMC) and "Holden's Engine Company" (HEC). For the most part, car bodies were now manufactured at Elizabeth, South Australia, with engines as before, confined to the Fishermans Bend plant in Port Melbourne, Victoria. The engine manufacturing business was successful, building four-cylinder "Family II" engines for use in cars built overseas. The final phase of the Commodore's recovery strategy involved the 1988 VN, a significantly wider model powered by the American-designed, Australian-assembled 3.8-litre Buick V6 engine.

Holden began to sell the subcompact Suzuki Swift-based Barina in 1985. The Barina was launched concurrently with the Suzuki-sourced Holden Drover, followed by the Scurry later on in 1985. In the previous year, Nissan Pulsar hatchbacks were rebadged as the Holden Astra, as a result of a deal with Nissan. This arrangement ceased in 1989 when Holden entered a new alliance with Toyota, forming a new company: United Australian Automobile Industries (UAAI). UAAI resulted in Holden selling rebadged versions of Toyota's Corolla and Camry, as the Holden Nova and Apollo respectively, with Toyota re-branding the Commodore as the Lexcen.

The company changed throughout the 1990s, increasing its Australian market share from 21 percent in 1991 to 28.2 percent in 1999. Besides manufacturing Australia's best selling car, which was exported in significant numbers, Holden continued to export many locally produced engines to power cars made elsewhere. In this decade, Holden adopted a strategy of importing cars it needed to offer a full range of competitive vehicles. During 1998, General Motors-Holden's Ltd name was shortened to "Holden Ltd".

On 26 April 1990, GM's New Zealand subsidiary Holden New Zealand announced that production at the assembly plant based in Trentham would be phased out and vehicles would be imported duty-free—this came after the 1984 closure of the Petone assembly line due to low output volumes. During the 1990s, Holden, other Australian automakers and trade unions pressured the Australian Government to halt the lowering of car import tariffs. By 1997, the federal government had already cut tariffs to 22.5 percent, from 57.5 percent ten years earlier; by 2000, a plan was formulated to reduce the tariffs to 15 percent. Holden was critical, saying that Australia's population was not large enough, and that the changes could tarnish the local industry.

Holden re-introduced its defunct Statesman title in 1990—this time under the Holden marque, as the Statesman and Caprice. For 1991, Holden updated the Statesman and Caprice with a range of improvements, including the introduction of four-wheel anti-lock brakes (ABS); although, a rear-wheel system had been standard on the Statesman Caprice from March 1976. ABS was added to the short-wheelbase Commodore range in 1992. Another returning variant was the full-size utility, and on this occasion it was based on the Commodore. The VN Commodore received a major facelift in 1993 with the VR—compared to the VN, approximately 80 percent of the car model was new. Exterior changes resulted in a smoother overall body and a "twin-kidney" grille—a Commodore styling trait that remained until the 2002 VY model and, as of 2013, remains a permanent staple on HSV variants.

Holden introduced the all-new VT Commodore in 1997, the outcome of a A$600 million development programme that spanned more than five years. The new model featured a rounded exterior body shell, improved dynamics and many firsts for an Australian-built car. Also, a stronger body structure increased crash safety. The locally produced Buick-sourced V6 engine powered the Commodore range, as did the 5.0-litre Holden V8 engine, and was replaced in 1999 by the 5.7-litre "LS" unit.

The UAAI badge-engineered cars first introduced in 1989 sold in far fewer numbers than anticipated, but the Holden Commodore, Toyota Camry, and Corolla were all successful when sold under their original nameplates. The first generation Nova and the donor Corolla were produced at Holden's Dandenong, Victoria facility until 1994. UAAI was dissolved in 1996, and Holden returned to selling only GM products. The Holden Astra and Vectra, both designed by Opel in Germany, replaced the Toyota-sourced Holden Nova and Apollo. This came after the 1994 introduction of the Opel Corsa replacing the already available Suzuki Swift as the source for the Holden Barina. Sales of the full-size Holden Suburban SUV sourced from Chevrolet commenced in 1998—lasting until 2001. Also in 1998, local assembly of the Vectra began at Elizabeth, South Australia. These cars were exported to Japan and Southeast Asia with Opel badges. However, the Vectra did not achieve sufficient sales in Australia to justify local assembly, and reverted to being fully imported in 2000.

Holden's market surge from the 1990s reversed in the 2000s decade. In Australia, Holden's market share dropped from 27.5 percent in 2000 to 15.2 percent in 2006. From March 2003, Holden no longer held the number one sales position in Australia, losing ground to Toyota.

This overall downturn affected Holden's profits; the company recorded a combined gain of A$842.9 million from 2002 to 2004, and a combined loss of A$290 million from 2005 to 2006. Factors contributing to the loss included the development of an all-new model, the strong Australian dollar and the cost of reducing the workforce at the Elizabeth plant, including the loss of 1,400 jobs after the closure of the third-shift assembly line in 2005, after two years in operation. Holden fared better in 2007, posting an A$6 million loss. This was followed by an A$70.2 million loss in the 2008, an A$210.6 million loss in 2009, and a profit of A$112 million in 2010. On 18 May 2005, "Holden Ltd" became "GM Holden Ltd", coinciding with the resettling to the new Holden headquarters on 191 Salmon Street, Port Melbourne, Victoria.

Holden caused controversy in 2005 with their Holden Employee Pricing television advertisement, which ran from October to December 2005. The campaign publicised, "for the first time ever, all Australians can enjoy the financial benefit of Holden Employee Pricing". However, this did not include a discounted dealer delivery fee and savings on factory fitted options and accessories that employees received. At the same time, employees were given a further discount of 25 to 29 percent on selected models.

Holden revived the Monaro coupe in 2001. Based on the VT Commodore architecture, the coupe attracted worldwide attention after being shown as a concept car at Australian auto shows. The VT Commodore received its first major update in 2002 with the VY series. A mildly facelifted VZ model launched in 2004, introducing the "High Feature" engine. This was built at the Fishermans Bend facility completed in 2003, with a maximum output of 900 engines per day. This has reportedly added A$5.2 billion to the Australian economy; exports account for about A$450 million alone. After the VZ, the "High Feature" engine powered the all-new Holden Commodore (VE). In contrast to previous models, the VE no longer used an Opel-sourced platform adapted both mechanically and in size, but was based on the GM Zeta platform that was earmarked to become a "Global RWD Architecture", until plans were cancelled due to the 2007/08 global financial crisis.

Throughout the 1990s, Opel had also been the source of many Holden models. To increase profitability, Holden looked to the South Korean Daewoo brand for replacements after acquiring a 44.6 percent stake—worth US$251 million—in the company in 2002 as a representative of GM. This was increased to 50.9 percent in 2005, but when GM further increased its stake to 70.1 percent around the time of its 2009 Chapter 11 reorganisation, Holden's interest was relinquished and transferred to another (undisclosed) part of GM.

The commencement of the Holden-branded Daewoo models began with the 2005 Holden Barina, which based on the Daewoo Kalos, replaced the Opel Corsa as the source of the Barina. In the same year, the Viva, based on the Daewoo Lacetti, replaced the entry-level Holden Astra Classic, although the new-generation Astra introduced in 2004 continued on. The Captiva crossover SUV came next in 2006. After discontinuing the Frontera and Jackaroo models in 2003, Holden was only left with one all-wheel drive model: the Adventra, a Commodore-based station wagon. The fourth model to be replaced with a South Korean alternative was the Vectra by the mid-size Epica in 2007. As a result of the split between GM and Isuzu, Holden lost the rights to use the "Rodeo" nameplate. Consequently, the Holden Rodeo was facelifted and relaunched as the Colorado in 2008. Following Holden's successful application for a A$149 million government grant to build a localised version of the Chevrolet Cruze in Australia from 2011, Holden in 2009 announced that it would initially import the small car unchanged from South Korea as the Holden Cruze.

Following the government grant announcement, Kevin Rudd, Australia's Prime Minister at the time, stated that production would support 600 new jobs at the Elizabeth facility; however, this failed to take into account Holden's previous announcement, whereby 600 jobs would be shed when production of the "Family II" engine ceased in late 2009. In mid-2013, Holden sought a further A$265 million, in addition to the A$275 million that was already committed by the governments of Canberra, South Australia and Victoria, to remain viable as a car manufacturer in Australia. A source close to Holden informed the "Australian" news publication that the car company is losing money on every vehicle that it produces and consequently initiated negotiations to reduce employee wages by up to A$200 per week to cut costs, following the announcement of 400 job cuts and an assembly line reduction of 65 (400 to 335) cars per day. From 2001 to 2012, Holden received over A$150 million a year in subsidy from Australian government. The subsidy from 2007 was more than Holden's capital investment of the same period. From 2004, Holden was only able to make a profit in 2010 and 2011.

In March 2012, Holden was given a $270 million lifeline by the Gillard Federal Government, Weatherill and Baillieu ministries. In return, Holden planned to inject over $1 billion into car manufacturing in Australia. They estimated the new investment package would return around $4 billion to the Australian economy and see GM Holden continue making cars in Australia until at least 2022.

Industry Minister Kim Carr confirmed on 10 July 2013 that talks had been scheduled between the Australian government and Holden. On 13 August 2013, 1,700 employees at the Elizabeth plant in northern Adelaide voted to accept a three-year wage freeze in order to decrease the chances of the production line's closure in 2016. Holden's ultimate survival, though, depended on continued negotiations with the Federal Government—to secure funding for the period from 2016 to 2022—and the final decision of the global headquarters in Detroit, US.

Following an unsuccessful attempt to secure the extra funding required from the new Liberal/National coalition government, on 11 December 2013, General Motors announced that Holden would cease engine and vehicle manufacturing operations in Australia by the end of 2017. As a result, 2,900 jobs would be lost over four years. Beyond 2017 Holden's Australian presence will consist of: a national sales company, a parts distribution centre and a global design studio.

In May 2014 GM reversed their decision to abandon the Lang Lang Proving Ground and decided to keep it as part of their engineering capability in Australia.

In 2015, Holden again began selling a range of Opel-derived cars comprising the Astra VXR and Insignia VXR (both based on the OPC models sold by Vauxhall) and Cascada. Later that year, Holden also announced plans to sell the European Astra and the Korean Cruze alongside each other from 2017.

In December 2015, Belgian entrepreneur Guido Dumarey commenced negotiations to buy the Commodore manufacturing plant in South Australia, with a view to continue producing a rebadged Zeta-based premium range of rear and all-wheel drive vehicles for local and export sales. The proposal was met with doubt in South Australia, and it later came to nothing. On 20 October 2017 Holden ceased manufacturing vehicles in Australia. Now Holden imports their cars from Opel in Germany and GM plants in Canada and USA.


On 8 May 2015 Jeff Rolfs, Holden's CFO, became interim chairman and managing director. Holden announced on 6 February 2015 that Mark Bernhard would return to Holden as chairman and managing director, the first Australian to hold the post in 25 years. In 2010 Holden sold vehicles across Australia through the Holden Dealer Network (310 authorised stores and 12 service centres), which employed more than 13,500 people.

In 1987 Holden established Holden Special Vehicles (HSV) in partnership with Tom Walkinshaw, who primarily manufactured modified, high-performance Commodore variants. To further reinforce the brand, HSV introduced the HSV Dealer Team into the V8 Supercar fold in 2005 under the naming rights of Toll HSV Dealer Team.

Holden's logo, of a lion holding a stone, was introduced in 1928. Holden's Motor Body Builders appointed Rayner Hoff to design the emblem, which refers to a fable in which observations of lions rolling stones led to the invention of the wheel. With the 1948 launch of the 48-215, Holden revised its logo. It commissioned another redesign in 1972 to better represent the company. The emblem was reworked once more in 1994.

Holden began to export vehicles in 1954, sending the FJ to New Zealand. Exports to New Zealand continued, but to broaden their export potential, Holden began to cater their Commodore, Monaro and Statesman/Caprice models for both right- and left-hand drive markets. The Middle East was Holden's largest export market, with the Commodore sold as the Chevrolet Lumina from 1998, and the Statesman from 1999 as the Chevrolet Caprice. Commodores were also sold as the Chevrolet Lumina in Brunei, Fiji and South Africa, and as the Chevrolet Omega in Brazil. Pontiac in North America also imported Commodore sedans from 2008 through to 2009 as the G8. The G8's cessation was a consequence of GM's Chapter 11 bankruptcy resulting in the demise of the Pontiac brand.

Sales of the Monaro began in 2003 to the Middle East as the Chevrolet Lumina Coupe. Later that year a modified version of the Monaro began selling in the United States (but not in Canada) as the Pontiac GTO, and under the Monaro name through Vauxhall dealerships in the United Kingdom. This arrangement continued through to 2005 when the car was discontinued. The long-wheelbase Statesman sales in the Chinese market as the Buick Royaum began in 2005, before being replaced in 2007 by the Statesman-based Buick Park Avenue. Statesman/Caprice exports to South Korea also began in 2005. These Korean models were sold as the Daewoo Statesman, and later as the Daewoo Veritas from 2008. Holden's move into international markets proved profitable; export revenue increased from A$973 million in 1999 to just under $1.3 billion in 2006.

From 2011 the WM Caprice was exported to North America as the Chevrolet Caprice PPV, a version of the Caprice built exclusively for law enforcement in North America and sold only to police. From 2007 the HSV-based Commodore was exported to the United Kingdom as the Vauxhall VXR8.

In 2013 Chevrolet announced that exports of the Commodore would resume to North America in the form of the VF Commodore as the Chevrolet SS sedan for the 2014 model year. The Chevrolet SS Sedan was also imported to the United States (but again, not to Canada) for 2015 with only minor changes, notably the addition of Magnetic Ride Control suspension and a Tremec TR-6060 manual transmission. For the 2016 model year the SS sedan received a facelift based on the VF Series II Commodore unveiled in September 2015. In 2017, production of Holden's last two American exports, the SS and the Caprice PPV was discontinued.


Whilst previously holding the number one position in Australia Vehicle sales, Holden has dropped down the leaderboard in recent years, which can be attributed to the large drop away of Commodore sales among other elements. Currently Holden as a full time importer, typically has had strong success with their Colorado and more recently, smaller success with Astra sedan, hatchback and wagon.

Holden has been involved with factory backed teams in Australian touring car racing since 1968. The main factory-backed teams have been the Holden Dealer Team (1969–1987) and the Holden Racing Team (1990–2016). Since 2017, Triple Eight Race Engineering has been Holden's factory team. Holden has won the Bathurst 1000 32 times, more than any other manufacturer, and has won the Australian Touring Car and Supercars Championship title 20 times. Brad Jones Racing, Charlie Schwerkolt Racing, Erebus Motorsport, Matt Stone Racing, Tekno Autosports and Walkinshaw Andretti United also run Holden Commodores in the series.





</doc>
<doc id="13627" url="https://en.wikipedia.org/wiki?curid=13627" title="Hank Greenberg">
Hank Greenberg

Henry Benjamin Greenberg (born Hyman Greenberg; January 1, 1911 – September 4, 1986), nicknamed "Hammerin' Hank", "Hankus Pankus", or "The Hebrew Hammer", was an American professional baseball player and team executive. He played in Major League Baseball (MLB), primarily for the Detroit Tigers as a first baseman in the 1930s and 1940s. A member of the Baseball Hall of Fame and a two-time Most Valuable Player (MVP) Award winner, he was one of the premier power hitters of his generation and is widely considered as one of the greatest sluggers in baseball history. He had 47 months of military service including service in World War II, all of which took place during his major league career.

Greenberg played the first twelve of his thirteen major league seasons for Detroit. He was an American League (AL) All-Star for four seasons and an AL MVP in 1935 (first baseman) and 1940 (left fielder). He had a batting average over .300 in eight seasons, and won two World Series championships with the Tigers ( and ). He was the AL home run leader four times and his 58 home runs for the Tigers in 1938 equaled Jimmie Foxx's 1932 mark for the most in one season by anyone but Babe Ruth, and tied Foxx for the most home runs between Ruth's record 60 in 1927 and Roger Maris' record 61 in 1961. Greenberg was the first major league player to hit 25 or more home runs in a season in each league, and remains the AL record-holder for most runs batted in in a single season by a right-handed batter (183 in 1937, a 154-game schedule). In 1947, Greenberg signed a contract for a record $85,000 salary before being sold to the Pittsburgh Pirates, where he played his final MLB season that year. After retiring from playing, Greenberg continued to work in baseball as a team executive for the Cleveland Indians and Chicago White Sox.

Greenberg was the first Jewish superstar in American team sports. He attracted national attention in 1934 when he refused to play on Yom Kippur, the holiest holiday in Judaism, even though he was not particularly observant religiously and the Tigers were in the middle of a pennant race. He was one of the few opposing players to publicly welcome African-American player Jackie Robinson to the major leagues in 1947.

Hank Greenberg was born Hyman Greenberg on January 1, 1911, in Greenwich Village, New York City, to Romanian-born Jewish immigrant parents David and Sarah Greenberg, who owned a successful cloth-shrinking plant in New York. He had two brothers, Ben, four years older, and Joe, five years younger, who also played baseball, and a sister, Lillian, two years older. His family moved to the Bronx when he was about seven.

He attended James Monroe High School in the Bronx, where he was an outstanding all-around athlete and was bestowed with the long-standing nickname of "Bruggy" by his basketball coach. His preferred sport was baseball, and his preferred position was first base. In high school basketball, he was on the Monroe team that won the city championship.

In 1929, the 18-year-old 6-foot-4-inch Greenberg was recruited by the New York Yankees, who already had Lou Gehrig at first base. Greenberg turned them down and instead attended New York University for a year, where he was a member of Sigma Alpha Mu, after which he signed with the Detroit Tigers for $9,000 ($ today).

Greenberg played minor league baseball for three years. Greenberg played 17 games in 1930 for the Hartford Senators, then played at Raleigh, North Carolina, for the Raleigh Capitals, where he hit .314 with 19 home runs. In 1931, he played at Evansville for the Evansville Hubs in the Illinois–Indiana–Iowa League (.318, 15 homers, 85 RBIs). In 1932, at Beaumont for the Beaumont Exporters in the Texas League, he hit 39 homers with 131 RBIs, won the MVP award, and led Beaumont to the Texas League title.

When he broke into the major leagues in 1930, Greenberg was the youngest MLB player (19).

In 1933, he rejoined the Tigers and hit .301 while driving in 87 runs. (a) At the same time, he was third in the league in strikeouts (78). 
(a) See note in Footnotes section below.
In 1934, his second major-league season, he hit .339 and helped the Tigers reach their first World Series in 25 years. He led the league in doubles, with 63 (the fourth-highest all-time in a single season), and extra base hits (96). He was third in the AL in slugging percentage (.600) – behind Jimmie Foxx and Lou Gehrig, but ahead of Babe Ruth, and in RBIs (139), sixth in batting average (.339), seventh in home runs (26), and ninth in on-base percentage (.404).

Late in the 1934 season, he announced that he would not play on September 10, which was Rosh Hashanah, the Jewish New Year, or on September 19, the Day of Atonement, Yom Kippur. Fans grumbled, "Rosh Hashanah comes every year but the Tigers haven't won the pennant since 1909." Greenberg did considerable soul-searching, and discussed the matter with his rabbi; finally he relented and agreed to play on Rosh Hashanah, but stuck with his decision not to play on Yom Kippur. Dramatically, Greenberg hit two home runs in a 2–1 Tigers victory over Boston on Rosh Hashanah. The next day's "Detroit Free Press" ran the Hebrew lettering for "Happy New Year" across its front page. Columnist and poet Edgar A. Guest expressed the general opinion in a poem titled "Speaking of Greenberg", in which he used the Irish (and thus Catholic) names Murphy and Mulroney. The poem ends with the lines ""We shall miss him on the infield and shall miss him at the bat / But he's true to his religion—and I honor him for that."" The complete text of the poem is at the end of Greenberg's biography page at the website of the International Jewish Sports Hall of Fame. The Detroit press was not so kind regarding the Yom Kippur decision, nor were many fans, but Greenberg in his autobiography recalled that he received a standing ovation from congregants at the Shaarey Zedek synagogue when he arrived. Absent Greenberg, the Tigers lost to the New York Yankees, 5–2. The Tigers went on to face the St. Louis Cardinals in the 1934 World Series.

In 1935 Greenberg led the league in RBIs (170), total bases (389), and extra base hits (98), tied Foxx for the AL title in home runs (36), was 2nd in the league in doubles (46), slugging percentage (.628), was 3rd in the league in triples (16), and in runs scored (121), 6th in on-base percentage (.411) and walks (87), and was 7th in batting average (.328). He was unanimously voted the American League's Most Valuable Player. At the All-Star break that season, Greenberg hit 25 home runs and set an MLB record (still standing) of 103 RBIs – but was not selected to the AL All-Star roster (both managers put themselves on the rosters but did not play). He helped lead the Tigers to their first World Series title, but sprained his wrist in the second game and did not play in the other 4 games.

In 1936, Greenberg reinjured his wrist in a collision with Jake Powell of the Washington Senators in April and did not play the remainder of the season. He finished the season with 16 hits, 1 home run, and 15 RBIs in 12 games.

In 1937, Greenberg recovered from his injury and was voted to the AL All-Star roster, but did not play. On September 19, 1937, he hit the first home run into the center field bleachers at Yankee Stadium. He led the AL by driving in 183 runs (third all-time, behind Hack Wilson in 1930 and Lou Gehrig in 1931), and in extra base hits (103), while batting .337 with 200 hits. He was second in the league in home runs (40), doubles (49), total bases (397), slugging percentage (.668), and walks (102), third in on-base percentage (.436), and seventh in batting average (.337). Greenberg came in third in the vote for MVP.

A prodigious home run hitter, Greenberg narrowly missed breaking Babe Ruth's single-season home run record in 1938, when he hit 58 home runs, leading the league for the second time. That year, he had 11 games with multiple home runs, a new major league record. Sammy Sosa tied the record in 1998. Greenberg matched what was then the single-season home run record by a right-handed batter, (Jimmie Foxx, 1932); the mark stood for 66 years until it was broken by Sammy Sosa and Mark McGwire. Greenberg also had a 59th home run washed away in a rainout. It has been long speculated that Greenberg was intentionally walked late in the season to prevent him from breaking Ruth's record, but Greenberg dismissed this speculation, calling it "crazy stories." Nonetheless, Howard Megdal has calculated that in September 1938, Greenberg was walked in over 20% of his plate appearances, the highest percentage in his career by far. Megdal's article cited this walk percentage statistic as evidence of AL teams not wanting Greenberg to break Ruth's record due to anti-Semitism. However, an examination of the box scores indicate this spike in walks was due to a few games against St. Louis Browns' pitchers with horrific control, not a general league tendency.

Greenberg was again voted to the AL All-Star roster in 1938, but because he was not named to the 1935 AL All-Star roster and was benched in the 1937 game, he declined to accept a starting position on the 1938 AL team and did not play (the NL won 4-1). He led the league in runs scored (144) and at-bats per home run (9.6), tied for the AL lead in walks (119), was second in RBIs (146), slugging percentage (.683), and total bases (380), and third in OBP (.438) and set a still-standing major league record of 39 homers in his home park, the newly reconfigured Briggs Stadium. He also set a major-league record with 11 multiple-home run games. He came in third in the vote for MVP.

In 1939 Greenberg was voted to the AL All-Star roster for the third year in a row and was a starter at first base, and singled and walked in 4 at-bats (AL won 3-1). He finished second in the AL in home runs (33) and strikeouts (95), third in doubles (42) and slugging percentage (.622), fourth in RBIs (112), sixth in walks (91), and ninth in on-base percentage (.420).

After the 1939 season ended, Greenberg was asked by general manager Jack Zeller to take a salary cut of $5,000 ($ today) as a result of his off year in power and run production. He was asked to move from first base to the outfield to accommodate Rudy York, who was one of the best young hitters of his generation; York was tried at catcher, third baseman, and outfielder and proved to be a defensive liability at each position. Greenberg in turn, demanded a $10,000 bonus if he mastered the outfield, insisting "he" was the one taking the risk in learning a new position. Greenberg received his bonus at the end of spring training.

In 1940, Greenberg switched from playing the first base position to the left field position. For the 4th consecutive time, he was voted by the season's AL All-Star team manager to the AL All-Star team. In the bottom of the 6th inning, Greenberg and Lou Finney were sent into the game to replace right fielder Charlie Keller and left fielder Ted Williams with Greenberg playing in left field and Finney in right field. Greenberg batted twice in the game and fouled out to the catcher two-times. The NL won the game 4-0. That season, he led the AL in home runs for the third time in 6 years with 41; in RBIs (150), doubles (50), total bases (384), extra base hits (99), at-bats per home run (14.0), and slugging percentage (.670; 44 points ahead of Joe DiMaggio). He was second in the league behind Williams in runs scored (129) and OBP (.433), all while batting .340 (fifth best in the AL). He also led the Tigers to the AL pennant, and won his second American League MVP award, becoming the first player in major-league history to win an MVP award at two different playing positions.

On October 16, 1940, Greenberg became the first American League player to register for the nation's first peacetime draft. In the spring of 1941, the Detroit draft board initially classified Greenberg as 4F for "flat feet" after his first physical for military service and was recommended for light duty. The rumors that he had bribed the board, and concern that he would be likened to Jack Dempsey who had received negative publicity for failure to serve in World War I, led Greenberg to request to be reexamined. On April 18, he was found fit for regular military service and was reclassified.
On May 7, 1941, he was inducted into the U.S. Army after playing left field in 19 games and reported to Fort Custer at Battle Creek, Michigan. His salary was cut from $55,000 ($ today) a year to $21 ($ today) a month. He was not bitter, and stated, "I made up my mind to go when I was called. My country comes first." In November, while serving as an anti-tank gunner, he was promoted to sergeant, but was honorably discharged on December 5 (the United States Congress released men aged 28 years and older from service), two days before Japan bombed Pearl Harbor.

Greenberg re-enlisted as a sergeant on February 1, 1942, and volunteered for service in the Army Air Forces, becoming the first major league player to do so. He graduated from Officer Candidate School and was commissioned as a first lieutenant in the Air Corps (the new "Air Forces" service retaining the old name for its own logistics and training elements) and was assigned to the Physical Education Program. In February 1944, he was sent to the U.S. Army Special Services school. Promoted to captain, he requested overseas duty later that year and served in the China-Burma-India Theater for over six months, scouting locations for B-29 bomber bases and was a physical training officer with the 58th Bomber Wing. He was a Special Services officer of the 20th Bomber Command, 20th Air Force in China when it began bombing Japan on June 15. He was ordered to New York, and in late 1944, to Richmond, Virginia. Greenberg served 47 months, the longest of any major league player.

Greenberg remained in military uniform until he was placed on the military inactive list and discharged from the U.S. Army on June 14, 1945. He was the first major league player to return to MLB after the war. He returned to the Tigers team, and in his first game back on July 1, he homered. The All-Star Game scheduled for July 10 had been officially cancelled on April 24 and MLB did not name All-Stars that season due to strict travel restrictions during the last days of the war with Germany and Japan and the ending of World War II. In place of the All-Star Game, seven interleague games were played (eight had been scheduled) on July 9 and 10 to benefit the American Red Cross and the War Relief fund. An Associated Press All-Star roster was named (no game was played) for the AL and NL by a group of their sportswriters that included Greenberg as one of the All-Stars.

Greenberg, who played left field in 72 games and batted .311 in 1945, helped lead the Tigers to a come-from-behind American League pennant, clinching it with a grand slam home run in the dark—there were no lights in Sportsman's Park in St. Louis—ninth inning of the final game of the season. The ump—former Yankee pitching star of the 1920s Murderers Row team George Pipgras—supposedly said, "Sorry Hank, but I'm gonna have to call the game. I can't see the ball." Greenberg replied, "Don't worry, George, I can see it just fine", so the game continued. It ended with Greenberg's grand slam on the next pitch, clinching Hal Newhouser's 25th victory of the season. His home run allowed the Tigers to clinch the pennant and avoid a one-game playoff (that would have been necessary without the win) against the now-second-place Washington Senators. The Tigers went on to beat the Cubs in the World Series in seven games. Only three home runs were hit in that World Series. Phil Cavarretta hit a home run for the Cubs in Game One, Greenberg hit a homer in Game Two, where he batted in three runs in a 4–1 Tigers win, and he hit a two-run homer in Game Six in the eighth inning that tied the score 8–8; the Cubs went on to win that game with a run in the bottom of the 12th.

In 1946, he returned to peak form and playing at first base. He led the AL in home runs (44) and RBIs (127), both for the fourth time. He was second in slugging percentage (.604) and total bases (316) behind Ted Williams.

In 1947, Greenberg and the Tigers had a lengthy salary dispute. When Greenberg decided to retire rather than play for less, Detroit sold his contract to the Pittsburgh Pirates. To persuade him not to retire, Pittsburgh made Greenberg the first baseball player to earn over $80,000 ($ today) in a season as pure salary (though the exact amount is a matter of some dispute). Team co-owner Bing Crosby recorded a song, "Goodbye, Mr. Ball, Goodbye" with Groucho Marx and Greenberg to celebrate Greenberg's arrival. The Pirates also reduced the size of Forbes Field's cavernous left field, renaming the section "Greenberg Gardens" to accommodate Greenberg's pull-hitting style. Greenberg played first base for the Pirates in 1947 and was one of the few opposing players to publicly welcome Jackie Robinson to the majors.
That year he also had a chance to mentor a young future Hall-of-Famer, the 24-year-old Ralph Kiner. Said Greenberg, "Ralph had a natural home run swing. All he needed was somebody to teach him the value of hard work and self-discipline. Early in the morning on off-days, every chance we got, we worked on hitting." Kiner would go on to hit 51 home runs that year to lead the National League.

In his final season of 1947, Greenberg tied for the league lead in walks with 104, with a .408 on-base percentage and finished eighth in the league in home runs and tenth in slugging percentage. Greenberg became the first major league player to hit 25 or more home runs in a season in each league. Johnny Mize became the second in 1950.

Nevertheless, Greenberg retired as a player to take a front-office post with the Cleveland Indians. No player had ever retired after a final season in which they hit so many home runs. Since then, only Ted Williams (1960, 29), Dave Kingman (1986; 35), Mark McGwire (2001; 29), Barry Bonds (2007; 28) and David Ortiz (2016; 38) have hit as many or more homers in their final season.

Through 2010, he was first in career home runs and RBIs (ahead of Shawn Green) and batting average (ahead of Ryan Braun), and fourth in hits (behind Lou Boudreau), among all-time Jewish major league baseball players.

As a fielder, the 193-cm (6-foot-4-inch) Greenberg was awkward and unsure of himself early in his career, but mastered first base through countless hours of practice. Over the course of his career he demonstrated a higher-than-average fielding percentage and range at first base. When asked to move to left field in 1940 to make room for Rudy York, he worked tirelessly to conquer that position as well, reducing his errors in the outfield from 15 in 1940 to 0 in 1945.

Greenberg felt that runs batted in were more important than home runs. He would tell his teammates, "just get on base", or "just get the runner to third", and he would do the rest.

Greenberg would likely have approached 500 home runs and 1,800 RBIs had he not served in the military. As it was, he compiled 331 home runs, 1,051 runs (b) and 1,276 RBI (c) in a 1,394-game career. (b and c, see in Footnotes section below). Greenberg also hit for average, earning a lifetime batting average of .313. Starring as a first baseman and outfielder with the Tigers (1930, 1933–46) and doing duty only briefly with the Pirates (1947), Greenberg played only nine full seasons. He missed all but 19 games of the 1941 season, the three full seasons that followed, and most of 1945 to World War II military service and missed most of another season with a broken wrist.

There are several discrepancies in Greenberg's career statistics among the major baseball websites:

After the 1947 season, Greenberg retired from the field to become the Cleveland Indians' farm system director and two years later, their General Manager and part-owner along with Bill Veeck. During his tenure, he sponsored more African American players than any other major league executive. Greenberg's contributions to the Cleveland farm system led to the team's successes throughout the 1950s, although Bill James once wrote that the Indians' late 1950s collapse should also be attributed to him. In 1949, Larry Doby also recommended Greenberg scout three players Doby used to play with in the Negro leagues: Hank Aaron, Ernie Banks, and Willie Mays. The next offseason Doby asked what Indians' scouts said about his recommendations. Said Greenberg, "Our guys checked 'em out and their reports were not good. They said that Aaron has a hitch in his swing and will never hit good pitching. Banks is too slow and didn't have enough range [at shortstop], and Mays can't hit a curveball." When Veeck sold his interest, Greenberg remained as general manager and part-owner until 1957. He was the mastermind behind a potential move of the club to Minneapolis that was vetoed by the rest of ownership at the last minute. Greenberg was furious and sold his share soon afterwards.

In 1959, Greenberg and Veeck teamed up for a second time when their syndicate purchased the Chicago White Sox; Veeck served as team president with Greenberg as vice president and general manager. During Veeck and Greenberg's first season, the White Sox won their first AL pennant since 1919. Veeck would sell his shares in the White Sox in 1961, and Greenberg stepped down as general manager on August 26 of that season.

After the 1960 season, the American League announced plans to put a team in Los Angeles. Greenberg immediately became the favorite to become the new team's first owner and persuaded Veeck to join him as his partner. However, when Dodgers owner Walter O'Malley got wind of these developments, he threatened to scuttle the whole deal by invoking his exclusive rights to operate a major league team in southern California. In truth, O'Malley wanted no part of competing against an expansion team owned by a master promoter such as Veeck, even if he was only a minority partner. Greenberg wouldn't budge and pulled out of the running for what became the Los Angeles Angels (now the Los Angeles Angels of Anaheim). Greenberg later became a successful investment banker, briefly returning to baseball as a minority partner with Veeck when the latter repurchased the White Sox in 1975.

Greenberg married Caral Gimbel (daughter of Bernard Gimbel of the Gimbel's New York department store family) on February 18, 1946, three days after signing a $60,000 ($ today) contract with the Tigers. The couple had three children—sons Glenn H. Greenberg and Stephen and a daughter, Alva—before divorcing in 1958. Their son, Stephen, played five years in the Washington Senators/Texas Rangers organization. In 1995, Stephen Greenberg co-founded Classic Sports Network with Brian Bedol, which was purchased by ESPN and became ESPN Classic. He also was the chairman of CSTV, the first cable network devoted exclusively to college sports.

Hank's grandson Spencer Greenberg is a machine learning scientist and Wall Street entrepreneur. In 1966, Greenberg married Mary Jo Tarola, a minor actress who appeared on-screen as Linda Douglas, and remained with her until his death. They had no children.



Incidents of anti-Semitism Greenberg faced included having players stare at him and having racial slurs thrown at him by spectators and sometimes opposing players. Examples of these imprecations were: "Hey Mo!" (referring to the Jewish prophet Moses) and "Throw a pork chop—he can't hit that!" (a reference to Judaic kosher laws). In the 1935 World Series umpire George Moriarty warned some Chicago Cubs players to stop yelling anti-Semitic slurs at Greenberg and eventually cleared the players from the Cubs bench. Moriarty was disciplined for this action by then-commissioner Kenesaw Mountain Landis.

Greenberg befriended Jackie Robinson after he signed with the Dodgers in 1947, and encouraged him; Robinson credited Greenberg with helping him through the difficulties of his rookie year.

Greenberg died of metastatic kidney cancer in Beverly Hills, California, in 1986, and his remains were entombed at Hillside Memorial Park Cemetery, in Culver City, California.

In an article in 1976 in "Esquire" magazine, sportswriter Harry Stein published an "All Time All-Star Argument Starter", consisting of five ethnic baseball teams. Greenberg was the first baseman on Stein's Jewish team.

In 2006, Greenberg was featured on a United States postage stamp. The stamp is one of a block of four honoring "baseball sluggers", the others being Mickey Mantle, Mel Ott, and Roy Campanella.







</doc>
<doc id="13628" url="https://en.wikipedia.org/wiki?curid=13628" title="Heinrich Schliemann">
Heinrich Schliemann

Heinrich Schliemann (; 6 January 1822 – 26 December 1890) was a German businessman and a pioneer in the field of archaeology. He was an advocate of the historicity of places mentioned in the works of Homer and an archaeological excavator of Hisarlik, now presumed to be the site of Troy, along with the Mycenaean sites Mycenae and Tiryns. His work lent weight to the idea that Homer's "Iliad" reflects historical events. Schliemann's excavation of nine levels of archaeological remains with dynamite has been criticized as destructive of significant historical artifacts, including the level that is believed to be the historical Troy.

Along with Arthur Evans, Schliemann was a pioneer in the study of Aegean civilization in the Bronze Age. The two men knew of each other, Evans having visited Schliemann's sites. Schliemann had planned to excavate at Knossos but died before fulfilling that dream. Evans bought the site and stepped in to take charge of the project, which was then still in its infancy.

Schliemann was born in Neubukow, Mecklenburg-Schwerin (part of the German Confederation), in 1822. His father, Ernst Schliemann, was a Lutheran minister. The family moved to Ankershagen in 1823 (today their home houses the "Heinrich Schliemann Museum").

Heinrich's father was a poor Pastor. His mother, Luise Therese Sophie Schliemann, died in 1831, when Heinrich was nine years old. After his mother's death, his father sent Heinrich to live with his uncle. When he was eleven years old, his father paid for him to enroll in the Gymnasium (grammar school) at Neustrelitz. Heinrich's later interest in history was initially encouraged by his father, who had schooled him in the tales of the Iliad and the Odyssey and had given him a copy of Ludwig Jerrer's "Illustrated History of the World" for Christmas in 1829. Schliemann later claimed that at the age of 7 he had declared he would one day excavate the city of Troy.

However, Heinrich had to transfer to the Realschule (vocational school) after his father was accused of embezzling church funds and had to leave that institution in 1836 when his father was no longer able to pay for it. His family's poverty made a university education impossible, so it was Schliemann's early academic experiences that influenced the course of his education as an adult. In his archaeological career, however, there was often a division between Schliemann and the educated professionals.

At age 14, after leaving Realschule, Heinrich became an apprentice at Herr Holtz's grocery in Fürstenberg. He later told that his passion for Homer was born when he heard a drunkard reciting it at the grocer's. He laboured for five years, until he was forced to leave because he burst a blood vessel lifting a heavy barrel. In 1841, Schliemann moved to Hamburg and became a cabin boy on the "Dorothea," a steamer bound for Venezuela. After twelve days at sea, the ship foundered in a gale. The survivors washed up on the shores of the Netherlands. Schliemann became a messenger, office attendant, and later, a bookkeeper in Amsterdam.

On March 1, 1844, 22-year-old Schliemann took a position with B. H. Schröder & Co., an import/export firm. In 1846, the firm sent him as a General Agent to St. Petersburg.

In time, Schliemann represented a number of companies. He learned Russian and Greek, employing a system that he used his entire life to learn languages; Schliemann claimed that it took him six weeks to learn a language and wrote his diary in the language of whatever country he happened to be in. By the end of his life, he could converse in English, French, Dutch, Spanish, Portuguese, Swedish, Polish, Italian, Greek, Latin, Russian, Arabic, and Turkish as well as German.

Schliemann's ability with languages was an important part of his career as a businessman in the importing trade. In 1850, he learned of the death of his brother, Ludwig, who had become wealthy as a speculator in the California gold fields.

Schliemann went to California in early 1851 and started a bank in Sacramento buying and reselling over a million dollars' worth of gold dust in just six months. When the local Rothschild agent complained about short-weight consignments he left California, pretending it was because of illness. While he was there, California became the 31st state in September 1850, and Schliemann acquired United States citizenship. While this story was propounded in Schliemann's autobiography of 1881, Christo Thanos and Wout Arentzen, state clearly that Schliemann was in St Petersburg that day, and "in actual fact, ...obtained his American citizenship only in 1869."

According to his memoirs, before arriving in California he dined in Washington, D.C. with President Millard Fillmore and his family, but Eric Cline says that Schliemann didn't attend but simply read about it in the papers.

Schliemann also published what he said was an eyewitness account of the San Francisco Fire of 1851, which he said was in June although it took place in May. At the time he was in Sacramento and used the report of the fire in the "Sacramento Daily Journal" to write his report.

On April 7, 1852, he sold his business and returned to Russia. There he attempted to live the life of a gentleman, which brought him into contact with Ekaterina Lyschin, the niece of one of his wealthy friends. Schliemann had previously learned that his childhood sweetheart, Minna, had married.

Heinrich and Ekaterina married on October 12, 1852. The marriage was troubled from the start.

Schliemann next cornered the market in indigo dye and then went into the indigo business itself, turning a good profit. Ekaterina and Heinrich had a son, Sergey, and two daughters, Natalya and Nadezhda, born in 1855, 1858, and 1861, respectively.

Schliemann made yet another quick fortune as a military contractor in the Crimean War, 1854–1856. He cornered the market in saltpeter, sulfur, and lead, constituents of ammunition, which he resold to the Russian government.

By 1858, Schliemann was 36 years old and wealthy enough to retire. In his memoirs, he claimed that he wished to dedicate himself to the pursuit of Troy.

As a consequence of his many travels, Schliemann was often separated from his wife and small children. He spent a month studying at the Sorbonne in 1866, while moving his assets from St. Petersburg to Paris to invest in real estate. He asked his wife to join him, but she refused.

Schliemann threatened to divorce Ekaterina twice before doing so. In 1869, he bought property and settled in Indianapolis for about three months to take advantage of Indiana's liberal divorce laws, although he obtained the divorce by lying about his residency in the U.S. and his intention to remain in the state. He moved to Athens as soon as an Indiana court granted him the divorce and married again three months later.

Schliemann's first interest of a classical nature seems to have been the location of Troy. At the time he began excavating in Turkey, the site commonly believed to be Troy was at Pınarbaşı, a hilltop at the south end of the Trojan Plain. The site had been previously excavated by archaeologist and local expert, Frank Calvert. Schliemann performed soundings at Pınarbaşı but was disappointed by his findings. It was Calvert who identified Hissarlik as Troy and suggested Schliemann dig there on land owned by Calvert's family.

In 1868, Schliemann visited sites in the Greek world, published "Ithaka, der Peloponnesus und Troja" in which he asserted that Hissarlik was the site of Troy, and submitted a dissertation in Ancient Greek proposing the same thesis to the University of Rostock. In 1869, he was awarded a PhD "in absentia" from the university of Rostock for that submission. David Traill wrote that the examiners gave him his PhD on the basis of his topographical analyses of Ithaca, which were in part simply translations of another author's work or drawn from poetic descriptions by the same author.

Schliemann was at first skeptical about the identification of Hissarlik with Troy but was persuaded by Calvert and took over Calvert's excavations on the eastern half of the Hissarlik site. The Turkish government owned the western half. Calvert became Schliemann's collaborator and partner.

Schliemann needed an assistant who was knowledgeable in matters pertaining to Greek culture. As he had divorced Ekaterina in 1869, he advertised for a wife in a newspaper in Athens. A friend, the Archbishop of Athens, suggested a relative of his, 17-year-old Sophia Engastromenos (1852–1932). Schliemann, age 47, married her in October 1869, despite the 30 year difference in age. They later had three children, Andromache, Troy, and Agamemnon Schliemann; he reluctantly allowed them to be baptized, but solemnized the ceremony in his own way by placing a copy of the "Iliad" on the children's heads and reciting 100 hexameters.

Schliemann began work on Troy in 1871. His excavations began before archaeology had developed as a professional field. Thinking that Homeric Troy must be in the lowest level, Schliemann and his workers dug hastily through the upper levels, reaching fortifications that he took to be his target. In 1872, he and Calvert fell out over this method. Schliemann was angry when Calvert published an article stating that the Trojan War period was missing from the site's archaeological record.

Schliemann was elected a member of the American Antiquarian Society in 1880.

A cache of gold and other objects appeared on or around May 27, 1873; Schliemann named it "Priam's Treasure". He later wrote that he had seen the gold glinting in the dirt and dismissed the workmen so that he and Sophia could excavate it themselves; they removed it in her shawl. However, Schliemann's oft-repeated story of the treasure's being carried by Sophia in her shawl was untrue. Schliemann later admitted fabricating it; at the time of the discovery Sophia was in fact with her family in Athens, following the death of her father. Sophia later wore "the Jewels of Helen" for the public. Those jewels, taken from the Pergamon Museum in Berlin by the Soviet Army (Red Army) in 1945, are now in the Pushkin Museum in Moscow. 

Schliemann published his findings in 1874, in "Trojanische Altertümer" ("Trojan Antiquities").

This publicity backfired when the Turkish government revoked Schliemann's permission to dig and sued him for a share of the gold. Collaborating with Calvert, Schliemann smuggled the treasure out of Turkey. He defended his "smuggling" in Turkey as an attempt to protect the items from corrupt local officials. Priam's Treasure today remains a subject of international dispute.

Schliemann published "Troja und seine Ruinen" ("Troy and Its Ruins") in 1875 and began excavation of the Treasury of Minyas at Orchomenus (Boeotia) in 1880. In 1876, he began digging at Mycenae. Upon discovering the Shaft Graves, with their skeletons and more regal gold (including the so-called Mask of Agamemnon), Schliemann cabled the king of Greece. The results were published in "Mykenai" in 1878.

Although he had received permission in 1876 to continue excavation, Schliemann did not reopen the dig site at Troy until 1878–1879, after another excavation in Ithaca designed to locate a site mentioned in the "Odyssey". This was his second excavation at Troy. Emile Burnouf and Rudolf Virchow joined him there in 1879. 

Schliemann made a third excavation at Troy in 1882–1883, an excavation of Tiryns with Wilhelm Dörpfeld in 1884, and a fourth excavation at Troy, also with Dörpfeld (who emphasized the importance of strata), in 1888–1890.

On August 1, 1890, Schliemann returned reluctantly to Athens, and in November travelled to Halle, where his chronic ear infection was operated upon, on November 13. The doctors deemed the operation a success, but his inner ear became painfully inflamed. Ignoring his doctors' advice, he left the hospital and travelled to Leipzig, Berlin, and Paris. From the latter, he planned to return to Athens in time for Christmas, but his ear condition became even worse. Too sick to make the boat ride from Naples to Greece, Schliemann remained in Naples but managed to make a journey to the ruins of Pompeii. On Christmas Day 1890, he collapsed into a coma; he died in a Naples hotel room the following day; the cause of death was cholesteatoma.

His corpse was then transported by friends to the First Cemetery in Athens. It was interred in a mausoleum shaped like a temple erected in ancient Greek style, designed by Ernst Ziller in the form of a pedimental sculpture. The frieze circling the outside of the mausoleum shows Schliemann conducting the excavations at Mycenae and other sites.

Schliemann's magnificent residence in the city centre of Athens, the "Iliou Melathron" (Ιλίου Μέλαθρον, "Palace of Ilium") houses today the Numismatic Museum of Athens.

Further excavation of the Troy site by others indicated that the level he named the Troy of the "Iliad" was inaccurate, although they retain the names given by Schliemann. In an article for "The Classical World," D.F. Easton wrote that Schliemann "was not very good at separating fact from interpretation" and claimed that, "Even in 1872 Frank Calvert could see from the pottery that Troy II had to be hundreds of years too early to be the Troy of the Trojan War, a point finally proven by the discovery of Mycenaean pottery in Troy VI in 1890."
"King Priam's Treasure" was found in the Troy II level, that of the Early Bronze Age, long before Priam's city of Troy VI or Troy VIIa in the prosperous and elaborate Mycenaean Age. Moreover, the finds were unique. The elaborate gold artifacts do not appear to belong to the Early Bronze Age.

His excavations were condemned by later archaeologists as having destroyed the main layers of the real Troy. Kenneth W. Harl, in the Teaching Company's "Great Ancient Civilizations of Asia Minor" lecture series, sarcastically claimed that Schliemann's excavations were carried out with such rough methods that he did to Troy what the Greeks could not do in their times, destroying and levelling down the entire city walls to the ground.

In 1972, Professor William Calder of the University of Colorado, speaking at a commemoration of Schliemann's birthday, claimed that he had uncovered several possible problems in Schliemann's work. Other investigators followed, such as Professor David Traill of the University of California.

An article published by the National Geographic Society called into question Schliemann's qualifications, his motives, and his methods:

Another article presented similar criticisms when reporting on a speech by University of Pennsylvania scholar C. Brian Rose:

Schliemann's methods have been described as "savage and brutal. He plowed through layers of soil and everything in them without proper record keeping—no mapping of finds, few descriptions of discoveries." Carl Blegen forgave his recklessness, saying "Although there were some regrettable blunders, those criticisms are largely colored by a comparison with modern techniques of digging; but it is only fair to remember that before 1876 very few persons, if anyone, yet really knew how excavations should properly be conducted. There was no science of archaeological investigation, and there was probably no other digger who was better than Schliemann in actual field work."

In 1874, Schliemann also initiated and sponsored the removal of medieval edifices from the Acropolis of Athens, including the great Frankish Tower. Despite considerable opposition, including from King George I of Greece, Schliemann saw the project through. The eminent historian of Frankish Greece William Miller later denounced this as "an act of vandalism unworthy of any people imbued with a sense of the continuity of history", and "pedantic barbarism".

Peter Ackroyd's novel "The Fall of Troy" (2006) is based on Schliemann's excavation of Troy. Schliemann is portrayed as "Heinrich Obermann".

Schliemann is also the subject of Chris Kuzneski's novel" The Lost Throne".

Schliemann is the subject of Irving Stone's novel "The Greek Treasure" (1975), which was the basis for the 2007 German television production "" ("Hunt for Troy").

Schliemann is a peripheral character in the historical mystery, "A Terrible Beauty". It is the 11th book in a series of novels featuring Lady Emily Hargreaves by Tasha Alexander. 







</doc>
<doc id="13629" url="https://en.wikipedia.org/wiki?curid=13629" title="Hypnos">
Hypnos

In Greek mythology, Hypnos (; , "sleep") is the personification of sleep; the Roman equivalent is known as Somnus. His name is the origin of the word hypnosis.

Hypnos is the son of Nyx ("The Night") and Erebus ("The Darkness"). His brother is Thanatos ("Death"). Both siblings live in the underworld ("Hades") or in Erebus, another valley of the Greek underworld. According to rumors, Hypnos lived in a big cave, which the river Lethe ("Forgetfulness") comes from and where night and day meet. His bed is made of ebony, on the entrance of the cave grow a number of poppies and other hypnotic plants. No light and no sound would ever enter his grotto. According to Homer, he lives on the island Lemnos, which later on has been claimed to be his very own dream-island. He is said to be a calm and gentle god, as he helps humans in need and, due to their sleep, owns half of their lives.

Hypnos lived next to his twin brother, Thanatos (Θάνατος, "death personified") in the underworld.

Hypnos' mother was Nyx (Νύξ, "Night"), the deity of Night, and his father was Erebus, the deity of Darkness. Nyx was a dreadful and powerful goddess, and even Zeus feared to enter her realm.

His wife, Pasithea, was one of the youngest of the Graces and was promised to him by Hera, who is the goddess of marriage and birth. Pasithea is the deity of hallucination or relaxation.

Hypnos used his powers to trick Zeus. Hypnos was able to trick him and help the Danaans win the Trojan war. During the war, Hera loathed her brother and husband, Zeus, so she devised a plot to trick him. She decided that in order to trick him she needed to make him so enamoured with her that he would fall for the trick. So she washed herself with ambrosia and anointed herself with oil, made especially for her to make herself impossible to resist for Zeus. She wove flowers through her hair, put on three brilliant pendants for earrings, and donned a wondrous robe. She then called for Aphrodite, the goddess of love, and asked her for a charm that would ensure that her trick would not fail. In order to procure the charm, however, she lied to Aphrodite because they sided on opposites sides of the war. She told Aphrodite that she wanted the charm to help herself and Zeus stop fighting. Aphrodite willingly agreed. Hera was almost ready to trick Zeus, but she needed the help of Hypnos, who had tricked Zeus once before.

Hera called on Hypnos and asked him to help her by putting Zeus to sleep. Hypnos was reluctant because the last time he had put the god to sleep, he was furious when he awoke. It was Hera who had asked him to trick Zeus the first time as well. She was furious that Heracles, Zeus' son, sacked the city of the Trojans. So she had Hypnos put Zeus to sleep, and set blasts of angry winds upon the sea while Heracles was still sailing home. When Zeus awoke he was furious and went on a rampage looking for Hypnos. Hypnos managed to avoid Zeus by hiding with his mother, Nyx. This made Hypnos reluctant to accept Hera's proposal and help her trick Zeus again. Hera first offered him a beautiful golden seat that can never fall apart and a footstool to go with it. He refused this first offer, remembering the last time he tricked Zeus. Hera finally got him to agree by promising that he would be married to Pasithea, one of the youngest Graces, whom he had always wanted to marry. Hypnos made her swear by the river Styx and call on gods of the underworld to be witnesses so that he would be ensured that he would marry Pasithea.

Hera went to see Zeus on Gargarus, the topmost peak of Mount Ida. Zeus was extremely taken by her and suspected nothing as Hypnos was shrouded in a thick mist and hidden upon a pine tree that was close to where Hera and Zeus were talking. Zeus asked Hera what she was doing there and why she had come from Olympus, and she told him the same lie she told Aphrodite. She told him that she wanted to go help her parent stop quarrelling and she stopped there to consult him because she didn't want to go without his knowledge and have him be angry with her when he found out. Zeus said that she could go any time, and that she should postpone her visit and stay there with him so they could enjoy each other's company. He told her that he was never in love with anyone as much as he loved her at that moment. He took her in his embrace and Hypnos went to work putting him to sleep, with Hera in his arms. While this went on, Hypnos travelled to the ships of the Achaeans to tell Poseidon, God of the Sea, that he could now help the Danaans and give them a victory while Zeus was sleeping. This is where Hypnos leaves the story, leaving Poseidon eager to help the Danaans. Thanks to Hypnos helping to trick Zeus, the war changed its course to Hera's favour, and Zeus never found out that Hypnos had tricked him one more time.

According to a passage in "Deipnosophistae", the sophist and dithyrambic poet Licymnius of Chios tells a different tale about the Endymion myth, in which Hypnos, in awe of his beauty, causes him to sleep with his eyes open, so he can fully admire his face.

Hypnos appears in numerous works of art, most of which are vases. An example of one vase that Hypnos is featured on is called "Ariadne Abandoned by Theseus," which is part of the Museum of Fine Arts in Boston’s collection. In this vase, Hypnos is shown as a winged god dripping Lethean water upon the head of Ariadne as she sleeps. One of the most famous works of art featuring Hypnos is a bronze head of Hypnos himself, now kept in the British Museum in London. This bronze head has wings sprouting from his temples and the hair is elaborately arranged, some tying in knots and some hanging freely from his head.

The English word "hypnosis" is derived from his name, referring to the fact that when hypnotized, a person is put into a sleep-like state (hypnos "sleep" + -osis "condition"). The class of medicines known as "hypnotics" which induce sleep also take their name from Hypnos.

Additionally, the English word "insomnia" comes from the name of his Latin counterpart, Somnus. (in- "not" + somnus "sleep"), as well as a few less-common words such as "somnolent", meaning sleepy or tending to cause sleep and hypersomnia meaning excessive sleep, which can be caused by many conditions (known as secondary hypersomnia) or a rare sleep disorder causing excessive sleep with unknown cause, called Idiopathic Hypersomnia.


3D model of "Bronze head of Hypnos" via laser scan of a cast of British Museum's bronze.


</doc>
<doc id="13631" url="https://en.wikipedia.org/wiki?curid=13631" title="Holy orders">
Holy orders

In the Christian churches, holy orders are ordained ministries such as bishop, priest, or deacon, and the sacrament or rite by which candidates are ordained to those orders. Churches recognizing these orders include the Catholic Church, the Eastern Orthodox (ιερωσύνη ["hierōsynē"], ιεράτευμα ["hierateuma"], Священство ["Svyashchenstvo"]), Oriental Orthodox, Anglican, Assyrian, Old Catholic, Independent Catholic and some Lutheran churches. Except for Lutherans and some Anglicans, these churches regard ordination as a sacrament (the "sacramentum ordinis"). The Anglo-Catholic tradition within Anglicanism identifies more with the Roman Catholic position about the sacramental nature of ordination.

Denominations have varied conceptions of holy orders. In the Anglican churches and some Lutheran churches the traditional orders of bishop, priest and deacon are bestowed using ordination rites. The extent to which ordination is considered sacramental in these traditions has, however, been a matter of some internal dispute. Baptists are among the denominations that do not consider ministry as being sacramental in nature and would not think of it in terms of "holy orders" as such. Historically, the word "order" (Latin "ordo") designated an established civil body or corporation with a hierarchy, and "ordinatio" meant legal incorporation into an "ordo". The word "holy" refers to the Church. In context, therefore, a holy order is set apart for ministry in the Church. Other positions, such as pope, patriarch, cardinal, monsignor, archbishop, archimandrite, archpriest, protopresbyter, hieromonk, protodeacon and archdeacon, are not sacramental orders but specialized ministries.

The Eastern Orthodox Church considers ordination (known as "Cheirotonia", "laying on of hands") to be a Sacred Mystery (what in the West is called a sacrament). Although all other mysteries may be performed by a presbyter, ordination may only be conferred by a bishop, and ordination of a bishop may only be performed by several bishops together. Cheirotonia always takes place during the Divine Liturgy.

It was the mission of the Apostles to go forth into all the world and preach the Gospel, baptizing those who believed in the name of the Holy Trinity (). In the Early Church those who presided over congregations were referred to variously as "episcopos" (bishop) or "presbyteros" (priest). These successors of the Apostles were ordained to their office by the laying on of hands, and according to Orthodox theology formed a living, organic link with the Apostles, and through them with Jesus Christ himself. This link is believed to continue in unbroken succession to this day. Over time, the ministry of bishops (who hold the fullness of the priesthood) and presbyters or priests (who hold a portion of the priesthood as bestowed by their bishop) came to be distinguished. In Orthodox terminology, "priesthood" or "sacerdotal" refers to the ministry of bishops and priests.

The Eastern Orthodox Church also has ordination to minor orders (known as "cheirothesia", "imposition of hands") which is performed outside of the Divine Liturgy, typically by a bishop, although certain archimandrites of stavropegial monasteries may bestow cheirothesia on members of their communities.

A bishop is the collector of the money of the diocese and the living Vessel of Grace through whom the "energeia" (divine grace) of the Holy Spirit flows into the rest of the church. A bishop is consecrated through the laying on of hands by several bishops. (With the consent of several other bishops, a single bishop has performed the ordination of another bishop in emergency situations, such as times of persecution), The consecration of a bishop takes place near the beginning of the Liturgy, since a bishop can, in addition to performing the Mystery of the Eucharist, also ordain priests and deacons. Before the commencement of the Holy Liturgy, the bishop-elect professes, in the middle of the church before the seated bishops who will consecrate him, in detail the doctrines of the Orthodox Christian Faith and pledges to observe the canons of the Apostles and Councils, the Typikon and customs of the Orthodox Church and to obey ecclesiastical authority. After the Little Entrance, the arch-priest and arch-deacon conduct the bishop-elect before the Royal Gates where he is met by the bishops and kneels before the altar on both knees. The Gospel Book is laid over his head and the consecrating bishops lay their hands upon the Gospel Book, while the prayers of ordination are read by the eldest bishop. After this, the newly consecrated bishop ascends the "synthranon" (bishop's throne in the sanctuary) for the first time. Customarily, the newly consecrated bishop ordains a priest and a deacon at the Liturgy during which he is consecrated.

A priest may serve only at the pleasure of his bishop. A bishop bestows faculties (permission to minister within his diocese) giving a priest chrism and an antimins; he may withdraw faculties and demand the return of these items. The ordination of a priest occurs before the Anaphora (Eucharistic Prayer) in order that he may on the same day take part in the celebration of the Eucharist: During the Great Entrance, the candidate for ordination carries the Aër (chalice veil) over his head (rather than on his shoulder, as a deacon otherwise carries it then) as a symbol of giving up his diaconate, and comes last in the procession and stands at the end of the pair of lines of the priests. After the Aër is taken from the candidate to cover the chalice and diskos, a chair is brought for the bishop to sit on by the northeast corner of the Holy Table (altar). Two deacons go to priest-elect who, at that point, had been standing alone in the middle of the church, and bow him down to the west (to the people) and to the east (to the clergy), asking their consent by saying “Command ye!” and then lead him through the holy doors of the altar where the archdeacon asks the bishop’s consent, saying, “Command, most sacred master!” after which a priest escorts the candidate three times around the Holy Table, during which he kisses each corner of the Holy Table as well as the bishop's epigonation and right hand and prostrates himself before the holy table at each circuit. The candidate is then taken to the southeast corner of the Holy Table and kneels on both knees, resting his forehead on the edge of the Holy Table. The ordaining bishop then places his omophor and right hand over the ordinand's head and recites aloud the first "Prayer of Cheirotonia" and then prays silently the other two prayers of cheirotonia while a deacon quietly recites a litany and the clergy, then the congregation, chant “Lord, have mercy”. Afterwards, the bishop brings the newly ordained priest to stand in the Holy Doors and presents him to the faithful. He then clothes the priest in each of his sacerdotal vestments, at each of which the people sing, "Worthy!". Later, after the Epiklesis of the Liturgy, the bishop hands him a portion of the Lamb (Host) saying:
A deacon may not perform any Sacrament and performs no liturgical services on his own but serves only as an assistant to a priest and may not even vest without the blessing of a priest. The ordination of a deacon occurs after the Anaphora (Eucharistic Prayer) since his role is not in performing the Holy Mystery but consists only in serving; the ceremony is much the same as at the ordination of a priest, but the deacon-elect is presented to the people and escorted to the holy doors by two sub-deacons (his peers, analogous to the two deacons who so present a priest-elect) is escorted three times around the Holy Table by a deacon, and he kneels on only one knee during the "Prayer of Cheirotonia". After being vested as a deacon and given a "liturgical fan (ripidion or hexapterygion)", he is led to the side of the Holy Table where he uses the ripidion to gently fan the Holy Gifts (consecrated Body and Blood of Christ).

The Anglican churches hold their bishops to be in apostolic succession, although there is some difference of opinion with regard to whether ordination is to be regarded as a sacrament. The Anglican Articles of Religion hold that only Baptism and the Lord's Supper are to be counted as sacraments of the gospel, and assert that other rites "commonly called Sacraments", considered to be sacraments by such as the Roman Catholic and Eastern churches, were not ordained by Christ in the Gospel. They do not have the nature of a sacrament of the gospel in the absence of any physical matter such as the water in Baptism and the bread and wine in the Eucharist. The Book of Common Prayer provides rites for ordination of bishops, priests and deacons. Only bishops may ordain. Within Anglicanism, three bishops are normally required for ordination to the episcopate, while one bishop is sufficient for performing ordinations to the priesthood and diaconate.

Lutherans reject the Roman Catholic understanding of holy orders because they do not think sacerdotalism is supported by the Bible. Martin Luther taught that each individual was expected to fulfill his God-appointed task in everyday life. The modern usage of the term vocation as a life-task was first employed by Martin Luther. In Luther's Small Catechism, the holy orders include but are not limited to the following: bishops, pastors, preachers, governmental offices, citizens, husbands, wives, children, employees, employers, young people, and widows. However, also according to the Book of Concord: "But if ordination be understood as applying to the ministry of the Word, we are not unwilling to call ordination a sacrament. For the ministry of the Word has God's command and glorious promises, Rom. 1:16: The Gospel is the power of God unto salvation to every one that believeth. Likewise, Isa. 55:11: So shall My Word be that goeth forth out of My mouth; it shall not return unto Me void, but it shall accomplish that which I please. 12.] If ordination be understood in this way, neither will we refuse to call the imposition of hands a sacrament. For the Church has the command to appoint ministers, which should be most pleasing to us, because we know that God approves this ministry, and is present in the ministry [that God will preach and work through men and those who have been chosen by men]."

The ministerial orders of the Catholic Church include the orders of bishops, deacons and presbyters, which in Latin is "sacerdos". The ordained priesthood and common priesthood (or priesthood of the all the baptized) are different in function and essence.

A distinction is made between "priest" and "presbyter". In the 1983 Code of Canon Law, "The Latin words "sacerdos" and "sacerdotium" are used to refer in general to the ministerial priesthood shared by bishops and presbyters. The words "presbyter, presbyterium and presbyteratus" refer to priests [in the English use of the word] and presbyters".

While the consecrated life is neither clerical nor lay by definition, clerics can be members of institutes of consecrated or secular (diocesan) life.

The sequence in which holy orders are received are: minor orders, deacon, priest, bishop.

For Catholics, it is typical in the year of seminary training that a man will be ordained to the diaconate, which Catholics since the Second Vatican Council sometimes call the "transitional diaconate" to distinguish men bound for priesthood from permanent deacons. They are licensed to preach sermons (under certain circumstances a permanent deacon may not receive faculties to preach), to perform baptisms, and to witness Catholic marriages, but to perform no other sacraments. They assist at the Eucharist or the Mass, but are not able to consecrate the bread and wine. Normally, after six months or more as a transitional deacon, a man will be ordained to the priesthood. Priests are able to preach, perform baptisms, confirm (with special dispensation from their ordinary), witness marriages, hear confessions and give absolutions, anoint the sick, and celebrate the Eucharist or the Mass.

Orthodox seminarians are typically tonsured as readers before entering seminary, and may later be made subdeacons or deacons; customs vary between seminaries and between Orthodox jurisdictions. Some deacons remain permanently in the diaconate while most subsequently are ordained as priests. Orthodox clergy are typically either married or monastic. Monastic deacons are called hierodeacons, monastic priests are called hieromonks. Orthodox clergy who marry must do so prior to ordination to the subdiaconate (or diaconate, according to local custom) and typically one is either tonsured a monk or married before ordination. A deacon or priest may not marry, or remarry if widowed, without abandoning his clerical office. Often, widowed priests take monastic vows. Orthodox bishops are always monks; a single or widowed man may be elected a bishop but he must be tonsured a monk before consecration as a bishop.

For Anglicans, a person is usually ordained a deacon once he (or she) has completed training at a theological college. The historic practice of a bishop tutoring a candidate himself ("reading for orders") is still to be found. The candidate then typically serves as an assistant curate and may later be ordained as a priest at the discretion of the bishop. Other deacons may choose to remain in this order. Anglican deacons can preach sermons, perform baptisms and conduct funerals, but, unlike priests, cannot celebrate the Eucharist. In most branches of the Anglican church, women can be ordained as priests, and in some of them, can also be ordained bishops.

Bishops are chosen from among priests in churches that adhere to Catholic usage.
In the Roman Catholic Church, bishops, like priests, are celibate and thus unmarried; further, a bishop is said to possess the fullness of the sacrament of holy orders, empowering him to ordain deacons, priests, and – with papal consent – other bishops. If a bishop, especially one acting as an ordinary – a head of a diocese or archdiocese – is to be ordained, three bishops must usually co-consecrate him with one bishop, usually an archbishop or the bishop of the place, being the chief consecrating prelate.

Among Eastern Rite Catholic and Eastern Orthodox churches, which permit married priests, bishops must either be unmarried or agree to abstain from contact with their wives. It is a common misconception that all such bishops come from religious orders; while this is generally true, it is not an absolute rule. In the case of both Catholics – (Western and) Eastern Catholic, Oriental Orthodox and Eastern Orthodox, they are usually leaders of territorial units called dioceses (or its equivalent in the east, an eparchy). Only bishops can validly administer the sacrament of holy orders.

The Roman Catholic Church unconditionally recognizes the validity of ordinations in the Eastern churches. Some Eastern Orthodox churches reordain Catholic priests who convert while others accept their Roman Catholic ordination using the concept of economia (church economy).

Anglican churches claim to have maintained apostolic succession. The succession of Anglican bishops is not universally recognized, however. The Roman Catholic Church judged Anglican orders invalid when Pope Leo XIII in 1896 wrote in "Apostolicae curae" that Anglican orders lack validity because the rite by which priests were ordained was not correctly worded from 1547 to 1553 and from 1559 to the time of Archbishop William Laud (Archbishop of Canterbury 1633–1645). The papacy claimed the form and matter was inadequate to make a Catholic bishop. The actual "mechanical" succession, prayer and laying on hands was not disputed. Two of the four consecrators of Matthew Parker in 1559 had been consecrated using the English Ordinal and two using the Roman Pontifical. Nonetheless, they believed that this caused a break of continuity in apostolic succession, making all further ordinations null and void.

Eastern Orthodox bishops have, on occasion, granted "economy" when Anglican priests convert to Orthodoxy. Various Orthodox churches have also declared Anglican orders valid subject to a finding that the bishops in question did indeed maintain the true faith, the Orthodox concept of apostolic succession being one in which the faith must be properly adhered to and transmitted, not simply that the ceremony by which a man is made a bishop is conducted correctly.

Changes in the Anglican Ordinal since King Edward VI, and a fuller appreciation of the pre-Reformation ordinals, suggest that the correctness of the enduring dismissal of Anglican orders is questionable. To reduce doubt concerning Anglican apostolic succession, especially since the 1930 Bonn agreement between the Anglican and Old Catholic churches, some Anglican bishops have included among their consecrators bishops of the Old Catholic Church, whose holy orders are recognised as valid and regular by the Roman Catholic Church.

Neither Roman Catholics nor Anglicans recognize the validity of ordinations of ministers in Protestant churches that do not maintain apostolic succession; but some Anglicans, especially Low Church or Evangelical ones, commonly treat Protestant ministers and their sacraments as valid. Rome also does not recognize the apostolic succession of those Lutheran bodies which retained apostolic succession.

Officially, the Anglican Communion accepts the ordinations of those denominations which are in full communion with their own churches, such as the Lutheran state churches of Scandinavia. Those clergy may preside at services requiring a priest if one is not otherwise available.

The rules discussed in this section are not considered to be among the infallible dogmas of the Catholic Church, but are mutable rules of discipline. See clerical celibacy for a more detailed discussion.

Married men may be ordained to the diaconate as Permanent Deacons, but in the Latin Rite of the Roman Catholic Church generally may not be ordained to the priesthood. In the Eastern Catholic Churches and in the Eastern Orthodox Church, married deacons may be ordained priests but may not become bishops. Bishops in the Eastern Rites and the Eastern Orthodox churches are almost always drawn from among monks, who have taken a vow of celibacy. They may be widowers, though; it is not required of them never to have been married.

In some cases, widowed permanent deacons have been ordained to the priesthood. There have been some situations in which men previously married and ordained to the priesthood in an Anglican church or in a Lutheran church have been ordained to the Catholic priesthood and allowed to function much as an Eastern Rite priest but in a Latin Rite setting. This is never "sub conditione" (conditionally), as there is in Catholic canon law no true priesthood in Protestant denominations. Such ordination may only happen with the approval of the priest's Bishop and a special permission by the Pope.

Anglican clergy may be married or may marry after ordination. In the Old Catholic Church and the Independent Catholic Churches there are no ordination restrictions related to marriage.

Ordination ritual and procedures vary by denomination. Different churches and denominations specify more or less rigorous requirements for entering into office, and the process of ordination is likewise given more or less ceremonial pomp depending on the group. Many Protestants still communicate authority and ordain to office by having the existing overseers physically lay hands on the candidates for office.

The American Methodist model is an episcopal system loosely based on the Anglican model, as the Methodist Church arose from the Anglican Church. It was first devised under the leadership of Bishops Thomas Coke and Francis Asbury of the Methodist Episcopal Church in the late 18th century. In this approach, an elder (or "presbyter") is ordained to word (preaching and teaching), sacrament (administering Baptism and the Lord's Supper), order (administering the life of the church and, in the case of bishops, ordaining others for mission and ministry), and service. A deacon is a person ordained only to word and service.

In the United Methodist Church, for instance, seminary graduates are examined and approved by the Conference Board of Ordained Ministry and then the Clergy Session. They are accepted as "probationary (provisional) members of the conference." The resident bishop may commission them to full-time ministry as "provisional" ministers. (Before 1996, the graduate was ordained as a transitional deacon at this point, a provisional role since eliminated. The order of deacon is now a separate and distinct clergy order in the United Methodist Church.) After serving the probationary period, of a minimum of two years, the probationer is then examined again and either continued on probation, discontinued altogether, or approved for ordination. Upon final approval by the Clergy Session of the Conference, the probationer becomes a full member of the Conference and is then ordained as an elder or deacon by the resident Bishop. Those ordained as elders are members of the Order of Elders, and those ordained deacons are members of the Order of Deacons.

The British Methodist Conference has two distinct orders of presbyter and deacon. It does not have bishops as a separate order of ministry.

John Wesley appointed Thomas Coke (above mentioned as bishop) as 'Superintendent', his translation of the Greek 'episcopos' – which is normally translated 'bishop' in English. The British Methodist Church has more than 500 Superintendents who are not a separate order of ministry but a role within the order of Presbyters.

In British Methodism the roles normally undertaken by bishops are expressed in ordaining presbyters and deacons by the annual Conference through its President (or a past president); in confirmation by all presbyters; in local oversight by Superintendents and in regional oversight by Chairs of District.

Presbyterian churches, following their Scottish forebears, reject the traditions surrounding overseers and instead identify the offices of bishop ("episkopos" in Greek) and elder ("presbuteros" in Greek, from which the term "presbyterian" comes). The two terms seem to be used interchangeably in the Bible (compare Titus 1.5–9 and I Tim. 3.2–7). Their form of church governance is known as presbyterian polity. While there is increasing authority with each level of gathering of elders ('Session' over a congregation or parish, then presbytery, then possibly a synod, then the General Assembly), there is no hierarchy of elders. Each elder has an equal vote at the court on which they stand.

Elders are usually chosen at their local level, either elected by the congregation and approved by the Session, or appointed directly by the Session. Some churches place limits on the term that the elders serve, while others ordain elders for life.

Presbyterians also ordain (by laying on of hands) ministers of Word and Sacrament (sometimes known as 'teaching elders'). These ministers are regarded simply as Presbyters ordained to a different function, but in practice they provide the leadership for local Session.

Some Presbyterians identify those appointed (by the laying on of hands) to serve in practical ways (Acts 6.1–7) as deacons ("diakonos" in Greek, meaning "servant"). In many congregations, a group of men or women is thus set aside to deal with matters such as congregational fabric and finance, releasing elders for more 'spiritual' work. These persons may be known as 'deacons', 'board members' or 'managers', depending on the local tradition. Unlike elders and minister, they are not usually 'ordained', and are often elected by the congregation for a set period of time.

Other Presbyterians have used an 'order of deacons' as full-time servants of the wider Church. Unlike ministers, they do not administer sacraments or routinely preach. The Church of Scotland has recently begun ordaining deacons to this role.

Unlike the Episcopalian system, but similar to the United Methodist system described above, the two Presbyterian offices are different in "kind" rather than in "degree", since one need not be a deacon before becoming an elder. Since there is no hierarchy, the two offices do not make up an "order" in the technical sense, but the terminology of holy orders is sometimes still developed.

Congregationalist churches implement different schemes, but the officers usually have less authority than in the presbyterian or episcopalian forms. Some ordain only ministers and rotate members on an advisory board (sometimes called a board of elders or a board of deacons). Because the positions are by comparison less powerful, there is usually less rigor or fanfare in how officers are ordained.

The Church of Jesus Christ of Latter-day Saints (LDS Church) accepts the legal authority of clergy to perform marriages but does not recognize any other sacraments performed by ministers not ordained to the Latter-day Saint priesthood. Although the Latter-day Saints do claim a doctrine of a certain spiritual "apostolic succession," it is significantly different from that claimed by Catholics and Protestants since there is no succession or continuity between the first century and the lifetime of Joseph Smith, the founder of the LDS church. Mormons teach that the priesthood was lost in ancient times not to be restored by Christ until the nineteenth century when it was given to Joseph Smith directly.

The Church of Jesus Christ of Latter-day Saints has a relatively open priesthood, ordaining nearly all worthy adult males and boys of the age of twelve and older. Latter-day Saint priesthood consists of two divisions: the Melchizedek Priesthood and Aaronic Priesthood. The Melchizedek Priesthood because Melchizedek was such a great high priest. Before his day it was called the Holy Priesthood, after the Order of the Son of God. But out of respect or reverence to the name of the Supreme Being, to avoid the too frequent repetition of his name, the church, in ancient days, called that priesthood after Melchizedek. The lesser priesthood is an appendage to the Melchizedek Priesthood. It is called the Aaronic Priesthood because it was conferred on Aaron and his sons throughout all their generations.
The offices, or ranks, of the Melchizedek order (in roughly descending order) include apostle, seventy, patriarch, high priest, and elder. The offices of the Aaronic order are bishop, priest, teacher, and deacon. The manner of ordination consists of the laying on of hands by two or more men holding at least the office being conferred while one acts as voice in conferring the priesthood or office and usually pronounces a blessing upon the recipient. Teachers and deacons do not have the authority to ordain others to the priesthood. All church members are authorized to teach and preach regardless of priesthood ordination so long as they maintain good standing within the church. The church does not use the term "holy orders."

Community of Christ has a largely volunteer priesthood, and all members of the priesthood are free to marry (as traditionally defined by the Christian community). The priesthood is divided into two orders, the Aaronic priesthood and the Melchisedec priesthood. The Aaronic order consists of the offices of deacon, teacher and priest. The Melchisedec Order consists of the offices of elder (including the specialized office of seventy) and high priest (including the specialized offices of evangelist, bishop, apostle, & prophet). Paid ministers include “appointees” and the general officers of the church, which include some specialized priesthood offices (such as the office of president, reserved for the three top members of the church leadership team). As of 1984, women have been eligible for priesthood, which is conferred through the sacrament of ordination by the laying-on-of-hands. While there is technically no age requirement for any office of priesthood, there is no automatic ordination or progression as in the LDS Church. Young people are occasionally ordained as deacon, and sometimes teacher or priest, but generally most priesthood members are called following completion of post secondary school education. In March 2007 a woman was ordained for the first time to the office of president.

The Roman Catholic Church, in accordance with its understanding of the theological tradition on the issue, and the definitive clarification found in the encyclical letter "Ordinatio Sacerdotalis" (1994) written by Pope John Paul II, officially teaches that it has no authority to ordain female as priests and thus there is no possibility of women becoming priests at any time in the future. "Ordaining" women as deaconesses is not a possibility in any sacramental sense of the diaconate, for a deaconess is not simply a female who is a deacon but instead holds a position of lay service. As such, she does not receive the sacrament of holy orders. Many Anglican and Protestant churches ordain women, but in many cases, only to the office of deacon.

Various branches of the Orthodox churches, including the Greek Orthodox, currently set aside wow s deaconesses. Some churches are internally divided on whether the Scriptures permit the ordination of female. When one considers the relative size of the churches (1.1 billion Roman Catholics, 300 million Orthodox, 590 million Anglicans and Protestants), it is a minority of Christian churches that ordain women. Protestants constitute about 27 percent of Christians worldwide, and most of their churches that do ordain women have only done so within the past century.

In some traditions women may be ordained to the same orders as men. In others femen are restricted from certain offices. Females may be ordained bishop in the Old Catholic churches and in the Anglican/Episcopal churches in Scotland, Ireland, Wales, Cuba, Brazil, South Africa, Canada, US, Australia, Aotearoa New Zealand and Polynesia. The Church of Ireland had installed Pat Storey in 2013. On 19 September 2013, Storey was chosen by the House of Bishops to succeed Richard Clarke as Bishop of Meath and Kildare. She was consecrated to the episcopate at Christ Church Cathedral, Dublin, on 30 November 2013. She is the first woman to be elected as a bishop in the Church of Ireland and the first females to be an Anglican Communion bishop in Ireland and Great Britain. The Church of England's General Synod voted in 2014 to allow females to be ordained to the episcopate, dwith Libby Lane being the first woman to be ordained bishop. Continuing Anglican churches of the world do not permit women to be ordained. In some Protestant denominations, female may serve as assistant pastors but not as pastors in charge of congregations. In some denominations, females can be ordained to be an elder or deacon. Some denominations allow for the ordination of females for certain religious orders. Within certain traditions, such as the Anglican and Lutheran, there is a diversity of theology and practice regarding ordination of women and females

The ordination of lesbian, gay, bisexual or transgender clergy who are sexually active, and open about it, represents a fiercely contested subject within many mainline Protestant communities. The majority of churches are opposed to such ordinations because they view homosexuality as incompatible with Biblical teaching and traditional Christian practice. Yet there are an increasing number of Christian congregations and communities that are open to ordaining people who are gay or lesbian. These are liberal Protestant denominations, such as the Episcopal Church the United Church of Christ, and the Evangelical Lutheran Church in America, plus the small Metropolitan Community Church, founded as a church intending to minister primarily to LGBT people, and the Church of Sweden where such clergy may serve in senior clerical positions.

The issue of ordination has caused particular controversy in the worldwide Anglican Communion, following the approval of Gene Robinson to be Bishop of New Hampshire in the US Episcopal Church.





</doc>
<doc id="13633" url="https://en.wikipedia.org/wiki?curid=13633" title="Homer">
Homer

Homer (; , "Hómēros") is the legendary author of the "Iliad" and the "Odyssey", two epic poems that are the central works of ancient Greek literature. The "Iliad" is set during the Trojan War, the ten-year siege of the city of Troy by a coalition of Greek kingdoms. It focuses on a quarrel between King Agamemnon and the warrior Achilles lasting a few weeks during the last year of the war. The "Odyssey" focuses on the ten-year journey home of Odysseus, king of Ithaca, after the fall of Troy. Many accounts of Homer's life circulated in classical antiquity, the most widespread being that he was a blind bard from Ionia, a region of central coastal Anatolia in present-day Turkey. Modern scholars consider these accounts legendary.

The Homeric Question – concerning by whom, when, where and under what circumstances the "Iliad" and "Odyssey" were composed – continues to be debated. Broadly speaking, modern scholarly opinion falls into two groups. One holds that most of the "Iliad" and (according to some) the "Odyssey" are the works of a single poet of genius. The other considers the Homeric poems to be the result of a process of working and reworking by many contributors, and that "Homer" is best seen as a label for an entire tradition. It is generally accepted that the poems were composed at some point around the late eighth or early seventh century BC.

The poems are in Homeric Greek, also known as Epic Greek, a literary language which shows a mixture of features of the Ionic and Aeolic dialects from different centuries; the predominant influence is Eastern Ionic. Most researchers believe that the poems were originally transmitted orally. From antiquity until the present day, the influence of the Homeric epics on Western civilization has been great, inspiring many of its most famous works of literature, music, art and film. The Homeric epics were the greatest influence on ancient Greek culture and education; to Plato, Homer was simply the one who "has taught Greece" – "ten Hellada pepaideuken".

Today only the "Iliad" and "Odyssey" are associated with the name 'Homer'. In antiquity, a very large number of other works were sometimes attributed to him, including the "Homeric Hymns", the "Contest of Homer and Hesiod", the "Little Iliad", the "Nostoi", the "Thebaid", the "Cypria", the "Epigoni", the comic mini-epic "Batrachomyomachia" ("The Frog-Mouse War"), the "Margites", the "Capture of Oechalia", and the "Phocais". These claims are not considered authentic today and were by no means universally accepted in the ancient world. As with the multitude of legends surrounding Homer's life, they indicate little more than the centrality of Homer to ancient Greek culture.

Many traditions circulated in the ancient world concerning Homer, most of which are lost. Modern scholarly consensus is that they have no value as history.

Some claims were established early and repeated often. They include that Homer was blind (taking as self-referential a passage describing the blind bard Demodocus), that he was born in Chios, that he was the son of the river Meles and the nymph Critheïs, that he was a wandering bard, that he composed a varying list of other works (the "Homerica"), that he died either in Ios or after failing to solve a riddle set by fishermen, and various explanations for the name "Homer". The two best known ancient biographies of Homer are the "Life of Homer" by the Pseudo-Herodotus and the "Contest of Homer and Hesiod".

 The study of Homer is one of the oldest topics in scholarship, dating back to antiquity. Nonetheless, the aims of Homeric studies have changed over the course of the millennia. The earliest preserved comments on Homer concern his treatment of the gods, which hostile critics such as the poet Xenophanes of Colophon denounced as immoral. The allegorist Theagenes of Rhegium is said to have defended Homer by arguing that the Homeric poems are allegories. The "Iliad" and the "Odyssey" were widely used as school texts in ancient Greek and Hellenistic cultures. They were the first literary works taught to all students. The "Iliad", particularly its first few books, was far more intently studied than the "Odyssey" during the Hellenistic and Roman periods.

As a result of the poems' prominence in classical Greek education, extensive commentaries on them developed to explain parts of the poems that were culturally or linguistically difficult. During the Hellenistic and Roman Periods, many interpreters, especially the Stoics, who believed that Homeric poems conveyed Stoic doctrines, regarded them as allegories, containing hidden wisdom. Perhaps partially because of the Homeric poems' extensive use in education, many authors believed that Homer's original purpose had been to educate. Homer's wisdom became so widely praised that he began to acquire the image of almost a prototypical philosopher. Byzantine scholars such as Eustathius of Thessalonica and John Tzetzes produced commentaries, extensions and scholia to Homer, especially in the twelfth century. Eustathius's commentary on the "Iliad" alone is massive, sprawling nearly 4,000 oversized pages in a twenty-first century printed version and his commentary on the "Odyssey" an additional nearly 2,000.

In 1488, the Greek scholar Demetrios Chalkokondyles published the "editio princeps" of the Homeric poems. The earliest modern Homeric scholars started with the same basic approaches towards the Homeric poems as scholars in antiquity. The allegorical interpretation of the Homeric poems that had been so prevalent in antiquity returned to become the prevailing view of the Renaissance. Renaissance humanists praised Homer as the archetypically wise poet, whose writings contain hidden wisdom, disguised through allegory. In western Europe during the Renaissance, Virgil was more widely read than Homer and Homer was often seen through a Virgilian lens. In 1664, contradicting the widespread praise of Homer as the epitome of wisdom, François Hédelin, abbé d'Aubignac wrote a scathing attack on the Homeric poems, declaring that they were incoherent, immoral, tasteless, and without style, that Homer never existed, and that the poems were hastily cobbled together by incompetent editors from unrelated oral songs. Fifty years later, the English scholar Richard Bentley concluded that Homer did exist, but that he was an obscure, prehistoric oral poet whose compositions bear little relation to the "Iliad" and the "Odyssey" as they have been passed down. According to Bentley, Homer "wrote a Sequel of Songs and Rhapsodies, to be sung by himself for small Earnings and good Cheer at Festivals and other Days of Merriment; the "Ilias" he wrote for men, and the "Odysseis" for the other Sex. These loose songs were not collected together in the Form of an epic Poem till Pisistratus' time, about 500 Years after."

Friedrich August Wolf's "Prolegomena ad Homerum", published in 1795, argued that much of the material later incorporated into the "Iliad" and the "Odyssey" was originally composed in the tenth century BC in the form of short, separate oral songs, which passed through oral tradition for roughly four hundred years before being assembled into prototypical versions of the "Iliad" and the "Odyssey" the sixth century BC by literate authors. After being written down, Wolf maintained that the two poems were extensively edited, modernized, and eventually shaped into their present state as artistic unities. Wolf and the "Analyst" school, which led the field in the nineteenth century, sought to recover the original, authentic poems which were thought to be concealed by later excrescences. Within the Analyst school were two camps: proponents of the "lay theory," which held that the "Iliad" and the "Odyssey" were put together from a large number of short, independent songs, and proponents of the "nucleus theory", which held that Homer had originally composed shorter versions of the "Iliad" and the "Odyssey", which later poets expanded and revised. A small group of scholars opposed to the Analysts, dubbed "Unitarians", saw the later additions as superior, the work of a single inspired poet. By around 1830, the central preoccupations of Homeric scholars, dealing with whether or not "Homer" actually existed, when and how the Homeric poems originated, how they were transmitted, when and how they were finally written down, and their overall unity, had been dubbed "the Homeric Question".

Following World War I, the Analyst school began to fall out of favor among Homeric scholars. It did not die out entirely, but it came to be increasingly seen as a discredited dead end. Starting in around 1928, Milman Parry and Albert Lord, after their studies of folk bards in the Balkans, developed the "Oral-Formulaic Theory" that the Homeric poems were originally composed through improvised oral performances, which relied on traditional epithets and poetic formulas. This theory found very wide scholarly acceptance and explained many previously puzzling features of the Homeric poems, including their unusually archaic language, their extensive use of stock epithets, and their other "repetitive" features. Many scholars concluded that the "Homeric question" had finally been answered. Meanwhile, the 'Neoanalysts' sought to bridge the gap between the 'Analysts' and 'Unitarians'. The Neoanalysts sought to trace the relationships between the Homeric poems and other epic poems, which have now been lost, but which modern scholars do possess some patchy knowledge of.

Most contemporary scholars, although they disagree on other questions about the genesis of the poems, agree that the "Iliad" and the "Odyssey" were not produced by the same author, based on "the many differences of narrative manner, theology, ethics, vocabulary, and geographical perspective, and by the apparently imitative character of certain passages of the "Odyssey" in relation to the "Iliad"." Nearly all scholars agree that the "Iliad" and the "Odyssey" are unified poems, in that each poem shows a clear overall design, and that they are not merely strung together from unrelated songs. It is also generally agreed that each poem was composed mostly by a single author, who probably relied heavily on older oral traditions. Nearly all scholars agree that the "Doloneia" in Book X of the "Iliad" is not part of the original poem, but rather a later insertion by a different poet.

Some ancient scholars believed Homer to have been an eyewitness to the Trojan War; others thought he had lived up to 500 years afterwards. Contemporary scholars continue to debate the date of the poems. A long history of oral transmission lies behind the composition of the poems, complicating the search for a precise date. At one extreme, Richard Janko has proposed a date for both poems to the eighth century BC based on linguistic analysis and statistics. Barry B. Powell dates the composition of the "Iliad" and the "Odyssey" to sometime between 800 and 750 BC, based on the statement from Herodotus, who lived in the late fifth century BC, that Homer lived four hundred years before his own time "and not more" (καὶ οὐ πλέοσι), and on the fact that the poems do not mention hoplite battle tactics, inhumation, or literacy. At the other extreme, scholars such as Gregory Nagy see "Homer" as a continually evolving tradition, which grew much more stable as the tradition progressed, but which did not fully cease to continue changing and evolving until as late as the middle of the second century BC. Martin Litchfield West has argued that the "Iliad" echoes the poetry of Hesiod, and that it must have been composed around 660–650 BC at the earliest, with the "Odyssey" up to a generation later. He also interprets passages in the "Iliad" as showing knowledge of historical events that occurred in the ancient Near East during the middle of the seventh century BC, including the destruction of Babylon by Sennacherib in 689 BC and the Sack of Thebes by Ashurbanipal in 663/4 BC.

"'Homer" is a name of unknown etymological origin, around which many theories were erected in antiquity. One such linkage was to the Greek ("hómēros"), "hostage" (or "surety"). The explanations suggested by modern scholars tend to mirror their position on the overall Homeric question. Nagy interprets it as "he who fits (the song) together". West has advanced both possible Greek and Phoenician etymologies.

Scholars continue to debate questions such as whether the Trojan War actually took place – and if so when and where – and to what extent the society depicted by Homer is based on his own or one which was, even at the time of the poems' composition, known only as legend. The Homeric epics are largely set in the east and center of the Mediterranean, with some scattered references to Egypt, Ethiopia and other distant lands, in a warlike society that resembles that of the Greek world slightly before the hypothesized date of the poems' composition.

In ancient Greek chronology, the sack of Troy was dated to 1184 BC. By the nineteenth century, there was widespread scholarly skepticism that the Trojan War had ever happened and that Troy had even existed, but in 1873 Heinrich Schliemann announced to the world that he had discovered the ruins of Homer's Troy at Hissarlik in modern Turkey. Some contemporary scholars think the destruction of Troy VIIa "circa" 1220 BC was the origin of the myth of the Trojan War, others that the poem was inspired by multiple similar sieges that took place over the centuries.

Most scholars now agree that the Homeric poems depict customs and elements of the material world that are derived from different periods of Greek history. For instance, the heroes in the poems use bronze weapons, characteristic of the Bronze Age in which the poems are set, rather than the later Iron Age during which they were composed; yet the same heroes are cremated (an Iron Age practice) rather than buried (as they were in the Bronze Age). In some parts of the Homeric poems, heroes are accurately described as carrying large shields like those used by warriors during the Mycenaean period, but, in other places, they are instead described carrying the smaller shields that were commonly used during the time when the poems were written in the early Iron Age.

In the "Iliad" 10.260–265, Odysseus is described as wearing a helmet made of boar's tusks. Such helmets were not worn in Homer's time, but were commonly worn by aristocratic warriors between 1600 and 1150 BC. The decipherment of Linear B in the 1950s by Michael Ventris and continued archaeological investigation has increased modern scholars' understanding of Aegean civilisation, which in many ways resembles the ancient Near East more than the society described by Homer. Some aspects of the Homeric world are simply made up; for instance, the "Iliad" 22.145–56 describes there being two springs that run near the city of Troy, one that runs steaming hot and the other that runs icy cold. It is here that Hector takes his final stand against Achilles. Archaeologists, however, have uncovered no evidence that springs of this description ever actually existed.

The Homeric epics are written in an artificial literary language or 'Kunstsprache' only used in epic hexameter poetry. Homeric Greek shows features of multiple regional Greek dialects and periods, but is fundamentally based on Ionic Greek, in keeping with the tradition that Homer was from Ionia. Linguistic analysis suggests that the "Iliad" was composed slightly before the "Odyssey", and that Homeric formulae preserve older features than other parts of the poems.

The Homeric poems were composed in unrhymed dactylic hexameter; ancient Greek metre was quantity rather than stress-based. Homer frequently uses set phrases such as epithets ('crafty Odysseus', 'rosy-fingered Dawn', 'owl-eyed Athena', etc.), Homeric formulae ('and then answered [him/her], Agamemnon, king of men', 'when the early-born rose-fingered Dawn came to light', 'thus he/she spoke'), simile, type scenes, ring composition and repetition. These habits aid the extemporizing bard, and are characteristic of oral poetry. For instance, the main words of a Homeric sentence are generally placed towards the beginning, whereas literate poets like Virgil or Milton use longer and more complicated syntactical structures. Homer then expands on these ideas in subsequent clauses; this technique is called parataxis.

The so-called 'type scenes' ("typischen Scenen"), were named by Walter Arend in 1933. He noted that Homer often, when describing frequently recurring activities such as eating, praying, fighting and dressing, used blocks of set phrases in sequence that were then elaborated by the poet. The 'Analyst' school had considered these repetitions as un-Homeric, whereas Arend interpreted them philosophically. Parry and Lord noted that these conventions are found in many other cultures.

'Ring composition' or chiastic structure (when a phrase or idea is repeated at both the beginning and end of a story, or a series of such ideas first appears in the order A, B, C... before being reversed as ...C, B, A) has been observed in the Homeric epics. Opinion differs as to whether these occurrences are a conscious artistic device, a mnemonic aid or a spontaneous feature of human storytelling.

Both of the Homeric poems begin with an invocation to the Muse. In the "Iliad", the poet invokes her to sing of "the anger of Achilles", and, in the "Odyssey", he asks her to sing of "the man of many ways". A similar opening was later employed by Virgil in his "Aeneid".

The orally transmitted Homeric poems were put into written form at some point between the eighth and sixth centuries BC. Some scholars believe that they were dictated by the poet; Albert Lord noted that, in the process of dictating, the Balkan bards he recorded revised and extended their lays. Some scholars hypothesize that a similar process occurred when the Homeric poems were first written.

Other scholars such as Gregory Nagy hold that, after the poems were formed in the eight century, they were orally transmitted with little deviation until they were written down in the sixth century. After textualisation, the poems were each divided into 24 rhapsodes, today referred to as books, and labelled by the letters of the Greek alphabet. These divisions probably date from before 200 BC, and may have been made by Homer.

In antiquity, it was widely held that the Homeric poems were collected and organised in Athens in the late sixth century BC by the tyrant Peisistratos (died 528/7 BC), in what subsequent scholars have dubbed the "Peisistratean recension". The idea that the Homeric poems were originally transmitted orally and first written down during the reign of Peisistratos is referenced by the first-century BC Roman orator Cicero and is also referenced in a number of other surviving sources, including two ancient "Lives of Homer". From around 150 BC, the texts of the Homeric poems seem to have become relatively established. After the establishment of the Library of Alexandria, Homeric scholars such as Zenodotus of Ephesus, Aristophanes of Byzantium and in particular Aristarchus of Samothrace helped establish a canonical text.

The first printed edition of Homer was produced in 1488 in Milan. Today scholars use medieval manuscripts, papyri and other sources; some argue for a "multi-text" view, rather than seeking a single definitive text. The nineteenth-century edition of Arthur Ludwich mainly follows Aristarchus's work, whereas van Thiel's (1991, 1996) follows the medieval vulgate. Others, such as Martin West (1998–2000) or T.W. Allen, fall somewhere between these two extremes.

</div>



This is a partial list of translations into English of Homer's "Iliad" and "Odyssey".






</doc>
<doc id="13635" url="https://en.wikipedia.org/wiki?curid=13635" title="Hugo Gernsback">
Hugo Gernsback

Hugo Gernsback (; born Hugo Gernsbacher, August 16, 1884 – August 19, 1967) was a Luxembourgish-American inventor, writer, editor, and magazine publisher, best known for publications including the first science fiction magazine. His contributions to the genre as publisher–although not as a writer–were so significant that, along with the novelists H. G. Wells and Jules Verne, he is sometimes called "The Father of Science Fiction". In his honour, annual awards presented at the World Science Fiction Convention are named the "Hugos".

Gernsback was born in 1884 in Luxembourg City, to Berta (Dürlacher), a housewife, and Moritz Gernsbacher, a winemaker. His family was Jewish. Gernsback emigrated to the United States in 1904 and later became a naturalized citizen. He married three times: to Rose Harvey in 1906, Dorothy Kantrowitz in 1921, and Mary Hancher in 1951. In 1925, he founded radio station WRNY, which was broadcast from the 18th floor of the Roosevelt Hotel in New York City. In 1928, WRNY aired some of the first television broadcasts. During the show, audio stopped and each artist waved or bowed onscreen. When audio resumed, they performed. Gernsback is also considered a pioneer in amateur radio.

Before helping to create science fiction, Gernsback was an entrepreneur in the electronics industry, importing radio parts from Europe to the United States and helping to popularize amateur "wireless". In April 1908 he founded "Modern Electrics", the world's first magazine about both electronics and radio, called "wireless" at the time. While the cover of the magazine itself states it was a catalog, most historians note that it contained articles, features, and plotlines, qualifying it as a magazine.

Under its auspices, in January 1909, he founded the Wireless Association of America, which had 10,000 members within a year. In 1912, Gernsback said that he estimated 400,000 people in the U.S. were involved in amateur radio. In 1913, he founded a similar magazine, "The Electrical Experimenter", which became "Science and Invention" in 1920. It was in these magazines that he began including scientific fiction stories alongside science journalism—including his own novel "Ralph 124C 41+" which he ran for 12 months from April 1911 in "Modern Electrics".

He died at Roosevelt Hospital in New York City on August 19, 1967.

Gernsback provided a forum for the modern genre of science fiction in 1926 by founding the first magazine dedicated to it, "Amazing Stories". The inaugural April issue comprised a one-page editorial and reissues of six stories, three less than ten years old and three by Poe, Verne, and Wells. He said he became interested in the concept after reading a translation of the work of Percival Lowell as a child. His idea of a perfect science fiction story was "75 percent literature interwoven with 25 percent science". He also played an important role in starting science fiction fandom, by organizing the Science Fiction League and by publishing the addresses of people who wrote letters to his magazines. Fans began to organize, and became aware of themselves as a movement, a social force; this was probably decisive for the subsequent history of the genre. He also created the term "science fiction", though he preferred the term "scientifiction".

In 1929, he lost ownership of his first magazines after a bankruptcy lawsuit. There is some debate about whether this process was genuine, manipulated by publisher Bernarr Macfadden, or was a Gernsback scheme to begin another company. After losing control of "Amazing Stories", Gernsback founded two new science fiction magazines, "Science Wonder Stories" and "Air Wonder Stories". A year later, due to Depression-era financial troubles, the two were merged into "Wonder Stories", which Gernsback continued to publish until 1936, when it was sold to Thrilling Publications and renamed "Thrilling Wonder Stories". Gernsback returned in 1952–53 with "Science-Fiction Plus".

Gernsback was noted for sharp (and sometimes shady) business practices, and for paying his writers extremely low fees or not paying them at all. H. P. Lovecraft and Clark Ashton Smith referred to him as "Hugo the Rat".

As Barry Malzberg has said:

Gernsback's venality and corruption, his sleaziness and his utter disregard for the financial rights of authors, have been well documented and discussed in critical and fan literature. That the founder of genre science fiction who gave his name to the field's most prestigious award and who was the Guest of Honor at the 1952 Worldcon was pretty much a crook (and a contemptuous crook who stiffed his writers but paid himself $100K a year as President of Gernsback Publications) has been clearly established. 

Jack Williamson, who had to hire an attorney associated with the American Fiction Guild to force Gernsback to pay him, summed up his importance for the genre:

At any rate, his main influence in the field was simply to start Amazing and Wonder Stories and get SF out to the public newsstands—and to name the genre he had earlier called "scientifiction."

Frederik Pohl said in 1965 that Gernsback's "Amazing Stories" published "the kind of stories Gernsback himself used to write: a sort of animated catalogue of gadgets". Gernsback's fiction includes the novel "Ralph 124C 41+"; the title is a pun on the phrase "one to foresee for many" ("one plus"). Even though "Ralph 124C 41+" has been described as pioneering many ideas and themes found in later SF work, it has often been neglected due to what most critics deem poor artistic quality. Author Brian Aldiss called the story a "tawdry illiterate tale" and a "sorry concoction", while author and editor Lester del Rey called it "simply dreadful." While most other modern critics have little positive to say about the story's writing, "Ralph 124C 41+" is considered by science fiction critic Gary Westfahl as "essential text for all studies of science fiction."

Gernsback's second novel, "Baron Münchausen's Scientific Adventures", was serialized in "Amazing Stories" in 1928.

Gernsback's third (and final) novel, "Ultimate World", written c. 1958, was not published until 1971. Lester del Rey described it simply as "a bad book", marked more by routine social commentary than by scientific insight or extrapolation. James Blish, in a caustic review, described the novel as "incompetent, pedantic, graceless, incredible, unpopulated and boring" and concluded that its publication "accomplishes nothing but the placing of a blot on the memory of a justly honored man."

Gernsback combined his fiction and science into "Everyday Science and Mechanics" magazine, serving as the editor in the 1930s.

The Hugo Awards or "Hugos" are the annual achievement awards presented at the World Science Fiction Convention, selected in a process that ends with vote by current Convention members. They originated and acquired the "Hugo" nickname during the 1950s and were formally defined as a convention responsibility under the name "Science Fiction Achievement Awards" early in the 1960s. The nickname soon became almost universal and its use legally protected; "Hugo Award(s)" replaced the longer name in all official uses after the 1991 cycle.

In 1960 Gernsback received a special Hugo Award as "The Father of Magazine Science Fiction".

The Science Fiction and Fantasy Hall of Fame inducted him in 1996, its inaugural class of two deceased and two living persons.

Science fiction author Brian W. Aldiss held a contrary view about Gernsback's contributions: "It is easy to argue that Hugo Gernsback ... was one of the worst disasters to hit the science fiction field ... Gernsback himself was utterly without any literary understanding. He created dangerous precedents which many later editors in the field followed."

Gernsback made significant contributions to the growth of early broadcasting, mostly through his efforts as a publisher. He originated the industry of specialized publications for radio with "Modern Electrics" and "Electrical Experimenter". Later on, and more influentially, he published "Radio News", which would have the largest readership among radio magazines in radio broadcasting's formative years. He edited "Radio News" until 1929. For a short time he hired John F. Rider to be editor. Rider was a former engineer working with the US Army Signal Corps and a radio engineer for A. H. Grebe, a radio manufacturer. However Rider would soon leave Gernsback and form his own publishing company, John F. Rider Publisher, New York around 1931.

Gernsback made use of the magazine to promote his own interests, including having his radio station's call letters on the cover starting in 1925. WRNY and "Radio News" were used to cross-promote each other, with programs on his station often used to discuss articles he had published, and articles in the magazine often covering program activities at WRNY. He also advocated for future directions in innovation and regulation of radio. The magazine contained many drawings and diagrams, encouraging radio listeners of the 1920s to experiment themselves to improve the technology. WRNY was often used as a laboratory to see if various radio inventions were worthwhile.

Articles that were published about television were also tested in this manner when the radio station was used to send pictures to experimental television receivers in August 1928. The technology, however, required sending sight and sound one after the other rather than sending both at the same time, as WRNY only broadcast on one channel. Such experiments were expensive, eventually contributing to Gernsback's Experimenter Publishing Company going into bankruptcy in 1929. WRNY was sold to Aviation Radio, who maintained the channel part-time to broadcast aviation weather reports and related feature programs. It left the air in 1934.

Gernsback held 80 patents by the time of his death in New York City on August 19, 1967.

Novels:


Short stories:








</doc>
<doc id="13636" url="https://en.wikipedia.org/wiki?curid=13636" title="History of computing hardware">
History of computing hardware

The history of computing hardware covers the developments from early simple devices to aid calculation to modern day computers. Before the 20th century, most calculations were done by humans. Early mechanical tools to help humans with digital calculations, like the abacus, were called "calculating machines", called by proprietary names, or referred to as calculators. The machine operator was called the computer.

The first aids to computation were purely mechanical devices which required the operator to set up the initial values of an elementary arithmetic operation, then manipulate the device to obtain the result. Later, computers represented numbers in a continuous form, for instance distance along a scale, rotation of a shaft, or a voltage. Numbers could also be represented in the form of digits, automatically manipulated by a mechanical mechanism. Although this approach generally required more complex mechanisms, it greatly increased the precision of results. A series of breakthroughs, such as miniaturized transistor computers, and the integrated circuit, caused digital computers to largely replace analog computers. The cost of computers gradually became so low that by the 1990s, personal computers, and then, in the 2000s, mobile computers, (smartphones and tablets) became ubiquitous.

Devices have been used to aid computation for thousands of years, mostly using one-to-one correspondence with fingers. The earliest counting device was probably a form of tally stick. Later record keeping aids throughout the Fertile Crescent included calculi (clay spheres, cones, etc.) which represented counts of items, probably livestock or grains, sealed in hollow unbaked clay containers. The use of counting rods is one example. The abacus was early used for arithmetic tasks. What we now call the Roman abacus was used in Babylonia as early as c. 2700–2300 BC. Since then, many other forms of reckoning boards or tables have been invented. In a medieval European counting house, a checkered cloth would be placed on a table, and markers moved around on it according to certain rules, as an aid to calculating sums of money.

Several analog computers were constructed in ancient and medieval times to perform astronomical calculations. These included the south-pointing chariot (c. 1050–771 BC) from ancient China, and the astrolabe and Antikythera mechanism from the Hellenistic world (c. 150–100 BC). In Roman Egypt, Hero of Alexandria (c. 10–70 AD) made mechanical devices including automata and a programmable cart. Other early mechanical devices used to perform one or another type of calculations include the planisphere and other mechanical computing devices invented by Abu Rayhan al-Biruni (c. AD 1000); the equatorium and universal latitude-independent astrolabe by Abū Ishāq Ibrāhīm al-Zarqālī (c. AD 1015); the astronomical analog computers of other medieval Muslim astronomers and engineers; and the astronomical clock tower of Su Song (1094) during the Song dynasty. The castle clock, a hydropowered mechanical astronomical clock invented by Ismail al-Jazari in 1206, was the first programmable analog computer. Ramon Llull invented the Lullian Circle: a notional machine for calculating answers to philosophical questions (in this case, to do with Christianity) via logical combinatorics. This idea was taken up by Leibniz centuries later, and is thus one of the founding elements in computing and information science.

Scottish mathematician and physicist John Napier discovered that the multiplication and division of numbers could be performed by the addition and subtraction, respectively, of the logarithms of those numbers. While producing the first logarithmic tables, Napier needed to perform many tedious multiplications. It was at this point that he designed his 'Napier's bones', an abacus-like device that greatly simplified calculations that involved multiplication and division.
Since real numbers can be represented as distances or intervals on a line, the slide rule was invented in the 1620s, shortly after Napier's work, to allow multiplication and division operations to be carried out significantly faster than was previously possible. Edmund Gunter built a calculating device with a single logarithmic scale at the University of Oxford. His device greatly simplified arithmetic calculations, including multiplication and division. William Oughtred greatly improved this in 1630 with his circular slide rule. He followed this up with the modern slide rule in 1632, essentially a combination of two Gunter rules, held together with the hands. Slide rules were used by generations of engineers and other mathematically involved professional workers, until the invention of the pocket calculator.

Wilhelm Schickard, a German polymath, designed a calculating machine in 1623 which combined a mechanised form of Napier's rods with the world's first mechanical adding machine built into the base. Because it made use of a single-tooth gear there were circumstances in which its carry mechanism would jam. A fire destroyed at least one of the machines in 1624 and it is believed Schickard was too disheartened to build another.

In 1642, while still a teenager, Blaise Pascal started some pioneering work on calculating machines and after three years of effort and 50 prototypes he invented a mechanical calculator. He built twenty of these machines (called Pascal's calculator or Pascaline) in the following ten years. Nine Pascalines have survived, most of which are on display in European museums. A continuing debate exists over whether Schickard or Pascal should be regarded as the "inventor of the mechanical calculator" and the range of issues to be considered is discussed elsewhere.

Gottfried Wilhelm von Leibniz invented the stepped reckoner and his famous stepped drum mechanism around 1672. He attempted to create a machine that could be used not only for addition and subtraction but would utilise a moveable carriage to enable long multiplication and division. Leibniz once said "It is unworthy of excellent men to lose hours like slaves in the labour of calculation which could safely be relegated to anyone else if machines were used." However, Leibniz did not incorporate a fully successful carry mechanism. Leibniz also described the binary numeral system, a central ingredient of all modern computers. However, up to the 1940s, many subsequent designs (including Charles Babbage's machines of the 1822 and even ENIAC of 1945) were based on the decimal system.

Around 1820, Charles Xavier Thomas de Colmar created what would over the rest of the century become the first successful, mass-produced mechanical calculator, the Thomas Arithmometer. It could be used to add and subtract, and with a moveable carriage the operator could also multiply, and divide by a process of long multiplication and long division. It utilised a stepped drum similar in conception to that invented by Leibniz. Mechanical calculators remained in use until the 1970s.

In 1804, Joseph-Marie Jacquard developed a loom in which the pattern being woven was controlled by a paper tape constructed from punched cards. The paper tape could be changed without changing the mechanical design of the loom. This was a landmark achievement in programmability. His machine was an improvement over similar weaving looms. Punched cards were preceded by punch bands, as in the machine proposed by Basile Bouchon. These bands would inspire information recording for automatic pianos and more recently numerical control machine tools.
In the late 1880s, the American Herman Hollerith invented data storage on punched cards that could then be read by a machine. To process these punched cards he invented the tabulator, and the keypunch machine. His machines used electromechanical relays and counters. Hollerith's method was used in the 1890 United States Census. That census was processed two years faster than the prior census had been. Hollerith's company eventually became the core of IBM.

By 1920, electromechanical tabulating machines could add, subtract, and print accumulated totals. Machine functions were directed by inserting dozens of wire jumpers into removable control panels. When the United States instituted Social Security in 1935, IBM punched-card systems were used to process records of 26 million workers. Punched cards became ubiquitous in industry and government for accounting and administration.

Leslie Comrie's articles on punched-card methods and W. J. Eckert's publication of "Punched Card Methods in Scientific Computation" in 1940, described punched-card techniques sufficiently advanced to solve some differential equations or perform multiplication and division using floating point representations, all on punched cards and unit record machines. Such machines were used during World War II for cryptographic statistical processing, as well as a vast number of administrative uses. The Astronomical Computing Bureau, Columbia University, performed astronomical calculations representing the state of the art in computing.

The book "IBM and the Holocaust" by Edwin Black outlines the ways in which IBM's technology helped facilitate Nazi genocide through generation and tabulation of punch cards based on national census data. "See also: Dehomag"

By the 20th century, earlier mechanical calculators, cash registers, accounting machines, and so on were redesigned to use electric motors, with gear position as the representation for the state of a variable. The word "computer" was a job title assigned to primarily women who used these calculators to perform mathematical calculations. By the 1920s, British scientist Lewis Fry Richardson's interest in weather prediction led him to propose human computers and numerical analysis to model the weather; to this day, the most powerful computers on Earth are needed to adequately model its weather using the Navier–Stokes equations.

Companies like Friden, Marchant Calculator and Monroe made desktop mechanical calculators from the 1930s that could add, subtract, multiply and divide. In 1948, the Curta was introduced by Austrian inventor Curt Herzstark. It was a small, hand-cranked mechanical calculator and as such, a descendant of Gottfried Leibniz's Stepped Reckoner and Thomas's Arithmometer.

The world's first "all-electronic desktop" calculator was the British Bell Punch ANITA, released in 1961. It used vacuum tubes, cold-cathode tubes and Dekatrons in its circuits, with 12 cold-cathode "Nixie" tubes for its display. The ANITA sold well since it was the only electronic desktop calculator available, and was silent and quick. The tube technology was superseded in June 1963 by the U.S. manufactured Friden EC-130, which had an all-transistor design, a stack of four 13-digit numbers displayed on a CRT, and introduced reverse Polish notation (RPN).

Charles Babbage, an English mechanical engineer and polymath, originated the concept of a programmable computer. Considered the "father of the computer", he conceptualized and invented the first mechanical computer in the early 19th century. After working on his revolutionary difference engine, designed to aid in navigational calculations, in 1833 he realized that a much more general design, an Analytical Engine, was possible. The input of programs and data was to be provided to the machine via punched cards, a method being used at the time to direct mechanical looms such as the Jacquard loom. For output, the machine would have a printer, a curve plotter and a bell. The machine would also be able to punch numbers onto cards to be read in later. It employed ordinary base-10 fixed-point arithmetic.

The Engine incorporated an arithmetic logic unit, control flow in the form of conditional branching and loops, and integrated memory, making it the first design for a general-purpose computer that could be described in modern terms as Turing-complete.

There was to be a store, or memory, capable of holding 1,000 numbers of 40 decimal digits each (ca. 16.7 kB). An arithmetical unit, called the "mill", would be able to perform all four arithmetic operations, plus comparisons and optionally square roots. Initially it was conceived as a difference engine curved back upon itself, in a generally circular layout, with the long store exiting off to one side. (Later drawings depict a regularized grid layout.) Like the central processing unit (CPU) in a modern computer, the mill would rely on its own internal procedures, roughly equivalent to microcode in modern CPUs, to be stored in the form of pegs inserted into rotating drums called "barrels", to carry out some of the more complex instructions the user's program might specify.
The programming language to be employed by users was akin to modern day assembly languages. Loops and conditional branching were possible, and so the language as conceived would have been Turing-complete as later defined by Alan Turing. Three different types of punch cards were used: one for arithmetical operations, one for numerical constants, and one for load and store operations, transferring numbers from the store to the arithmetical unit or back. There were three separate readers for the three types of cards.

The machine was about a century ahead of its time. However, the project was slowed by various problems including disputes with the chief machinist building parts for it. All the parts for his machine had to be made by hand—this was a major problem for a machine with thousands of parts. Eventually, the project was dissolved with the decision of the British Government to cease funding. Babbage's failure to complete the analytical engine can be chiefly attributed to difficulties not only of politics and financing, but also to his desire to develop an increasingly sophisticated computer and to move ahead faster than anyone else could follow. Ada Lovelace, Lord Byron's daughter, translated and added notes to the ""Sketch of the Analytical Engine"" by Luigi Federico Menabrea. This appears to be the first published description of programming, so Ada Lovelace is widely regarded as the first computer programmer.

Following Babbage, although unaware of his earlier work, was Percy Ludgate, an accountant from Dublin, Ireland. He independently designed a programmable mechanical computer, which he described in a work that was published in 1909.

In the first half of the 20th century, analog computers were considered by many to be the future of computing. These devices used the continuously changeable aspects of physical phenomena such as electrical, mechanical, or hydraulic quantities to model the problem being solved, in contrast to digital computers that represented varying quantities symbolically, as their numerical values change. As an analog computer does not use discrete values, but rather continuous values, processes cannot be reliably repeated with exact equivalence, as they can with Turing machines.

The first modern analog computer was a tide-predicting machine, invented by Sir William Thomson, later Lord Kelvin, in 1872. It used a system of pulleys and wires to automatically calculate predicted tide levels for a set period at a particular location and was of great utility to navigation in shallow waters. His device was the foundation for further developments in analog computing.

The differential analyser, a mechanical analog computer designed to solve differential equations by integration using wheel-and-disc mechanisms, was conceptualized in 1876 by James Thomson, the brother of the more famous Lord Kelvin. He explored the possible construction of such calculators, but was stymied by the limited output torque of the ball-and-disk integrators. In a differential analyzer, the output of one integrator drove the input of the next integrator, or a graphing output.
An important advance in analog computing was the development of the first fire-control systems for long range ship gunlaying. When gunnery ranges increased dramatically in the late 19th century it was no longer a simple matter of calculating the proper aim point, given the flight times of the shells. Various spotters on board the ship would relay distance measures and observations to a central plotting station. There the fire direction teams fed in the location, speed and direction of the ship and its target, as well as various adjustments for Coriolis effect, weather effects on the air, and other adjustments; the computer would then output a firing solution, which would be fed to the turrets for laying. In 1912, British engineer Arthur Pollen developed the first electrically powered mechanical analogue computer (called at the time the Argo Clock). It was used by the Imperial Russian Navy in World War I. The alternative Dreyer Table fire control system was fitted to British capital ships by mid-1916.

Mechanical devices were also used to aid the accuracy of aerial bombing. Drift Sight was the first such aid, developed by Harry Wimperis in 1916 for the Royal Naval Air Service; it measured the wind speed from the air, and used that measurement to calculate the wind's effects on the trajectory of the bombs. The system was later improved with the Course Setting Bomb Sight, and reached a climax with World War II bomb sights, Mark XIV bomb sight (RAF Bomber Command) and the Norden (United States Army Air Forces).

The art of mechanical analog computing reached its zenith with the differential analyzer, built by H. L. Hazen and Vannevar Bush at MIT starting in 1927, which built on the mechanical integrators of James Thomson and the torque amplifiers invented by H. W. Nieman. A dozen of these devices were built before their obsolescence became obvious; the most powerful was constructed at the University of Pennsylvania's Moore School of Electrical Engineering, where the ENIAC was built.

A fully electronic analog computer was built by Helmut Hölzer in 1942 at Peenemünde Army Research Center

By the 1950s the success of digital electronic computers had spelled the end for most analog computing machines, but hybrid analog computers, controlled by digital electronics, remained in substantial use into the 1950s and 1960s, and later in some specialized applications.

The principle of the modern computer was first described by computer scientist Alan Turing, who set out the idea in his seminal 1936 paper, "On Computable Numbers". Turing reformulated Kurt Gödel's 1931 results on the limits of proof and computation, replacing Gödel's universal arithmetic-based formal language with the formal and simple hypothetical devices that became known as Turing machines. He proved that some such machine would be capable of performing any conceivable mathematical computation if it were representable as an algorithm. He went on to prove that there was no solution to the "Entscheidungsproblem" by first showing that the halting problem for Turing machines is undecidable: in general, it is not possible to decide algorithmically whether a given Turing machine will ever halt.

He also introduced the notion of a "universal machine" (now known as a universal Turing machine), with the idea that such a machine could perform the tasks of any other machine, or in other words, it is provably capable of computing anything that is computable by executing a program stored on tape, allowing the machine to be programmable. Von Neumann acknowledged that the central concept of the modern computer was due to this paper. Turing machines are to this day a central object of study in theory of computation. Except for the limitations imposed by their finite memory stores, modern computers are said to be Turing-complete, which is to say, they have algorithm execution capability equivalent to a universal Turing machine.

The era of modern computing began with a flurry of development before and during World War II. Most digital computers built in this period were electromechanical – electric switches drove mechanical relays to perform the calculation. These devices had a low operating speed and were eventually superseded by much faster all-electric computers, originally using vacuum tubes.

The Z2 was one of the earliest examples of an electromechanical relay computer, and was created by German engineer Konrad Zuse in 1940. It was an improvement on his earlier Z1; although it used the same mechanical memory, it replaced the arithmetic and control logic with electrical relay circuits.
In the same year, electro-mechanical devices called bombes were built by British cryptologists to help decipher German Enigma-machine-encrypted secret messages during World War II. The bombes' initial design was created in 1939 at the UK Government Code and Cypher School (GC&CS) at Bletchley Park by Alan Turing, with an important refinement devised in 1940 by Gordon Welchman. The engineering design and construction was the work of Harold Keen of the British Tabulating Machine Company. It was a substantial development from a device that had been designed in 1938 by Polish Cipher Bureau cryptologist Marian Rejewski, and known as the "cryptologic bomb" (Polish: ""bomba kryptologiczna"").

In 1941, Zuse followed his earlier machine up with the Z3, the world's first working electromechanical programmable, fully automatic digital computer. The Z3 was built with 2000 relays, implementing a 22-bit word length that operated at a clock frequency of about 5–10 Hz. Program code and data were stored on punched film. It was quite similar to modern machines in some respects, pioneering numerous advances such as floating point numbers. Replacement of the hard-to-implement decimal system (used in Charles Babbage's earlier design) by the simpler binary system meant that Zuse's machines were easier to build and potentially more reliable, given the technologies available at that time. The Z3 was probably a Turing-complete machine. In two 1936 patent applications, Zuse also anticipated that machine instructions could be stored in the same storage used for data—the key insight of what became known as the von Neumann architecture, first implemented in 1948 in America in the electromechanical IBM SSEC and in Britain in the fully electronic Manchester Baby.

Zuse suffered setbacks during World War II when some of his machines were destroyed in the course of Allied bombing campaigns. Apparently his work remained largely unknown to engineers in the UK and US until much later, although at least IBM was aware of it as it financed his post-war startup company in 1946 in return for an option on Zuse's patents.

In 1944, the Harvard Mark I was constructed at IBM's Endicott laboratories; it was a similar general purpose electro-mechanical computer to the Z3, but was not quite Turing-complete.

The term digital was first suggested by George Robert Stibitz and refers to where a signal, such as a voltage, is not used to directly represent a value (as it would be in an analog computer), but to encode it. In November 1937, George Stibitz, then working at Bell Labs (1930–1941), completed a relay-based calculator he later dubbed the "Model K" (for "kitchen table", on which he had assembled it), which became the first binary adder. Typically signals have two states – low (usually representing 0) and high (usually representing 1), but sometimes three-valued logic is used, especially in high-density memory. Modern computers generally use binary logic, but many early machines were decimal computers. In these machines, the basic unit of data was the decimal digit, encoded in one of several schemes, including binary-coded decimal or BCD, bi-quinary, excess-3, and two-out-of-five code. 

The mathematical basis of digital computing is Boolean algebra, developed by the British mathematician George Boole in his work "The Laws of Thought", published in 1854. His Boolean algebra was further refined in the 1860s by William Jevons and Charles Sanders Peirce, and was first presented systematically by Ernst Schröder and A. N. Whitehead. In 1879 Gottlob Frege develops the formal approach to logic and proposes the first logic language for logical equations.

In the 1930s and working independently, American electronic engineer Claude Shannon and Soviet logician Victor Shestakov both showed a one-to-one correspondence between the concepts of Boolean logic and certain electrical circuits, now called logic gates, which are now ubiquitous in digital computers. They showed that electronic relays and switches can realize the expressions of Boolean algebra. This thesis essentially founded practical digital circuit design.

Purely electronic circuit elements soon replaced their mechanical and electromechanical equivalents, at the same time that digital calculation replaced analog. Machines such as the Z3, the Atanasoff–Berry Computer, the Colossus computers, and the ENIAC were built by hand, using circuits containing relays or valves (vacuum tubes), and often used punched cards or punched paper tape for input and as the main (non-volatile) storage medium.

The engineer Tommy Flowers joined the telecommunications branch of the General Post Office in 1926. While working at the research station in Dollis Hill in the 1930s, he began to explore the possible use of electronics for the telephone exchange. Experimental equipment that he built in 1934 went into operation 5 years later, converting a portion of the telephone exchange network into an electronic data processing system, using thousands of vacuum tubes.

In the US, in the period summer 1937 to the fall of 1939 Arthur Dickinson (IBM) invented the first digital electronic computer. This calculating device was fully electronic – control, calculations and output (the first electronic display). John Vincent Atanasoff and Clifford E. Berry of Iowa State University developed the Atanasoff–Berry Computer (ABC) in 1942, the first binary electronic digital calculating device. This design was semi-electronic (electro-mechanical control and electronic calculations), and used about 300 vacuum tubes, with capacitors fixed in a mechanically rotating drum for memory. However, its paper card writer/reader was unreliable and the regenerative drum contact system was mechanical. The machine's special-purpose nature and lack of changeable, stored program distinguish it from modern computers.

Computers whose logic was primarily built using vacuum tubes are now known as first generation computers.

During World War II, British codebreakers at Bletchley Park (40 miles north of London) achieved a number of successes at breaking encrypted enemy military communications. The German encryption machine, Enigma, was first attacked with the help of the electro-mechanical bombes. Women often operated these bombe machines. They ruled out possible Enigma settings by performing chains of logical deductions implemented electrically. Most possibilities led to a contradiction, and the few remaining could be tested by hand.

The Germans also developed a series of teleprinter encryption systems, quite different from Enigma. The Lorenz SZ 40/42 machine was used for high-level Army communications, code-named "Tunny" by the British. The first intercepts of Lorenz messages began in 1941. As part of an attack on Tunny, Max Newman and his colleagues developed the Heath Robinson, a fixed-function machine to aid in code breaking. . Tommy Flowers, a senior engineer at the Post Office Research Station was recommended to Max Newman by Alan Turing and spent eleven months from early February 1943 designing and building the more flexible Colossus computer (which superseded the Heath Robinson). After a functional test in December 1943, Colossus was shipped to Bletchley Park, where it was delivered on 18 January 1944 and attacked its first message on 5 February.
Colossus was the world's first electronic digital programmable computer. It used a large number of valves (vacuum tubes). It had paper-tape input and was capable of being configured to perform a variety of boolean logical operations on its data, but it was not Turing-complete. Data input to Colossus was by photoelectric reading of a paper tape transcription of the enciphered intercepted message. This was arranged in a continuous loop so that it could be read and re-read multiple times – there being no internal store for the data. The reading mechanism ran at 5,000 characters per second with the paper tape moving at . Colossus Mark 1 contained 1500 thermionic valves (tubes), but Mark 2 with 2400 valves and five processors in parallel, was both 5 times faster and simpler to operate than Mark 1, greatly speeding the decoding process. Mark 2 was designed while Mark 1 was being constructed. Allen Coombs took over leadership of the Colossus Mark 2 project when Tommy Flowers moved on to other projects. The first Mark 2 Colossus became operational on 1 June 1944, just in time for the Allied Invasion of Normandy on D-Day.

Most of the use of Colossus was in determining the start positions of the Tunny rotors for a message, which was called "wheel setting". Colossus included the first ever use of shift registers and systolic arrays, enabling five simultaneous tests, each involving up to 100 Boolean calculations. This enabled five different possible start positions to be examined for one transit of the paper tape. As well as wheel setting some later Colossi included mechanisms intended to help determine pin patterns known as "wheel breaking". Both models were programmable using switches and plug panels in a way their predecessors had not been. Ten Mk 2 Colossi were operational by the end of the war. 
Without the use of these machines, the Allies would have been deprived of the very valuable intelligence that was obtained from reading the vast quantity of enciphered high-level telegraphic messages between the German High Command (OKW) and their army commands throughout occupied Europe. Details of their existence, design, and use were kept secret well into the 1970s. Winston Churchill personally issued an order for their destruction into pieces no larger than a man's hand, to keep secret that the British were capable of cracking Lorenz SZ cyphers (from German rotor stream cipher machines) during the oncoming Cold War. Two of the machines were transferred to the newly formed GCHQ and the others were destroyed. As a result, the machines were not included in many histories of computing. A reconstructed working copy of one of the Colossus machines is now on display at Bletchley Park.

The US-built ENIAC (Electronic Numerical Integrator and Computer) was the first electronic programmable computer built in the US. Although the ENIAC was similar to the Colossus it was much faster and more flexible. It was unambiguously a Turing-complete device and could compute any problem that would fit into its memory. Like the Colossus, a "program" on the ENIAC was defined by the states of its patch cables and switches, a far cry from the stored program electronic machines that came later. Once a program was written, it had to be mechanically set into the machine with manual resetting of plugs and switches. The programmers of the ENIAC were women who had been trained as mathematicians.

It combined the high speed of electronics with the ability to be programmed for many complex problems. It could add or subtract 5000 times a second, a thousand times faster than any other machine. It also had modules to multiply, divide, and square root. High-speed memory was limited to 20 words (equivalent to about 80 bytes). Built under the direction of John Mauchly and J. Presper Eckert at the University of Pennsylvania, ENIAC's development and construction lasted from 1943 to full operation at the end of 1945. The machine was huge, weighing 30 tons, using 200 kilowatts of electric power and contained over 18,000 vacuum tubes, 1,500 relays, and hundreds of thousands of resistors, capacitors, and inductors. One of its major engineering feats was to minimize the effects of tube burnout, which was a common problem in machine reliability at that time. The machine was in almost constant use for the next ten years.

Early computing machines were programmable in the sense that they could follow the sequence of steps they had been set up to execute, but the "program", or steps that the machine was to execute, were set up usually by changing how the wires were plugged into a patch panel or plugboard. "Reprogramming", when it was possible at all, was a laborious process, starting with engineers working out flowcharts, designing the new set up, and then the often-exacting process of physically re-wiring patch panels. Stored-program computers, by contrast, were designed to store a set of instructions (a program), in memory – typically the same memory as stored data.

The theoretical basis for the stored-program computer had been proposed by Alan Turing in his 1936 paper. In 1945 Turing joined the National Physical Laboratory and began his work on developing an electronic stored-program digital computer. His 1945 report ‘Proposed Electronic Calculator’ was the first specification for such a device.

Meanwhile, John von Neumann at the Moore School of Electrical Engineering, University of Pennsylvania, circulated his "First Draft of a Report on the EDVAC" in 1945. Although substantially similar to Turing's design and containing comparatively little engineering detail, the computer architecture it outlined became known as the "von Neumann architecture". Turing presented a more detailed paper to the National Physical Laboratory (NPL) Executive Committee in 1946, giving the first reasonably complete design of a stored-program computer, a device he called the Automatic Computing Engine (ACE). However, the better-known EDVAC design of John von Neumann, who knew of Turing's theoretical work, received more publicity, despite its incomplete nature and questionable lack of attribution of the sources of some of the ideas.

Turing thought that the speed and the size of computer memory were crucial elements, so he proposed a high-speed memory of what would today be called 25 KB, accessed at a speed of 1 MHz. The ACE implemented subroutine calls, whereas the EDVAC did not, and the ACE also used "Abbreviated Computer Instructions," an early form of programming language.

The Manchester Baby was the world's first electronic stored-program computer. It was built at the Victoria University of Manchester by Frederic C. Williams, Tom Kilburn and Geoff Tootill, and ran its first program on 21 June 1948.

The machine was not intended to be a practical computer but was instead designed as a testbed for the Williams tube, the first random-access digital storage device. Invented by Freddie Williams and Tom Kilburn at the University of Manchester in 1946 and 1947, it was a cathode ray tube that used an effect called secondary emission to temporarily store electronic binary data, and was used successfully in several early computers.

Although the computer was considered "small and primitive" by the standards of its time, it was the first working machine to contain all of the elements essential to a modern electronic computer. As soon as the Baby had demonstrated the feasibility of its design, a project was initiated at the university to develop it into a more usable computer, the Manchester Mark 1. The Mark 1 in turn quickly became the prototype for the Ferranti Mark 1, the world's first commercially available general-purpose computer.

The Baby had a 32-bit word length and a memory of 32 words. As it was designed to be the simplest possible stored-program computer, the only arithmetic operations implemented in hardware were subtraction and negation; other arithmetic operations were implemented in software. The first of three programs written for the machine found the highest proper divisor of 2 (262,144), a calculation that was known would take a long time to run—and so prove the computer's reliability—by testing every integer from 2 − 1 downwards, as division was implemented by repeated subtraction of the divisor. The program consisted of 17 instructions and ran for 52 minutes before reaching the correct answer of 131,072, after the Baby had performed 3.5 million operations (for an effective CPU speed of 1.1 kIPS).

The Experimental machine led on to the development of the Manchester Mark 1 at the University of Manchester. Work began in August 1948, and the first version was operational by April 1949; a program written to search for Mersenne primes ran error-free for nine hours on the night of 16/17 June 1949.
The machine's successful operation was widely reported in the British press, which used the phrase "electronic brain" in describing it to their readers.

The computer is especially historically significant because of its pioneering inclusion of index registers, an innovation which made it easier for a program to read sequentially through an array of words in memory. Thirty-four patents resulted from the machine's development, and many of the ideas behind its design were incorporated in subsequent commercial products such as the and 702 as well as the Ferranti Mark 1. The chief designers, Frederic C. Williams and Tom Kilburn, concluded from their experiences with the Mark 1 that computers would be used more in scientific roles than in pure mathematics. In 1951 they started development work on Meg, the Mark 1's successor, which would include a floating point unit.

The other contender for being the first recognizably modern digital stored-program computer was the EDSAC, designed and constructed by Maurice Wilkes and his team at the University of Cambridge Mathematical Laboratory in England at the University of Cambridge in 1949. The machine was inspired by John von Neumann's seminal "First Draft of a Report on the EDVAC" and was one of the first usefully operational electronic digital stored-program computer.

EDSAC ran its first programs on 6 May 1949, when it calculated a table of squares and a list of prime numbers.The EDSAC also served as the basis for the first commercially applied computer, the LEO I, used by food manufacturing company J. Lyons & Co. Ltd. EDSAC 1 and was finally shut down on 11 July 1958, having been superseded by EDSAC 2 which stayed in use until 1965.

ENIAC inventors John Mauchly and J. Presper Eckert proposed the EDVAC's construction in August 1944, and design work for the EDVAC commenced at the University of Pennsylvania's Moore School of Electrical Engineering, before the ENIAC was fully operational. The design implemented a number of important architectural and logical improvements conceived during the ENIAC's construction, and a high-speed serial-access memory. However, Eckert and Mauchly left the project and its construction floundered.

It was finally delivered to the U.S. Army's Ballistics Research Laboratory at the Aberdeen Proving Ground in August 1949, but due to a number of problems, the computer only began operation in 1951, and then only on a limited basis.

The first commercial computer was the Ferranti Mark 1, built by Ferranti and delivered to the University of Manchester in February 1951. It was based on the Manchester Mark 1. The main improvements over the Manchester Mark 1 were in the size of the primary storage (using random access Williams tubes), secondary storage (using a magnetic drum), a faster multiplier, and additional instructions. The basic cycle time was 1.2 milliseconds, and a multiplication could be completed in about 2.16 milliseconds. The multiplier used almost a quarter of the machine's 4,050 vacuum tubes (valves). A second machine was purchased by the University of Toronto, before the design was revised into the Mark 1 Star. At least seven of these later machines were delivered between 1953 and 1957, one of them to Shell labs in Amsterdam.

In October 1947, the directors of J. Lyons & Company, a British catering company famous for its teashops but with strong interests in new office management techniques, decided to take an active role in promoting the commercial development of computers. The LEO I computer became operational in April 1951 and ran the world's first regular routine office computer job. On 17 November 1951, the J. Lyons company began weekly operation of a bakery valuations job on the LEO (Lyons Electronic Office). This was the first business to go live on a stored program computer.
In June 1951, the UNIVAC I (Universal Automatic Computer) was delivered to the U.S. Census Bureau. Remington Rand eventually sold 46 machines at more than US$1 million each ($ as of 2019). UNIVAC was the first "mass produced" computer. It used 5,200 vacuum tubes and consumed 125 kW of power. Its primary storage was serial-access mercury delay lines capable of storing 1,000 words of 11 decimal digits plus sign (72-bit words).

IBM introduced a smaller, more affordable computer in 1954 that proved very popular. The IBM 650 weighed over 900 kg, the attached power supply weighed around 1350 kg and both were held in separate cabinets of roughly 1.5 meters by 0.9 meters by 1.8 meters. It cost US$500,000 ($ as of 2019) or could be leased for US$3,500 a month ($ as of 2019). Its drum memory was originally 2,000 ten-digit words, later expanded to 4,000 words. Memory limitations such as this were to dominate programming for decades afterward. The program instructions were fetched from the spinning drum as the code ran. Efficient execution using drum memory was provided by a combination of hardware architecture: the instruction format included the address of the next instruction; and software: the Symbolic Optimal Assembly Program, SOAP, assigned instructions to the optimal addresses (to the extent possible by static analysis of the source program). Thus many instructions were, when needed, located in the next row of the drum to be read and additional wait time for drum rotation was not required.

In 1951, British scientist Maurice Wilkes developed the concept of microprogramming from the realisation that the central processing unit of a computer could be controlled by a miniature, highly specialised computer program in high-speed ROM. Microprogramming allows the base instruction set to be defined or extended by built-in programs (now called firmware or microcode). This concept greatly simplified CPU development. He first described this at the University of Manchester Computer Inaugural Conference in 1951, then published in expanded form in IEEE Spectrum in 1955.

It was widely used in the CPUs and floating-point units of mainframe and other computers; it was implemented for the first time in EDSAC 2, which also used multiple identical "bit slices" to simplify design. Interchangeable, replaceable tube assemblies were used for each bit of the processor.

Magnetic drum memories were developed for the US Navy during WW II with the work continuing at Engineering Research Associates (ERA) in 1946 and 1947. ERA, then a part of Univac included a drum memory in its 1103, announced in February 1953. The first mass-produced computer, the IBM 650, also announced in 1953 had about 8.5 kilobytes of drum memory.

Magnetic core memory patented in 1949 with its first usage demonstrated for the Whirlwind computer in August 1953. Commercialization followed quickly. Magnetic core was used in peripherals of the IBM 702 delivered in July 1955, and later in the 702 itself. The IBM 704 (1955) and the Ferranti Mercury (1957) used magnetic-core memory. It went on to dominate the field into the 1970s, when it was replaced with semiconductor memory. Magnetic core peaked in volume about 1975 and declined in usage and market share thereafter.

As late as 1980, PDP-11/45 machines using magnetic-core main memory and drums for swapping were still in use at many of the original UNIX sites.

The bipolar transistor was invented in 1947. From 1955 onward transistors replaced vacuum tubes in computer designs, giving rise to the "second generation" of computers. Compared to vacuum tubes, transistors have many advantages: they are smaller, and require less power than vacuum tubes, so give off less heat. Silicon junction transistors were much more reliable than vacuum tubes and had longer, indefinite, service life. Transistorized computers could contain tens of thousands of binary logic circuits in a relatively compact space. Transistors greatly reduced computers' size, initial cost, and operating cost.
Typically, second-generation computers were composed of large numbers of printed circuit boards such as the IBM Standard Modular System
each carrying one to four logic gates or flip-flops.

At the University of Manchester, a team under the leadership of Tom Kilburn designed and built a machine using the newly developed transistors instead of valves. Initially the only devices available were germanium point-contact transistors, less reliable than the valves they replaced but which consumed far less power. Their first transistorised computer and the first in the world, was operational by 1953, and a second version was completed there in April 1955. The 1955 version used 200 transistors, 1,300 solid-state diodes, and had a power consumption of 150 watts. However, the machine did make use of valves to generate its 125 kHz clock waveforms and in the circuitry to read and write on its magnetic drum memory, so it was not the first completely transistorized computer.

That distinction goes to the Harwell CADET of 1955, built by the electronics division of the Atomic Energy Research Establishment at Harwell. The design featured a 64-kilobyte magnetic drum memory store with multiple moving heads that had been designed at the National Physical Laboratory, UK. By 1953 this team had transistor circuits operating to read and write on a smaller magnetic drum from the Royal Radar Establishment. The machine used a low clock speed of only 58 kHz to avoid having to use any valves to generate the clock waveforms.

CADET used 324 point-contact transistors provided by the UK company Standard Telephones and Cables; 76 junction transistors were used for the first stage amplifiers for data read from the drum, since point-contact transistors were too noisy. From August 1956 CADET was offering a regular computing service, during which it often executed continuous computing runs of 80 hours or more. Problems with the reliability of early batches of point contact and alloyed junction transistors meant that the machine's mean time between failures was about 90 minutes, but this improved once the more reliable bipolar junction transistors became available.

The Manchester University Transistor Computer's design was adopted by the local engineering firm of Metropolitan-Vickers in their Metrovick 950, the first commercial transistor computer anywhere. Six Metrovick 950s were built, the first completed in 1956. They were successfully deployed within various departments of the company and were in use for about five years. A second generation computer, the IBM 1401, captured about one third of the world market. IBM installed more than ten thousand 1401s between 1960 and 1964.

Transistorized electronics improved not only the CPU (Central Processing Unit), but also the peripheral devices. The second generation disk data storage units were able to store tens of millions of letters and digits. Next to the fixed disk storage units, connected to the CPU via high-speed data transmission, were removable disk data storage units. A removable disk pack can be easily exchanged with another pack in a few seconds. Even if the removable disks' capacity is smaller than fixed disks, their interchangeability guarantees a nearly unlimited quantity of data close at hand. Magnetic tape provided archival capability for this data, at a lower cost than disk.

Many second-generation CPUs delegated peripheral device communications to a secondary processor. For example, while the communication processor controlled card reading and punching, the main CPU executed calculations and binary branch instructions. One databus would bear data between the main CPU and core memory at the CPU's fetch-execute cycle rate, and other databusses would typically serve the peripheral devices. On the PDP-1, the core memory's cycle time was 5 microseconds; consequently most arithmetic instructions took 10 microseconds (100,000 operations per second) because most operations took at least two memory cycles; one for the instruction, one for the operand data fetch.

During the second generation remote terminal units (often in the form of Teleprinters like a Friden Flexowriter) saw greatly increased use. Telephone connections provided sufficient speed for early remote terminals and allowed hundreds of kilometers separation between remote-terminals and the computing center. Eventually these stand-alone computer networks would be generalized into an interconnected "network of networks"—the Internet.

The early 1960s saw the advent of supercomputing. The Atlas was a joint development between the University of Manchester, Ferranti, and Plessey, and was first installed at Manchester University and officially commissioned in 1962 as one of the world's first supercomputers – considered to be the most powerful computer in the world at that time. It was said that whenever Atlas went offline half of the United Kingdom's computer capacity was lost. It was a second-generation machine, using discrete germanium transistors. Atlas also pioneered the Atlas Supervisor, "considered by many to be the first recognisable modern operating system".

In the US, a series of computers at Control Data Corporation (CDC) were designed by Seymour Cray to use innovative designs and parallelism to achieve superior computational peak performance. The CDC 6600, released in 1964, is generally considered the first supercomputer. The CDC 6600 outperformed its predecessor, the IBM 7030 Stretch, by about a factor of 3. With performance of about 1 megaFLOPS, the CDC 6600 was the world's fastest computer from 1964 to 1969, when it relinquished that status to its successor, the CDC 7600.

The "third-generation" of digital electronic computers used integrated circuits as the basis of their logic.

The idea of the integrated circuit was conceived by a radar scientist working for the Royal Radar Establishment of the Ministry of Defence, Geoffrey W.A. Dummer. 

The first practical integrated circuits were invented by Jack Kilby at Texas Instruments and Robert Noyce at Fairchild Semiconductor. Kilby recorded his initial ideas concerning the integrated circuit in July 1958, successfully demonstrating the first working integrated example on 12 September 1958. Noyce also came up with his own idea of an integrated circuit half a year after Kilby. His chip solved many practical problems that Kilby's had not. Produced at Fairchild Semiconductor, it was made of silicon, whereas Kilby's chip was made of germanium. Fairchild's planar process then allowed integrated circuits to be laid out using the same principles as those of printed circuits.

Third generation (integrated circuit) computers first appeared in the early 1960s in computers developed for government purposes, and then in commercial computers beginning in the middle 1960s.

The "fourth-generation" of digital electronic computers used microprocessors as the basis of their logic. 

While the subject of exactly which device was the first microprocessor is contentious, partly due to lack of agreement on the exact definition of the term "microprocessor", it is largely undisputed that the first single-chip microprocessor was the Intel 4004, designed and realized by Ted Hoff, Federico Faggin, and Stanley Mazor at Intel. It should be noted that Tadashi Sasaki and Masatoshi Shima of Busicom, a calculator manufacturer, had the initial insight that the CPU be a 4-bit integrated circuit, and that Intel could supply the ICs.
While the earliest microprocessor ICs literally contained only the processor, i.e. the central processing unit, of a computer, their progressive development naturally led to chips containing most or all of the internal electronic parts of a computer. The integrated circuit in the image on the right, for example, an Intel 8742, is an 8-bit microcontroller that includes a CPU running at 12 MHz, 128 bytes of RAM, 2048 bytes of EPROM, and I/O in the same chip.

During the 1960s there was considerable overlap between second and third generation technologies. IBM implemented its IBM Solid Logic Technology modules in hybrid circuits for the IBM System/360 in 1964. As late as 1975, Sperry Univac continued the manufacture of second-generation machines such as the UNIVAC 494. The Burroughs large systems such as the B5000 were stack machines, which allowed for simpler programming. These pushdown automatons were also implemented in minicomputers and microprocessors later, which influenced programming language design. Minicomputers served as low-cost computer centers for industry, business and universities. It became possible to simulate analog circuits with the "simulation program with integrated circuit emphasis", or SPICE (1971) on minicomputers, one of the programs for electronic design automation ().
The microprocessor led to the development of the microcomputer, small, low-cost computers that could be owned by individuals and small businesses. Microcomputers, the first of which appeared in the 1970s, became ubiquitous in the 1980s and beyond.

While which specific system is considered the first microcomputer is a matter of debate, as there were several unique hobbyist systems developed based on the Intel 4004 and its successor, the Intel 8008, the first commercially available microcomputer kit was the Intel 8080-based Altair 8800, which was announced in the January 1975 cover article of "Popular Electronics". However, this was an extremely limited system in its initial stages, having only 256 bytes of DRAM in its initial package and no input-output except its toggle switches and LED register display. Despite this, it was initially surprisingly popular, with several hundred sales in the first year, and demand rapidly outstripped supply. Several early third-party vendors such as Cromemco and Processor Technology soon began supplying additional S-100 bus hardware for the Altair 8800.

In April 1975 at the Hannover Fair, Olivetti presented the P6060, the world's first complete, pre-assembled personal computer system. The central processing unit consisted of two cards, code named PUCE1 and PUCE2, and unlike most other personal computers was built with TTL components rather than a microprocessor. It had one or two 8" floppy disk drives, a 32-character plasma display, 80-column graphical thermal printer, 48 Kbytes of RAM, and BASIC language. It weighed . As a complete system, this was a significant step from the Altair, though it never achieved the same success. It was in competition with a similar product by IBM that had an external floppy disk drive.

From 1975 to 1977, most microcomputers, such as the MOS Technology KIM-1, the Altair 8800, and some versions of the Apple I, were sold as kits for do-it-yourselfers. Pre-assembled systems did not gain much ground until 1977, with the introduction of the Apple II, the Tandy TRS-80, the first SWTPC computers, and the Commodore PET. Computing has evolved with microcomputer architectures, with features added from their larger brethren, now dominant in most market segments.

A NeXT Computer and its object-oriented development tools and libraries were used by Tim Berners-Lee and Robert Cailliau at CERN to develop the world's first web server software, CERN httpd, and also used to write the first web browser, WorldWideWeb. These facts, along with the close association with Steve Jobs, secure the 68030 NeXT a place in history as one of the most significant computers of all time.

Systems as complicated as computers require very high reliability. ENIAC remained on, in continuous operation from 1947 to 1955, for eight years before being shut down. Although a vacuum tube might fail, it would be replaced without bringing down the system. By the simple strategy of never shutting down ENIAC, the failures were dramatically reduced. The vacuum-tube SAGE air-defense computers became remarkably reliable – installed in pairs, one off-line, tubes likely to fail did so when the computer was intentionally run at reduced power to find them. Hot-pluggable hard disks, like the hot-pluggable vacuum tubes of yesteryear, continue the tradition of repair during continuous operation. Semiconductor memories routinely have no errors when they operate, although operating systems like Unix have employed memory tests on start-up to detect failing hardware. Today, the requirement of reliable performance is made even more stringent when server farms are the delivery platform. Google has managed this by using fault-tolerant software to recover from hardware failures, and is even working on the concept of replacing entire server farms on-the-fly, during a service event.

In the 21st century, multi-core CPUs became commercially available. Content-addressable memory (CAM) has become inexpensive enough to be used in networking, and is frequently used for on-chip cache memory in modern microprocessors, although no computer system has yet implemented hardware CAMs for use in programming languages. Currently, CAMs (or associative arrays) in software are programming-language-specific. Semiconductor memory cell arrays are very regular structures, and manufacturers prove their processes on them; this allows price reductions on memory products. During the 1980s, CMOS logic gates developed into devices that could be made as fast as other circuit types; computer power consumption could therefore be decreased dramatically. Unlike the continuous current draw of a gate based on other logic types, a CMOS gate only draws significant current during the 'transition' between logic states, except for leakage.

This has allowed computing to become a commodity which is now ubiquitous, embedded in many forms, from greeting cards and telephones to satellites. The thermal design power which is dissipated during operation has become as essential as computing speed of operation. In 2006 servers consumed 1.5% of the total energy budget of the U.S. The energy consumption of computer data centers was expected to double to 3% of world consumption by 2011. The SoC (system on a chip) has compressed even more of the integrated circuitry into a single chip; SoCs are enabling phones and PCs to converge into single hand-held wireless mobile devices.

MIT Technology Review reported 10 November 2017 that IBM has created a 50-qubit computer; currently its quantum state lasts 50 microseconds. Physical Review X reported a technique for 'single-gate sensing as a viable readout method for spin qubits' (a singlet-triplet spin state in silicon) on 26 November 2018. A Google team has succeeded in operating their RF pulse modulator chip at 3 Kelvin, simplifying the cryogenics of their 72-qubit computer, which is setup to operate at 0.3 Kelvin; but the readout circuitry and another driver remain to be brought into the cryogenics. "See: Quantum supremacy"

Computing hardware and its software have even become a metaphor for the operation of the universe.

An indication of the rapidity of development of this field can be inferred from the history of the seminal 1947 article by Burks, Goldstine and von Neumann. By the time that anyone had time to write anything down, it was obsolete. After 1945, others read John von Neumann's "First Draft of a Report on the EDVAC", and immediately started implementing their own systems. To this day, the rapid pace of development has continued, worldwide.

A 1966 article in "Time" predicted that: "By 2000, the machines will be producing so much that everyone in the U.S. will, in effect, be independently wealthy. How to use leisure time will be a major problem."






</doc>
<doc id="13637" url="https://en.wikipedia.org/wiki?curid=13637" title="Hausdorff space">
Hausdorff space

In topology and related branches of mathematics, a Hausdorff space, separated space or T space is a topological space where for any two distinct points there exists a neighbourhood of each which is disjoint from the neighbourhood of the other. Of the many separation axioms that can be imposed on a topological space, the "Hausdorff condition" (T) is the most frequently used and discussed. It implies the uniqueness of limits of sequences, nets, and filters.

Hausdorff spaces are named after Felix Hausdorff, one of the founders of topology. Hausdorff's original definition of a topological space (in 1914) included the Hausdorff condition as an axiom.

Points "x" and "y" in a topological space "X" can be "separated by neighbourhoods" if there exists a neighbourhood "U" of "x" and a neighbourhood "V" of "y" such that "U" and "V" are disjoint ().
"X" is a Hausdorff space if all distinct points in "X" are pairwise neighbourhood-separable. This condition is the third separation axiom (after T and T), which is why Hausdorff spaces are also called "T spaces". The name "separated space" is also used.

A related, but weaker, notion is that of a preregular space. "X" is a preregular space if any two topologically distinguishable points can be separated by disjoint neighbourhoods. Preregular spaces are also called "R spaces".

The relationship between these two conditions is as follows. A topological space is Hausdorff if and only if it is both preregular (i.e. topologically distinguishable points are separated by neighbourhoods) and Kolmogorov (i.e. distinct points are topologically distinguishable). A topological space is preregular if and only if its Kolmogorov quotient is Hausdorff.

For a topological space "X", the following are equivalent:

Almost all spaces encountered in analysis are Hausdorff; most importantly, the real numbers (under the standard metric topology on real numbers) are a Hausdorff space. More generally, all metric spaces are Hausdorff. In fact, many spaces of use in analysis, such as topological groups and topological manifolds, have the Hausdorff condition explicitly stated in their definitions.

A simple example of a topology that is T but is not Hausdorff is the cofinite topology defined on an infinite set.

Pseudometric spaces typically are not Hausdorff, but they are preregular, and their use in analysis is usually only in the construction of Hausdorff gauge spaces. Indeed, when analysts run across a non-Hausdorff space, it is still probably at least preregular, and then they simply replace it with its Kolmogorov quotient, which is Hausdorff.

In contrast, non-preregular spaces are encountered much more frequently in abstract algebra and algebraic geometry, in particular as the Zariski topology on an algebraic variety or the spectrum of a ring. They also arise in the model theory of intuitionistic logic: every complete Heyting algebra is the algebra of open sets of some topological space, but this space need not be preregular, much less Hausdorff, and in fact usually is neither. The related concept of Scott domain also consists of non-preregular spaces.

While the existence of unique limits for convergent nets and filters implies that a space is Hausdorff, there are non-Hausdorff T spaces in which every convergent sequence has a unique limit.

Subspaces and products of Hausdorff spaces are Hausdorff, but quotient spaces of Hausdorff spaces need not be Hausdorff. In fact, "every" topological space can be realized as the quotient of some Hausdorff space.

Hausdorff spaces are T, meaning that all singletons are closed. Similarly, preregular spaces are R.

Another nice property of Hausdorff spaces is that compact sets are always closed. This may fail in non-Hausdorff spaces such as Sierpiński space. 

The definition of a Hausdorff space says that points can be separated by neighborhoods. It turns out that this implies something which is seemingly stronger: in a Hausdorff space every pair of disjoint compact sets can also be separated by neighborhoods, in other words there is a neighborhood of one set and a neighborhood of the other, such that the two neighborhoods are disjoint. This is an example of the general rule that compact sets often behave like points.

Compactness conditions together with preregularity often imply stronger separation axioms. For example, any locally compact preregular space is completely regular. Compact preregular spaces are normal, meaning that they satisfy Urysohn's lemma and the Tietze extension theorem and have partitions of unity subordinate to locally finite open covers. The Hausdorff versions of these statements are: every locally compact Hausdorff space is Tychonoff, and every compact Hausdorff space is normal Hausdorff.

The following results are some technical properties regarding maps (continuous and otherwise) to and from Hausdorff spaces.

Let "f" : "X" → "Y" be a continuous function and suppose "Y" is Hausdorff. Then the graph of "f", formula_1, is a closed subset of "X" × "Y".

Let "f" : "X" → "Y" be a function and let formula_2 be its kernel regarded as a subspace of "X" × "X".

If "f,g" : "X" → "Y" are continuous maps and "Y" is Hausdorff then the equalizer formula_3 is closed in "X". It follows that if "Y" is Hausdorff and "f" and "g" agree on a dense subset of "X" then "f" = "g". In other words, continuous functions into Hausdorff spaces are determined by their values on dense subsets.

Let "f" : "X" → "Y" be a closed surjection such that "f"("y") is compact for all "y" ∈ "Y". Then if "X" is Hausdorff so is "Y".

Let "f" : "X" → "Y" be a quotient map with "X" a compact Hausdorff space. Then the following are equivalent:

All regular spaces are preregular, as are all Hausdorff spaces. There are many results for topological spaces that hold for both regular and Hausdorff spaces.
Most of the time, these results hold for all preregular spaces; they were listed for regular and Hausdorff spaces separately because the idea of preregular spaces came later.
On the other hand, those results that are truly about regularity generally do not also apply to nonregular Hausdorff spaces.

There are many situations where another condition of topological spaces (such as paracompactness or local compactness) will imply regularity if preregularity is satisfied.
Such conditions often come in two versions: a regular version and a Hausdorff version.
Although Hausdorff spaces are not, in general, regular, a Hausdorff space that is also (say) locally compact will be regular, because any Hausdorff space is preregular.
Thus from a certain point of view, it is really preregularity, rather than regularity, that matters in these situations.
However, definitions are usually still phrased in terms of regularity, since this condition is better known than preregularity.

See History of the separation axioms for more on this issue.

The terms "Hausdorff", "separated", and "preregular" can also be applied to such variants on topological spaces as uniform spaces, Cauchy spaces, and convergence spaces.
The characteristic that unites the concept in all of these examples is that limits of nets and filters (when they exist) are unique (for separated spaces) or unique up to topological indistinguishability (for preregular spaces).

As it turns out, uniform spaces, and more generally Cauchy spaces, are always preregular, so the Hausdorff condition in these cases reduces to the T condition.
These are also the spaces in which completeness makes sense, and Hausdorffness is a natural companion to completeness in these cases.
Specifically, a space is complete if and only if every Cauchy net has at "least" one limit, while a space is Hausdorff if and only if every Cauchy net has at "most" one limit (since only Cauchy nets can have limits in the first place).

The algebra of continuous (real or complex) functions on a compact Hausdorff space is a commutative C*-algebra, and conversely by the Banach–Stone theorem one can recover the topology of the space from the algebraic properties of its algebra of continuous functions. This leads to noncommutative geometry, where one considers noncommutative C*-algebras as representing algebras of functions on a noncommutative space.





</doc>
<doc id="13644" url="https://en.wikipedia.org/wiki?curid=13644" title="Hawkwind">
Hawkwind

Hawkwind are an English rock band and one of the earliest space rock groups. Formed in November 1969, Hawkwind have gone through many incarnations and they have incorporated different styles into their music, including hard rock, progressive rock and psychedelic rock. Their lyrics favour urban and science fiction themes. They are also regarded as an influential proto-punk band.

Dozens of musicians, dancers and writers have worked with the band since their inception. Notable musicians to have performed in the band include Lemmy, Ginger Baker, Nik Turner and Huw Lloyd-Langton, but the band are most closely associated with their founder, the singer, songwriter and guitarist Dave Brock, who is the only remaining original member.

They are best known for the song "Silver Machine", which became a number three UK hit single in 1972, but they scored further hit singles with "Urban Guerrilla" (another Top 40 hit) and "Shot Down in the Night." The band had a run of twenty-two of their albums charting in the UK from 1971 to 1993. 

Dave Brock and Mick Slattery had been in the London-based psychedelic band Famous Cure, and a meeting with bassist John Harrison revealed a mutual interest in electronic music which led the trio to embark upon a new musical venture together. Seventeen-year-old drummer Terry Ollis replied to an advert in a music weekly, while Nik Turner and Michael "Dik Mik" Davies, old acquaintances of Brock, offered help with transport and gear, but were soon pulled into the band.

Gatecrashing a local talent night at the All Saints Hall, Notting Hill, they were so disorganised as to not even have a name, opting for "Group X" at the last minute, nor any songs, choosing to play an extended 20-minute jam on the Byrds' "Eight Miles High." BBC Radio 1 DJ John Peel was in the audience and was impressed enough to tell event organiser, Douglas Smith, to keep an eye on them. Smith signed them up and got them a deal with Liberty Records on the back of a deal he was setting up for Cochise.

The band settled on the name "Hawkwind" after briefly being billed as "Group X" and "Hawkwind Zoo".

An Abbey Road session took place recording demos of "Hurry on Sundown" and others (included on the remasters version of "Hawkwind"), after which Slattery left to be replaced by Huw Lloyd-Langton, who had known Brock from his days working in a music shop selling guitar strings to Brock, then a busker.

Pretty Things guitarist Dick Taylor was brought in to produce the 1970 debut album "Hawkwind". Although it was not a commercial success, it did bring them to the attention of the UK underground scene, which found them playing free concerts, benefit gigs, and festivals. Playing free outside the Bath Festival, they encountered another Ladbroke Grove based band, the Pink Fairies, who shared similar interests in music and recreational activities; a friendship developed which led to the two bands becoming running partners and performing as "Pinkwind". Their use of drugs, however, led to the departure of Harrison, who did not partake, to be replaced briefly by Thomas Crimble (about July 1970 – March 1971). Crimble played on a few BBC sessions before leaving to help organise the Glastonbury Free Festival 1971; he sat in during the band's performance there. Lloyd-Langton also quit, after a bad LSD trip at the Isle of Wight Festival led to a nervous breakdown.

Their follow-up album, 1971's "In Search of Space", brought greater commercial success, reaching number 18 on the UK album charts. This album offered a refinement of the band's image and philosophy courtesy of graphic artist Barney Bubbles and underground press writer Robert Calvert, as depicted in the accompanying "Hawklog" booklet, which would be further developed into the "Space Ritual" stage show. Science fiction author Michael Moorcock and dancer Stacia also started contributing to the band. Dik Mik had left the band, replaced by sound engineer Del Dettmar, but chose to return for this album giving the band two electronics players. Bass player Dave Anderson, who had been in the German band Amon Düül II, had also joined and played on the album but departed before its release because of personal tensions with some other members of the band. Anderson and Lloyd-Langton then formed the short-lived band Amon Din. Meanwhile, Ollis quit, unhappy with the commercial direction the band were heading in.
The addition of bassist Ian "Lemmy" Kilmister and drummer Simon King propelled the band to greater heights. One of the early gigs the band played was a benefit for the Greasy Truckers at The Roundhouse on 13 February 1972. A live album of the concert, "Greasy Truckers Party", was released, and after re-recording the vocal, a single, "Silver Machine", was also released, reaching number three in the UK charts. This generated sufficient funds for the subsequent album "Doremi Fasol Latido" Space Ritual tour. The show featured dancers Stacia and Miss Renee typically performing either topless or wearing only body paint, mime artist Tony Carrera and a light show by Liquid Len and was recorded on the elaborate package "Space Ritual". At the height of their success, in 1973, the band released the single "Urban Guerrilla", which coincided with an IRA bombing campaign in London, so the BBC refused to play it and the band's management reluctantly decided to withdraw it fearing accusations of opportunism, despite the disc having already climbed to number 39 in the UK chart.

Dik Mik departed during 1973 and Calvert ended his association with the band to concentrate on solo projects. Dettmar also indicated that he was to leave the band, so Simon House was recruited as keyboardist and violinist playing live shows, a North America tour and recording the 1974 album "Hall of the Mountain Grill". Dettmar left after a European tour and emigrated to Canada, whilst Alan Powell deputised for an incapacitated King on that European tour, but remained giving the band two drummers.

At the beginning of 1975, the band recorded the album "Warrior on the Edge of Time" in collaboration with Michael Moorcock, loosely based on his Eternal Champion figure. However, during a North American tour in May, Lemmy was caught in possession of amphetamine crossing the border from the US into Canada. The border police mistook the powder for cocaine and he was jailed, forcing the band to cancel some shows. Fed up with his erratic behaviour, the band dismissed the bass player replacing him with their long-standing friend and former Pink Fairies guitarist Paul Rudolph. Lemmy then teamed up with another Pink Fairies guitarist, Larry Wallis, to form Motörhead, named after the last song he had written for Hawkwind.

Calvert made a guest appearance with the band for their headline set at the Reading Festival in August 1975, after which he chose to rejoin the band as a full-time lead vocalist. Stacia chose to relinquish her dancing duties and settle down to family life. The band changed record company to Tony Stratton-Smith's Charisma Records and, on Stratton-Smith's suggestion, band management from Douglas Smith to Tony Howard.

"Astounding Sounds, Amazing Music" is the first album of this era and highlights both Calvert's well-crafted lyrics written with stage performance in mind and a greater proficiency and scope in the music. But on the eve of recording the follow-up "Back on the Streets" single, Turner was dismissed for his erratic live playing and Powell was deemed surplus to requirements. After a tour to promote the single and during the recording of the next album, Rudolph was also dismissed, for allegedly trying to steer the band into a musical direction at odds with Calvert and Brock's vision.

Adrian "Ade" Shaw, who, as bass player for Magic Muscle, had supported Hawkwind on the "Space Ritual" tour, came in for the 1977 album "Quark, Strangeness and Charm". The band continued to enjoy moderate commercial success, but Calvert's mental illness often caused problems. A manic phase saw the band abandon a European tour in France, while a depression phase during a 1978 North American tour convinced Brock to disband the group. In between these two tours, the band had recorded the album "PXR5" in January 1978, but its release was delayed until 1979.

On 23 December 1977 in Barnstaple, Brock and Calvert had performed a one-off gig with Devon band Ark as the Sonic Assassins, and looking for a new project in 1978, bassist Harvey Bainbridge and drummer Martin Griffin were recruited from this event. Steve Swindells was recruited as keyboard player. The band was named Hawklords, (probably for legal reasons, the band having recently split from their management), and recording took place on a farm in Devon using a mobile studio, resulting in the album "25 Years On". King had originally been the drummer for the project but quit during recording sessions to return to London, while House, who had temporarily left the band to join a David Bowie tour, elected to remain with Bowie full-time, but nevertheless contributed violin to these sessions. At the end of the band's UK tour, Calvert, wanting King back in the band, dismissed Griffin, then promptly resigned himself, choosing to pursue a career in literature. Swindells left to record a solo album after an offer had been made to him by the record company ATCO.

In late 1979, Hawkwind reformed with Brock, Bainbridge and King being joined by Huw Lloyd-Langton (who had played on the debut album) and Tim Blake (formerly of Gong), embarking upon a UK tour despite not having a record deal or any product to promote. Some shows were recorded and a deal was made with Bronze Records, resulting in the "Live Seventy Nine" album, quickly followed by the studio album "Levitation". However, during the recording of "Levitation" King quit and Ginger Baker was drafted in for the sessions, but he chose to stay with the band for the tour, during which Blake left to be replaced by Keith Hale.

In 1981 Baker and Hale left after their insistence that Bainbridge should be dismissed was ignored, and Brock and Bainbridge elected to handle synthesisers and sequencers themselves, with drummer Griffin from the Hawklords rejoining. Three albums, which again saw Moorcock contributing lyrics and vocals, were recorded for RCA/Active: "Sonic Attack", the electronic "Church of Hawkwind" and "Choose Your Masques". This band headlined the 1981 Glastonbury Festival and made an appearance at the 1982 Donington Monsters of Rock Festival, as well as continuing to play the summer solstice at Stonehenge Free Festival.

In the early 1980s, Brock had started using drum machines for his home demos and became increasingly frustrated at the inability of drummers to keep perfect time, leading to a succession of drummers coming and going. First, Griffin was ousted and the band tried King again, but, unhappy with his playing at that time, he was rejected. Andy Anderson briefly joined while he was also playing for The Cure, and Robert Heaton also filled the spot briefly prior to the rise of New Model Army. Lloyd Langton Group drummer John Clark did some recording sessions, and in late 1983 Rick Martinez joined the band to play drums on the "Earth Ritual" tour in February and March 1984, later replaced by Clive Deamer.

Turner had returned as a guest for the 1982 "Choose Your Masques" tour and was invited back permanently. Further tours ensued with Phil "Dead Fred" Reeves augmenting the line-up on keyboards and violin, but neither Turner nor Reeves would appear on the only recording of 1983–84, "The Earth Ritual Preview", but there was a guest spot for Lemmy. The "Earth Ritual" tour was filmed for Hawkwind's first video release, "Night of the Hawk".

Alan Davey was a young fan of the band who had sent a tape of his playing to Brock, and Brock chose to oust Reeves moving Bainbridge from bass to keyboards to accommodate Davey. This experimental line-up played at the Stonehenge Free Festival in 1984, which was filmed and release as "Stonehenge 84". Subsequent personal and professional tensions between Brock and Turner led to the latter's expulsion at the beginning of 1985. Clive Deamer, who was deemed "too professional" for the band, was eventually replaced in 1985 by Danny Thompson Jr, a friend of bassist Alan Davey, and remained almost to the end of the decade.

Hawkwind's association with Moorcock climaxed in their most ambitious project, "The Chronicle of the Black Sword", based loosely around the Elric series of books and theatrically staged with Tony Crerar as the central character. Moorcock contributed lyrics, but only performed some spoken pieces on some live dates. The tour was recorded and issued as an album "Live Chronicles" and video "The Chronicle of the Black Sword". A headline appearance at the 1986 Reading Festival was followed by a UK tour to promote the "Live Chronicles" album which was filmed and released as "Chaos". In 1988 the band recorded the album "The Xenon Codex" with Guy Bidmead, but all was not well in the band and soon after, both Lloyd-Langton and Thompson departed.

Drummer Richard Chadwick, who joined in the summer of 1988, had been playing in small alternative free festival bands, most notably Bath's Smart Pils, for a decade and had frequently crossed paths with Hawkwind and Brock. He was initially invited simply to play with the band, but eventually replaced stand in drummer Mick Kirton to become the band's drummer to the present day.

To fill in the gap of lead sound, lost when Lloyd-Langton left, violinist House was re-instated into the line-up in 1989 (having previously been a member from 1974 until 1978), and, notably, Hawkwind embarked on their first North American visit in eleven years (since the somewhat disastrous 1978 tour), in which House did not partake. The successfully received tour was the first of several over the coming years, in an effort by the band to re-introduce themselves to the American market.

Bridget Wishart, an associate of Chadwick's from the festival circuit, also joined to become the band's one and only singing front-woman, the band had been fronted in earlier days by Stacia but only as a dancer. This band produced two albums, 1990's "Space Bandits" and 1991's "Palace Springs" and also filmed a 1-hour appearance for the "Bedrock TV" series.

1990 saw Hawkwind tour North America again, the second instalment in a series of American visits made at around this time in an effort to re-establish the Hawkwind brand in America. The original business plan was to hold three consecutive US tours, annually, from 1989–1991, with the first losing money, the second breaking even, and the third turning a profit, ultimately bringing Hawkwind back into recognition across the Atlantic. Progress, however, was somewhat stunted, due to ex-member Nik Turner touring the United States with his own band at the time, in which the shows were often marketed as Hawkwind.

Still supporting Space Bandits, 1991 commenced with perhaps the most surprising Hawkwind tour in the band's history, without Dave Brock. Brock's temporary replacement was former Smart Pils guitarist Steve Bemand (who had played with Chadwick and Wishart in the Demented Stoats). The tour began in Amsterdam on 12 March and took in Germany, Greece, Italy and France before wrapping up in Belgium on 10 April after 24 dates.

In 1991 Bainbridge, House and Wishart departed and the band continued as a three piece relying heavily on synthesisers and sequencers to create a wall-of-sound. The 1992 album "Electric Tepee" combined hard rock and light ambient pieces, while "It is the Business of the Future to be Dangerous" is almost devoid of the rock leanings. "The Business Trip" is a record of the previous album's tour, but rockier as would be expected from a live outing. The "White Zone" album was released under the alias Psychedelic Warriors to distance itself entirely from the rock expectancy of Hawkwind.

A general criticism of techno music at that time was its facelessness and lack of personality, which the band were coming to feel also plagued them. Ron Tree had known the band on the festival circuit and offered his services as a front-man, and the band duly employed him for the album "Alien 4" and its accompanying tour which resulted in the album "Love in Space" and "video".

In 1996, unhappy with the musical direction of the band, bassist Davey left, forming his own Middle-Eastern flavoured hard-rock group Bedouin and a Motörhead tribute act named Ace of Spades. His bass playing role was reluctantly picked up by singer Tree and the band were joined full-time by lead guitarist Jerry Richards (another stalwart of the festival scene, playing for Tubilah Dog who had merged with Brock's Agents of Chaos during 1988) for the albums "Distant Horizons" and "In Your Area". Rasta chanter Captain Rizz also joined the band for guest spots during live shows.

Hawkestra — a re-union event featuring appearances from past and present members — had originally been intended to coincide with the band's 30th anniversary and the release of the career spanning "Epocheclipse – 30 Year Anthology" set, but logistical problems delayed it until 21 October 2000. It took place at the Brixton Academy with about 20 members taking part in a 3+ hour set which was filmed and recorded. Guests included Samantha Fox who sang "Master of the Universe". However, arguments and disputes over financial recompense and musical input resulted in the prospect of the event being re-staged unlikely, and any album or DVD release being indefinitely shelved.

The Hawkestra had set a template for Brock to assemble a core band of Tree, Brock, Richards, Davey, Chadwick and for the use of former members as guests on live shows and studio recordings. The 2000 Christmas Astoria show was recorded with contributions from House, Blake, Rizz, Moorcock, Jez Huggett and Keith Kniveton and released as "Yule Ritual" the following year. In 2001, Davey agreed to rejoin the band permanently, but only after the departure of Tree and Richards.

Meanwhile, having rekindled relationships with old friends at the Hawkestra, Turner organised further Hawkestra gigs resulting in the formation of xhawkwind.com, a band consisting mainly of ex-Hawkwind members and playing old Hawkwind songs. An appearance at Guilfest in 2002 led to confusion as to whether this actually was Hawkwind, sufficiently irking Brock into taking legal action to prohibit Turner from trading under the name Hawkwind. Turner lost the case and the band began performing as Space Ritual.

An appearance at the Canterbury Sound Festival in August 2001, resulting in another live album "Canterbury Fayre 2001", saw guest appearances from Lloyd-Langton, House, Kniveton with Arthur Brown on "Silver Machine". The band organised the first of their own weekend festivals, named Hawkfest, in Devon in the summer of 2002. Brown joined the band in 2002 for a Winter tour which featured some Kingdom Come songs and saw appearances from Blake and Lloyd-Langton, the Newcastle show being released on DVD as "Out of the Shadows" and the London show on CD as "Spaced Out in London".

In 2005 a new album "Take Me to Your Leader" was released. Recorded by the core band of Brock/Davey/Chadwick, contributors included new keyboardist Jason Stuart, Arthur Brown, tabloid writer and TV personality Matthew Wright, 1970s New Wave singer Lene Lovich, Simon House and Jez Huggett. This was followed in 2006 by the CD/DVD "Take Me to Your Future".

The band were the subject of an hour-long television documentary entitled "Hawkwind: Do Not Panic" that aired on BBC Four as part of the "Originals" series. It was broadcast on 30 March 2007 and repeated on 10 August 2007. Although Brock participated in its making he did not appear in the programme, it is alleged that he requested all footage of himself be removed after he was denied any artistic control over the documentary. In one of the documentary's opening narratives regarding Brock, it is stated that he declined to be interviewed for the programme because of Nik Turner's involvement, indicating that the two men have still not reconciled over the xhawkwind.com incident.

December 2006 saw the official departure of Alan Davey, who left to perform and record with two new bands: Gunslinger and Thunor. He was replaced by Mr Dibs, a long-standing member of the road crew. The band performed at their annual Hawkfest festival and headlined the US festival Nearfest and played gigs in PA and NY. At the end of 2007, Tim Blake once again joined the band filling the lead role playing keyboards and theremin. The band played 5 Christmas dates, the London show being released as an audio CD and video DVD under the title "Knights of Space".

In January 2008 the band reversed its anti-taping policy, long a sore-point with many fans, announcing that it would allow audio recording and non-commercial distribution of such recordings, provided there was no competing official release. At the end of 2008, Atomhenge Records (a subsidiary of Cherry Red Records) commenced the re-issuing of Hawkwind's back catalogue from the years 1976 through to 1997 with the release of two triple CD anthologies "Spirit of the Age (anthology 1976–84)" and "The Dream Goes On (anthology 1985–97)".

On 8 September 2008 keyboard player Jason Stuart died due to a brain haemorrhage. In October 2008, Niall Hone (former Tribe of Cro) joined Hawkwind for their Winter 2008 tour playing guitar, along with returning synth/theremin player Tim Blake. In this period, Hone also occasionally played bass guitar alongside Mr Dibs and used laptops for live electronic improvisation.

In 2009, the band began occasionally featuring Jon Sevink, from The Levellers as guest violinist at some shows. Later that year, Hawkwind embarked on a winter tour to celebrate the band's 40th anniversary, including two gigs on 28 and 29 August marking the anniversary of their first live performances. In 2010, Hawkwind held their annual Hawkfest at the site of the original Isle of Wight Festival, marking the 40th anniversary of their appearance there.

On 21 June 2010, Hawkwind released a studio album entitled "Blood of the Earth" on Eastworld Records. During and since the "Blood of the Earth" support tours, Hone's primary on-stage responsibility shifted to bass, while Mr. Dibs moved to a more traditional lead singer/front man role.

In 2011, Hawkwind toured Australia for the second time.

April 2012 saw the release of a new album, "Onward", again on Eastworld. Keyboardist Dead Fred rejoined Hawkwind for the 2012 tour in support of "Onward" and has since remained with the band. In November 2012, Brock, Chadwick and Hone — credited as "Hawkwind Light Orchestra" — released "Stellar Variations" on Esoteric Recordings.

2013 marked the first Hawkeaster, a two-day festival held in Seaton, Devon during the Easter weekend. A US tour was booked for October 2013, but due to health issues, was postponed and later cancelled.

In February 2014, as part of a one-off Space Ritual performance, Hawkwind performed at the O2 Shepherd's Bush Empire featuring an appearance by Brian Blessed for the spoken word element of Sonic Attack; a studio recording of this performance was released as a single in September 2014. Later in the year, former Soft Machine guitarist John Etheridge joined the live line-up of the band, though he had departed again prior to early 2015 dates.

Following Hawkeaster 2015, Hawkwind made their debut visit to Japan, playing two sold-out shows in Tokyo. Hawkwind performed two Solstice Ritual shows in December 2015, with Steve Hillage guesting, and Haz Wheaton joining Hawkwind on bass guitar. Wheaton is a former member of the band's road crew who had previously appeared with Technicians of Spaceship Hawkwind, a "skeleton crew" spin off live band. Additionally, he had guested on bass for Dave Brock's solo album "Brockworld" released earlier in the year.

The band released "The Machine Stops" on 15 April 2016. The album marked Wheaton's first appearance on a Hawkwind studio album, and the first album without Tim Blake's involvement since he had rejoined the band in 2010 and appeared on "Blood of the Earth". His departure was offset by increased synthesiser work by Hone and Brock.

Dead Fred's last live appearance with Hawkwind was at The Eastbourne Winter Gardens April 1, 2016. Hone took over keyboards and synth duties live until though Blake returned for shows in summer 2016.

It was announced in November 2016 that Hawkwind were recording a new studio album, entitled "Into The Woods". Keyboardist-guitarist Magnus Martin replaced both Hone and Blake in the lineup for the new album, leaving the 2017 core band composed of Brock, Chadwick, Mr Dibs, Wheaton and Martin.

In 2018, Hawkwind recorded an acoustic album "The Road to Utopia" consisting primarily of cover versions of their 1970s songs with production, arrangement and additional orchestrations by Mike Batt and a guest appearance from Eric Clapton. Batt is scheduled to conduct a series concerts of Hawkwind songs featuring the band and orchestra in October and November.

In August 2018 Haz Wheaton left and joined Electric Wizard. Niall Hone returned on bass. Mr Dibs left on August 22 stating ‘irreconcilable differences’ in a statement on the Hawkwind fans Facebook page.

Hawkwind have been cited as an influence by artists such as Monster Magnet, the Sex Pistols (who covered "Silver Machine"), Henry Rollins and Dez Cadena of Black Flag, Ty Segall, The Mekano Set, and Ozric Tentacles.

Hard rock musician Lemmy of the band Motörhead gained a lot from his tenure in Hawkwind. He has remarked, "I really found myself as an instrumentalist in Hawkwind. Before that I was just a guitar player who was pretending to be good, when actually I was no good at all. In Hawkwind I became a good bass player. It was where I learned I was good at something."



There are three biographies of Hawkwind.


</doc>
<doc id="13645" url="https://en.wikipedia.org/wiki?curid=13645" title="Horse">
Horse

The horse ("Equus ferus caballus") is one of two extant subspecies of "Equus ferus". It is an odd-toed ungulate mammal belonging to the taxonomic family Equidae. The horse has evolved over the past 45 to 55 million years from a small multi-toed creature, "Eohippus", into the large, single-toed animal of today. Humans began domesticating horses around 4000 BC, and their domestication is believed to have been widespread by 3000 BC. Horses in the subspecies "caballus" are domesticated, although some domesticated populations live in the wild as feral horses. These feral populations are not true wild horses, as this term is used to describe horses that have never been domesticated, such as the endangered Przewalski's horse, a separate subspecies, and the only remaining true wild horse. There is an extensive, specialized vocabulary used to describe equine-related concepts, covering everything from anatomy to life stages, size, colors, markings, breeds, locomotion, and behavior.

Horses' anatomy enables them to make use of speed to escape predators and they have a well-developed sense of balance and a strong fight-or-flight response. Related to this need to flee from predators in the wild is an unusual trait: horses are able to sleep both standing up and lying down, with younger horses tending to sleep significantly more than adults. Female horses, called mares, carry their young for approximately 11 months, and a young horse, called a foal, can stand and run shortly following birth. Most domesticated horses begin training under saddle or in harness between the ages of two and four. They reach full adult development by age five, and have an average lifespan of between 25 and 30 years.

Horse breeds are loosely divided into three categories based on general temperament: spirited "hot bloods" with speed and endurance; "cold bloods", such as draft horses and some ponies, suitable for slow, heavy work; and "warmbloods", developed from crosses between hot bloods and cold bloods, often focusing on creating breeds for specific riding purposes, particularly in Europe. There are more than 300 breeds of horse in the world today, developed for many different uses.

Horses and humans interact in a wide variety of sport competitions and non-competitive recreational pursuits, as well as in working activities such as police work, agriculture, entertainment, and therapy. Horses were historically used in warfare, from which a wide variety of riding and driving techniques developed, using many different styles of equipment and methods of control. Many products are derived from horses, including meat, milk, hide, hair, bone, and pharmaceuticals extracted from the urine of pregnant mares. Humans provide domesticated horses with food, water and shelter, as well as attention from specialists such as veterinarians and farriers.

Specific terms and specialized language are used to describe equine anatomy, different life stages, colors and breeds.

Depending on breed, management and environment, the modern domestic horse has a life expectancy of 25 to 30 years. Uncommonly, a few animals live into their 40s and, occasionally, beyond. The oldest verifiable record was "Old Billy", a 19th-century horse that lived to the age of 62. In modern times, Sugar Puff, who had been listed in "Guinness World Records" as the world's oldest living pony, died in 2007 at age 56.

Regardless of a horse or pony's actual birth date, for most competition purposes a year is added to its age each January 1 of each year in the Northern Hemisphere and each August 1 in the Southern Hemisphere. The exception is in endurance riding, where the minimum age to compete is based on the animal's actual calendar age.

The following terminology is used to describe horses of various ages:

In horse racing, these definitions may differ: For example, in the British Isles, Thoroughbred horse racing defines colts and fillies as less than five years old. However, Australian Thoroughbred racing defines colts and fillies as less than four years old.

The height of horses is measured at the highest point of the withers, where the neck meets the back. This point is used because it is a stable point of the anatomy, unlike the head or neck, which move up and down in relation to the body of the horse.

In English-speaking countries, the height of horses is often stated in units of hands and inches: one hand is equal to . The height is expressed as the number of full hands, followed by a point, then the number of additional inches, and ending with the abbreviation "h" or "hh" (for "hands high"). Thus, a horse described as "15.2 h" is 15 hands plus 2 inches, for a total of in height.
The size of horses varies by breed, but also is influenced by nutrition. Light riding horses usually range in height from and can weigh from . Larger riding horses usually start at about and often are as tall as , weighing from . Heavy or draft horses are usually at least high and can be as tall as high. They can weigh from about .

The largest horse in recorded history was probably a Shire horse named Mammoth, who was born in 1848. He stood high and his peak weight was estimated at . The current record holder for the world's smallest horse is Thumbelina, a fully mature miniature horse affected by dwarfism. She is tall and weighs .

Ponies are taxonomically the same animals as horses. The distinction between a horse and pony is commonly drawn on the basis of height, especially for competition purposes. However, height alone is not dispositive; the difference between horses and ponies may also include aspects of phenotype, including conformation and temperament.

The traditional standard for height of a horse or a pony at maturity is . An animal 14.2 h or over is usually considered to be a horse and one less than 14.2 h a pony, but there are many exceptions to the traditional standard. In Australia, ponies are considered to be those under . For competition in the Western division of the United States Equestrian Federation, the cutoff is . The International Federation for Equestrian Sports, the world governing body for horse sport, uses metric measurements and defines a pony as being any horse measuring less than at the withers without shoes, which is just over 14.2 h, and , or just over 14.2 h, with shoes.

Height is not the sole criterion for distinguishing horses from ponies. Breed registries for horses that typically produce individuals both under and over 14.2 h consider all animals of that breed to be horses regardless of their height. Conversely, some pony breeds may have features in common with horses, and individual animals may occasionally mature at over 14.2 h, but are still considered to be ponies.

Ponies often exhibit thicker manes, tails, and overall coat. They also have proportionally shorter legs, wider barrels, heavier bone, shorter and thicker necks, and short heads with broad foreheads. They may have calmer temperaments than horses and also a high level of intelligence that may or may not be used to cooperate with human handlers. Small size, by itself, is not an exclusive determinant. For example, the Shetland pony which averages , is considered a pony. Conversely, breeds such as the Falabella and other miniature horses, which can be no taller than , are classified by their registries as very small horses, not ponies.

Horses have 64 chromosomes. The horse genome was sequenced in 2007. It contains 2.7 billion DNA base pairs, which is larger than the dog genome, but smaller than the human genome or the bovine genome. The map is available to researchers.

Horses exhibit a diverse array of coat colors and distinctive markings, described by a specialized vocabulary. Often, a horse is classified first by its coat color, before breed or sex. Horses of the same color may be distinguished from one another by white markings, which, along with various spotting patterns, are inherited separately from coat color.

Many genes that create horse coat colors and patterns have been identified. Current genetic tests can identify at least 13 different alleles influencing coat color, and research continues to discover new genes linked to specific traits. The basic coat colors of chestnut and black are determined by the gene controlled by the Melanocortin 1 receptor, also known as the "extension gene" or "red factor," as its recessive form is "red" (chestnut) and its dominant form is black. Additional genes control suppression of black color to point coloration that results in a bay, spotting patterns such as pinto or leopard, dilution genes such as palomino or dun, as well as graying, and all the other factors that create the many possible coat colors found in horses.

Horses that have a white coat color are often mislabeled; a horse that looks "white" is usually a middle-aged or older gray. Grays are born a darker shade, get lighter as they age, but usually keep black skin underneath their white hair coat (with the exception of pink skin under white markings). The only horses properly called white are born with a predominantly white hair coat and pink skin, a fairly rare occurrence. Different and unrelated genetic factors can produce white coat colors in horses, including several different alleles of dominant white and the sabino-1 gene. However, there are no "albino" horses, defined as having both pink skin and red eyes.

Gestation lasts approximately 340 days, with an average range 320–370 days, and usually results in one foal; twins are rare. Horses are a precocial species, and foals are capable of standing and running within a short time following birth. Foals are usually born in the spring. The estrous cycle of a mare occurs roughly every 19–22 days and occurs from early spring into autumn. Most mares enter an "anestrus" period during the winter and thus do not cycle in this period. Foals are generally weaned from their mothers between four and six months of age.

Horses, particularly colts, sometimes are physically capable of reproduction at about 18 months, but domesticated horses are rarely allowed to breed before the age of three, especially females. Horses four years old are considered mature, although the skeleton normally continues to develop until the age of six; maturation also depends on the horse's size, breed, sex, and quality of care. Larger horses have larger bones; therefore, not only do the bones take longer to form bone tissue, but the epiphyseal plates are larger and take longer to convert from cartilage to bone. These plates convert after the other parts of the bones, and are crucial to development.

Depending on maturity, breed, and work expected, horses are usually put under saddle and trained to be ridden between the ages of two and four. Although Thoroughbred race horses are put on the track as young as the age of two in some countries, horses specifically bred for sports such as dressage are generally not put under saddle until they are three or four years old, because their bones and muscles are not solidly developed. For endurance riding competition, horses are not deemed mature enough to compete until they are a full 60 calendar months (five years) old.

The horse skeleton averages 205 bones. A significant difference between the horse skeleton and that of a human is the lack of a collarbone—the horse's forelimbs are attached to the spinal column by a powerful set of muscles, tendons, and ligaments that attach the shoulder blade to the torso. The horse's legs and hooves are also unique structures. Their leg bones are proportioned differently from those of a human. For example, the body part that is called a horse's "knee" is actually made up of the carpal bones that correspond to the human wrist. Similarly, the hock contains bones equivalent to those in the human ankle and heel. The lower leg bones of a horse correspond to the bones of the human hand or foot, and the fetlock (incorrectly called the "ankle") is actually the proximal sesamoid bones between the cannon bones (a single equivalent to the human metacarpal or metatarsal bones) and the proximal phalanges, located where one finds the "knuckles" of a human. A horse also has no muscles in its legs below the knees and hocks, only skin, hair, bone, tendons, ligaments, cartilage, and the assorted specialized tissues that make up the hoof.

The critical importance of the feet and legs is summed up by the traditional adage, "no foot, no horse". The horse hoof begins with the distal phalanges, the equivalent of the human fingertip or tip of the toe, surrounded by cartilage and other specialized, blood-rich soft tissues such as the laminae. The exterior hoof wall and horn of the sole is made of keratin, the same material as a human fingernail. The end result is that a horse, weighing on average , travels on the same bones as would a human on tiptoe. For the protection of the hoof under certain conditions, some horses have horseshoes placed on their feet by a professional farrier. The hoof continually grows, and in most domesticated horses needs to be trimmed (and horseshoes reset, if used) every five to eight weeks, though the hooves of horses in the wild wear down and regrow at a rate suitable for their terrain.

Horses are adapted to grazing. In an adult horse, there are 12 incisors at the front of the mouth, adapted to biting off the grass or other vegetation. There are 24 teeth adapted for chewing, the premolars and molars, at the back of the mouth. Stallions and geldings have four additional teeth just behind the incisors, a type of canine teeth called "tushes". Some horses, both male and female, will also develop one to four very small vestigial teeth in front of the molars, known as "wolf" teeth, which are generally removed because they can interfere with the bit. There is an empty interdental space between the incisors and the molars where the bit rests directly on the gums, or "bars" of the horse's mouth when the horse is bridled.

An estimate of a horse's age can be made from looking at its teeth. The teeth continue to erupt throughout life and are worn down by grazing. Therefore, the incisors show changes as the horse ages; they develop a distinct wear pattern, changes in tooth shape, and changes in the angle at which the chewing surfaces meet. This allows a very rough estimate of a horse's age, although diet and veterinary care can also affect the rate of tooth wear.

Horses are herbivores with a digestive system adapted to a forage diet of grasses and other plant material, consumed steadily throughout the day. Therefore, compared to humans, they have a relatively small stomach but very long intestines to facilitate a steady flow of nutrients. A horse will eat of food per day and, under normal use, drink of water. Horses are not ruminants, they have only one stomach, like humans, but unlike humans, they can utilize cellulose, a major component of grass. Horses are hindgut fermenters. Cellulose fermentation by symbiotic bacteria occurs in the cecum, or "water gut", which food goes through before reaching the large intestine. Horses cannot vomit, so digestion problems can quickly cause colic, a leading cause of death.

The horses' senses are based on their status as prey animals, where they must be aware of their surroundings at all times. They have the largest eyes of any land mammal, and are lateral-eyed, meaning that their eyes are positioned on the sides of their heads. This means that horses have a range of vision of more than 350°, with approximately 65° of this being binocular vision and the remaining 285° monocular vision. Horses have excellent day and night vision, but they have two-color, or dichromatic vision; their color vision is somewhat like red-green color blindness in humans, where certain colors, especially red and related colors, appear as a shade of green.

Their sense of smell, while much better than that of humans, is not quite as good as that of a dog. It is believed to play a key role in the social interactions of horses as well as detecting other key scents in the environment. Horses have two olfactory centers. The first system is in the nostrils and nasal cavity, which analyze a wide range of odors. The second, located under the nasal cavity, are the Vomeronasal organs, also called Jacobson's organs. These have a separate nerve pathway to the brain and appear to primarily analyze pheromones.

A horse's hearing is good, and the pinna of each ear can rotate up to 180°, giving the potential for 360° hearing without having to move the head. Noise impacts the behavior of horses and certain kinds of noise may contribute to stress: A 2013 study in the UK indicated that stabled horses were calmest in a quiet setting, or if listening to country or classical music, but displayed signs of nervousness when listening to jazz or rock music. This study also recommended keeping music under a volume of 21 decibels. An Australian study found that stabled racehorses listening to talk radio had a higher rate of gastric ulcers than horses listening to music, and racehorses stabled where a radio was played had a higher overall rate of ulceration than horses stabled where there was no radio playing.

Horses have a great sense of balance, due partly to their ability to feel their footing and partly to highly developed proprioception—the unconscious sense of where the body and limbs are at all times. A horse's sense of touch is well developed. The most sensitive areas are around the eyes, ears, and nose. Horses are able to sense contact as subtle as an insect landing anywhere on the body.

Horses have an advanced sense of taste, which allows them to sort through fodder and choose what they would most like to eat, and their prehensile lips can easily sort even small grains. Horses generally will not eat poisonous plants, however, there are exceptions; horses will occasionally eat toxic amounts of poisonous plants even when there is adequate healthy food.

All horses move naturally with four basic gaits: the four-beat walk, which averages ; the two-beat trot or jog at (faster for harness racing horses); the canter or lope, a three-beat gait that is ; and the gallop. The gallop averages , but the world record for a horse galloping over a short, sprint distance is . Besides these basic gaits, some horses perform a two-beat pace, instead of the trot. There also are several four-beat "ambling" gaits that are approximately the speed of a trot or pace, though smoother to ride. These include the lateral rack, running walk, and tölt as well as the diagonal fox trot. Ambling gaits are often genetic in some breeds, known collectively as gaited horses. Often, gaited horses replace the trot with one of the ambling gaits.

Horses are prey animals with a strong fight-or-flight response. Their first reaction to threat is to startle and usually flee, although they will stand their ground and defend themselves when flight is impossible or if their young are threatened. They also tend to be curious; when startled, they will often hesitate an instant to ascertain the cause of their fright, and may not always flee from something that they perceive as non-threatening. Most light horse riding breeds were developed for speed, agility, alertness and endurance; natural qualities that extend from their wild ancestors. However, through selective breeding, some breeds of horses are quite docile, particularly certain draft horses.

Horses are herd animals, with a clear hierarchy of rank, led by a dominant individual, usually a mare. They are also social creatures that are able to form companionship attachments to their own species and to other animals, including humans. They communicate in various ways, including vocalizations such as nickering or whinnying, mutual grooming, and body language. Many horses will become difficult to manage if they are isolated, but with training, horses can learn to accept a human as a companion, and thus be comfortable away from other horses. However, when confined with insufficient companionship, exercise, or stimulation, individuals may develop stable vices, an assortment of bad habits, mostly stereotypies of psychological origin, that include wood chewing, wall kicking, "weaving" (rocking back and forth), and other problems.

Studies have indicated that horses perform a number of cognitive tasks on a daily basis, meeting mental challenges that include food procurement and identification of individuals within a social system. They also have good spatial discrimination abilities. They are naturally curious and apt to investigate things they have not seen before. Studies have assessed equine intelligence in areas such as problem solving, speed of learning, and memory. Horses excel at simple learning, but also are able to use more advanced cognitive abilities that involve categorization and concept learning. They can learn using habituation, desensitization, classical conditioning, and operant conditioning, and positive and negative reinforcement. One study has indicated that horses can differentiate between "more or less" if the quantity involved is less than four.

Domesticated horses may face greater mental challenges than wild horses, because they live in artificial environments that prevent instinctive behavior whilst also learning tasks that are not natural. Horses are animals of habit that respond well to regimentation, and respond best when the same routines and techniques are used consistently. One trainer believes that "intelligent" horses are reflections of intelligent trainers who effectively use response conditioning techniques and positive reinforcement to train in the style that best fits with an individual animal's natural inclinations.

Horses are mammals, and as such are warm-blooded, or endothermic creatures, as opposed to cold-blooded, or poikilothermic animals. However, these words have developed a separate meaning in the context of equine terminology, used to describe temperament, not body temperature. For example, the "hot-bloods", such as many race horses, exhibit more sensitivity and energy, while the "cold-bloods", such as most draft breeds, are quieter and calmer. Sometimes "hot-bloods" are classified as "light horses" or "riding horses", with the "cold-bloods" classified as "draft horses" or "work horses".
"Hot blooded" breeds include "oriental horses" such as the Akhal-Teke, Arabian horse, Barb and now-extinct Turkoman horse, as well as the Thoroughbred, a breed developed in England from the older oriental breeds. Hot bloods tend to be spirited, bold, and learn quickly. They are bred for agility and speed. They tend to be physically refined—thin-skinned, slim, and long-legged. The original oriental breeds were brought to Europe from the Middle East and North Africa when European breeders wished to infuse these traits into racing and light cavalry horses.

Muscular, heavy draft horses are known as "cold bloods", as they are bred not only for strength, but also to have the calm, patient temperament needed to pull a plow or a heavy carriage full of people. They are sometimes nicknamed "gentle giants". Well-known draft breeds include the Belgian and the Clydesdale. Some, like the Percheron, are lighter and livelier, developed to pull carriages or to plow large fields in drier climates. Others, such as the Shire, are slower and more powerful, bred to plow fields with heavy, clay-based soils. The cold-blooded group also includes some pony breeds.

"Warmblood" breeds, such as the Trakehner or Hanoverian, developed when European carriage and war horses were crossed with Arabians or Thoroughbreds, producing a riding horse with more refinement than a draft horse, but greater size and milder temperament than a lighter breed. Certain pony breeds with warmblood characteristics have been developed for smaller riders. Warmbloods are considered a "light horse" or "riding horse".

Today, the term "Warmblood" refers to a specific subset of sport horse breeds that are used for competition in dressage and show jumping. Strictly speaking, the term "warm blood" refers to any cross between cold-blooded and hot-blooded breeds. Examples include breeds such as the Irish Draught or the Cleveland Bay. The term was once used to refer to breeds of light riding horse other than Thoroughbreds or Arabians, such as the Morgan horse.

Horses are able to sleep both standing up and lying down. In an adaptation from life in the wild, horses are able to enter light sleep by using a "stay apparatus" in their legs, allowing them to doze without collapsing. Horses sleep better when in groups because some animals will sleep while others stand guard to watch for predators. A horse kept alone will not sleep well because its instincts are to keep a constant eye out for danger.

Unlike humans, horses do not sleep in a solid, unbroken period of time, but take many short periods of rest. Horses spend four to fifteen hours a day in standing rest, and from a few minutes to several hours lying down. Total sleep time in a 24-hour period may range from several minutes to a couple of hours, mostly in short intervals of about 15 minutes each. The average sleep time of a domestic horse is said to be 2.9 hours per day.

Horses must lie down to reach REM sleep. They only have to lie down for an hour or two every few days to meet their minimum REM sleep requirements. However, if a horse is never allowed to lie down, after several days it will become sleep-deprived, and in rare cases may suddenly collapse as it involuntarily slips into REM sleep while still standing. This condition differs from narcolepsy, although horses may also suffer from that disorder.

The horse adapted to survive in areas of wide-open terrain with sparse vegetation, surviving in an ecosystem where other large grazing animals, especially ruminants, could not. Horses and other equids are odd-toed ungulates of the order Perissodactyla, a group of mammals that was dominant during the Tertiary period. In the past, this order contained 14 families, but only three—Equidae (the horse and related species), Tapiridae (the tapir), and Rhinocerotidae (the rhinoceroses)—have survived to the present day.

The earliest known member of the family Equidae was the "Hyracotherium", which lived between 45 and 55 million years ago, during the Eocene period. It had 4 toes on each front foot, and 3 toes on each back foot. The extra toe on the front feet soon disappeared with the "Mesohippus", which lived 32 to 37 million years ago. Over time, the extra side toes shrank in size until they vanished. All that remains of them in modern horses is a set of small vestigial bones on the leg below the knee, known informally as splint bones. Their legs also lengthened as their toes disappeared until they were a hooved animal capable of running at great speed. By about 5 million years ago, the modern "Equus" had evolved. Equid teeth also evolved from browsing on soft, tropical plants to adapt to browsing of drier plant material, then to grazing of tougher plains grasses. Thus proto-horses changed from leaf-eating forest-dwellers to grass-eating inhabitants of semi-arid regions worldwide, including the steppes of Eurasia and the Great Plains of North America.

By about 15,000 years ago, "Equus ferus" was a widespread holarctic species. Horse bones from this time period, the late Pleistocene, are found in Europe, Eurasia, Beringia, and North America. Yet between 10,000 and 7,600 years ago, the horse became extinct in North America and rare elsewhere. The reasons for this extinction are not fully known, but one theory notes that extinction in North America paralleled human arrival. Another theory points to climate change, noting that approximately 12,500 years ago, the grasses characteristic of a steppe ecosystem gave way to shrub tundra, which was covered with unpalatable plants.

A truly wild horse is a species or subspecies with no ancestors that were ever domesticated. Therefore, most "wild" horses today are actually feral horses, animals that escaped or were turned loose from domestic herds and the descendants of those animals. Only two never-domesticated subspecies, the Tarpan and the Przewalski's Horse, survived into recorded history and only the latter survives today.

The Przewalski's horse ("Equus ferus przewalskii"), named after the Russian explorer Nikolai Przhevalsky, is a rare Asian animal. It is also known as the Mongolian wild horse; Mongolian people know it as the "taki", and the Kyrgyz people call it a "kirtag". The subspecies was presumed extinct in the wild between 1969 and 1992, while a small breeding population survived in zoos around the world. In 1992, it was reestablished in the wild due to the conservation efforts of numerous zoos. Today, a small wild breeding population exists in Mongolia. There are additional animals still maintained at zoos throughout the world.

The tarpan or European wild horse ("Equus ferus ferus") was found in Europe and much of Asia. It survived into the historical era, but became extinct in 1909, when the last captive died in a Russian zoo. Thus, the genetic line was lost. Attempts have been made to recreate the tarpan, which resulted in horses with outward physical similarities, but nonetheless descended from domesticated ancestors and not true wild horses.

Periodically, populations of horses in isolated areas are speculated to be relict populations of wild horses, but generally have been proven to be feral or domestic. For example, the Riwoche horse of Tibet was proposed as such, but testing did not reveal genetic differences from domesticated horses. Similarly, the Sorraia of Portugal was proposed as a direct descendant of the Tarpan based on shared characteristics, but genetic studies have shown that the Sorraia is more closely related to other horse breeds and that the outward similarity is an unreliable measure of relatedness.

Besides the horse, there are six other species of genus "Equus" in the Equidae family. These are the ass or donkey, "Equus asinus"; the mountain zebra, "Equus zebra"; plains zebra, "Equus quagga"; Grévy's zebra, "Equus grevyi"; the kiang, "Equus kiang"; and the onager, "Equus hemionus".

Horses can crossbreed with other members of their genus. The most common hybrid is the mule, a cross between a "jack" (male donkey) and a mare. A related hybrid, a hinny, is a cross between a stallion and a jenny (female donkey). Other hybrids include the zorse, a cross between a zebra and a horse. With rare exceptions, most hybrids are sterile and cannot reproduce.

Domestication of the horse most likely took place in central Asia prior to 3500 BC. Two major sources of information are used to determine where and when the horse was first domesticated and how the domesticated horse spread around the world. The first source is based on palaeological and archaeological discoveries; the second source is a comparison of DNA obtained from modern horses to that from bones and teeth of ancient horse remains.

The earliest archaeological evidence for the domestication of the horse comes from sites in Ukraine and Kazakhstan, dating to approximately 3500–4000 BC. By 3000 BC, the horse was completely domesticated and by 2000 BC there was a sharp increase in the number of horse bones found in human settlements in northwestern Europe, indicating the spread of domesticated horses throughout the continent. The most recent, but most irrefutable evidence of domestication comes from sites where horse remains were interred with chariots in graves of the Sintashta and Petrovka cultures c. 2100 BC.

Domestication is also studied by using the genetic material of present-day horses and comparing it with the genetic material present in the bones and teeth of horse remains found in archaeological and palaeological excavations. The variation in the genetic material shows that very few wild stallions contributed to the domestic horse, while many mares were part of early domesticated herds. This is reflected in the difference in genetic variation between the DNA that is passed on along the paternal, or sire line (Y-chromosome) versus that passed on along the maternal, or dam line (mitochondrial DNA). There are very low levels of Y-chromosome variability, but a great deal of genetic variation in mitochondrial DNA. There is also regional variation in mitochondrial DNA due to the inclusion of wild mares in domestic herds. Another characteristic of domestication is an increase in coat color variation. In horses, this increased dramatically between 5000 and 3000 BC.

Before the availability of DNA techniques to resolve the questions related to the domestication of the horse, various hypotheses were proposed. One classification was based on body types and conformation, suggesting the presence of four basic prototypes that had adapted to their environment prior to domestication. Another hypothesis held that the four prototypes originated from a single wild species and that all different body types were entirely a result of selective breeding after domestication. However, the lack of a detectable substructure in the horse has resulted in a rejection of both hypotheses.

Feral horses are born and live in the wild, but are descended from domesticated animals. Many populations of feral horses exist throughout the world. Studies of feral herds have provided useful insights into the behavior of prehistoric horses, as well as greater understanding of the instincts and behaviors that drive horses that live in domesticated conditions.

There are also semi-feral horses in many parts of the world, such as Dartmoor and the New Forest in the UK, where the animals are all privately owned but live for significant amounts of time in "wild" conditions on undeveloped, often public, lands. Owners of such animals often pay a fee for grazing rights.

The concept of purebred bloodstock and a controlled, written breed registry has come to be particularly significant and important in modern times. Sometimes purebred horses are incorrectly or inaccurately called "thoroughbreds". Thoroughbred is a specific breed of horse, while a "purebred" is a horse (or any other animal) with a defined pedigree recognized by a breed registry. Horse breeds are groups of horses with distinctive characteristics that are transmitted consistently to their offspring, such as conformation, color, performance ability, or disposition. These inherited traits result from a combination of natural crosses and artificial selection methods. Horses have been selectively bred since their domestication. An early example of people who practiced selective horse breeding were the Bedouin, who had a reputation for careful practices, keeping extensive pedigrees of their Arabian horses and placing great value upon pure bloodlines. These pedigrees were originally transmitted via an oral tradition. In the 14th century, Carthusian monks of southern Spain kept meticulous pedigrees of bloodstock lineages still found today in the Andalusian horse.

Breeds developed due to a need for "form to function", the necessity to develop certain characteristics in order to perform a particular type of work. Thus, a powerful but refined breed such as the Andalusian developed as riding horses with an aptitude for dressage. Heavy draft horses developed out of a need to perform demanding farm work and pull heavy wagons. Other horse breeds developed specifically for light agricultural work, carriage and road work, various sport disciplines, or simply as pets. Some breeds developed through centuries of crossing other breeds, while others descended from a single foundation sire, or other limited or restricted foundation bloodstock. One of the earliest formal registries was General Stud Book for Thoroughbreds, which began in 1791 and traced back to the foundation bloodstock for the breed. There are more than 300 horse breeds in the world today.

Worldwide, horses play a role within human cultures and have done so for millennia. The genetic makeup of the human population in a geographical area is affected by the presence or absence of horses (more variation in Africa, less in Eurasian steppes). Societies where horse riding is an integral part of life have developed traditional attires specially suited for horse riding such as tightly wrapping waistbands or cummerbunds giving wide support useful for protecting the spine during long journeys, and voluminous headgear such as turban to protect the skull during falls from the horse. Horses are used for leisure activities, sports, and working purposes. The Food and Agriculture Organization (FAO) estimates that in 2008, there were almost 59,000,000 horses in the world, with around 33,500,000 in the Americas, 13,800,000 in Asia and 6,300,000 in Europe and smaller portions in Africa and Oceania. There are estimated to be 9,500,000 horses in the United States alone. The American Horse Council estimates that horse-related activities have a direct impact on the economy of the United States of over $39 billion, and when indirect spending is considered, the impact is over $102 billion. In a 2004 "poll" conducted by Animal Planet, more than 50,000 viewers from 73 countries voted for the horse as the world's 4th favorite animal.

Communication between human and horse is paramount in any equestrian activity; to aid this process horses are usually ridden with a saddle on their backs to assist the rider with balance and positioning, and a bridle or related headgear to assist the rider in maintaining control. Sometimes horses are ridden without a saddle, and occasionally, horses are trained to perform without a bridle or other headgear. Many horses are also driven, which requires a harness, bridle, and some type of vehicle.

Historically, equestrians honed their skills through games and races. Equestrian sports provided entertainment for crowds and honed the excellent horsemanship that was needed in battle. Many sports, such as dressage, eventing and show jumping, have origins in military training, which were focused on control and balance of both horse and rider. Other sports, such as rodeo, developed from practical skills such as those needed on working ranches and stations. Sport hunting from horseback evolved from earlier practical hunting techniques. Horse racing of all types evolved from impromptu competitions between riders or drivers. All forms of competition, requiring demanding and specialized skills from both horse and rider, resulted in the systematic development of specialized breeds and equipment for each sport. The popularity of equestrian sports through the centuries has resulted in the preservation of skills that would otherwise have disappeared after horses stopped being used in combat.

Horses are trained to be ridden or driven in a variety of sporting competitions. Examples include show jumping, dressage, three-day eventing, competitive driving, endurance riding, gymkhana, rodeos, and fox hunting. Horse shows, which have their origins in medieval European fairs, are held around the world. They host a huge range of classes, covering all of the mounted and harness disciplines, as well as "In-hand" classes where the horses are led, rather than ridden, to be evaluated on their conformation. The method of judging varies with the discipline, but winning usually depends on style and ability of both horse and rider.
Sports such as polo do not judge the horse itself, but rather use the horse as a partner for human competitors as a necessary part of the game. Although the horse requires specialized training to participate, the details of its performance are not judged, only the result of the rider's actions—be it getting a ball through a goal or some other task. Examples of these sports of partnership between human and horse include jousting, in which the main goal is for one rider to unseat the other, and buzkashi, a team game played throughout Central Asia, the aim being to capture a goat carcass while on horseback.

Horse racing is an equestrian sport and major international industry, watched in almost every nation of the world. There are three types: "flat" racing; steeplechasing, i.e. racing over jumps; and harness racing, where horses trot or pace while pulling a driver in a small, light cart known as a sulky. A major part of horse racing's economic importance lies in the gambling associated with it.

There are certain jobs that horses do very well, and no technology has yet developed to fully replace them. For example, mounted police horses are still effective for certain types of patrol duties and crowd control. Cattle ranches still require riders on horseback to round up cattle that are scattered across remote, rugged terrain. Search and rescue organizations in some countries depend upon mounted teams to locate people, particularly hikers and children, and to provide disaster relief assistance. Horses can also be used in areas where it is necessary to avoid vehicular disruption to delicate soil, such as nature reserves. They may also be the only form of transport allowed in wilderness areas. Horses are quieter than motorized vehicles. Law enforcement officers such as park rangers or game wardens may use horses for patrols, and horses or mules may also be used for clearing trails or other work in areas of rough terrain where vehicles are less effective.

Although machinery has replaced horses in many parts of the world, an estimated 100 million horses, donkeys and mules are still used for agriculture and transportation in less developed areas. This number includes around 27 million working animals in Africa alone. Some land management practices such as cultivating and logging can be efficiently performed with horses. In agriculture, less fossil fuel is used and increased environmental conservation occurs over time with the use of draft animals such as horses. Logging with horses can result in reduced damage to soil structure and less damage to trees due to more selective logging.

Horses have been used in warfare for most of recorded history. The first archaeological evidence of horses used in warfare dates to between 4000 and 3000 BC, and the use of horses in warfare was widespread by the end of the Bronze Age. Although mechanization has largely replaced the horse as a weapon of war, horses are still seen today in limited military uses, mostly for ceremonial purposes, or for reconnaissance and transport activities in areas of rough terrain where motorized vehicles are ineffective. Horses have been used in the 21st century by the Janjaweed militias in the War in Darfur.

Modern horses are often used to reenact many of their historical work purposes. Horses are used, complete with equipment that is authentic or a meticulously recreated replica, in various live action historical reenactments of specific periods of history, especially recreations of famous battles. Horses are also used to preserve cultural traditions and for ceremonial purposes. Countries such as the United Kingdom still use horse-drawn carriages to convey royalty and other VIPs to and from certain culturally significant events. Public exhibitions are another example, such as the Budweiser Clydesdales, seen in parades and other public settings, a team of draft horses that pull a beer wagon similar to that used before the invention of the modern motorized truck.

Horses are frequently used in television, films and literature. They are sometimes featured as a major character in films about particular animals, but also used as visual elements that assure the accuracy of historical stories. Both live horses and iconic images of horses are used in advertising to promote a variety of products. The horse frequently appears in coats of arms in heraldry, in a variety of poses and equipment. The mythologies of many cultures, including Greco-Roman, Hindu, Islamic, and Norse, include references to both normal horses and those with wings or additional limbs, and multiple myths also call upon the horse to draw the chariots of the Moon and Sun. The horse also appears in the 12-year cycle of animals in the Chinese zodiac related to the Chinese calendar.

People of all ages with physical and mental disabilities obtain beneficial results from association with horses. Therapeutic riding is used to mentally and physically stimulate disabled persons and help them improve their lives through improved balance and coordination, increased self-confidence, and a greater feeling of freedom and independence. The benefits of equestrian activity for people with disabilities has also been recognized with the addition of equestrian events to the Paralympic Games and recognition of para-equestrian events by the International Federation for Equestrian Sports (FEI). Hippotherapy and therapeutic horseback riding are names for different physical, occupational, and speech therapy treatment strategies that utilize equine movement. In hippotherapy, a therapist uses the horse's movement to improve their patient's cognitive, coordination, balance, and fine motor skills, whereas therapeutic horseback riding uses specific riding skills.

Horses also provide psychological benefits to people whether they actually ride or not. "Equine-assisted" or "equine-facilitated" therapy is a form of experiential psychotherapy that uses horses as companion animals to assist people with mental illness, including anxiety disorders, psychotic disorders, mood disorders, behavioral difficulties, and those who are going through major life changes. There are also experimental programs using horses in prison settings. Exposure to horses appears to improve the behavior of inmates and help reduce recidivism when they leave.

Horses are raw material for many products made by humans throughout history, including byproducts from the slaughter of horses as well as materials collected from living horses.

Products collected from living horses include mare's milk, used by people with large horse herds, such as the Mongols, who let it ferment to produce kumis. Horse blood was once used as food by the Mongols and other nomadic tribes, who found it a convenient source of nutrition when traveling. Drinking their own horses' blood allowed the Mongols to ride for extended periods of time without stopping to eat. The drug Premarin is a mixture of estrogens extracted from the urine of pregnant mares (pregnant mares' urine), and was previously a widely used drug for hormone replacement therapy. The tail hair of horses can be used for making bows for string instruments such as the violin, viola, cello, and double bass.

Horse meat has been used as food for humans and carnivorous animals throughout the ages. It is eaten in many parts of the world, though consumption is taboo in some cultures, and a subject of political controversy in others. Horsehide leather has been used for boots, gloves, jackets, baseballs, and baseball gloves. Horse hooves can also be used to produce animal glue. Horse bones can be used to make implements. Specifically, in Italian cuisine, the horse tibia is sharpened into a probe called a "spinto", which is used to test the readiness of a (pig) ham as it cures. In Asia, the saba is a horsehide vessel used in the production of kumis.

Horses are grazing animals, and their major source of nutrients is good-quality forage from hay or pasture. They can consume approximately 2% to 2.5% of their body weight in dry feed each day. Therefore, a adult horse could eat up to of food. Sometimes, concentrated feed such as grain is fed in addition to pasture or hay, especially when the animal is very active. When grain is fed, equine nutritionists recommend that 50% or more of the animal's diet by weight should still be forage.

Horses require a plentiful supply of clean water, a minimum of to per day. Although horses are adapted to live outside, they require shelter from the wind and precipitation, which can range from a simple shed or shelter to an elaborate stable.

Horses require routine hoof care from a farrier, as well as vaccinations to protect against various diseases, and dental examinations from a veterinarian or a specialized equine dentist. If horses are kept inside in a barn, they require regular daily exercise for their physical health and mental well-being. When turned outside, they require well-maintained, sturdy fences to be safely contained. Regular grooming is also helpful to help the horse maintain good health of the hair coat and underlying skin.




</doc>
<doc id="13647" url="https://en.wikipedia.org/wiki?curid=13647" title="Hermann Ebbinghaus">
Hermann Ebbinghaus

Hermann Ebbinghaus (January 24, 1850 – February 26, 1909) was a German psychologist who pioneered the experimental study of memory, and is known for his discovery of the forgetting curve and the spacing effect. He was also the first person to describe the learning curve. He was the father of the neo-Kantian philosopher Julius Ebbinghaus.

Ebbinghaus was born in Barmen, in the Rhine Province of the Kingdom of Prussia,as the son of a wealthy merchant, Carl Ebbinghaus. Little is known about his infancy except that he was brought up in the Lutheran faith and was a pupil at the town Gymnasium. At the age of 17 (1867), he began attending the University of Bonn, where he had planned to study history and philology. However, during his time there he developed an interest in philosophy. In 1870, his studies were interrupted when he served with the Prussian Army in the Franco-Prussian War. Following this short stint in the military, Ebbinghaus finished his dissertation on Eduard von Hartmann's "" (philosophy of the unconscious) and received his doctorate on August 16, 1873, when he was 23 years old. During the next three years, he spent time at Halle and Berlin.

After acquiring his PhD, Ebbinghaus moved around England and France, tutoring students to support himself. In England, he may have taught in two small schools in the south of the country (Gorfein, 1885). In London, in a used bookstore, he came across Gustav Fechner's book "Elemente der Psychophysik" ("Elements of Psychophysics"), which spurred him to conduct his famous memory experiments. After beginning his studies at the University of Berlin, he founded the third psychological testing lab in Germany (third to Wilhelm Wundt and Georg Elias Müller). He began his memory studies here in 1879. In 1885 — the same year that he published his monumental work, "Über das Gedächtnis. Untersuchungen zur experimentellen Psychologie", later published in English under the title "Memory: A Contribution to Experimental Psychology" — he was made a professor at the University of Berlin, most likely in recognition of this publication. In 1890, along with Arthur König, he founded the psychological journal "Zeitschrift für Physiologie und Psychologie der Sinnesorgane" ("The Psychology and Physiology of the Sense Organs'").

In 1894, he was passed over for promotion to head of the philosophy department at Berlin, most likely due to his lack of publications. Instead, Carl Stumpf received the promotion. As a result of this, Ebbinghaus left to join the University of Breslau (now Wrocław, Poland), in a chair left open by Theodor Lipps (who took over Stumpf's position when he moved to Berlin). While in Breslau, he worked on a commission that studied how children's mental ability declined during the school day. While the specifics on how these mental abilities were measured have been lost, the successes achieved by the commission laid the groundwork for future intelligence testing. At Breslau, he again founded a psychological testing laboratory.

In 1902, Ebbinghaus published his next piece of writing entitled "Die Grundzüge der Psychologie" ("Fundamentals of Psychology"). It was an instant success and continued to be long after his death. In 1904, he moved to Halle where he spent the last few years of his life. His last published work, "Abriss der Psychologie" ("Outline of Psychology") was published six years later, in 1908. This, too, continued to be a success, being re-released in eight different editions. Shortly after this publication, on February 26, 1909, Ebbinghaus died from pneumonia at the age of 59.

Ebbinghaus was determined to show that higher mental processes could actually be studied using experimentation, which was in opposition to the popularly held thought of the time. To control for most potentially confounding variables, Ebbinghaus wanted to use simple acoustic encoding and maintenance rehearsal for which a list of words could have been used. As learning would be affected by prior knowledge and understanding, he needed something that could be easily memorized but which had no prior cognitive associations. Easily formable associations with regular words would interfere with his results, so he used items that would later be called "nonsense syllables" (also known as the CVC trigram). A nonsense syllable is a consonant-vowel-consonant combination, where the consonant does not repeat and the syllable does not have prior meaning. BOL (sounds like "Ball") and DOT (already a word) would then not be allowed. However, syllables such as DAX, BOK, and YAT would all be acceptable (though Ebbinghaus left no examples). After eliminating the meaning-laden syllables, Ebbinghaus ended up with 2,300 resultant syllables. Once he had created his collection of syllables, he would pull out a number of random syllables from a box and then write them down in a notebook. Then, to the regular sound of a metronome, and with the same voice inflection, he would read out the syllables, and attempt to recall them at the end of the procedure. One investigation alone required 15,000 recitations.

It was later determined that humans impose meaning even on nonsense syllables to make them more meaningful. The nonsense syllable PED (which is the first three letters of the word "pedal") turns out to be less nonsensical than a syllable such as KOJ; the syllables are said to differ in association value. It appears that Ebbinghaus recognized this, and only referred to the strings of syllables as "nonsense" in that the syllables might be less likely to have a specific meaning and he should make no attempt to make associations with them for easier retrieval.

There are several limitations to his work on memory. The most important one was that Ebbinghaus was the only subject in his study. This limited the study's generalizability to the population. Although he attempted to regulate his daily routine to maintain more control over his results, his decision to avoid the use of participants sacrificed the external validity of the study despite sound internal validity. In addition, although he tried to account for his personal influences, there is an inherent bias when someone serves as researcher as well as participant. Also, Ebbinghaus's memory research halted research in other, more complex matters of memory such as semantic and procedural memory and mnemonics.

In 1885, he published his groundbreaking "Über das Gedächtnis" ("On Memory", later translated to English as "Memory. A Contribution to Experimental Psychology") in which he described experiments he conducted on himself to describe the processes of learning and forgetting.

Ebbinghaus made several findings that are still relevant and supported to this day. First, arguably his most famous finding, the forgetting curve. The forgetting curve describes the exponential loss of information that one has learned. The sharpest decline occurs in the first twenty minutes and the decay is significant through the first hour. The curve levels off after about one day.

The learning curve described by Ebbinghaus refers to how fast one learns information. The sharpest increase occurs after the first try and then gradually evens out, meaning that less and less new information is retained after each repetition. Like the forgetting curve, the learning curve is exponential. Ebbinghaus had also documented the serial position effect, which describes how the position of an item affects recall. The two main concepts in the serial position effect are recency and primacy. The recency effect describes the increased recall of the most recent information because it is still in the short-term memory. The primacy effect causes better memory of the first items in a list due to increased rehearsal and commitment to long-term memory.

Another important discovery is that of savings. This refers to the amount of information retained in the subconscious even after this information cannot be consciously accessed. Ebbinghaus would memorize a list of items until perfect recall and then would not access the list until he could no longer recall any of its items. He then would relearn the list, and compare the new learning curve to the learning curve of his previous memorization of the list. The second list was generally memorized faster, and this difference between the two learning curves is what Ebbinghaus called "savings". Ebbinghaus also described the difference between involuntary and voluntary memory, the former occurring "with apparent spontaneity and without any act of the will" and the latter being brought "into consciousness by an exertion of the will".

Prior to Ebbinghaus, most contributions to the study of memory were undertaken by philosophers and centered on observational description and speculation. For example, Immanuel Kant used pure description to discuss recognition and its components and Sir Francis Bacon claimed that the simple observation of the rote recollection of a previously learned list was "no use to the art" of memory. This dichotomy between descriptive and experimental study of memory would resonate later in Ebbinghaus's life, particularly in his public argument with former colleague Wilhelm Dilthey. However, more than a century before Ebbinghaus, Johann Andreas Segner invented the "Segner-wheel" to see the length of after-images by seeing how fast a wheel with a hot coal attached had to move for the red ember circle from the coal to appear complete. (see iconic memory)

Ebbinghaus's effect on memory research was almost immediate. With very few works published on memory in the previous two millennia, Ebbinghaus's works spurred memory research in the United States in the 1890s, with 32 papers published in 1894 alone. This research was coupled with the growing development of mechanized mnemometers, or devices that aided in the recording and study of memory.

The reaction to his work in his day was mostly positive. Noted psychologist William James called the studies "heroic" and said that they were "the single most brilliant investigation in the history of psychology". Edward B. Titchener also mentioned that the studies were the greatest undertaking in the topic of memory since Aristotle.

Ebbinghaus can also be credited with pioneering sentence completion exercises, which he developed in studying the abilities of schoolchildren. It was these same exercises that Alfred Binet had borrowed and incorporated into the Binet-Simon intelligence scale. Sentence completion had since then also been used extensively in memory research, especially in tapping into measures of implicit memory, and also has been used in psychotherapy as a tool to help tap into the motivations and drives of the patient. He had also influenced Charlotte Bühler, who along with Lev Vygotsky and others went on to study language meaning and society.

Ebbinghaus is also largely credited with drafting the first standard research report. In his paper on memory, Ebbinghaus arranged his research into four sections: the introduction, the methods, the results, and a discussion section. The clarity and organization of this format was so impressive to contemporaries that it has now become standard in the discipline, and all research reports follow the same standards laid out by Ebbinghaus.

Unlike notable contemporaries like Titchener and James, Ebbinghaus did not promote any specific school of psychology nor was he known for extensive lifetime research, having done only three works. He never attempted to bestow upon himself the title of the pioneer of experimental psychology, did not seek to have any "disciples", and left the exploitation of the new field to others.

In addition to pioneering experimental psychology, Ebbinghaus was also a strong defender of this direction of the new science, as is illustrated by his public dispute with University of Berlin colleague, Wilhelm Dilthey. Shortly after Ebbinghaus left Berlin in 1893, Dilthey published a paper extolling the virtues of descriptive psychology, and condemning experimental psychology as boring, claiming that the mind was too complex, and that introspection was the desired method of studying the mind. The debate at the time had been primarily whether psychology should aim to explain or understand the mind and whether it belonged to the natural or human sciences. Many had seen Dilthey's work as an outright attack on experimental psychology, Ebbinghaus included, and he responded to Dilthey with a personal letter and also a long scathing public article. Amongst his counterarguments against Dilthey he mentioned that it is inevitable for psychology to do hypothetical work and that the kind of psychology that Dilthey was attacking was the one that existed before Ebbinghaus's "experimental revolution". Charlotte Bühler echoed his words some forty years later, stating that people like Ebbinghaus "buried the old psychology in the 1890s". Ebbinghaus explained his scathing review by saying that he could not believe that Dilthey was advocating the status quo of structuralists like Wilhelm Wundt and Titchener and attempting to stifle psychology's progress.

Some contemporary texts still describe Ebbinghaus as a philosopher rather than a psychologist and he had also spent his life as a professor of philosophy. However, Ebbinghaus himself would probably describe himself as a psychologist considering that he fought to have psychology viewed as a separate discipline from philosophy.

There has been some speculation as to what influenced Ebbinghaus in his undertakings. None of his professors seem to have influenced him, nor are there suggestions that his colleagues affected him. Von Hartmann's work, on which Ebbinghaus based his doctorate, did suggest that higher mental processes were hidden from view, which may have spurred Ebbinghaus to attempt to prove otherwise. The one influence that has always been cited as having inspired Ebbinghaus was Gustav Fechner's two-volume "Elemente der Psychophysik." ("Elements of Psychophysics", 1860), a book which he purchased second-hand in England. It is said that the meticulous mathematical procedures impressed Ebbinghaus so much that he wanted to do for psychology what Fechner had done for psychophysics. This inspiration is also evident in that Ebbinghaus dedicated his second work "Principles of Psychology" to Fechner, signing it "I owe everything to you."




</doc>
<doc id="13648" url="https://en.wikipedia.org/wiki?curid=13648" title="Hilbert (disambiguation)">
Hilbert (disambiguation)

David Hilbert (1862–1943) was a German mathematician.

Hilbert may also refer to:

People:

Places:

Other uses:



</doc>
<doc id="13652" url="https://en.wikipedia.org/wiki?curid=13652" title="Hindi">
Hindi

Hindi (Devanagari: हिन्दी, "Hindī"), or Modern Standard Hindi (Devanagari: मानक हिन्दी, "Mānak Hindī") is a standardised and Sanskritised register of the Hindustani language. Hindi, written in the Devanagari script, is one of the official languages of India, along with the English language. It is one of the 22 scheduled languages of the Republic of India. However, it is not the national language of India because no language was given such a status in the Indian constitution.

Hindi is the "lingua franca" of the "Hindi belt", and to a lesser extent other parts of India (usually in a simplified or pidginized variety such as Bazaar Hindustani or Haflong Hindi). Outside India, several other languages are recognized officially as "Hindi" but do not refer to the Standard Hindi language described here and instead descend from other dialects of Hindustani, such as Awadhi and Bhojpuri. Such languages include "Fiji Hindi", which is official in Fiji, and Caribbean Hindustani, which is a recognized language in Trinidad and Tobago, Guyana, and Suriname. Apart from specialized vocabulary, spoken Hindi is mutually intelligible with Urdu, another recognized register of Hindustani.

As a linguistic variety, Hindi is the fourth most-spoken first language in the world, after Mandarin, Spanish and English. Alongside Urdu as Hindustani, it is the third most-spoken language in the world, after Mandarin and English.

The term "Hindī" originally was used to refer to inhabitants of the region east of the Indus. It was borrowed from Classical Persian "Hindī" (Iranian Persian "Hendi"), meaning "Indian", from the proper noun "Hind" "India".

The name "Hindavī" was used by Amir Khusrow in his poetry.

Like other Indo-Aryan languages, Hindi is a direct descendant of an early form of Vedic Sanskrit, through Sauraseni Prakrit and Śauraseni Apabhraṃśa (from Sanskrit "apabhraṃśa" "corrupted"), which emerged in the 7th century A.D.

Modern Standard Hindi is based on the Khariboli dialect, the vernacular of Delhi and the surrounding region, which came to replace earlier prestige dialects such as Awadhi, Maithili (sometimes regarded as separate from the Hindi dialect continuum) and Braj. "Urdu" – another form of Hindustani – acquired linguistic prestige in the later Mughal period (1800s), and underwent significant Persian influence. Modern Hindi and its literary tradition evolved towards the end of the 18th century. However, modern Hindi's earlier literary stages before standardization can be traced to the 16th century. In the late 19th century, a movement to further develop Hindi as a standardised form of Hindustani separate from Urdu took form. In 1881, Bihar accepted Hindi as its sole official language, replacing Urdu, and thus became the first state of India to adopt Hindi. Modern Standard Hindi is one of the youngest Indian languages in this regard.

After independence, the government of India instituted the following conventions:

On 14 September 1949, the Constituent Assembly of India adopted Hindi written in the Devanagari script as the official language of the Republic of India replacing Urdu's previous usage in British India. To this end, several stalwarts rallied and lobbied pan-India in favor of Hindi, most notably along with Hazari Prasad Dwivedi, Kaka Kalelkar, Maithili Sharan Gupt and Seth Govind Das who even debated in Parliament on this issue. As such, on the 50th birthday of Beohar Rajendra Simha on 14 September 1949, the efforts came to fruition following the adoption of Hindi as the official language. Now, it is celebrated as Hindi Day.

In Northeast India a pidgin known as Haflong Hindi has developed as a "lingua franca" for various tribes in Assam that speak other languages natively. In Arunachal Pradesh, Hindi emerged as a lingua franca among locals who speak over 50 dialects natively.

Part XVII of the Indian Constitution deals with the official language of the Indian Commonwealth. Under Article 343, the official languages of the Union has been prescribed, which includes Hindi in Devanagari script and English:

(1) The official language of the Union shall be Hindi in Devanagari script. The form of numerals to be used for the official purposes of the Union shall be the international form of Indian numerals.
(2) Notwithstanding anything in clause (1), for a period of fifteen years from the commencement of this Constitution, the English language shall continue to be used for all the official purposes of the Union for which it was being used immediately before such commencement: Provided that the President may, during the said period, by order authorize the use of the Hindi language in addition to the English language and of the Devanagari form of numerals in addition to the international form of Indian numerals for any of the official purposes of the Union.

It shall be the duty of the Union to promote the spread of the Hindi language, to develop it so that it may serve as a medium of expression for all the elements of the composite culture of India and to secure its enrichment by assimilating without interfering with its genius, the forms, style and expressions used in Hindustani and in the other languages of India specified in the Eighth Schedule, and by drawing, wherever necessary or desirable, for its vocabulary, primarily on Sanskrit and secondarily on other languages.

It was envisioned that Hindi would become the sole working language of the Union Government by 1965 (per directives in Article 344 (2) and Article 351), with state governments being free to function in the language of their own choice. However, widespread resistance to the imposition of Hindi on non-native speakers, especially in South India (such as the those in Tamil Nadu) led to the passage of the Official Languages Act of 1963, which provided for the continued use of English indefinitely for all official purposes, although the constitutional directive for the Union Government to encourage the spread of Hindi was retained and has strongly influenced its policies.

At the state level, Hindi is the official language of the following Indian states: Bihar, Chhattisgarh, Haryana, Himachal Pradesh, Jharkhand, Madhya Pradesh, Mizoram, Rajasthan, Uttar Pradesh, Uttarakhand and West Bengal. Each may also designate a "co-official language"; in Uttar Pradesh, for instance, depending on the political formation in power, this language is generally Urdu. Similarly, Hindi is accorded the status of official language in the following Union Territories: Andaman & Nicobar Islands, Chandigarh, Dadra & Nagar Haveli, Daman & Diu, National Capital Territory.

National language status for Hindi is a long-debated theme. In 2010, the Gujarat High Court clarified that Hindi is not the national language of India because the constitution does not mention it as such.

Outside Asia, the Awadhi language (A Hindi dialect) with influence from Bhojpuri, Bihari languages, Fijian and English is spoken in Fiji. It is an official language in Fiji as per the 1997 Constitution of Fiji, where it referred to it as "Hindustani", however in the 2013 Constitution of Fiji, it is simply called "Fiji Hindi". It is spoken by 380,000 people in Fiji.

Hindi is also spoken by a large population of Madheshis (people having roots in north-India but have migrated to Nepal over hundreds of years) of Nepal. Hindi is quite easy to understand for some Pakistanis, who speak Urdu, which, like Hindi, is part of Hindustani. Apart from this, Hindi is spoken by the large Indian diaspora which hails from, or has its origin from the "Hindi Belt" of India. A substantially large North Indian diaspora lives in countries like the United States of America, the United Kingdom, the United Arab Emirates, Trinidad and Tobago, Guyana, Suriname, South Africa, Fiji and Mauritius, where it is natively spoken at home and among their own Hindustani-speaking communities. Outside India, Hindi speakers are 8 million in Nepal; 863,077 in United States of America; 450,170 in Mauritius; 380,000 in Fiji; 250,292 in South Africa; 150,000 in Suriname; 100,000 in Uganda; 45,800 in United Kingdom; 20,000 in New Zealand; 20,000 in Germany; 16,000 in Trinidad and Tobago; 3,000 in Singapore.

Linguistically, Hindi and Urdu are two registers of the same language and are mutually intelligible. Hindi is written in the Devanagari script and uses more Sanskrit words, whereas Urdu is written in the Perso-Arabic script and uses more Arabic and Persian words. Hindi is the most commonly used official language in India. Urdu is the and "lingua franca" of Pakistan and is one of 22 official languages of India.

The splitting of Hindi and Urdu into separate languages is largely motivated by politics, namely the Indo-Pakistani rivalry.

Hindi is written in the Devanagari script, an abugida. Devanagari consists of 11 vowels and 33 consonants and is written from left to right. Unlike for Sanskrit, Devanagari is not entirely phonetic for Hindi, especially failing to mark schwa dropping in spoken Standard Hindi.

The Government of India uses Hunterian transliteration as its official system of writing Hindi in the Latin script. Various other systems also exist, such as IAST, ITRANS and ISO 15919.

Traditionally, Hindi words are divided into five principal categories according to their etymology:


Hindi also makes extensive use of loan translation (calqueing) and occasionally phono-semantic matching of English.

Hindi has naturally inherited a large portion of its vocabulary from Śaurasenī Prākṛt, in the form of "tadbhava" words. This process usually involves compensatory lengthening of vowels preceding consonant clusters in Prakrit, e.g. Sanskrit "tīkṣṇa" > Prakrit "tikkha" > Hindi "tīkhā".

Much of Modern Standard Hindi's vocabulary is borrowed from Sanskrit as "tatsam" borrowings, especially in technical and academic fields. The formal Hindi standard, from which much of the Persian, Arabic and English vocabulary has been replaced by neologisms compounding "tatsam" words, is called "Śuddh Hindi" (pure Hindi), and is viewed as a more prestigious dialect over other more colloquial forms of Hindi.

Excessive use of "tatsam" words sometimes creates problems for native speakers. They may have Sanskrit consonant clusters which do not exist in native Hindi, causing difficulties in pronunciation.

As a part of the process of Sanskritization, new words are coined using Sanskrit components to be used as replacements for supposedly foreign vocabulary. Usually these neologisms are calques of English words already adopted into spoken Hindi. Some terms such as "dūrbhāṣ" "telephone", literally "far-speech" and "dūrdarśan" "television", literally "far-sight" have even gained some currency in formal Hindi in the place of the English borrowings "(ṭeli)fon" and "ṭīvī".

Hindi also features significant Persian influence, standardised from spoken Hindustani. Early borrowings, beginning in the mid-12th century, were specific to Islam (e.g. "Muhammad", "islām") and so Persian was simply an intermediary for Arabic. Later, under the Delhi Sultanate and Mughal Empire, Persian became the primary administrative language in the Hindi heartland. Persian borrowings reached a heyday in the 17th century, pervading all aspects of life. Even grammatical constructs, namely the izafat, were assimilated into Hindi.

Post-Partition the Indian government advocated for a policy of Sanskritization leading to a marginalization of the Persian element in Hindi. However, many Persian words (e.g. "muśkil" "difficult", "bas" "enough", "havā" "air", "x(a)yāl" "thought") have remained entrenched in Modern Standard Hindi, and a larger amount are still used in Urdu poetry written in the Devanagari script.

Arabic also shows influence in Hindi, often via Persian but sometimes directly.

Hindi literature is broadly divided into four prominent forms or styles, being "Bhakti" (devotional – Kabir, Raskhan); "Śṛṇgār" (beauty – Keshav, Bihari); "Vīgāthā" (epic); and "Ādhunik" (modern).

Medieval Hindi literature is marked by the influence of Bhakti movement and the composition of long, epic poems. It was primarily written in other varieties of Hindi, particularly Avadhi and Braj Bhasha, but to a degree also in Khariboli, the basis for Modern Standard Hindi. During the British Raj, Hindustani became the prestige dialect.

"Chandrakanta", written by Devaki Nandan Khatri in 1888, is considered the first authentic work of prose in modern Hindi. The person who brought realism in the Hindi prose literature was Munshi Premchand, who is considered as the most revered figure in the world of Hindi fiction and progressive movement. Literary, or "Sāhityik", Hindi was popularised by the writings of Swami Dayananda Saraswati, Bhartendu Harishchandra and others. The rising numbers of newspapers and magazines made Hindustani popular with the educated people.

The "Dvivedī Yug" ("Age of Dwivedi") in Hindi literature lasted from 1900 to 1918. It is named after Mahavir Prasad Dwivedi, who played a major role in establishing Modern Standard Hindi in poetry and broadening the acceptable subjects of Hindi poetry from the traditional ones of religion and romantic love.

In the 20th century, Hindi literature saw a romantic upsurge. This is known as "Chāyāvād" ("shadow-ism") and the literary figures belonging to this school are known as "Chāyāvādī". Jaishankar Prasad, Suryakant Tripathi 'Nirala', Mahadevi Varma and Sumitranandan Pant, are the four major "Chāyāvādī" poets.

"Uttar Ādhunik" is the post-modernist period of Hindi literature, marked by a questioning of early trends that copied the West as well as the excessive ornamentation of the "Chāyāvādī" movement, and by a return to simple language and natural themes.

The Hindi Wikipedia was the first Indic-language wiki to reach 100,000 articles. Hindi literature, music, and film have all been disseminated via the internet. In 2015, Google reported a 94% increase in Hindi-content consumption year-on-year, adding that 21% of users in India prefer content in Hindi.

Many Hindi newspapers also offer digital editions.

The following is a sample text in High Hindi, of the Article 1 of the Universal Declaration of Human Rights (by the United Nations):









</doc>
<doc id="13653" url="https://en.wikipedia.org/wiki?curid=13653" title="Huginn and Muninn">
Huginn and Muninn

In Norse mythology, Huginn (from Old Norse "thought") and Muninn (Old Norse "memory" or "mind") are a pair of ravens that fly all over the world, Midgard, and bring information to the god Odin. Huginn and Muninn are attested in the "Poetic Edda", compiled in the 13th century from earlier traditional sources: the "Prose Edda" and "Heimskringla", written in the 13th century by Snorri Sturluson; in the "Third Grammatical Treatise", compiled in the 13th century by Óláfr Þórðarson; and in the poetry of skalds. The names of the ravens are sometimes modernly anglicized as Hugin and Munin.

In the "Poetic Edda", a disguised Odin expresses that he fears that they may not return from their daily flights. The "Prose Edda" explains that Odin is referred to as "raven-god" due to his association with Huginn and Muninn. In the "Prose Edda" and the "Third Grammatical Treatise", the two ravens are described as perching on Odin's shoulders. "Heimskringla" details that Odin gave Huginn and Muninn the ability to speak.

Migration Period golden bracteates, Vendel era helmet plates, a pair of identical Germanic Iron Age bird-shaped brooches, Viking Age objects depicting a moustached man wearing a helmet, and a portion of the 10th or 11th century may depict Odin with one of the ravens. Huginn and Muninn's role as Odin's messengers has been linked to shamanic practices, the Norse raven banner, general raven symbolism among the Germanic peoples, and the Norse concepts of the fylgja and the hamingja.

In the "Poetic Edda" poem "Grímnismál", the god Odin (disguised as "Grímnir") provides the young Agnarr with information about Odin's companions. He tells the prince about Odin's wolves Geri and Freki, and, in the next stanza of the poem, states that Huginn and Muninn fly daily across the entire world, Midgard. Grímnir says that he worries Huginn may not come back, yet more does he fear for Muninn:

In the "Prose Edda" book "Gylfaginning" (chapter 38), the enthroned figure of High tells Gangleri (king Gylfi in disguise) that two ravens named Huginn and Muninn sit on Odin's shoulders. The ravens tell Odin everything they see and hear. Odin sends Huginn and Muninn out at dawn, and the birds fly all over the world before returning at dinner-time. As a result, Odin is kept informed of many events. High adds that it is from this association that Odin is referred to as "raven-god". The above-mentioned stanza from "Grímnismál" is then quoted.

In the "Prose Edda" book "Skáldskaparmál" (chapter 60), Huginn and Muninn appear in a list of poetic names for ravens. In the same chapter, excerpts from a work by the skald Einarr Skúlason are provided. In these excerpts Muninn is referenced in a common noun for 'raven' and Huginn is referenced in a kenning for 'carrion'.

In the "Heimskringla" book "Ynglinga saga", a euhemerized account of the life of Odin is provided. Chapter 7 describes that Odin had two ravens, and upon these ravens he bestowed the gift of speech. These ravens flew all over the land and brought him information, causing Odin to become "very wise in his lore."

In the "Third Grammatical Treatise" an anonymous verse is recorded that mentions the ravens flying from Odin's shoulders; Huginn seeking hanged men, and Muninn slain bodies. The verse reads:

Migration Period (5th and 6th centuries CE) gold bracteates (types A, B, and C) feature a depiction of a human figure above a horse, holding a spear and flanked by one or more often two birds. The presence of the birds has led to the iconographic identification of the human figure as the god Odin, flanked by Huginn and Muninn. Like Snorri's "Prose Edda" description of the ravens, a bird is sometimes depicted at the ear of the human, or at the ear of the horse. Bracteates have been found in Denmark, Sweden, Norway and, in smaller numbers, England and areas south of Denmark. Austrian Germanist Rudolf Simek states that these bracteates may depict Odin and his ravens healing a horse and may indicate that the birds were originally not simply his battlefield companions but also "Odin's helpers in his veterinary function."

Vendel era helmet plates (from the 6th or 7th century) found in a grave in Sweden depict a helmeted figure holding a spear and a shield while riding a horse, flanked by two birds. The plate has been interpreted as Odin accompanied by two birds: his ravens.

A pair of identical Germanic Iron Age bird-shaped brooches from Bejsebakke in northern Denmark may be depictions of Huginn and Muninn. The back of each bird features a mask motif, and the feet of the birds are shaped like the heads of animals. The feathers of the birds are also composed of animal heads. Together, the animal heads on the feathers form a mask on the back of the bird. The birds have powerful beaks and fan-shaped tails, indicating that they are ravens. The brooches were intended to be worn on each shoulder, after Germanic Iron Age fashion. Archaeologist Peter Vang Petersen comments that while the symbolism of the brooches is open to debate, the shape of the beaks and tail feathers confirm that the brooch depictions are ravens. Petersen notes that "raven-shaped ornaments worn as a pair, after the fashion of the day, one on each shoulder, makes one's thoughts turn towards Odin's ravens and the cult of Odin in the Germanic Iron Age." Petersen says that Odin is associated with disguise and that the masks on the ravens may be portraits of Odin.

The Oseberg tapestry fragments, discovered within the Viking Age Oseberg ship burial in Norway, feature a scene containing two black birds hovering over a horse, possibly originally leading a wagon (as a part of a procession of horse-led wagons on the tapestry). In her examination of the tapestry, scholar Anne Stine Ingstad interprets these birds as Huginn and Muninn flying over a covered cart containing an image of Odin, drawing comparison with the images of Nerthus attested by Tacitus in 1 CE.

Excavations in Ribe in Denmark have recovered a Viking Age lead metal-caster's mould and 11 identical casting-moulds. These objects depict a moustached man wearing a helmet that features two head-ornaments. Archaeologist Stig Jensen proposes that these ornaments should be interpreted as Huginn and Muninn, and the wearer as Odin. He notes that "similar depictions occur everywhere the Vikings went—from eastern England to Russia and naturally also in the rest of Scandinavia."

A portion of (a partly surviving runestone erected at Kirk Andreas on the Isle of Man) depicts a bearded human holding a spear downward at a wolf, his right foot in its mouth, and a large bird on his shoulder. Andy Orchard comments that this bird may be either Huginn or Muninn. Rundata dates the cross to 940, while Pluskowski dates it to the 11th century. This depiction has been interpreted as Odin, with a raven or eagle at his shoulder, being consumed by the monstrous wolf Fenrir during the events of Ragnarök.

In November 2009, the Roskilde Museum announced the discovery and subsequent display of a niello-inlaid silver figurine found in Lejre, Denmark, which they dubbed "Odin from Lejre". The silver object depicts a person sitting on a throne. The throne features the heads of animals and is flanked by two birds. The Roskilde Museum identifies the figure as Odin sitting on his throne Hliðskjálf, flanked by the ravens Huginn and Muninn.

Scholars have linked Odin's relation to Huginn and Muninn to shamanic practice. John Lindow relates Odin's ability to send his "thought" (Huginn) and "mind" (Muninn) to the trance-state journey of shamans. Lindow says the "Grímnismál" stanza where Odin worries about the return of Huginn and Muninn "would be consistent with the danger that the shaman faces on the trance-state journey."

Rudolf Simek is critical of the approach, stating that "attempts have been made to interpret Odin's ravens as a personification of the god's intellectual powers, but this can only be assumed from the names Huginn and Muninn themselves which were unlikely to have been invented much before the 9th or 10th centuries" yet that the two ravens, as Odin's companions, appear to derive from much earlier times. Instead, Simek connects Huginn and Muninn with wider raven symbolism in the Germanic world, including the raven banner (described in English chronicles and Scandinavian sagas), a banner which was woven in a method that allowed it, when fluttering in the wind, to appear as if the raven depicted upon it was beating its wings.

Anthony Winterbourne connects Huginn and Muninn to the Norse concepts of the fylgja—a concept with three characteristics; shape-shifting abilities, good fortune, and the guardian spirit—and the hamingja—the ghostly double of a person that may appear in the form of an animal. Winterbourne states that "The shaman's journey through the different parts of the cosmos is symbolized by the "hamingja" concept of the shape-shifting soul, and gains another symbolic dimension for the Norse soul in the account of Oðin's ravens, Huginn and Muninn." In response to Simek's criticism of attempts to interpret the ravens "philosophically", Winterbourne says that "such speculations [...] simply strengthen the conceptual significance made plausible by other features of the mythology" and that the names "Huginn" and "Muninn" "demand more explanation than is usually provided."

The "Heliand", an Old Saxon adaptation of the New Testament from the 9th century, differs from the New Testament in that an explicit reference is made to a dove sitting on the shoulder of Christ. Regarding this, G. Ronald Murphy says "In placing the powerful white dove not just above Christ, but right on his shoulder, the "Heliand" author has portrayed Christ, not only as the Son of the All-Ruler, but also as a new Woden. This deliberate image of Christ triumphantly astride the land with the magnificent bird on his shoulders (the author is perhaps a bit embarrassed that the bird is an unwarlike dove!) is an image intended to calm the fears and longings of those who mourn the loss of Woden and who want to return to the old religion's symbols and ways. With this image, Christ becomes a Germanic god, one into whose ears the Spirit of the Almighty whispers".

Bernd Heinrich theorizes that Huginn and Muninn, along with Odin and his wolves Geri and Freki, reflect a symbiosis observed in the natural world among ravens, wolves, and humans on the hunt:




</doc>
<doc id="13654" url="https://en.wikipedia.org/wiki?curid=13654" title="Heat engine">
Heat engine

In thermodynamics and engineering, a heat engine is a system that converts heat or thermal energy—and chemical energy—to mechanical energy, which can then be used to do mechanical work. It does this by bringing a working substance from a higher state temperature to a lower state temperature. A heat source generates thermal energy that brings the working substance to the high temperature state. The working substance generates work in the working body of the engine while transferring heat to the colder sink until it reaches a low temperature state. During this process some of the thermal energy is converted into work by exploiting the properties of the working substance. The working substance can be any system with a non-zero heat capacity, but it usually is a gas or liquid. During this process, a lot of heat is lost to the surroundings and so cannot be converted to work.

In general an engine converts energy to mechanical work. Heat engines distinguish themselves from other types of engines by the fact that their efficiency is fundamentally limited by Carnot's theorem. Although this efficiency limitation can be a drawback, an advantage of heat engines is that most forms of energy can be easily converted to heat by processes like exothermic reactions (such as combustion), absorption of light or energetic particles, friction, dissipation and resistance. Since the heat source that supplies thermal energy to the engine can thus be powered by virtually any kind of energy, heat engines are very versatile and have a wide range of applicability.

Heat engines are often confused with the cycles they attempt to implement. Typically, the term "engine" is used for a physical device and "cycle" for the model.

In thermodynamics, heat engines are often modeled using a standard engineering model such as the Otto cycle. The theoretical model can be refined and augmented with actual data from an operating engine, using tools such as an indicator diagram. Since very few actual implementations of heat engines exactly match their underlying thermodynamic cycles, one could say that a thermodynamic cycle is an ideal case of a mechanical engine. In any case, fully understanding an engine and its efficiency requires gaining a good understanding of the (possibly simplified or idealized) theoretical model, the practical nuances of an actual mechanical engine, and the discrepancies between the two.

In general terms, the larger the difference in temperature between the hot source and the cold sink, the larger is the potential thermal efficiency of the cycle. On Earth, the cold side of any heat engine is limited to being close to the ambient temperature of the environment, or not much lower than 300 kelvins, so most efforts to improve the thermodynamic efficiencies of various heat engines focus on increasing the temperature of the source, within material limits. The maximum theoretical efficiency of a heat engine (which no engine ever attains) is equal to the temperature difference between the hot and cold ends divided by the temperature at the hot end, all expressed as absolute temperatures (in kelvins).

The efficiency of various heat engines proposed or used today has a large range: 

All these processes gain their efficiency (or lack thereof) from the temperature drop across them. Significant energy may be used for auxiliary equipment, such as pumps, which effectively reduces efficiency.

Examples of everyday heat engines include the steam engine and the internal combustion engine. The stirling engine is also heat engine, as well as the drinking bird toy. All of these heat engines are powered by the expansion of heated gases.

It is important to note that although some cycles have a typical combustion location (internal or external), they often can be implemented with the other. For example, John Ericsson developed an external heated engine running on a cycle very much like the earlier Diesel cycle. In addition, externally heated engines can often be implemented in open or closed cycles.

Earth's atmosphere and hydrosphere—Earth’s heat engine—are coupled processes that constantly even out solar heating imbalances through evaporation of surface water, convection, rainfall, winds, and ocean circulation, when distributing heat around the globe.

The Hadley system provides an example of a heat engine. The Hadley circulation is identified with rising of warm and moist air in the equatorial region with descent of colder air in the subtropics corresponding to a thermally driven direct circulation, with consequent net production of kinetic energy.

In these cycles and engines, the working fluids are gases and liquids. The engine converts the working fluid from a gas to a liquid, from liquid to gas, or both, generating work from the fluid expansion or compression.

In these cycles and engines the working fluid is always a gas (i.e., there is no phase change):

In these cycles and engines the working fluid are always like liquid:



A domestic refrigerator is an example of a heat pump: a heat engine in reverse. Work is used to create a heat differential. Many cycles can run in reverse to move heat from the cold side to the hot side, making the cold side cooler and the hot side hotter. Internal combustion engine versions of these cycles are, by their nature, not reversible.

Refrigeration cycles include:

The Barton evaporation engine is a heat engine based on a cycle producing power and cooled moist air from the evaporation of water into hot dry air.

Mesoscopic heat engines are nanoscale devices that may serve the goal of processing heat fluxes and perform useful work at small scales. Potential applications include e.g. electric cooling devices.
In such mesoscopic heat engines, work per cycle of operation fluctuates due to thermal noise.
There is exact equality that relates average of exponents of work performed by any heat engine and the heat transfer from the hotter heat bath. This relation transforms the Carnot's inequality into exact equality.

The efficiency of a heat engine relates how much useful work is output for a given amount of heat energy input.

From the laws of thermodynamics, after a completed cycle:

In other words, a heat engine absorbs heat energy from the high temperature heat source, converting part of it to useful work and delivering the rest to the cold temperature heat sink.

In general, the efficiency of a given heat transfer process (whether it be a refrigerator, a heat pump or an engine) is defined informally by the ratio of "what you get out" to "what you put in".

In the case of an engine, one desires to extract work and puts in a heat transfer.

The "theoretical" maximum efficiency of any heat engine depends only on the temperatures it operates between. This efficiency is usually derived using an ideal imaginary heat engine such as the Carnot heat engine, although other engines using different cycles can also attain maximum efficiency. Mathematically, this is because in reversible processes, the change in entropy of the cold reservoir is the negative of that of the hot reservoir (i.e., formula_7), keeping the overall change of entropy zero. Thus:

where formula_9 is the absolute temperature of the hot source and formula_10 that of the cold sink, usually measured in kelvins. Note that formula_11 is positive while formula_12 is negative; in any reversible work-extracting process, entropy is overall not increased, but rather is moved from a hot (high-entropy) system to a cold (low-entropy one), decreasing the entropy of the heat source and increasing that of the heat sink.

The reasoning behind this being the maximal efficiency goes as follows. It is first assumed that if a more efficient heat engine than a Carnot engine is possible, then it could be driven in reverse as a heat pump. Mathematical analysis can be used to show that this assumed combination would result in a net decrease in entropy. Since, by the second law of thermodynamics, this is statistically improbable to the point of exclusion, the Carnot efficiency is a theoretical upper bound on the reliable efficiency of "any" thermodynamic cycle.

Empirically, no heat engine has ever been shown to run at a greater efficiency than a Carnot cycle heat engine.

Figure 2 and Figure 3 show variations on Carnot cycle efficiency. Figure 2 indicates how efficiency changes with an increase in the heat addition temperature for a constant compressor inlet temperature. Figure 3 indicates how the efficiency changes with an increase in the heat rejection temperature for a constant turbine inlet temperature.

The most Carnot efficiency as a criterion of heat engine performance is the fact that by its nature, any maximally efficient Carnot cycle must operate at an infinitesimal temperature gradient. This is because "any" transfer of heat between two bodies at differing temperatures is irreversible, and therefore the Carnot efficiency expression only applies in the infinitesimal limit. The major problem with that is that the object of most heat engines is to output some sort of power, and infinitesimal power is usually not what is being sought.

A different measure of ideal heat engine efficiency is given by considerations of endoreversible thermodynamics, where the cycle is identical to the Carnot cycle except in that the two processes of heat transfer are "not" reversible (Callen 1985):

This model does a better job of predicting how well real-world heat engines can do (Callen 1985, see also endoreversible thermodynamics):

As shown, the endoreversible efficiency much more closely models the observed.

Heat engines have been known since antiquity but were only made into useful devices at the time of the industrial revolution in the 18th century. They continue to be developed today.

Engineers have studied the various heat engine cycles extensively in effort to improve the amount of usable work they could extract from a given power source. The Carnot cycle limit cannot be reached with any gas-based cycle, but engineers have worked out at least two ways to possibly go around that limit, and one way to get better efficiency without bending any rules.

Each process is one of the following:




</doc>
<doc id="13655" url="https://en.wikipedia.org/wiki?curid=13655" title="Heimdallr">
Heimdallr

In Norse mythology, Heimdallr is a god who possesses the resounding horn Gjallarhorn, owns the golden-maned horse Gulltoppr, is called the shining god and the whitest of the gods, has gold teeth, and is the son of Nine Mothers (who may represent personified waves). Heimdallr is attested as possessing foreknowledge, keen eyesight and hearing, and keeps watch for invaders and the onset of Ragnarök while drinking fine mead in his dwelling Himinbjörg, located where the burning rainbow bridge Bifröst meets the sky. Heimdallr is said to be the originator of social classes among humanity and once regained Freyja's treasured possession Brísingamen while doing battle in the shape of a seal with Loki. Heimdallr and Loki are foretold to kill one another during the events of Ragnarök. Heimdallr is additionally referred to as Rig, Hallinskiði, Gullintanni, and Vindlér or Vindhlér.

Heimdallr is attested in the "Poetic Edda", compiled in the 13th century from earlier traditional material; in the "Prose Edda" and "Heimskringla", both written in the 13th century by Snorri Sturluson; in the poetry of skalds; and on an Old Norse runic inscription found in England. Two lines of an otherwise lost poem about the god, "Heimdalargaldr", survive. Due to the problematic and enigmatic nature of these attestations, scholars have produced various theories about the nature of the god, including his apparent relation to rams, that he may be a personification of or connected to the world tree Yggdrasil, and potential Indo-European cognates.

The etymology of the name is obscure, but 'the one who illuminates the world' has been proposed. "Heimdallr" may be connected to "Mardöll", one of Freyja's names. "Heimdallr" and its variants are sometimes modernly anglicized as Heimdall (; with the nominative "-r" dropped).

Heimdallr is attested as having three other names; "Hallinskiði", "Gullintanni", and "Vindlér" or "Vindhlér". The name "Hallinskiði" is obscure, but has resulted in a series of attempts at deciphering it. "Gullintanni" literally means 'the one with the golden teeth'. "Vindlér" (or "Vindhlér") translates as either 'the one protecting against the wind' or 'wind-sea'. All three have resulted in numerous theories about the god.

A lead spindle whorl bearing an Old Norse Younger Futhark inscription that mentions Heimdallr was discovered in Saltfleetby, England on September 1, 2010. The spindle whorl itself is dated from the year 1000 to 1100 AD. On the inscription, the god Heimdallr is mentioned alongside the god Odin and Þjálfi, a name of one of the god Thor's servants. Regarding the inscription reading, John Hines of Cardiff University comments that there is "quite an essay to be written over the uncertainties of translation and identification here; what are clear, and very important, are the names of two of the Norse gods on the side, Odin and Heimdallr, while Þjalfi (masculine, not the feminine in -a) is the recorded name of a servant of the god Thor."

In the "Poetic Edda", Heimdallr is attested in six poems; "Völuspá", "Grímnismál", "Lokasenna", "Þrymskviða", "Rígsþula", and "Hrafnagaldr Óðins".

Heimdallr is mentioned thrice in "Völuspá". In the first stanza of the poem, the undead völva reciting the poem calls out for listeners to be silent and refers to Heimdallr:

This stanza has led to various scholarly interpretations. The "holy races" have been considered variously as either humanity or the gods. The notion of humanity as "Heimdallr's sons" is otherwise unattested and has also resulted in various interpretations. Some scholars have pointed to the prose introduction to the poem "Rígsþula", where Heimdallr is said to have once gone about people, slept between couples, and so doled out classes among them (see "Rígsthula" section below).

Later in "Völuspá", the völva foresees the events of Ragnarök and the role in which Heimdallr and Gjallarhorn will play at its onset; Heimdallr will raise his horn and blow loudly. Due to manuscript differences, translations of the stanza vary:

Regarding this stanza, scholar Andy Orchard comments that the name "Gjallarhorn" may here mean "horn of the river Gjöll" as "Gjöll is the name of one of the rivers of the Underworld, whence much wisdom is held to derive", but notes that in the poem "Grímnismál" Heimdallr is said to drink fine mead in his heavenly home Himinbjörg.

Earlier in the same poem, the völva mentions a scenario involving the hearing or horn (depending on translation of the Old Norse noun "hljóð"—translations bolded below for the purpose of illustration) of the god Heimdallr:

Scholar Paul Schach comments that the stanzas in this section of " Völuspá" are "all very mysterious and obscure, as it was perhaps meant to be". Schach details that ""Heimdallar hljóð" has aroused much speculation. Snorri [in the "Prose Edda"] seems to have confused this word with "gjallarhorn", but there is otherwise no attestation of the use of "hljóð" in the sense of 'horn' in Icelandic. Various scholars have read this as "hearing" rather than "horn".

Scholar Carolyne Larrington comments that if "hearing" rather than "horn" is understood to appear in this stanza, the stanza indicates that Heimdallr, like Odin, has left a body part in the well; his ear. Larrington says that "Odin exchanged one of his eyes for wisdom from Mimir, guardian of the well, while Heimdall seems to have forfeited his ear."

In the poem "Grímnismál", Odin (disguised as "Grímnir"), tortured, starved and thirsty, tells the young Agnar of a number of mythological locations. The eighth location he mentions is Himinbjörg, where he says that Heimdallr drinks fine mead:

Regarding the above stanza, Henry Adams Bellows comments that "in this stanza the two functions of Heimdall—as father of humanity [ . . . ] and as warder of the gods—seem both to be mentioned, but the second line in the manuscripts is apparently in bad shape, and in the editions it is more or less conjecture".

In the poem "Lokasenna", Loki flyts with various gods who have met together to feast. At one point during the exchanges, the god Heimdallr says that Loki is drunk and witless, and asks Loki why he won't stop speaking. Loki tells Heimdallr to be silent, that he was fated a "hateful life", that Heimdallr must always have a muddy back, and that he must serve as watchman of the gods. The goddess Skaði interjects and the flyting continues in turn.

The poem "Þrymskviða" tells of Thor's loss of his hammer, Mjöllnir, to the jötnar and quest to get it back. At one point in the tale, the gods gather at the thing and debate how to get Thor's hammer back from the jötnar, who demand the beautiful goddess Freyja in return for it. Heimdallr advises that they simply dress Thor up as Freyja, during which he is described as "hvítastr ása" (translations of the phrase vary below) and is said to have foresight like the Vanir, a group of gods:

Regarding Heimdallr's status as "hvítastr ása" (variously translated above as "brightest" (Thorpe), "whitest" (Bellows), and "most glittering" (Dodds)) and the comparison to the Vanir, scholar John Lindow comments that there are no other indications of Heimdallr being considered among the Vanir, and that Heimdallr's status as ""hvítastr ása "" has not been explained.

The introductory prose to the poem "Rígsþula" says that "people say in the old stories" that Heimdallr, described as a god among the Æsir, once fared on a journey. Heimdallr wandered along a seashore, and referred to himself as "Rígr". In the poem, Rígr, who is described as a wise and powerful god, walks in the middle of roads on his way to steads, where he meets a variety of couples and dines with them, giving them advice and spending three nights at a time between them in their bed. The wives of the couples become pregnant, and from them come the various classes of humanity. Eventually a warrior home produces a promising boy, and as the boy grows older, Rígr comes out of a thicket, teaches the boy runes, gives him a name, and proclaims him to be his son. Rígr tells him to strike out and get land for himself. The boy does so, and so becomes a great war leader with many estates. He marries a beautiful woman and the two have many children and are happy. One of the children eventually becomes so skilled that he is able to share in runic knowledge with Heimdallr, and so earns the title of "Rígr" himself. The poem continues without further mention of the god.

In the "Prose Edda", Heimdallr is mentioned in the books "Gylfaginning", "Skáldskaparmál", and "Háttatal". In "Gylfaginning", the enthroned figure of High tells the disguised mythical king Gangleri of various gods, and, in chapter 25, mentions Heimdallr. High says that Heimdallr is known "the white As", is "great and holy", and that nine maidens, all sisters, gave birth to him. Heimdallr is called "Hallinskiði" and "Gullintanni", and he has gold teeth. High continues that Heimdallr lives in "a place" called Himinbjörg and that it is near Bifröst. Heimdallr is the watchman of the gods, and he sits on the edge of heaven to guard the Bifröst bridge from the berg jötnar. Heimdallr requires less sleep than a bird, can see at night just as well as if it were day, and for over a hundred leagues. Heimdallr's hearing is also quite keen; he can hear grass as it grows on the earth, wool as it grows on sheep, and anything louder. Heimdallr possesses a trumpet, Gjallarhorn, that, when blown, can be heard in all worlds, and "the head is referred to as Heimdall's sword". High then quotes the above-mentioned "Grímnismál" stanza about Himinbjörg and provides two lines from the otherwise lost poem about Heimdallr, "Heimdalargaldr", in which Heimdallr proclaims himself to be the son of Nine Mothers.

In chapter 49, High tells of the god Baldr's funeral procession. Various deities are mentioned as having attended, including Heimdallr, who there rode his horse Gulltopr.

In chapter 51, High foretells the events of Ragnarök. After the enemies of the gods will gather at the plain Vígríðr, Heimdallr will stand and mightily blow into Gjallarhorn. The gods will awake and assemble together at the thing. At the end of the battle between various gods and their enemies, Heimdallr will face Loki and they will kill one another. After, the world will be engulfed in flames. High then quotes the above-mentioned stanza regarding Heimdallr raising his horn in "Völuspá".

At the beginning of "Skáldskaparmál", Heimdallr is mentioned as having attended a banquet in Asgard with various other deities. Later in the book, "Húsdrápa", a poem by 10th century skald Úlfr Uggason, is cited, during which Heimdallr is described as having ridden to Baldr's funeral pyre.

In chapter 8, means of referring to Heimdallr are provided; "son of nine mothers", "guardian of the gods", "the white As" (see "Poetic Edda" discussion regarding "hvítastr ása" above), "Loki's enemy", and "recoverer of Freyja's necklace". The section adds that the poem "Heimdalargaldr" is about him, and that, since the poem, "the head has been called Heimdall's doom: man's doom is an expression for sword". Hiemdallr is the owner of Gulltoppr, is also known as Vindhlér, and is a son of Odin. Heimdallr visits Vágasker and Singasteinn and there vied with Loki for Brísingamen. According to the chapter, the skald Úlfr Uggason composed a large section of his "Húsdrápa" about these events and that "Húsdrápa" says that the two were in the shape of seals. A few chapters later, ways of referring to Loki are provided, including "wrangler with Heimdall and Skadi", and section of Úlfr Uggason's "Húsdrápa" is then provided in reference:

The chapter points out that in the above "Húsdrápa" section Heimdallr is said to be the son of nine mothers.

Heimdallr is mentioned once in "Háttatal". There, in a composition by Snorri Sturluson, a sword is referred to as "Vindhlér's helmet-filler", meaning "Heimdallr's head".

In "Ynglinga saga" compiled in "Heimskringla", Snorri presents a euhemerized origin of the Norse gods and rulers descending from them. In chapter 5, Snorri asserts that the Æsir settled in what is now Sweden and built various temples. Snorri writes that Odin settled in Lake Logrin "at a place which formerly was called Sigtúnir. There he erected a large temple and made sacrifices according to the custom of the Æsir. He took possession of the land as far as he had called it Sigtúnir. He gave dwelling places to the temple priests." Snorri adds that, after this, Njörðr dwelt in Nóatún, Freyr dwelt in Uppsala, Heimdall at Himinbjörg, Thor at Þrúðvangr, Baldr at Breiðablik and that to everyone Odin gave fine estates.

A figure holding a large horn to his lips and clasping a sword on his hip appears on a stone cross from the Isle of Man. Some scholars have theorized that this figure is a depiction of Heimdallr with Gjallarhorn.

A 9th or 10th century Gosforth Cross in Cumbria, England depicts a figure holding a horn and a sword standing defiantly before two open-mouthed beasts. This figure has been often theorized as depicting Heimdallr with Gjallarhorn.

Heimdallr's attestations have proven troublesome and enigmatic to interpret for scholars. Scholar Georges Dumézil summarizes the difficulties as follows:




</doc>
<doc id="13658" url="https://en.wikipedia.org/wiki?curid=13658" title="House of Lords">
House of Lords

The House of Lords, also known as the House of Peers, is the upper house of the Parliament of the United Kingdom. Membership is granted, respectively ruled, by appointment, heredity or official function. Like the House of Commons, it meets in the Palace of Westminster. Officially, the full name of the house is the Right Honourable the Lords Spiritual and Temporal of the United Kingdom of Great Britain and Northern Ireland in Parliament assembled.

Unlike the elected House of Commons, members of the House of Lords (excluding 90 hereditary peers elected among themselves and two peers who are "ex officio" members) are appointed. The membership of the House of Lords is drawn from the peerage and is made up of Lords Spiritual and Lords Temporal. The Lords Spiritual are 26 bishops in the established Church of England. Of the Lords Temporal, the majority are life peers who are appointed by the monarch on the advice of the Prime Minister, or on the advice of the House of Lords Appointments Commission. However, they also include some hereditary peers including four dukes.

Membership was once an entitlement of all hereditary peers, other than those in the peerage of Ireland, but under the House of Lords Act 1999, the right to membership was restricted to 92 hereditary peers. Since 2008, only one of them is female (Countess of Mar); most hereditary peerages can be inherited only by men.

While the House of Commons has a defined 650-seat membership, the number of members in the House of Lords is not fixed. In 2013, there were 781 sitting Lords. As of 2013, the House of Lords was the only upper house of any bicameral parliament in the world to be larger than its lower house.

The House of Lords scrutinises bills that have been approved by the House of Commons. It regularly reviews and amends Bills from the Commons. While it is unable to prevent Bills passing into law, except in certain limited circumstances, it can delay Bills and force the Commons to reconsider their decisions. In this capacity, the House of Lords acts as a check on the House of Commons that is independent from the electoral process. Bills can be introduced into either the House of Lords or the House of Commons. While members of the Lords may also take on roles as government ministers, high-ranking officials such as cabinet ministers are usually drawn from the Commons. The House of Lords has its own support services, separate from the Commons, including the House of Lords Library.

The Queen's Speech is delivered in the House of Lords during the State Opening of Parliament. In addition to its role as the upper house, until the establishment of the Supreme Court in 2009, the House of Lords, through the Law Lords, acted as the final court of appeal in the United Kingdom judicial system. The House also has a Church of England role, in that Church Measures must be tabled within the House by the Lords Spiritual.

Today's Parliament of the United Kingdom largely descends, in practice, from the Parliament of England, though the Treaty of Union of 1706 and the Acts of Union that ratified the Treaty in 1707 and created a new Parliament of Great Britain to replace the Parliament of England and the Parliament of Scotland. This new parliament was, in effect, the continuation of the Parliament of England with the addition of 45 MPs and 16 Peers to represent Scotland.

The House of Lords developed from the "Great Council" ("Magnum Concilium") that advised the King during medieval times. This royal council came to be composed of ecclesiastics, noblemen, and representatives of the counties of England and Wales (afterwards, representatives of the boroughs as well). The first English Parliament is often considered to be the "Model Parliament" (held in 1295), which included archbishops, bishops, abbots, earls, barons, and representatives of the shires and boroughs of it.

The power of Parliament grew slowly, fluctuating as the strength of the monarchy grew or declined. For example, during much of the reign of Edward II (1307–1327), the nobility was supreme, the Crown weak, and the shire and borough representatives entirely powerless. In 1569, the authority of Parliament was for the first time recognised not simply by custom or royal charter, but by an authoritative statute, passed by Parliament itself.

During the reign of Edward II's successor, Edward III, Parliament clearly separated into two distinct chambers: the House of Commons (consisting of the shire and borough representatives) and the House of Lords (consisting of the bishops, abbots and peers). The authority of Parliament continued to grow, and during the early 15th century both Houses exercised powers to an extent not seen before. The Lords were far more powerful than the Commons because of the great influence of the great landowners and the prelates of the realm.

The power of the nobility declined during the civil wars of the late 15th century, known as the Wars of the Roses. Much of the nobility was killed on the battlefield or executed for participation in the war, and many aristocratic estates were lost to the Crown. Moreover, feudalism was dying, and the feudal armies controlled by the barons became obsolete. Henry VII (1485–1509) clearly established the supremacy of the monarch, symbolised by the "Crown Imperial". The domination of the Sovereign continued to grow during the reigns of the Tudor monarchs in the 16th century. The Crown was at the height of its power during the reign of Henry VIII (1509–1547).

The House of Lords remained more powerful than the House of Commons, but the Lower House continued to grow in influence, reaching a zenith in relation to the House of Lords during the middle 17th century. Conflicts between the King and the Parliament (for the most part, the House of Commons) ultimately led to the English Civil War during the 1640s. In 1649, after the defeat and execution of King Charles I, the Commonwealth of England was declared, but the nation was effectively under the overall control of Oliver Cromwell, Lord Protector of England, Scotland and Ireland.

The House of Lords was reduced to a largely powerless body, with Cromwell and his supporters in the Commons dominating the Government. On 19 March 1649, the House of Lords was abolished by an Act of Parliament, which declared that "The Commons of England [find] by too long experience that the House of Lords is useless and dangerous to the people of England." The House of Lords did not assemble again until the Convention Parliament met in 1660 and the monarchy was restored. It returned to its former position as the more powerful chamber of Parliament—a position it would occupy until the 19th century.

The 19th century was marked by several changes to the House of Lords. The House, once a body of only about 50 members, had been greatly enlarged by the liberality of George III and his successors in creating peerages. The individual influence of a Lord of Parliament was thus diminished.

Moreover, the power of the House as a whole decreased, whilst that of the House of Commons grew. Particularly notable in the development of the Lower House's superiority was the Reform Bill of 1832. The electoral system of the House of Commons was far from democratic: property qualifications greatly restricted the size of the electorate, and the boundaries of many constituencies had not been changed for centuries.

Entire cities such as Manchester had not even one representative in the House of Commons, while the 11 voters living in Old Sarum retained their ancient right to elect two MPs. A small borough was susceptible to bribery, and was often under the control of a patron, whose nominee was guaranteed to win an election. Some aristocrats were patrons of numerous "pocket boroughs", and therefore controlled a considerable part of the membership of the House of Commons.

When the House of Commons passed a Reform Bill to correct some of these anomalies in 1831, the House of Lords rejected the proposal. The popular cause of reform, however, was not abandoned by the ministry, despite a second rejection of the bill in 1832. Prime Minister Charles Grey, 2nd Earl Grey advised the King to overwhelm opposition to the bill in the House of Lords by creating about 80 new pro-Reform peers. William IV originally balked at the proposal, which effectively threatened the opposition of the House of Lords, but at length relented.

Before the new peers were created, however, the Lords who opposed the bill admitted defeat and abstained from the vote, allowing the passage of the bill. The crisis damaged the political influence of the House of Lords but did not altogether end it. A vital reform was effected by the Lords themselves in 1868, when they changed their standing orders to abolish proxy voting, preventing Lords from voting without taking the trouble to attend. Over the course of the century the power of the Upper House were further reduced stepwise, culminating in the 20th century with the Parliament Act of 1911. Then the Commons gradually became the stronger House of Parliament.

The status of the House of Lords returned to the forefront of debate after the election of a Liberal Government in 1906. In 1909, the Chancellor of the Exchequer, David Lloyd George, introduced into the House of Commons the "People's Budget", which proposed a land tax targeting wealthy landowners. The popular measure, however, was defeated in the heavily Conservative House of Lords.

Having made the powers of the House of Lords a primary campaign issue, the Liberals were narrowly re-elected in January 1910. Prime Minister H. H. Asquith then proposed that the powers of the House of Lords be severely curtailed. After a further general election in December 1910, and with an undertaking by King George V to create sufficient new Liberal peers to overcome Lords' opposition to the measure if necessary, the Asquith Government secured the passage of a bill to curtail the powers of the House of Lords.

The Parliament Act 1911 effectively abolished the power of the House of Lords to reject legislation, or to amend it in a way unacceptable to the House of Commons: most bills could be delayed for no more than three parliamentary sessions or two calendar years. It was not meant to be a permanent solution; more comprehensive reforms were planned. Neither party, however, pursued the matter with much enthusiasm, and the House of Lords remained primarily hereditary. In 1949, the Parliament Act reduced the delaying power of the House of Lords further to two sessions or one year.

In 1958, the predominantly hereditary nature of the House of Lords was changed by the Life Peerages Act 1958, which authorised the creation of life baronies, with no numerical limits. The number of Life Peers then gradually increased, though not at a constant rate.

The Labour Party had for most of the 20th century a commitment, based on the party's historic opposition to class privilege, to abolish the House of Lords, or at least expel the hereditary element. In 1968, the Labour Government of Harold Wilson attempted to reform the House of Lords by introducing a system under which hereditary peers would be allowed to remain in the House and take part in debate, but would be unable to vote. This plan, however, was defeated in the House of Commons by a coalition of traditionalist Conservatives (such as Enoch Powell), and Labour members who continued to advocate the outright abolition of the Upper House (such as Michael Foot).

When Michael Foot became leader of the Labour Party in 1980, abolition of the House of Lords became a part of the party's agenda; under his successor, Neil Kinnock, however, a reformed Upper House was proposed instead. In the meantime, the creation of hereditary peerages (except for members of the Royal Family) has been arrested, with the exception of three creations during the administration of the Conservative Margaret Thatcher in the 1980s.

Whilst some hereditary peers were at best apathetic, the Labour Party's clear commitments were not lost on Merlin Hanbury-Tracy, 7th Baron Sudeley, who for decades was considered an expert on the House of Lords. In December 1979 the Conservative Monday Club published his extensive paper entitled "Lords Reform – Why tamper with the House of Lords?" and in July 1980 "The Monarchist" carried another article by Sudeley entitled "Why Reform or Abolish the House of Lords?". In 1990 he wrote a further booklet for the Monday Club entitled "The Preservation of the House of Lords".

There were no women sitting in the House of Lords until 1958, when a small number came into the chamber as a result of the Life Peerages Act 1958. One of these was Irene Curzon, 2nd Baroness Ravensdale, who had inherited her father's peerage in 1925 and was made a life peer to enable her to sit. After a campaign stretching back in some cases to the 1920s, another twelve women who held hereditary peerages in their own right were finally admitted by the Peerage Act 1963.

The Labour Party included in its 1997 general election Manifesto a commitment to remove the hereditary peerage from the House of Lords. Their subsequent election victory in 1997 under Tony Blair led to the denouement of the traditional House of Lords. The Labour Government introduced legislation to expel all hereditary peers from the Upper House as a first step in Lords reform. As a part of a compromise, however, it agreed to permit 92 hereditary peers to remain until the reforms were complete. Thus all but 92 hereditary peers were expelled under the House of Lords Act 1999 (see below for its provisions), making the House of Lords predominantly an appointed house.

Since 1999, however, no further reform has taken place. The Wakeham Commission proposed introducing a 20% elected element to the Lords, but this plan was widely criticised. A parliamentary Joint Committee was established in 2001 to resolve the issue, but it reached no conclusion and instead gave Parliament seven options to choose from (fully appointed, 20% elected, 40% elected, 50% elected, 60% elected, 80%, and fully elected). In a confusing series of votes in February 2003, all of these options were defeated, although the 80% elected option fell by just three votes in the Commons. Socialist MPs favouring outright abolition voted against all the options.

In 2005, a cross-party group of senior MPs (Kenneth Clarke, Paul Tyler, Tony Wright, George Young and Robin Cook) published a report proposing that 70% of members of the House of Lords should be elected — each member for a single long term — by the single transferable vote system. Most of the remainder were to be appointed by a Commission to ensure a mix of "skills, knowledge and experience". This proposal was also not implemented. A cross-party campaign initiative called "Elect the Lords" was set up to make the case for a predominantly elected Second Chamber in the run up to the 2005 general election.

At the 2005 election, the Labour Party proposed further reform of the Lords, but without specific details. The Conservative Party, which had, prior to 1997, opposed any tampering with the House of Lords, favoured an 80% elected Second Chamber, while the Liberal Democrats called for a fully elected Senate. During 2006, a cross-party committee discussed Lords reform, with the aim of reaching a consensus: its findings were published in early 2007.

On 7 March 2007, members of the House of Commons voted ten times on a variety of alternative compositions for the upper chamber. Outright abolition, a wholly appointed house, a 20% elected house, a 40% elected house, a 50% elected house and a 60% elected house were all defeated in turn. Finally the vote for an 80% elected chamber was won by 305 votes to 267, and the vote for a wholly elected chamber was won by an even greater margin: 337 to 224. Significantly this last vote represented an overall majority of MPs.

Furthermore, examination of the names of MPs voting at each division shows that, of the 305 who voted for the 80% elected option, 211 went on to vote for the 100% elected option. Given that this vote took place after the vote on 80% – whose result was already known when the vote on 100% took place – this showed a clear preference for a fully elected upper house among those who voted for the only other option that passed. But this was nevertheless only an indicative vote and many political and legislative hurdles remained to be overcome for supporters of an elected second chamber. The House of Lords, soon after, rejected this proposal and voted for an entirely appointed House of Lords.

In July 2008, Jack Straw, the Secretary of State for Justice and Lord Chancellor, introduced a white paper to the House of Commons proposing to replace the House of Lords with an 80–100% elected chamber, with one third being elected at each general election, for a term of approximately 12–15 years. The white paper states that as the peerage would be totally separated from membership of the upper house, the name "House of Lords" would no longer be appropriate: It goes on to explain that there is cross-party consensus for the new chamber to be titled the "Senate of the United Kingdom"; however, to ensure the debate remains on the role of the upper house rather than its title, the white paper is neutral on the title of the new house.

On 30 November 2009, a "Code of Conduct for Members of the House of Lords" was agreed by them; certain amendments were agreed by them on 30 March 2010 and on 12 June 2014. The scandal over expenses in the Commons was at its highest pitch only six months before, and the Labourite leadership under Baroness Royall of Blaisdon determined that something sympathetic should be done.

In Meg Russell's article "Is the House of Lords already reformed?", she states three essential features of a legitimate House of Lords. The first is that it must have adequate powers over legislation to make the government think twice before making a decision. The House of Lords, she argues, currently has enough power to make it relevant. During Tony Blair's first year, he was defeated 38 times in the Lords. Secondly, as to the composition of the Lords, Meg Russell suggests that the composition must be distinct from the Commons, otherwise it would render the Lords useless. The third feature is the perceived legitimacy of the Lords. She writes, "In general legitimacy comes with election."

If the Lords have a distinct and elected composition, this would probably come about through fixed term proportional representation. If this happens, then the perceived legitimacy of the Lords could arguably outweigh the legitimacy of the Commons. This would especially be the case if the House of Lords had been elected more recently than the House of Commons as it could be said to reflect the will of the people better than the Commons.

In this scenario, there may well come a time when the Lords twice reject a Bill from the Commons and it is forced through. This would in turn trigger questions about the amount of power the Lords should have and there would be pressure for it to increase. This hypothetical process is known as the "circumnavigation of power theory". It implies that it would never be in any government's interest to legitimise the Lords, as they would be forfeiting their own power.

The Conservative–Liberal Democrat coalition agreed, after the 2010 general election, to outline clearly a provision for a wholly or mainly elected second chamber, elected by proportional representation. These proposals sparked a debate on 29 June 2010. As an interim measure, appointment of new peers would reflect the shares of the vote secured by the political parties in the last general election.

Detailed proposals for Lords reform, including a draft House of Lords Reform Bill, were published on 17 May 2011. These included a 300-member hybrid house, of whom 80% would be elected. A further 20% would be appointed, and reserve space would be included for some Church of England bishops. Under the proposals, members would also serve single non-renewable terms of 15 years. Former MPs would be allowed to stand for election to the Upper House, but members of the Upper House would not be immediately allowed to become MPs.

The details of the proposal were:

The proposals were considered by a Joint Committee on House of Lords Reform made up of both MPs and Peers, which issued its final report on 23 April 2012, making the following suggestions:

Deputy Prime Minister Nick Clegg introduced the House of Lords Reform Bill 2012 on 27 June 2012 which built on proposals published on 17 May 2011. However, this Bill was abandoned by the Government on 6 August 2012 following opposition from within the Conservative Party.

A private members bill to introduce some reforms was introduced by Dan Byles in 2013. The House of Lords Reform Act 2014 received the Royal Assent in 2014. Under the new law:


The House of Lords (Expulsion and Suspension) Act 2015 authorised the House to expel or suspend members.

This act makes provision to preferentially admit bishops of the Church of England who are women to the Lords Spiritual in the 10 years following its commencement.

In 2015, Rachel Treweek, Bishop of Gloucester, became the first woman to sit as a Lord Spiritual in the House of Lords.

The size of the House of Lords has varied greatly throughout its history. From about 220 members in the early 1700s, it increased to a record size of 1,330 in October 1999, before Lords reform reduced it to 669 by March 2000.

In April 2011, a cross-party group of former leading politicians, including many senior members of the House of Lords, called on the Prime Minister David Cameron to stop creating new peers. He had created 117 new peers since becoming prime minister in May 2010, a faster rate of elevation than any PM in British history. The expansion occurred while his government had tried (in vain) to reduce the size of the House of Commons by 50 members, from 650 to 600.

In August 2014, despite there being a seating capacity of only around 230 to 400 on the benches in the Lords chamber, the House had 774 active members (plus 54 who were not entitled to attend or vote, having been suspended or granted leave of absence). This made the House of Lords the largest parliamentary chamber in any democracy. In August 2014, former Speaker of the House of Commons Betty Boothroyd requested that "older peers should retire gracefully" to ease the overcrowding in the House of Lords. She also criticised successive prime ministers for filling the second chamber with "lobby fodder" in an attempt to help their policies become law. She made her remarks days before a new batch of peers were due to be created.

In August 2015, following the creation of a further 45 peers in the Dissolution Honours, the total number of eligible members of the Lords increased to 826. In a report entitled "Does size matter?" the BBC said: "Increasingly, yes. Critics argue the House of Lords is the second largest legislature after the Chinese National People's Congress and dwarfs Upper Houses in other bi-cameral democracies such as the United States (100 senators), France (348 senators), Australia (76 senators) and India (250 members). The Lords is also larger than the Supreme People's Assembly of North Korea (687 members). [...] Peers grumble that there is not enough room to accommodate all of their colleagues in the Chamber, where there are only about 400 seats, and say they are constantly jostling for space – particularly during high-profile sittings", but added, "On the other hand, defenders of the Lords say that it does a vital job scrutinising legislation, a lot of which has come its way from the Commons in recent years".

Legislation, with the exception of money bills, may be introduced in either House.

The House of Lords debates legislation, and has power to amend or reject bills. However, the power of the Lords to reject a bill passed by the House of Commons is severely restricted by the Parliament Acts. Under those Acts, certain types of bills may be presented for the Royal Assent without the consent of the House of Lords (i.e. the Commons can override the Lords' veto). The House of Lords cannot delay a money bill (a bill that, in the view of the Speaker of the House of Commons, solely concerns national taxation or public funds) for more than one month.

Other public bills cannot be delayed by the House of Lords for more than two parliamentary sessions, or one calendar year. These provisions, however, only apply to public bills that originate in the House of Commons, and cannot have the effect of extending a parliamentary term beyond five years. A further restriction is a constitutional convention known as the Salisbury Convention, which means that the House of Lords does not oppose legislation promised in the Government's election manifesto.

By a custom that prevailed even before the Parliament Acts, the House of Lords is further restrained insofar as financial bills are concerned. The House of Lords may neither originate a bill concerning taxation or Supply (supply of treasury or exchequer funds), nor amend a bill so as to insert a taxation or Supply-related provision. (The House of Commons, however, often waives its privileges and allows the Upper House to make amendments with financial implications.) Moreover, the Upper House may not amend any Supply Bill. The House of Lords formerly maintained the absolute power to reject a bill relating to revenue or Supply, but this power was curtailed by the Parliament Acts, as aforementioned.

The House of Lords does not control the term of the Prime Minister or of the Government. Only the Lower House may force the Prime Minister to resign or call elections by passing a motion of no-confidence or by withdrawing supply. Thus, the House of Lords' oversight of the government is limited.

Most Cabinet ministers are from the House of Commons rather than the House of Lords. In particular, all Prime Ministers since 1902 have been members of the Lower House. (Alec Douglas-Home, who became Prime Minister in 1963 whilst still an Earl, disclaimed his peerage and was elected to the Commons soon after his term began.) In recent history, it has been very rare for major cabinet positions (except Lord Chancellor and Leader of the House of Lords) to have been filled by peers.

Exceptions include Lord Carrington, who was the Foreign Secretary between 1979 and 1982, Lord Young of Graffham (Minister without Portfolio, then Secretary of State for Employment and then Secretary of State for Trade and Industry from 1984 to 1989), Baroness Amos, who served as Secretary of State for International Development and Lord Mandelson, who served as First Secretary of State, Secretary of State for Business, Innovation and Skills and President of the Board of Trade. Lord Robertson of Port Ellen was briefly a peer whilst serving as Secretary of State for Defence before resigning to take up the post of Secretary General of NATO. From 1999 to 2010 the Attorney General for England and Wales was a Member of the House of Lords; the most recent was Patricia Scotland.

The House of Lords remains a source for junior ministers and members of government. Like the House of Commons, the Lords also has a Government Chief Whip as well as several Junior Whips. Where a government department is not represented by a minister in the Lords or one is not available, government whips will act as spokesmen for them.

Historically, the House of Lords held several judicial functions. Most notably, until 2009 the House of Lords served as the court of last resort for most instances of UK law. Since 1 October 2009 this role is now held by the Supreme Court of the United Kingdom.

The Lords' judicial functions originated from the ancient role of the Curia Regis as a body that addressed the petitions of the King's subjects. The functions were exercised not by the whole House, but by a committee of "Law Lords". The bulk of the House's judicial business was conducted by the twelve Lords of Appeal in Ordinary, who were specifically appointed for this purpose under the Appellate Jurisdiction Act 1876.

The judicial functions could also be exercised by Lords of Appeal (other members of the House who happened to have held high judicial office). No Lord of Appeal in Ordinary or Lord of Appeal could sit judicially beyond the age of seventy-five. The judicial business of the Lords was supervised by the Senior Lord of Appeal in Ordinary and their deputy, the Second Senior Lord of Appeal in Ordinary.

The jurisdiction of the House of Lords extended, in civil and in criminal cases, to appeals from the courts of England and Wales, and of Northern Ireland. From Scotland, appeals were possible only in civil cases; Scotland's High Court of Justiciary is the highest court in criminal matters. The House of Lords was not the United Kingdom's only court of last resort; in some cases, the Judicial Committee of the Privy Council performs such a function. The jurisdiction of the Privy Council in the United Kingdom, however, is relatively restricted; it encompasses appeals from ecclesiastical courts, disputes under the House of Commons Disqualification Act 1975, and a few other minor matters. Issues related to devolution were transferred from the Privy Council to the Supreme Court in 2009.

The twelve Law Lords did not all hear every case; rather, after World War II cases were heard by panels known as Appellate Committees, each of which normally consisted of five members (selected by the Senior Lord). An Appellate Committee hearing an important case could consist of more than five members. Though Appellate Committees met in separate committee rooms, judgement was given in the Lords Chamber itself. No further appeal lay from the House of Lords, although the House of Lords could refer a "preliminary question" to the European Court of Justice in cases involving an element of European Union law, and a case could be brought at the European Court of Human Rights if the House of Lords did not provide a satisfactory remedy in cases where the European Convention on Human Rights was relevant.

A distinct judicial function—one in which the whole House used to participate—is that of trying impeachments. Impeachments were brought by the House of Commons, and tried in the House of Lords; a conviction required only a majority of the Lords voting. Impeachments, however, are to all intents and purposes obsolete; the last impeachment was that of Henry Dundas, 1st Viscount Melville, in 1806.

Similarly, the House of Lords was once the court that tried peers charged with high treason or felony. The House would be presided over not by the Lord Chancellor, but by the Lord High Steward, an official especially appointed for the occasion of the trial. If Parliament was not in session, then peers could be tried in a separate court, known as the Lord High Steward's Court. Only peers, their wives, and their widows (unless remarried) were entitled to such trials; the Lords Spiritual were tried in ecclesiastical courts. In 1948, the right of peers to be tried in such special courts was abolished; now, they are tried in the regular courts. The last such trial in the House was of Edward Russell, 26th Baron de Clifford, in 1935. An illustrative dramatisation circa 1928 of a trial of a peer (the fictional Duke of Denver) on a charge of murder (a felony) is portrayed in the 1972 BBC Television adaption of Dorothy L. Sayers' Lord Peter Wimsey mystery "Clouds of Witness".

The Constitutional Reform Act 2005 resulted in the creation of a separate Supreme Court of the United Kingdom, to which the judicial function of the House of Lords, and some of the judicial functions of the Judicial Committee of the Privy Council, were transferred. In addition, the office of Lord Chancellor was reformed by the act, removing his ability to act as both a government minister and a judge. This was motivated in part by concerns about the historical admixture of legislative, judicial, and executive power. The new Supreme Court is located at Middlesex Guildhall.

Members of the House of Lords who sit by virtue of their ecclesiastical offices are known as Lords Spiritual. Formerly, the Lords Spiritual were the majority in the English House of Lords, comprising the church's archbishops, (diocesan) bishops, abbots, and those priors who were entitled to wear a mitre. After the English Reformation's highpoint in 1539, only the archbishops and bishops continued to attend, as the Dissolution of the Monasteries had just disproved of and suppressed the positions of abbot and prior. In 1642, during the few Lords' gatherings convened during English Interregnum which saw periodic war, the Lords Spiritual were excluded altogether, but they returned under the Clergy Act 1661.

The number of Lords Spiritual was further restricted by the Bishopric of Manchester Act 1847, and by later Acts. The Lords Spiritual can now number no more than 26; these are the Archbishop of Canterbury, the Archbishop of York, the Bishop of London, the Bishop of Durham, the Bishop of Winchester (who sit by right regardless of seniority) and the 21 longest-serving bishops from other dioceses in the Church of England (excluding the dioceses of Sodor and Man and Gibraltar in Europe, as these lie entirely outside the United Kingdom). Following a change to the law in 2014 to allow women to be ordained bishops, the Lords Spiritual (Women) Act 2015 was passed, which provides that whenever a vacancy arises among the Lords Spiritual during the ten years following the Act coming into force, the vacancy has to be filled by a woman, if one is eligible. This does not apply to the five bishops who sit by right.

The current Lords Spiritual represent only the Church of England. Bishops of the Church of Scotland historically sat in the Parliament of Scotland but were finally excluded in 1689 (after a number of previous exclusions) when the Church of Scotland became permanently Presbyterian. There are no longer bishops in the Church of Scotland in the traditional sense of the word, and that Church has never sent members to sit in the Westminster House of Lords. The Church of Ireland did obtain representation in the House of Lords after the union of Ireland and Great Britain in 1801.

Of the Church of Ireland's ecclesiastics, four (one archbishop and three bishops) were to sit at any one time, with the members rotating at the end of every parliamentary session (which normally lasted about one year). The Church of Ireland, however, was disestablished in 1871, and thereafter ceased to be represented by Lords Spiritual. Bishops of Welsh sees in the Church of England originally sat in the House of Lords (after 1847, only if their seniority within the Church entitled them to), but the Church in Wales ceased to be a part of the Church of England in 1920 and was simultaneously disestablished in Wales. Accordingly, bishops of the Church in Wales were no longer eligible to be appointed to the House as bishops of the Church of England, but those already appointed remained.

Other ecclesiastics have sat in the House of Lords as Lords Temporal in recent times: Chief Rabbi Immanuel Jakobovits was appointed to the House of Lords (with the consent of the Queen, who acted on the advice of Prime Minister Margaret Thatcher), as was his successor Chief Rabbi Jonathan Sacks. Julia Neuberger is the Senior Rabbi to the West London Synagogue. In recognition of his work at reconciliation and in the peace process in Northern Ireland, the Archbishop of Armagh (the senior Anglican bishop in Northern Ireland), Robin Eames, was appointed to the Lords by John Major. Other clergymen appointed include Donald Soper, Timothy Beaumont, and some Scottish clerics.

There have been no Roman Catholic clergymen appointed, though it was rumoured that Cardinal Basil Hume and his successor Cormac Murphy O'Connor were offered peerages, by James Callaghan, Margaret Thatcher and Tony Blair respectively, but declined. Hume later accepted the Order of Merit, a personal appointment of the Queen, shortly before his death. O'Connor said he had his maiden speech ready, but Roman Catholics who have received Holy Orders are prohibited by Canon Law from holding major offices connected with any government other than the Holy See.

Former Archbishops of Canterbury, having reverted to the status of bishop but who are no longer diocesans, are invariably given life peerages and sit as Lords Temporal.

By custom at least one of the Bishops reads prayers in each legislative day (a role taken by the chaplain in the Commons). They often speak in debates; in 2004 Rowan Williams, the Archbishop of Canterbury, opened a debate into sentencing legislation. Measures (proposed laws of the Church of England) must be put before the Lords, and the Lords Spiritual have a role in ensuring that this takes place.

Since the Dissolution of the Monasteries, the Lords Temporal have been the most numerous group in the House of Lords. Unlike the Lords Spiritual, they may be publicly partisan, aligning themselves with one or another of the political parties that dominate the House of Commons. Publicly non-partisan Lords are called crossbenchers. Originally, the Lords Temporal included several hundred hereditary peers (that is, those whose peerages may be inherited), who ranked variously as dukes, marquesses, earls, viscounts, and barons (as well as Scottish Lords of Parliament). Such hereditary dignities can be created by the Crown; in modern times this is done on the advice of the Prime Minister of the day (except in the case of members of the Royal Family).

Holders of Scottish and Irish peerages were not always permitted to sit in the Lords. When Scotland united with England to form Great Britain in 1707, it was provided that the Scottish hereditary peers would only be able to elect 16 representative peers to sit in the House of Lords; the term of a representative was to extend until the next general election. A similar provision was enacted when Ireland merged with Great Britain in 1801 to form the United Kingdom; the Irish peers were allowed to elect 28 representatives, who were to retain office for life. Elections for Irish representatives ended in 1922, when most of Ireland became an independent state; elections for Scottish representatives ended with the passage of the Peerage Act 1963, under which all Scottish peers obtained seats in the Upper House.

In 1999, the Labour government brought forward the House of Lords Act removing the right of several hundred hereditary peers to sit in the House. The Act provided, as a measure intended to be temporary, that 92 people would continue to sit in the Lords by virtue of hereditary peerages, and this is still in effect.

Of the 92, two remain in the House of Lords because they hold royal offices connected with Parliament: the Earl Marshal and the Lord Great Chamberlain. Of the remaining ninety peers sitting in the Lords by virtue of a hereditary peerage, 15 are elected by the whole House and 75 are chosen by fellow hereditary peers in the House of Lords, grouped by party. (If a hereditary peerage holder is given a life peerage, he or she becomes a member of the House of Lords without a need for a by-election.) The exclusion of other hereditary peers removed Charles, Prince of Wales (who is also Earl of Chester) and all other Royal Peers, including Prince Philip, Duke of Edinburgh; Prince Andrew, Duke of York; Prince Edward, Earl of Wessex; Prince Richard, Duke of Gloucester; and Prince Edward, Duke of Kent.

The number of peers to be chosen by a political group reflects the proportion of hereditary peers that belonged to that group (see current composition below) in 1999. When an elected hereditary peer dies, a by-election is held, with a variant of the Alternative Vote system being used. If the recently deceased hereditary peer had been elected by the whole House, then so is his or her replacement; a hereditary peer elected by a specific political group (including the non-aligned crossbenchers) is replaced by a vote of the hereditary peers already elected to the Lords belonging to that political group (whether elected by that group or by the whole house).

Until 2009, the Lords Temporal also included the Lords of Appeal in Ordinary, a group of individuals appointed to the House of Lords so that they could exercise its judicial functions. Lords of Appeal in Ordinary, more commonly known as Law Lords, were first appointed under the Appellate Jurisdiction Act 1876. They were selected by the Prime Minister of the day, but were formally appointed by the Sovereign. A Lord of Appeal in Ordinary had to retire at the age of 70, or, if his or her term was extended by the government, at the age of 75; after reaching such an age, the Law Lord could not hear any further cases in the House of Lords.

The number of Lords of Appeal in Ordinary (excluding those who were no longer able to hear cases because of age restrictions) was limited to twelve, but could be changed by statutory instrument. By a convention of the House, Lords of Appeal in Ordinary did not take part in debates on new legislation, so as to maintain judicial independence. Lords of Appeal in Ordinary held their seats in the House of Lords for life, remaining as members even after reaching the judicial retirement age of 70 or 75. Former Lord Chancellors and holders of other high judicial office could also sit as Law Lords under the Appellate Jurisdiction Act, although in practice this right was only rarely exercised.

Under the Constitutional Reform Act 2005, the Lords of Appeal in Ordinary when the Act came into effect in 2009 became judges of the new Supreme Court of the United Kingdom and were then barred from sitting or voting in the House of Lords until they had retired as judges. One of the main justifications for the new Supreme Court was to establish a separation of powers between the judiciary and the legislature. It is therefore unlikely that future appointees to the Supreme Court of the United Kingdom will be made Lords of Appeal in Ordinary.

The largest group of Lords Temporal, and indeed of the whole House, are life peers. Life peerages rank only as barons or baronesses, and are created under the Life Peerages Act 1958. Like all other peers, life peers are created by the Sovereign, who acts on the advice of the Prime Minister or the House of Lords Appointments Commission. By convention, however, the Prime Minister allows leaders of other parties to nominate some life peers, so as to maintain a political balance in the House of Lords. Moreover, some non-party life peers (the number being determined by the Prime Minister) are nominated by the independent House of Lords Appointments Commission.

In 2000, the government announced it would set up an Independent Appointments Commission, under Lord Stevenson of Coddenham, to select fifteen so-called "people's peers" for life peerages. However, when the choices were announced in April 2001, from a list of 3,000 applicants, the choices were treated with criticism in the media, as all were distinguished in their field, and none were "ordinary people" as some had originally hoped.

Several different qualifications apply for membership of the House of Lords. No person may sit in the House of Lords if under the age of 21. Furthermore, only United Kingdom, Irish and Commonwealth citizens may sit in the House of Lords. The nationality restrictions were previously more stringent: under the Act of Settlement 1701, and prior to the British Nationality Act 1948, only natural-born subjects qualified.

Additionally, some bankruptcy-related restrictions apply to members of the Upper House. A person may not sit in the House of Lords if he or she is the subject of a Bankruptcy Restrictions Order (applicable in England and Wales only), or if he or she is adjudged bankrupt (in Northern Ireland), or if his or her estate is sequestered (in Scotland). A final restriction bars an individual convicted of high treason from sitting in the House of Lords until completing his or her full term of imprisonment. An exception applies, however, if the individual convicted of high treason receives a full pardon. Note that an individual serving a prison sentence for an offence other than high treason is "not" automatically disqualified.

Women were excluded from the House of Lords until the Life Peerages Act 1958, passed to address the declining number of active members, made possible the creation of peerages for life. Women were immediately eligible and four were among the first life peers appointed. However, hereditary peeresses continued to be excluded until the passage of the Peerage Act 1963. Since the passage of the House of Lords Act 1999, hereditary peeresses remain eligible for election to the Upper House; there is one (Margaret of Mar, 31st Countess of Mar) among the 90 hereditary peers who continue to sit.

The Honours (Prevention of Abuses) Act 1925 made it illegal for a peerage, or other honour, to be bought or sold. Nonetheless, there have been repeated allegations that life peerages (and thus membership of the House of Lords) have been made available to major political donors in exchange for donations. The most prominent case, the 2006 Cash for Honours scandal, saw a police investigation, with no charges being brought. A 2015 study found that of 303 people nominated for peerages in the period 2005–14, a total of 211 were former senior figures within politics (including former MPs), or were non-political appointments. Of the remaining 92 political appointments from outside public life, 27 had made significant donations to political parties. The authors concluded firstly that nominees from outside public life were much more likely to have made large gifts than peers nominated after prior political or public service. They also found that significant donors to parties were far more likely to be nominated for peerages than other party members.

Traditionally there was no mechanism by which members could resign or be removed from the House of Lords (compare the situation as regards resignation from the House of Commons). The Peerage Act 1963 permitted a person to disclaim their newly inherited peerage (within certain time limits); this meant that such a person could effectively renounce their membership of the Lords. This might be done in order to remain or become qualified to sit in the House of Commons, as in the case of Tony Benn (formerly the second Viscount Stansgate), who had campaigned for such a change.

The House of Lords Reform Act 2014 made provision for members' resignation from the House, removal for non-attendance, and automatic expulsion upon conviction for a serious criminal offence (if resulting in a jail sentence of at least one year). In June 2015, under the House of Lords (Expulsion and Suspension) Act 2015, the House's Standing Orders may provide for the expulsion or suspension of a member upon a resolution of the House.

Traditionally the House of Lords did not elect its own speaker, unlike the House of Commons; rather, the "ex officio" presiding officer was the Lord Chancellor. With the passage of the Constitutional Reform Act 2005, the post of Lord Speaker was created, a position to which a peer is elected by the House and subsequently appointed by the Crown. The first Lord Speaker, elected on 4 May 2006, was Baroness Hayman, a former Labour peer. As the Speaker is expected to be an impartial presiding officer, Hayman resigned from the Labour Party. In 2011, Baroness D'Souza was elected as the second Lord Speaker, replacing Hayman in September 2011. D'Souza was in turn succeeded by Lord Fowler in September 2016, the incumbent Lord Speaker.

This reform of the post of Lord Chancellor was made due to the perceived constitutional anomalies inherent in the role. The Lord Chancellor was not only the Speaker of the House of Lords, but also a member of the Cabinet; his or her department, formerly the Lord Chancellor's Department, is now called the Ministry of Justice. The Lord Chancellor is no longer the head of the judiciary of England and Wales. Hitherto, the Lord Chancellor was part of all three branches of government: the legislative, the executive, and the judicial.

The overlap of the legislative and executive roles is a characteristic of the Westminster system, as the entire cabinet consists of members of the House of Commons or the House of Lords; however, in June 2003, the Blair Government announced its intention to abolish the post of Lord Chancellor because of the office's mixed executive and judicial responsibilities. The abolition of the office was rejected by the House of Lords, and the Constitutional Reform Act 2005 was thus amended to preserve the office of Lord Chancellor. The Act no longer guarantees that the office holder of Lord Chancellor is the presiding officer of the House of Lords, and therefore allows the House of Lords to elect a speaker of their own.
The Lord Speaker may be replaced as presiding officer by one of his or her deputies. The Chairman of Committees, the Principal Deputy Chairman of Committees, and several Chairmen are all deputies to the Lord Speaker, and are all appointed by the House of Lords itself at the beginning of each session. By custom, the Crown appoints each Chairman, Principal Deputy Chairman and Deputy Chairman to the additional office of Deputy Speaker of the House of Lords. There was previously no legal requirement that the Lord Chancellor or a Deputy Speaker be a member of the House of Lords (though the same has long been customary).

Whilst presiding over the House of Lords, the Lord Chancellor traditionally wore ceremonial black and gold robes. Robes of black and gold are now worn by the Lord Chancellor and Secretary of State for Justice in the House of Commons, on ceremonial occasions. This is no longer a requirement for the Lord Speaker except for State occasions outside of the chamber. The Speaker or Deputy Speaker sits on the Woolsack, a large red seat stuffed with wool, at the front of the Lords Chamber.

When the House of Lords resolves itself into committee (see below), the Chairman of Committees or a Deputy Chairman of Committees presides, not from the Woolsack, but from a chair at the Table of the House. The presiding officer has little power compared to the Speaker of the House of Commons. He or she only acts as the mouthpiece of the House, performing duties such as announcing the results of votes. This is because, unlike in the House of Commons where all statements are directed to "Mr/Madam Speaker", in the House of Lords they are directed to "My Lords"; i.e., the entire body of the House.

The Lord Speaker or Deputy Speaker cannot determine which members may speak, or discipline members for violating the rules of the House; these measures may be taken only by the House itself. Unlike the politically neutral Speaker of the House of Commons, the Lord Chancellor and Deputy Speakers originally remained members of their respective parties, and were permitted to participate in debate; however, this is no longer true of the new role of Lord Speaker.

Another officer of the body is the Leader of the House of Lords, a peer selected by the Prime Minister. The Leader of the House is responsible for steering Government bills through the House of Lords, and is a member of the Cabinet. The Leader also advises the House on proper procedure when necessary, but such advice is merely informal, rather than official and binding. A Deputy Leader is also appointed by the Prime Minister, and takes the place of an absent or unavailable leader.

The Clerk of the Parliaments is the chief clerk and officer of the House of Lords (but is not a member of the House itself). The Clerk, who is appointed by the Crown, advises the presiding officer on the rules of the House, signs orders and official communications, endorses bills, and is the keeper of the official records of both Houses of Parliament. Moreover, the Clerk of the Parliaments is responsible for arranging by-elections of hereditary peers when necessary. The deputies of the Clerk of the Parliaments (the Clerk Assistant and the Reading Clerk) are appointed by the Lord Speaker, subject to the House's approval.

The Gentleman Usher of the Black Rod is also an officer of the House; he takes his title from the symbol of his office, a black rod. Black Rod (as the Gentleman Usher is normally known) is responsible for ceremonial arrangements, is in charge of the House's doorkeepers, and may (upon the order of the House) take action to end disorder or disturbance in the Chamber. Black Rod also holds the office of Serjeant-at-Arms of the House of Lords, and in this capacity attends upon the Lord Speaker. The Gentleman Usher of the Black Rod's duties may be delegated to the Yeoman Usher of the Black Rod or to the Assistant Serjeant-at-Arms.

The House of Lords and the House of Commons assemble in the Palace of Westminster. The Lords Chamber is lavishly decorated, in contrast with the more modestly furnished Commons Chamber. Benches in the Lords Chamber are coloured red. The Woolsack is at the front of the Chamber; the Government sit on benches on the right of the Woolsack, while members of the Opposition sit on the left. Crossbenchers, sit on the benches immediately opposite the Woolsack.

The Lords Chamber is the site of many formal ceremonies, the most famous of which is the State Opening of Parliament, held at the beginning of each new parliamentary session. During the State Opening, the Sovereign, seated on the Throne in the Lords Chamber and in the presence of both Houses of Parliament, delivers a speech outlining the Government's agenda for the upcoming parliamentary session.

In the House of Lords, members need not seek the recognition of the presiding officer before speaking, as is done in the House of Commons. If two or more Lords simultaneously rise to speak, the House decides which one is to be heard by acclamation, or, if necessary, by voting on a motion. Often, however, the Leader of the House will suggest an order, which is thereafter generally followed. Speeches in the House of Lords are addressed to the House as a whole ("My Lords") rather than to the presiding officer alone (as is the custom in the Lower House). Members may not refer to each other in the second person (as "you"), but rather use third person forms such as "the noble Duke", "the noble Earl", "the noble Lord", "my noble friend", "The most Reverend Primate", etc.

Each member may make no more than one speech on a motion, except that the mover of the motion may make one speech at the beginning of the debate and another at the end. Speeches are not subject to any time limits in the House; however, the House may put an end to a speech by approving a motion "that the noble Lord be no longer heard". It is also possible for the House to end the debate entirely, by approving a motion "that the Question be now put". This procedure is known as Closure, and is extremely rare.

Once all speeches on a motion have concluded, or Closure invoked, the motion may be put to a vote. The House first votes by voice vote; the Lord Speaker or Deputy Speaker puts the question, and the Lords respond either "content" (in favour of the motion) or "not content" (against the motion). The presiding officer then announces the result of the voice vote, but if his assessment is challenged by any Lord, a recorded vote known as a division follows.

Members of the House enter one of two lobbies (the "content" lobby or the "not-content" lobby) on either side of the Chamber, where their names are recorded by clerks. At each lobby are two Tellers (themselves members of the House) who count the votes of the Lords. The Lord Speaker may not take part in the vote. Once the division concludes, the Tellers provide the results thereof to the presiding officer, who then announces them to the House.

If there is an equality of votes, the motion is decided according to the following principles: legislation may proceed in its present form, unless there is a majority in favour of amending or rejecting it; any other motions are rejected, unless there is a majority in favour of approving it. The quorum of the House of Lords is just three members for a general or procedural vote, and 30 members for a vote on legislation. If fewer than three or 30 members (as appropriate) are present, the division is invalid.

By contrast with the House of Commons, the House of Lords has not until recently had an established procedure for putting sanctions on its members. When a cash for influence scandal was referred to the Committee of Privileges in January 2009, the Leader of the House of Lords also asked the Privileges Committee to report on what sanctions the House had against its members. After seeking advice from the Attorney General for England and Wales and the former Lord Chancellor James Lord Mackay of Clashfern, the committee decided that the House "possessed an inherent power" to suspend errant members, although not to withhold a writ of summons nor to expel a member permanently. When the House subsequently suspended Lord Truscott and Lord Taylor of Blackburn for their role in the scandal, they were the first to meet this fate since 1642.

Recent changes have expanded the disciplinary powers of the House. Section 3 of the House of Lords Reform Act 2014 now provides that any member of the House of Lords convicted of a crime and sentenced to imprisonment for more than one year loses their seat. The House of Lords (Expulsion and Suspension) Act 2015 allows the House to set up procedures to suspend, and to expel, its members.

There are two motions which have grown up through custom and practice and which govern questionable conduct within the House. They are brought into play by a member standing up, possibly intervening on another member, and moving the motion without notice. When the debate is getting excessively heated, it is open to a member to move "that the Standing Order on Asperity of Speech be read by the Clerk". The motion can be debated, but if agreed by the House, the Clerk of the Parliaments will read out Standing Order 33 which provides "That all personal, sharp, or taxing speeches be forborn". The Journals of the House of Lords record only four instances on which the House has ordered the Standing Order to be read since the procedure was invented in 1871.

For more serious problems with an individual Lord, the option is available to move "That the noble Lord be no longer heard". This motion also is debatable, and the debate which ensues has sometimes offered a chance for the member whose conduct has brought it about to come to order so that the motion can be withdrawn. If the motion is passed, its effect is to prevent the member from continuing their speech on the motion then under debate. The Journals identify eleven occasions on which this motion has been moved since 1884; four were eventually withdrawn, one was voted down, and six were passed.

In 1958, to counter criticism that some peers only appeared at major decisions in the House and thereby particular votes were swayed, the Standing Orders of the House of Lords were enhanced. Peers who did not wish to attend meetings regularly or were prevented by ill health, age or further reasons, were now able to request Leave of Absence. During the granted time a peer is expected not to visit the House's meetings until either its expiration or termination, announced at least a month prior to their return.

Members of the House of Lords can, since 2010, opt to receive a £300 per day attendance allowance, plus limited travel expenses. Peers can elect to receive a reduced attendance allowance of £150 per day instead. Prior to 2010 peers from outside London could claim an overnight allowance of £174.

Unlike in the House of Commons, when the term committee is used to describe a stage of a bill, this committee does not take the form of a public bill committee, but what is described as Committee of the Whole House. It is made up of all Members of the House of Lords allowing any Member to contribute to debates if he or she chooses to do so and allows for more flexible rules of procedure. It is presided over by the Chairman of Committees.

The term committee is also used to describe Grand Committee, where the same rules of procedure apply as in the main chamber, except that no divisions may take place. For this reason, business that is discussed in Grand Committee is usually uncontroversial and likely to be agreed unanimously.

Public bills may also be committed to pre-legislative committees. A pre-legislative Committee is specifically constituted for a particular bill. These committees are established in advance of the bill being laid before either the House of Lords or the House of Commons and can take evidence from the public. Such committees are rare and do not replace any of the usual stages of a bill, including committee stage.

The House of Lords also has 15 Select Committees. Typically, these are "sessional committees", meaning that their members are appointed by the House at the beginning of each session, and continue to serve until the next parliamentary session begins. In practice, these are often permanent committees, which are re-established during every session. These committees are typically empowered to make reports to the House "from time to time", that is, whenever they wish. Other committees are "ad-hoc committees", which are set up to investigate a specific issue. When they are set up by a motion in the House, the motion will set a deadline by which the Committee must report. After this date, the Committee will cease to exist unless it is granted an extension. One example of this is the Committee on Public Service and Demographic Change. The House of Lords may appoint a chairman for a committee; if it does not do so, the Chairman of Committees or a Deputy Chairman of Committees may preside instead. Most of the Select Committees are also granted the power to co-opt members, such as the European Union Committee. The primary function of Select Committees is to scrutinise and investigate Government activities; to fulfil these aims, they are permitted to hold hearings and collect evidence. Bills may be referred to Select Committees, but are more often sent to the Committee of the Whole House and Grand Committees.

The committee system of the House of Lords also includes several Domestic Committees, which supervise or consider the House's procedures and administration. One of the Domestic Committees is the Committee of Selection, which is responsible for assigning members to many of the House's other committees.

There are currently sitting members of the House of Lords. An additional Lords are ineligible from participation, including eight peers who are constitutionally disqualified as members of the Judiciary.

The House of Lords Act 1999 allocated 75 of the 92 hereditary peers to the parties based on the proportion of hereditary peers that belonged to that party in 1999:

Of the initial 42 hereditary peers elected as Conservatives, one, Lord Willoughby de Broke, defected to UKIP, though he left the party in 2018.

Fifteen hereditary peers are elected by the whole House, and the remaining hereditary peers are the two royal office-holders, the Earl Marshal and the Lord Great Chamberlain, both of whom are currently on leave of absence.

A report in 2007 stated that many members of the Lords (particularly the life peers) do not attend regularly; the average daily attendance was around 408.

While the number of hereditary peers is limited to 92, and that of Lords spiritual to 26, there is no maximum limit to the number of life peers who may be members of the House of Lords at any time.











</doc>
<doc id="13660" url="https://en.wikipedia.org/wiki?curid=13660" title="Homeomorphism">
Homeomorphism

In the mathematical field of topology, a homeomorphism, topological isomorphism, or bicontinuous function is a continuous function between topological spaces that has a continuous inverse function. Homeomorphisms are the isomorphisms in the category of topological spaces—that is, they are the mappings that preserve all the topological properties of a given space. Two spaces with a homeomorphism between them are called homeomorphic, and from a topological viewpoint they are the same. The word "homeomorphism" comes from the Greek words "ὅμοιος" ("homoios") = similar or same and "μορφή" ("morphē") = shape, form, introduced to mathematics by Henri Poincaré in 1895. 

Very roughly speaking, a topological space is a geometric object, and the homeomorphism is a continuous stretching and bending of the object into a new shape. Thus, a square and a circle are homeomorphic to each other, but a sphere and a torus are not. However, this description can be misleading. Some continuous deformations are not homeomorphisms, such as the deformation of a line into a point. Some homeomorphisms are not continuous deformations, such as the homeomorphism between a trefoil knot and a circle.

An often-repeated mathematical joke is that topologists can't tell the difference between a coffee cup and a donut, since a sufficiently pliable donut could be reshaped to the form of a coffee cup by creating a dimple and progressively enlarging it, while preserving the donut hole in a cup's handle.

A function formula_1 between two topological spaces is a homeomorphism if it has the following properties:


A homeomorphism is sometimes called a bicontinuous function. If such a function exists, we say formula_6 and formula_7 are homeomorphic. A self-homeomorphism is a homeomorphism from a topological space onto itself. "Being homeomorphic" is an equivalence relation on topological spaces. Its equivalence classes are called homeomorphism classes.



The third requirement, that formula_20 be continuous, is essential. Consider for instance the function formula_21 (the unit circle in formula_22) defined byformula_23. This function is bijective and continuous, but not a homeomorphism (formula_24 is compact but formula_25 is not). The function formula_20 is not continuous at the point formula_27, because although formula_20 maps formula_27 to formula_30, any neighbourhood of this point also includes points that the function maps close to formula_31, but the points it maps to numbers in between lie outside the neighbourhood.

Homeomorphisms are the isomorphisms in the category of topological spaces. As such, the composition of two homeomorphisms is again a homeomorphism, and the set of all self-homeomorphisms formula_32 forms a group, called the homeomorphism group of "X", often denoted formula_33. This group can be given a topology, such as the compact-open topology, which under certain assumptions makes it a topological group.

For some purposes, the homeomorphism group happens to be too big, but by means of the isotopy relation, one can reduce this group to the mapping class group.

Similarly, as usual in category theory, given two spaces that are homeomorphic, the space of homeomorphisms between them, formula_34, is a torsor for the homeomorphism groups formula_33 and formula_36, and, given a specific homeomorphism between formula_6 and formula_7, all three sets are identified.


The intuitive criterion of stretching, bending, cutting and gluing back together takes a certain amount of practice to apply correctly—it may not be obvious from the description above that deforming a line segment to a point is impermissible, for instance. It is thus important to realize that it is the formal definition given above that counts. In this case, for example, the line segment possesses infinitely many points, and therefore cannot be put into a bijection with a set containing only a finite number of points, including a single point.

This characterization of a homeomorphism often leads to a confusion with the concept of homotopy, which is actually "defined" as a continuous deformation, but from one "function" to another, rather than one space to another. In the case of a homeomorphism, envisioning a continuous deformation is a mental tool for keeping track of which points on space "X" correspond to which points on "Y"—one just follows them as "X" deforms. In the case of homotopy, the continuous deformation from one map to the other is of the essence, and it is also less restrictive, since none of the maps involved need to be one-to-one or onto. Homotopy does lead to a relation on spaces: homotopy equivalence.

There is a name for the kind of deformation involved in visualizing a homeomorphism. It is (except when cutting and regluing are required) an isotopy between the identity map on "X" and the homeomorphism from "X" to "Y".




</doc>
<doc id="13661" url="https://en.wikipedia.org/wiki?curid=13661" title="Hvergelmir">
Hvergelmir

In Norse mythology, Hvergelmir (Old Norse "bubbling boiling spring") is a major spring. Hvergelmir is attested in the "Poetic Edda", compiled in the 13th century from earlier traditional sources, and the "Prose Edda", written in the 13th century by Snorri Sturluson. In the "Poetic Edda", Hvergelmir is mentioned in a single stanza, which details that it is the location where liquid from the antlers of the stag Eikþyrnir flow, and that the spring, "whence all waters rise", is the source of numerous rivers. The "Prose Edda" repeats this information and adds that the spring is located in Niflheim, that it is one of the three major springs at the primary roots of the cosmic tree Yggdrasil (the other two are Urðarbrunnr and Mímisbrunnr), and that within the spring are a vast amount of snakes and the dragon Níðhöggr.

Hvergelmir is attested in the following works:

Hvergelmir receives a single mention in the "Poetic Edda", found in the poem "Grímnismál":

This stanza is followed by three stanzas consisting mainly of the names of 42 rivers. Some of these rivers lead to the dwelling of the gods (such as Gömul and Geirvimul), while at least two (Gjöll and Leipt), reach to Hel.

Hvergelmir is mentioned several times in the "Prose Edda". In "Gylfaginning", Just-as-High explains that the spring Hvergelmir is located in the foggy realm of Niflheim: "It was many ages before the earth was created that Niflheim was made, and in its midst lies a spring called Hvergelmir, and from it flows the rivers called Svol, Gunnthra, Fiorm, Fimbulthul, Slidr and Hrid, Sylg and Ylg, Vid, Leiptr; Gioll is next to Hell-gates."

Later in "Gylfaginning", Just-as-High describes the central tree Yggdrasil. Just-as-High says that three roots of the tree support it and "extend very, very far" and that the third of these three roots extends over Niflheim. Beneath this root, says Just-as-High, is the spring Hvergelmir, and that the base of the root is gnawed on by the dragon Níðhöggr. Additionally, High says that Hvergelmir contains not only Níðhöggr but also so many snakes that "no tongue can enumerate them".

The spring is mentioned a third time in "Gylfaginning" where High recounts its source: the stag Eikþyrnir stands on top of the afterlife hall Valhalla feeding branches of Yggdrasil, and from the stag's antlers drips great amounts of liquid down into Hvergelmir. High tallies 26 rivers here.

Hvergelmir is mentioned a final time in the "Prose Edda" where Third discusses the unpleasantries of Náströnd. Third notes that Hvergelmir yet worse than the venom-filled Náströnd because—by way of quoting a portion of a stanza from the "Poetic Edda" poem "Völuspá"—"There Nidhogg torments the bodies of the dead".



</doc>
<doc id="13665" url="https://en.wikipedia.org/wiki?curid=13665" title="Hausdorff maximal principle">
Hausdorff maximal principle

In mathematics, the Hausdorff maximal principle is an alternate and earlier formulation of Zorn's lemma proved by Felix Hausdorff in 1914 (Moore 1982:168). It states that in any partially ordered set, every totally ordered subset is contained in a maximal totally ordered subset.

The Hausdorff maximal principle is one of many statements equivalent to the axiom of choice over ZF (Zermelo–Fraenkel set theory without the axiom of choice). The principle is also called the Hausdorff maximality theorem or the Kuratowski lemma (Kelley 1955:33).

The Hausdorff maximal principle states that, in any partially ordered set, every totally ordered subset is contained in a maximal totally ordered subset. Here a maximal totally ordered subset is one that, if enlarged in any way, does not remain totally ordered. The maximal set produced by the principle is not unique, in general; there may be many maximal totally ordered subsets containing a given totally ordered subset.

An equivalent form of the principle is that in every partially ordered set there exists a maximal totally ordered subset.

To prove that it follows from the original form, let "A" be a poset. Then formula_1 is a totally ordered subset of "A", hence there exists a maximal totally ordered subset containing formula_1, in particular "A" contains a maximal totally ordered subset.

For the converse direction, let "A" be a partially ordered set and "T" a totally ordered subset of "A". Then
is partially ordered by set inclusion formula_4, therefore it contains a maximal totally ordered subset "P". Then the set formula_5 satisfies the desired properties.

The proof that the Hausdorff maximal principle is equivalent to Zorn's lemma is very similar to this proof.

EXAMPLE 1. If "A" is any collection of sets, the relation "is a proper subset of" is a strict partial order on "A". Suppose that "A" is the collection of all circular regions (interiors of circles) in the plane. One maximal totally ordered sub-collection of "A" consists of all circular regions with centers at the origin. Another maximal totally ordered sub-collection consists of all circular regions bounded by circles tangent from the right to the y-axis at the origin.

EXAMPLE 2. If (x, y) and (x, y) are two points of the plane ℝ, define (x, y) < (x, y)

if y = y and x < x. This is a partial ordering of ℝ under which two points are comparable only if they lie on the same horizontal line. The maximal totally ordered sets are horizontal lines in ℝ.




</doc>
<doc id="13666" url="https://en.wikipedia.org/wiki?curid=13666" title="Hel (being)">
Hel (being)

In Norse mythology, Hel is a being who presides over a realm of the same name, where she receives a portion of the dead. Hel is attested in the "Poetic Edda", compiled in the 13th century from earlier traditional sources, and the "Prose Edda", written in the 13th century by Snorri Sturluson. In addition, she is mentioned in poems recorded in "Heimskringla" and "Egils saga" that date from the 9th and 10th centuries, respectively. An episode in the Latin work "Gesta Danorum", written in the 12th century by Saxo Grammaticus, is generally considered to refer to Hel, and Hel may appear on various Migration Period bracteates.

In the "Poetic Edda", "Prose Edda", and "Heimskringla", Hel is referred to as a daughter of Loki. In the "Prose Edda" book "Gylfaginning", Hel is described as having been appointed by the god Odin as ruler of a realm of the same name, located in Niflheim. In the same source, her appearance is described as half blue and half flesh-coloured and further as having a gloomy, downcast appearance. The "Prose Edda" details that Hel rules over vast mansions with many servants in her underworld realm and plays a key role in the attempted resurrection of the god Baldr.

Scholarly theories have been proposed about Hel's potential connections to figures appearing in the 11th-century "Old English Gospel of Nicodemus" and Old Norse "Bartholomeus saga postola", that she may have been considered a goddess with potential Indo-European parallels in Bhavani, Kali, and Mahakali or that Hel may have become a being only as a late personification of the location of the same name.

The Old Norse feminine proper noun "Hel" is identical to the name of the location over which she rules, Old Norse "Hel". The word has cognates in all branches of the Germanic languages, including Old English "hell" (and thus Modern English "hell"), Old Frisian "helle", Old Saxon "hellia", Old High German "hella", and Gothic "halja". All forms ultimately derive from the reconstructed Proto-Germanic feminine noun *"xaljō" or *"haljō" ('concealed place, the underworld'). In turn, the Proto-Germanic form derives from the o-grade form of the Proto-Indo-European root *"kel-", *"kol"-: 'to cover, conceal, save'.

The term is etymologically related to Modern English "hall" and therefore also "Valhalla", an afterlife 'hall of the slain' in Norse Mythology. "Hall" and its numerous Germanic cognates derive from Proto-Germanic *"hallō" 'covered place, hall', from Proto-Indo-European *"kol-".

Related early Germanic terms and concepts include Proto-Germanic *"xalja-rūnō(n)", a feminine compound noun, and *"xalja-wītjan", a neutral compound noun. This form is reconstructed from the Latinized Gothic plural noun *"haliurunnae" (attested by Jordanes; according to philologist Vladimir Orel, meaning 'witches'), Old English "helle-rúne" ('sorceress, necromancer', according to Orel), and Old High German "helli-rūna" 'magic'. The compound is composed of two elements: *"xaljō" (*"haljō") and *"rūnō", the Proto-Germanic precursor to Modern English "rune". The second element in the Gothic "haliurunnae" may however instead be an agent noun from the verb "rinnan" ("to run, go"), which would make its literal meaning "one who travels to the netherworld".)

Proto-Germanic *"xalja-wītjan" (or *"halja-wītjan") is reconstructed from Old Norse "hel-víti" 'hell', Old English "helle-wíte" 'hell-torment, hell', Old Saxon "helli-wīti" 'hell', and the Middle High German feminine noun "helle-wīze". The compound is a compound of *"xaljō" (discussed above) and *"wītjan" (reconstructed from forms such as Old English "witt" 'right mind, wits', Old Saxon "gewit" 'understanding', and Gothic "un-witi" 'foolishness, understanding').

The "Poetic Edda", compiled in the 13th century from earlier traditional sources, features various poems that mention Hel. In the "Poetic Edda" poem "Völuspá", Hel's realm is referred to as the "Halls of Hel." In stanza 31 of "Grímnismál", Hel is listed as living beneath one of three roots growing from the world tree Yggdrasil. In "Fáfnismál", the hero Sigurd stands before the mortally wounded body of the dragon Fáfnir, and states that Fáfnir lies in pieces, where "Hel can take" him. In "Atlamál", the phrases "Hel has half of us" and "sent off to Hel" are used in reference to death, though it could be a reference to the location and not the being, if not both. In stanza 4 of "Baldrs draumar", Odin rides towards the "high hall of Hel."

Hel may also be alluded to in "Hamðismál". Death is periphrased as "joy of the troll-woman" (or "ogress") and ostensibly it is Hel being referred to as the troll-woman or the ogre ("flagð"), although it may otherwise be some unspecified "dís".

Hel is referred to in the "Prose Edda", written in the 13th century by Snorri Sturluson. In chapter 34 of the book "Gylfaginning", Hel is listed by High as one of the three children of Loki and Angrboða; the wolf Fenrir, the serpent Jörmungandr, and Hel. High continues that, once the gods found that these three children are being brought up in the land of Jötunheimr, and when the gods "traced prophecies that from these siblings great mischief and disaster would arise for them" then the gods expected a lot of trouble from the three children, partially due to the nature of the mother of the children, yet worse so due to the nature of their father.

High says that Odin sent the gods to gather the children and bring them to him. Upon their arrival, Odin threw Jörmungandr into "that deep sea that lies round all lands," Odin threw Hel into Niflheim, and bestowed upon her authority over nine worlds, in that she must "administer board and lodging to those sent to her, and that is those who die of sickness or old age." High details that in this realm Hel has "great Mansions" with extremely high walls and immense gates, a hall called Éljúðnir, a dish called "Hunger," a knife called "Famine," the servant Ganglati (Old Norse "lazy walker"), the serving-maid Ganglöt (also "lazy walker"), the entrance threshold "Stumbling-block," the bed "Sick-bed," and the curtains "Gleaming-bale." High describes Hel as "half black and half flesh-coloured," adding that this makes her easily recognizable, and furthermore that Hel is "rather downcast and fierce-looking."

In chapter 49, High describes the events surrounding the death of the god Baldr. The goddess Frigg asks who among the Æsir will earn "all her love and favour" by riding to Hel, the location, to try to find Baldr, and offer Hel herself a ransom. The god Hermóðr volunteers and sets off upon the eight-legged horse Sleipnir to Hel. Hermóðr arrives in Hel's hall, finds his brother Baldr there, and stays the night. The next morning, Hermóðr begs Hel to allow Baldr to ride home with him, and tells her about the great weeping the Æsir have done upon Baldr's death. Hel says the love people have for Baldr that Hermóðr has claimed must be tested, stating:

If all things in the world, alive or dead, weep for him, then he will be allowed to return to the Æsir. If anyone speaks against him or refuses to cry, then he will remain with Hel.
Later in the chapter, after the female jötunn Þökk refuses to weep for the dead Baldr, she responds in verse, ending with "let Hel hold what she has." In chapter 51, High describes the events of Ragnarök, and details that when Loki arrives at the field Vígríðr "all of Hel's people" will arrive with him.

In chapter 5 of the "Prose Edda" book "Skáldskaparmál", Hel is mentioned in a kenning for Baldr ("Hel's companion"). In chapter 16, "Hel's [...] relative or father" is given as a kenning for Loki. In chapter 50, Hel is referenced ("to join the company of the quite monstrous wolf's sister") in the skaldic poem "Ragnarsdrápa".

In the "Heimskringla" book "Ynglinga saga", written in the 13th century by Snorri Sturluson, Hel is referred to, though never by name. In chapter 17, the king Dyggvi dies of sickness. A poem from the 9th-century "Ynglingatal" that forms the basis of "Ynglinga saga" is then quoted that describes Hel's taking of Dyggvi:

In chapter 45, a section from "Ynglingatal" is given which refers to Hel as "howes'-warder" (meaning "guardian of the graves") and as taking King Halfdan Hvitbeinn from life. In chapter 46, King Eystein Halfdansson dies by being knocked overboard by a sail yard. A section from "Ynglingatal" follows, describing that Eystein "fared to" Hel (referred to as "Býleistr's-brother's-daughter"). In chapter 47, the deceased Eystein's son King Halfdan dies of an illness, and the excerpt provided in the chapter describes his fate thereafter, a portion of which references Hel:

In a stanza from "Ynglingatal" recorded in chapter 72 of the "Heimskringla" book "Saga of Harald Sigurdsson", "given to Hel" is again used as a phrase to referring to death.

The Icelanders' saga "Egils saga" contains the poem "Sonatorrek". The saga attributes the poem to 10th century skald Egill Skallagrímsson, and writes that it was composed by Egill after the death of his son Gunnar. The final stanza of the poem contains a mention of Hel, though not by name:

In the account of Baldr's death in Saxo Grammaticus' early 13th century work "Gesta Danorum", the dying Baldr has a dream visitation from Proserpina (here translated as "the goddess of death"):

The following night the goddess of death appeared to him in a dream standing at his side, and declared that in three days time she would clasp him in her arms. It was no idle vision, for after three days the acute pain of his injury brought his end.

Scholars have assumed that Saxo used Proserpina as a goddess equivalent to the Norse Hel.

It has been suggested that several imitation medallions and bracteates of the Migration Period (ca. first centuries AD) feature depictions of Hel. In particular the bracteates IK 14 and IK 124 depict a rider traveling down a slope and coming upon a female being holding a scepter or a staff. The downward slope may indicate that the rider is traveling towards the realm of the dead and the woman with the scepter may be a female ruler of that realm, corresponding to Hel.

Some B-class bracteates showing three godly figures have been interpreted as depicting Baldr's death, the best known of these is the Fakse bracteate. Two of the figures are understood to be Baldr and Odin while both Loki and Hel have been proposed as candidates for the third figure. If it is Hel she is presumably greeting the dying Baldr as he comes to her realm.

The "Old English Gospel of Nicodemus", preserved in two manuscripts from the 11th century, contains a female figure referred to as "Seo hell" who engages in flyting with Satan and tells him to leave her dwelling (Old English "ut of mynre onwununge"). Regarding Seo Hell in the "Old English Gospel of Nicodemus", Michael Bell states that "her vivid personification in a dramatically excellent scene suggests that her gender is more than grammatical, and invites comparison with the Old Norse underworld goddess Hel and the Frau Holle of German folklore, to say nothing of underworld goddesses in other cultures" yet adds that "the possibility that these genders "are" merely grammatical is strengthened by the fact that an Old Norse version of Nicodemus, possibly translated under English influence, personifies Hell in the neutral (Old Norse "þat helvíti")."

The Old Norse "Bartholomeus saga postola", an account of the life of Saint Bartholomew dating from the 13th century, mentions a "Queen Hel." In the story, a devil is hiding within a pagan idol, and bound by Bartholomew's spiritual powers to acknowledge himself and confess, the devil refers to Jesus as the one which "made war on Hel our queen" (Old Norse "heriaði a Hel drottning vara"). "Queen Hel" is not mentioned elsewhere in the saga.

Michael Bell says that while Hel "might at first appear to be identical with the well-known pagan goddess of the Norse underworld" as described in chapter 34 of "Gylfaginning", "in the combined light of the Old English and Old Norse versions of "Nicodemus" she casts quite a different a shadow," and that in "Bartholomeus saga postola" "she is clearly the queen of the Christian, not pagan, underworld."

Jacob Grimm theorized that Hel (whom he refers to here as "Halja", the theorized Proto-Germanic form of the term) is essentially an "image of a greedy, unrestoring, female deity" and that "the higher we are allowed to penetrate into our antiquities, the less hellish and more godlike may "Halja" appear. Of this we have a particularly strong guarantee in her affinity to the Indian Bhavani, who travels about and bathes like Nerthus and Holda, but is likewise called "Kali" or "Mahakali", the great "black" goddess. In the underworld she is supposed to sit in judgment on souls. This office, the similar name and the black hue [...] make her exceedingly like "Halja". And "Halja" is one of the oldest and commonest conceptions of our heathenism."

Grimm theorizes that the Helhest, a three legged-horse that roams the countryside "as a harbinger of plague and pestilence" in Danish folklore, was originally the steed of the goddess Hel, and that on this steed Hel roamed the land "picking up the dead that were her due." In addition, Grimm says that a wagon was once ascribed to Hel, with which Hel made journeys. Grimm says that Hel is an example of a "half-goddess;" "one who cannot be shown to be either wife or daughter of a god, and who stands in a dependent relation to higher divinities" and that "half-goddesses" stand higher than "half-gods" in Germanic mythology.

Hilda Ellis Davidson (1948) states that Hel "as a goddess" in surviving sources seems to belong to a genre of literary personification, that the word "hel" is generally "used simply to signify death or the grave," and that the word often appears as the equivalent to the English 'death,' which Davidson states "naturally lends itself to personification by poets." Davidson explains that "whether this personification has originally been based on a belief in a goddess of death called Hel is another question," but that she does not believe that the surviving sources give any reason to believe so. Davidson adds that, on the other hand, various other examples of "certain supernatural women" connected with death are to be found in sources for Norse mythology, that they "seem to have been closely connected with the world of death, and were pictured as welcoming dead warriors," and that the depiction of Hel "as a goddess" in "Gylfaginning" "might well owe something to these."

In a later work (1998), Davidson states that the description of Hel found in chapter 33 of "Gylfaginning" "hardly suggests a goddess." Davidson adds that "yet this is not the impression given in the account of Hermod's ride to Hel later in "Gylfaginning" (49)" and points out that here Hel "[speaks] with authority as ruler of the underworld" and that from her realm "gifts are sent back to Frigg and Fulla by Balder's wife Nanna as from a friendly kingdom." Davidson posits that Snorri may have "earlier turned the goddess of death into an allegorical figure, just as he made Hel, the underworld of shades, a place 'where wicked men go,' like the Christian Hell ("Gylfaginning" 3)." Davidson continues that:

On the other hand, a goddess of death who represents the horrors of slaughter and decay is something well known elsewhere; the figure of Kali in India is an outstanding example. Like Snorri's Hel, she is terrifying to in appearance, black or dark in colour, usually naked, adorned with severed heads or arms or the corpses of children, her lips smeared with blood. She haunts the battlefield or cremation ground and squats on corpses. Yet for all this she is "the recipient of ardent devotion from countless devotees who approach her as their mother" [...].

Davidson further compares to early attestations of the Irish goddesses Badb (Davidson points to the description of Badb from "The Destruction of Da Choca's Hostel" where Badb is wearing a dusky mantle, has a large mouth, is dark in color, and has gray hair falling over her shoulders, or, alternatively, "as a red figure on the edge of the ford, washing the chariot of a king doomed to die") and The Morrígan. Davidson concludes that, in these examples, "here we have the fierce destructive side of death, with a strong emphasis on its physical horrors, so perhaps we should not assume that the gruesome figure of Hel is wholly Snorri's literary invention."

John Lindow states that most details about Hel, as a figure, are not found outside of Snorri's writing in "Gylfaginning", and says that when older skaldic poetry "says that people are 'in' rather than 'with' Hel, we are clearly dealing with a place rather than a person, and this is assumed to be the older conception," that the noun and place "Hel" likely originally simply meant "grave," and that "the personification came later." He also draws a parallel between the personified Hel's banishment to the underworld and the binding of Fenrir as part of a recurring theme of the bound monster, where an enemy of the gods is bound but destined to break free at Ragnarok. Rudolf Simek theorizes that the figure of Hel is "probably a very late personification of the underworld Hel," and says that "the first scriptures using the goddess Hel are found at the end of the 10th and in the 11th centuries." Simek states that the allegorical description of Hel's house in "Gylfaginning" "clearly stands in the Christian tradition," and that "on the whole nothing speaks in favour of there being a belief in Hel in pre-Christian times." However, Simek also cites Hel as possibly appearing as one of three figures appearing together on Migration Period B-bracteates.

In January 2017, the Icelandic Naming Committee ruled that parents could not name their child "Hel" "on the grounds that the name would cause the child significant distress and trouble as it grows up". 





</doc>
<doc id="13667" url="https://en.wikipedia.org/wiki?curid=13667" title="Hawar Islands">
Hawar Islands

The Hawar Islands (; transliterated: Juzur Ḩawār) are an archipelago of desert islands owned by Bahrain, situated off the west coast of Qatar in the Gulf of Bahrain of the Persian Gulf.

The islands used to be one of the settlements of the Bahraini branch of the Dawasir who settled there in the early 19th century. The islands were first surveyed in 1820, when they were called the Warden’s Islands, and two villages were recorded. They are now uninhabited, other than a police garrison and a hotel on the main island; access to all but Hawar island itself is severely restricted. Local fishermen are allowed to fish in adjacent waters and there is some recreational fishing and tourism on and around the islands. Fresh water has always been scarce; historically it was obtained by surface collection and even today, with the desalinisation plant, additional supplies have to be brought in.

Despite their proximity to Qatar (they are only about from the Qatari mainland whilst being about from the main islands of Bahrain), most of the islands belong to Bahrain, having been a part of a dispute between Bahrain and Qatar which was resolved in 2001. The islands were formerly coincident with municipality or "Minţaqat" Juzur Ḩawār (مِنْطَقَة جُزُر حَوَار) and are now administered as part of the Southern Governorate of Bahrain. The land area of the islands is approximately 52 km.

Although there are 36 islands in the group, many of the smaller islands are little more than sand or shingle accumulations on areas of exposed bedrock molded by the ongoing processes of sedimentation and accretion.
The application named 8 major islands (see table hereafter), which conforms to the description of the islands when first surveyed as consisting of 8 or 9 islands. It has often been described as an archipelago of 16 islands. Janan Island, to the south of Hawar island, is not legally considered to be a part of the group and is owned by Qatar.

The islands are home to many bird species, notably Socotra cormorants. There are small herds of Arabian oryx and sand gazelle on Hawar island, and the seas around support a large population of dugong.

The islands were listed as a Ramsar site in 1997. In 2002, the Bahraini government applied to have the islands recognised as a World Heritage Site due to their unique environment and habitat for endangered species; the application was ultimately unsuccessful.

The islands were formerly coincident with municipality or "Minţaqat" Juzur Ḩawār (مِنْطَقَة جُزُر حَوَار) and are now administered as part of the Southern Governorate of Bahrain.

In 2014, a Best Western hotel with 140 rooms replaced a much smaller Hawar Islands Resort. However, the resort closed in mid-2016.

By far the largest island is Hawar, which accounts for more than 41 km of the 54.5 km land area. Following in size are Suwād al Janūbīyah, Suwād ash Shamālīyah, Rubud Al Sharqiyah, Rubud Al Gharbiyah, and Muhazwarah (Umm Hazwarah).

The following were not considered as part of the Hawar islands in the International Court of Justice (ICJ) judgment, being located between Hawar and the Bahrain Islands and not disputed by Qatar, but have been included in the Hawar archipelago by the Bahrain government as part of the 2002 World Heritage Site application.

Janan Island, a small island south of Hawar island, was also considered in the 2001 judgment. Based on a previous agreement when both Qatar and Bahrain were under British protection, it was judged to be separate from the Hawar islands and so considered by the court separately. It was awarded to Qatar.





</doc>
<doc id="13669" url="https://en.wikipedia.org/wiki?curid=13669" title="Hans-Dietrich Genscher">
Hans-Dietrich Genscher

Hans-Dietrich Genscher (21 March 1927 – 31 March 2016) was a German statesman and a member of the liberal Free Democratic Party (FDP), who served as the Federal Minister of the Interior from 1969 to 1974, and as the Federal Minister of Foreign Affairs and Vice Chancellor of Germany from 1974 to 1992 (except for a two-week break in 1982, after the FDP had left the Third Schmidt cabinet), making him the longest-serving occupant of either post and the only person, holding one of these posts under two different Chancellors of the Federal Republic of Germany. In 1991 he was chairman of the Organization for Security and Co-operation in Europe (OSCE).

A proponent of Realpolitik, Genscher has been called "a master of diplomacy." He is widely regarded as having been a principal "architect of German reunification." In 1991, he played a pivotal role in the breakup of Yugoslavia by successfully pushing for international recognition of Croatia, Slovenia and other republics declaring independence, in an effort to halt "a trend towards a Greater Serbia." After leaving office, he worked as a lawyer and international consultant. He was President of the German Council on Foreign Relations and was involved with several international organisations, and with former Czech President Václav Havel, he called for a Cold War museum to be built in Berlin.

Genscher was born on 21 March 1927 in Reideburg (Province of Saxony-Anhalt), now a part of Halle, in what later became East Germany. He was the son of Hilda Kreime and Kurt Genscher. His father, a lawyer, died when Genscher was nine years old. In 1943, he was drafted to serve as a member of the Air Force Support Personnel ("Luftwaffenhelfer") at the age of 16. At age 17, close to the end of the war, he and his fellow soldiers became members of the Nazi Party due to a collective application ("Sammelantrag") by his Wehrmacht unit. He later said he was unaware of it at the time.
Late in the war, Genscher was deployed as a soldier in General Walther Wenck's 12th Army, which ostensibly was directed to relieve the siege of Berlin. After the German surrender he was an American and British prisoner of war, but was released after two months. Following World War II, he studied law and economics at the universities of Halle and Leipzig (1946–1949) and joined the East German Liberal Democratic Party (LDPD) in 1946.

In 1952, Genscher fled to West Germany, where he joined the Free Democratic Party (FDP). He passed his second state examination in law in Hamburg in 1954 and became a solicitor in Bremen. During these early years after the war, Genscher continuously struggled with illness. From 1956 to 1959 he was a research assistant of the FDP parliamentary group in Bonn. From 1959 to 1965 he was the FDP group managing director, while from 1962 to 1964 he was National Secretary of the FDP.

In 1965 Genscher was elected on the North Rhine-Westphalian FDP list to the West German parliament and remained a member of parliament until his retirement in 1998. He was elected deputy national chairman in 1968. From 1969 he served as minister of the interior in the SPD-FDP coalition government led by Chancellor Willy Brandt.

In 1974 he became foreign minister and vice chancellor, both posts he would hold for 18 years. From 1 October 1974 to 23 February 1985 he was Chairman of the FDP. It was during his tenure as party chairman that the FDP switched from being the junior member of social-liberal coalition to being the junior member of the 1982 coalition with the CDU/CSU. In 1985 he gave up the post of national chairman. After his resignation as Foreign Minister, Genscher was appointed honorary chairman of the FDP in 1992.

After the federal election of 1969 Genscher was instrumental in the formation of the social-liberal coalition of chancellor Willy Brandt and was on 22 October 1969 appointed as federal minister of the interior. 
In 1972, while minister for the interior, Genscher rejected Israel's offer to send an Israeli special forces unit to Germany to deal with the Munich Olympics hostage crisis. A flawed rescue attempt by German police forces at Fürstenfeldbruck air base resulted in a bloody shootout, which left all eleven hostages, five terrorists, and one German policeman dead. Genscher's popularity with Israel declined further when he endorsed the release of the three captured attackers following the hijacking of a Lufthansa aircraft on 29 October 1972.

In the SPD–FDP coalition, Genscher helped shape Brandt's policy of deescalation with the communist East, commonly known as "Ostpolitik", which was continued under chancellor Helmut Schmidt after Brandt's resignation in 1974. He would later be a driving factor in continuing this policy in the new conservative-liberal coalition under Helmut Kohl.

In the negotiations on a coalition government of SPD and FDP following the 1976 elections, it took Genscher 73 days to reach agreement with Chancellor Helmut Schmidt.

As Foreign Minister, Genscher stood for a policy of compromise between East and West, and developed strategies for an active policy of détente and the continuation of the East-West dialogue with the USSR. He was widely regarded a strong advocate of negotiated settlements to international problems. As a popular story on Genscher's preferred method of shuttle diplomacy has it, "two Lufthansa jets crossed over the Atlantic, and Genscher was on both."

Genscher was a major player in the negotiations on the text of the Helsinki Accords. In December 1976, the General Assembly of the United Nations in New York City accepted Genscher's proposal of an anti-terrorism convention in New York, which was set among other things, to respond to demands from hostage-takers under any circumstances.

Genscher was one of the FDP's driving forces when, in 1982, the party switched sides from its coalition with the SPD to support the CDU/CSU in their Constructive vote of no confidence to have incumbent Helmut Schmidt replaced with opposition leader Helmut Kohl as Chancellor. The reason for this was the increase in the differences between the coalition partners, particularly in economic and social policy. The switch was controversial, not least in his own party.

At several points in his tenure, he irritated the governments of the United States and other allies of Germany by appearing not to support Western initiatives fully. "During the Cold War, his penchant to seek the middle ground at times exasperated United States policy-makers who wanted a more decisive, less equivocal Germany," according to Tyler Marshall. Genscher's perceived quasi-neutralism was dubbed "Genscherism". "Fundamental to "Genscherism" was said to be the belief that Germany could play a role as a bridge between East and West without losing its status as a reliable NATO ally." In the 1980s, Genscher opposed the deployment of new short-range NATO missiles in Germany. At the time, the Reagan Administration questioned whether Germany was straying from the Western alliance and following a program of its own.

In 1984, Genscher became the first Western foreign minister to visit Tehran since the Iranian Revolution of 1979. In 1988, he appointed Jürgen Hellner as West Germany's new ambassador to Libya, a post that had been vacant since the 1986 Berlin discotheque bombing, a tragedy which U.S. officials blamed on the government of Muammar Gaddafi.

Genscher's proposals frequently set the tone and direction of foreign affairs among Western Europe's democracies. He was also an active participant in the further development of the European Union, taking an active part in the Single European Act Treaty negotiations in the mid-1980s, as well as the joint publication of the Genscher-Colombo plan with Italian Minister of Foreign Affairs Emilio Colombo which advocated further integration and deepening of relations in the European Union towards a more federal Europe. He later was among the politicians who pushed hard for monetary union alongside Edouard Balladur, France's finance minister, and Giuliano Amato, circulating a memorandum to that effect.

Genscher retained his posts as foreign minister and vice chancellor through German reunification and until 1992 when he stepped down for health reasons.

Genscher is most respected for his efforts that helped spell the end of the Cold War, in the late 1980s when Communist eastern European governments toppled, and which led to German reunification. During his time in office, he focused on maintaining stability and balance between the West and the Soviet bloc. From the beginning, he argued that the West should seek cooperation with Communist governments rather than treat them as implacably hostile; this policy was embraced by many Germans and other Europeans.

Genscher had great interest in European integration and the success of German reunification. He soon pushed for effective support of political reform processes in Poland and Hungary. For this purpose, he visited Poland to meet the chairman of Solidarity Lech Wałęsa as early as January 1980. Especially from 1987 he campaigned for an "active relaxation" policy response by the West to the Soviet efforts. In the years before German reunification, he made a point of maintaining strong ties with his birthplace Halle, which was regarded as significant by admirers and critics alike.

When thousands of East Germans sought refuge in West German embassies in Czechoslovakia and Poland, Genscher held discussions on the refugee crisis at the United Nations in New York with the foreign ministers of Czechoslovakia, Poland, East Germany and the Soviet Union in September 1989. Genscher's 30 September 1989 speech from the balcony of the German embassy in Prague was an important milestone on the road to the end of the GDR. In the embassy courtyard thousands of East German citizens had assembled. They were trying to travel to West Germany, but were being denied permission to travel by the Czechoslovak government at the request of East Germany. He announced that he had reached an agreement with the Communist Czechoslovak government that the refugees could leave: "We have come to you to tell you that today, your departure ..." (German: "Wir sind zu Ihnen gekommen, um Ihnen mitzuteilen, dass heute Ihre Ausreise ..."). After these words, the speech was drowned in cheers.

With his fellow foreign ministers James Baker of the United States and Eduard Shevardnadze of the Soviet Union, Genscher is widely credited with securing Germany's subsequent peaceful unification and the withdrawal of Soviet forces. He negotiated the German reunification in 1990 with his counterpart from the GDR, Markus Meckel. In November 1990, Genscher and his Polish counterpart Krzysztof Skubiszewski signed the German-Polish Border Treaty on the establishment of the Oder–Neisse line as Poland's western border. Meanwhile, he strongly endorsed the plans of the Bush Administration to assure continued U.S. influence in a post-Cold War Europe.

In 1991, Genscher successfully pushed for Germany's recognition of the Republic of Croatia in the Croatian War of Independence shortly after the Yugoslav attack on Vukovar. After Croatia and Slovenia had declared independence, Genscher concluded that Yugoslavia could not be held together, and that republics that wanted to break from the Serbian-dominated federation deserved quick diplomatic recognition. He hoped that such recognition would stop the fighting. The rest of the European Union was subsequently pressured to follow suit soon afterward. The UN Secretary-General Javier Pérez de Cuéllar had warned the German Government, that a recognition of Slovenia and Croatia would lead to an increase in aggression in the former Yugoslavia.

At a meeting of the European Community's foreign ministers in 1991, Genscher proposed to press for a war crimes trial for President Saddam Hussein of Iraq, accusing him of aggression against Kuwait, using chemical weapons against civilians and condoning genocide against the Kurds.

During the Gulf War, Genscher sought to deal with Iraq after other Western leaders had decided to go to war to force it out of Kuwait. Germany made a substantial financial contribution to the allied cause but, citing constitutional restrictions on the use of its armed forces, provided almost no military assistance. In January 1991, Germany sent Genscher on a state visit to Israel and followed up with an agreement to provide the Jewish state with $670 million in military aid, including financing for two submarines long coveted by Israel, a battery of Patriot missiles to defend against Iraqi missiles, 58 armored vehicles specially fitted to detect chemical and biological attacks, and a shipment of gas masks. When, in the aftermath of the war, a far-reaching political debate broke out over how Germany should fulfill its global responsibilities, Genscher responded that if foreign powers expect Germany to assume greater responsibility in the world, they should give it a chance to express its views "more strongly" in the United Nations Security Council. He also famously held that "whatever floats is fine, whatever rolls is not" to sum up Germany's military export policy for restless countries – based on a navy's unsuitability for use against a country's own people.

In 1992, Genscher, together with his Danish colleague Uffe Ellemann-Jensen, took the initiative to create the Council of the Baltic Sea States (CBSS) and the EuroFaculty.

More than half a century after Nazi leaders assembled their infamous exhibition "Degenerate Art," a sweeping condemnation of the work of the avant-garde, Genscher opened a re-creation of the show at the Altes Museum in March 1992, describing Nazi attempts to restrict artistic expression as "a step toward the catastrophe that produced the mass murder of European Jews and the war of extermination against Germany's neighbors." "The paintings in this exhibition have survived oppression and censorship," he asserted in his opening remarks. "They are not only a monument but also a sign of hope. They stand for the triumph of creative freedom over barbarism."

On 18 May 1992 Genscher retired at his own request from the federal government, which he had been member of for a total of 23 years. At the time, he was the world's longest-serving foreign minister and Germany's most popular politician. He had announced his decision three weeks earlier, on 27 April 1992. At that time he was Europe's longest-serving foreign minister. Genscher did not specify his reasons for quitting; however, he had suffered two heart attacks by that time. His resignation took effect in May, but he remained a member of parliament and continued to be influential in the Free Democratic Party.

Following Genscher's resignation, Chancellor Helmut Kohl and FDP chairman Otto Graf Lambsdorff named Irmgard Schwaetzer, a former aide to Genscher, to be the new Foreign Minister. In a surprise decision, however, a majority of the FDP parliamentary group rejected her nomination and voted instead to name Justice Minister Klaus Kinkel to head the Foreign Ministry.

Ahead of the German presidential election in 1994, Genscher proclaimed his lack of interest in the position, but was nonetheless widely considered a leading contender. After a poll taken for "Stern" magazine showed him to be the favored candidate of 48 percent of German voters, he reiterated in 1993 that he would "in no case" accept the presidency.

Having finished his political career, Genscher remained active as a lawyer and in international organizations. In late 1992, Genscher was appointed chairman of a newly established donors' board of the Berlin State Opera. Between 1997 and 2010, Genscher was affiliated with the law firm Büsing, Müffelmann & Theye. He founded his own consulting firm, Hans-Dietrich Genscher Consult GmbH, in 2000. Between 2001 and 2003, he served as president of the German Council on Foreign Relations. In 2001, Genscher headed an arbitration that ended a monthlong battle between German airline Lufthansa and its pilots' union and resulted in an agreement on increasing wages by more than 15 percent by the end of the following year.

In 2008, Genscher joined former Czech President Václav Havel, former United States Ambassador to Germany John Kornblum and several other well-known political figures in calling for a Cold War museum to be built at Checkpoint Charlie in Berlin. In 2009 Genscher expressed public concern at Pope Benedict XVI's lifting of excommunication of the bishops of the Society of Saint Pius X. Genscher wrote in the "Mitteldeutsche Zeitung": "Poles can be proud of Pope John Paul II. At the last papal election, we said We are the pope! But please—not like this." He argued that Pope Benedict XVI was making a habit of offending non-Catholics. "This is a deep moral and political question. It is about respect for the victims of crimes against humanity", Genscher said.

On 20 December 2013, it was revealed that Genscher played a key role in coordinating the release and flight to Germany of Mikhail Khodorkovsky, the former head of Yukos. Genscher had first met Khodorkovsky in 2002 and had chaired a conference at which Khodorkovsky blasted Russian President Vladimir Putin's pursuit of his oil company. Khodorkovsky asked his lawyers during a 2011 prison visit to let Genscher help mediate early release. Once Putin was re-elected in 2012, German Chancellor Angela Merkel instructed her officials to lobby for the president to meet Genscher. The subsequent negotiations involved two meetings between Genscher and Putin — one at Berlin Tegel Airport at the end of Putin's first visit to Germany after he was re-elected in 2012, the other in Moscow. While keeping the chancellor informed, Khodorkovsky's attorneys and Genscher spent the ensuing months developing a variety of legal avenues that could allow Putin to release his former rival early, ranging from amendments to existing laws to clemency. When Khodorkovsky's mother was in a Berlin hospital with cancer in November 2013, Genscher passed a message to Khodorkovsky suggesting the prisoner should write a pardon letter to Putin emphasizing his mother's ill health. Following Putin's pardoning of Khodorkovsky "for humanitarian reasons" in December 2013, a private plane provided by Genscher brought Khodorkovsky to Berlin for a family reunion at the Hotel Adlon.

Genscher signed on in 2014 to be a member of the Southern Corridor Advisory Panel, a BP-led consortium which includes former British Prime Minister Tony Blair and Peter Sutherland, chairman of Goldman Sachs International. The panel's purpose is to facilitate the expansion of a vast natural-gas field in the Caspian Sea and the building of two pipelines across Europe. The $45 billion enterprise, championed by the Azerbaijani president, Ilham Aliyev, has been called by critics "the Blair Rich Project."

Genscher died at his home outside Bonn in Wachtberg on 31 March 2016 from heart failure, one week and three days after his 89th birthday.


Genscher has been awarded honorary citizenship by his birthplace Halle (Saale) (in 1991) and the city of Berlin (in 1993).







 


</doc>
<doc id="13675" url="https://en.wikipedia.org/wiki?curid=13675" title="Henry Ainsworth">
Henry Ainsworth

Henry Ainsworth (1571–1622) was an English Nonconformist clergyman and scholar.

He was born of a farming family of Swanton Morley, Norfolk. He was educated at St John's College, Cambridge, later moving to Caius College, and, after associating with the Puritan party in the Church, eventually joined the Brownists.

Driven abroad to Holland in about 1593 due to the government of Queen Elizabeth's dissatisfaction with his non-conformist views, he found a home in "a blind lane at Amsterdam", acting as "porter" to a bookseller, who, on discovering his knowledge of Hebrew, introduced him to other scholars. When part of the London church, of which Francis Johnson (then in prison) was pastor, reassembled in Amsterdam, Ainsworth was chosen as their doctor or teacher. In 1596 he drew up a confession of their faith, reissued in Latin in 1598 and dedicated to the various universities of Europe (including St Andrews, Scotland). Johnson joined his flock in 1597, and in 1604 he and Ainsworth composed "An Apology or Defence of such true Christians as are commonly but unjustly called Brownists".

Organizing the church was not easy and dissension was rife. Though often involved in controversy, Ainsworth was not arrogant, but was a steadfast and cultured champion of the principles represented by the early Congregationalists. Amid all the controversy, he steadily pursued his studies. The combination was so unique that some have mistaken him for two different individuals. Confusion has also been occasioned through his friendly controversy with one John Ainsworth, who left the Anglican for the Roman Catholic church.

In 1610 Ainsworth was forced reluctantly to withdraw, with a large part of their church, from Johnson and those who adhered to him. A difference of principle as to the church's right to revise its officers' decisions had been growing between them; Ainsworth taking the more Congregational view. In spirit he remained a man of peace.

He died in 1622 in Amsterdam.

In 1608 Ainsworth answered Richard Bernard's "The Separatist Schisme", but his greatest minor work in this field was his reply to John Smyth (commonly called "the Se-Baptist"), entitled "Defence of Holy Scripture, Worship and Ministry used in the Christian Churches separated from Antichrist, against the Challenges, Cavils and Contradictions of Mr Smyth" (1609).

His scholarly works include his "Annotations"—on "Genesis" (1616); "Exodus" (1617); "Leviticus" (1618); "Numbers" (1619); "Deuteronomy" (1619); "Psalms" (including a metrical version, 1612); and the "Song of Solomon" (1623). These were collected in folio in 1627. From the outset the "Annotations" took a commanding place, especially among continental scholars, establishing a scholarly tradition for English nonconformity.

His publication of Psalms, "The Book of Psalmes: Englished both in Prose and Metre with Annotations" (Amsterdam, 1612), which includes thirty-nine separate monophonic psalm tunes, constituted the Ainsworth Psalter, the only book of music brought to New England in 1620 by the Pilgrim settlers. Although its content was later reworked into the Bay Psalm Book, it had an important influence on the early development of American psalmody.

Ainsworth died in 1622, or early in 1623, for in that year was published his "Seasonable Discourse, or a Censure upon a Dialogue of the Anabaptists", in which the editor speaks of him as a departed worthy.


</doc>
<doc id="13677" url="https://en.wikipedia.org/wiki?curid=13677" title="Hindus">
Hindus

Hindus () are persons who regard themselves as culturally, ethnically, or religiously adhering to aspects of Hinduism. Historically, the term has also been used as a geographical, cultural, and later religious identifier for people indigenous to the Indian subcontinent.

The historical meaning of the term "Hindu" has evolved with time. Starting with the Persian and Greek references to the land of the Indus in the 1st millennium BCE through the texts of the medieval era, the term Hindu implied a geographic, ethnic or cultural identifier for people living in the Indian subcontinent around or beyond the Sindhu (Indus) river. By the 16th century, the term began to refer to residents of the subcontinent who were not Turkic or Muslims.

The historical development of Hindu self-identity within the local South Asian population, in a religious or cultural sense, is unclear. Competing theories state that Hindu identity developed in the British colonial era, or that it developed post-8th century CE after the Islamic invasion and medieval Hindu-Muslim wars. A sense of Hindu identity and the term "Hindu" appears in some texts dated between the 13th and 18th century in Sanskrit and regional languages. The 14th- and 18th-century Indian poets such as Vidyapati, Kabir and Eknath used the phrase "Hindu dharma" (Hinduism) and contrasted it with "Turaka dharma" (Islam). The Christian friar Sebastiao Manrique used the term 'Hindu' in religious context in 1649. In the 18th century, the European merchants and colonists began to refer to the followers of Indian religions collectively as "Hindus", in contrast to "Mohamedans" for Mughals and Arabs following Islam. By the mid-19th century, colonial orientalist texts further distinguished Hindus from Buddhists, Sikhs and Jains, but the colonial laws continued to consider all of them to be within the scope of the term "Hindu" until about mid-20th century. Scholars state that the custom of distinguishing between Hindus, Buddhists, Jains and Sikhs is a modern phenomenon. Hindoo is an archaic spelling variant, whose use today may be considered derogatory.
At more than 1.03 billion, Hindus are the world's third largest group after Christians and Muslims. The vast majority of Hindus, approximately 966 million, live in India, according to India's 2011 census. After India, the next 9 countries with the largest Hindu populations are, in decreasing order: Nepal, Bangladesh, Indonesia, Pakistan, Sri Lanka, United States, Malaysia, United Kingdom and Myanmar. These together accounted for 99% of the world's Hindu population, and the remaining nations of the world together had about 6 million Hindus in 2010.

The word "Hindu" is derived from the Indo-Aryan and Sanskrit word "Sindhu", which means "a large body of water", covering "river, ocean". It was used as the name of the Indus river and also referred to its tributaries. The actual term " first occurs, states Gavin Flood, as "a Persian geographical term for the people who lived beyond the river Indus (Sanskrit: "Sindhu")", more specifically in the 6th-century BCE inscription of Darius I. The Punjab region, called Sapta Sindhu in the Vedas, is called "Hapta Hindu" in Zend Avesta. The 6th-century BCE inscription of Darius I mentions the province of "Hi[n]dush", referring to northwestern India. The people of India were referred to as "Hinduvān" (Hindus) and "hindavī" was used as the adjective for Indian in the 8th century text "Chachnama". The term 'Hindu' in these ancient records is an ethno-geographical term and did not refer to a religion. The Arabic equivalent "Al-Hind" likewise referred to the country of India.

Among the earliest known records of 'Hindu' with connotations of religion may be in the 7th-century CE Chinese text "Record of the Western Regions" by the Buddhist scholar Xuanzang. Xuanzang uses the transliterated term "In-tu" whose "connotation overflows in the religious" according to Arvind Sharma. While Xuanzang suggested that the term refers to the country named after the moon, another Buddhist scholar I-tsing contradicted the conclusion saying that "In-tu" was not a common name for the country.

Al-Biruni's 11th-century text "Tarikh Al-Hind", and the texts of the Delhi Sultanate period use the term 'Hindu', where it includes all non-Islamic people such as Buddhists, and retains the ambiguity of being "a region or a religion". The 'Hindu' community occurs as the amorphous 'Other' of the Muslim community in the court chronicles, according to Romila Thapar. Wilfred Cantwell Smith notes that 'Hindu' retained its geographical reference initially: 'Indian', 'indigenous, local', virtually 'native'. Slowly, the Indian groups themselves started using the term, differentiating themselves and their "traditional ways" from those of the invaders.
The text "Prithviraj Raso", by Chanda Baradai, about the 1192 CE defeat of Prithviraj Chauhan at the hands of Muhammad Ghori, is full of references to "Hindus" and "Turks", and at one stage, says "both the religions have drawn their curved swords;" however, the date of this text is unclear and considered by most scholars to be more recent. In Islamic literature, 'Abd al-Malik Isami's Persian work, "Futuhu's-salatin", composed in the Deccan in 1350, uses the word " to mean Indian in the ethno-geographical sense and the word " to mean 'Hindu' in the sense of a follower of the Hindu religion". The poet Vidyapati's poem "Kirtilata" contrasts the cultures of Hindus and Turks (Muslims) in a city and concludes "The Hindus and the Turks live close together; Each makes fun of the other's religion ("dhamme")." One of the earliest uses of word 'Hindu' in religious context in a European language (Spanish), was the publication in 1649 by Sebastiao Manrique.

Other prominent mentions of 'Hindu' include the epigraphical inscriptions from Andhra Pradesh kingdoms who battled military expansion of Muslim dynasties in the 14th century, where the word 'Hindu' partly implies a religious identity in contrast to 'Turks' or Islamic religious identity. The term "Hindu" was later used occasionally in some Sanskrit texts such as the later Rajataranginis of Kashmir (Hinduka, c. 1450) and some 16th- to 18th-century Bengali Gaudiya Vaishnava texts, including "Chaitanya Charitamrita" and "Chaitanya Bhagavata". These texts used it to contrast Hindus from Muslims who are called Yavanas (foreigners) or Mlecchas (barbarians), with the 16th-century "Chaitanya Charitamrita" text and the 17th-century "Bhakta Mala" text using the phrase "Hindu dharma".

One of the earliest but ambiguous uses of the word Hindu is, states Arvind Sharma, in the 'Brahmanabad settlement' which Muhammad ibn Qasim made with non-Muslims after the Arab invasion of northwestern Sindh region of India, in 712 CE. The term 'Hindu' meant people who were non-Muslims, and it included Buddhists of the region. In the 11th-century text of Al Biruni, Hindus are referred to as "religious antagonists" to Islam, as those who believe in rebirth, presents them to hold a diversity of beliefs, and seems to oscillate between Hindus holding a centralist and pluralist religious views. In the texts of Delhi Sultanate era, states Sharma, the term Hindu remains ambiguous on whether it means people of a region or religion, giving the example of Ibn Battuta's explanation of the name "Hindu Kush" for a mountain range in Afghanistan. It was so called, wrote Ibn Battuta, because many Indian slaves died there of snow cold, as they were marched across that mountain range. The term "Hindu" there is ambivalent and could mean geographical region or religion.

The term Hindu appears in the texts from the Mughal Empire era. It broadly refers to non-Muslims. Pashaura Singh states, "in Persian writings, Sikhs were regarded as Hindu in the sense of non-Muslim Indians". Jahangir, for example, called the Sikh Guru Arjan a Hindu:

During the colonial era, the term Hindu had connotations of native religions of India, that is religions other than Christianity and Islam. In early colonial era Anglo-Hindu laws and British India court system, the term Hindu referred to people of all Indian religions and two non-Indian religions:

The 20th-century colonial laws of British India segregated people's rights by their religion, evolving to provide Muslims with Sharia law, Christians, Jews and Parsis of British India with their own religious laws. The British government created a compendium of religious laws for Hindus, and the term 'Hindu' in these colonial 'Hindu laws', decades before India's independence, applied to Buddhists, Jains and Sikhs.

Beyond the stipulations of British law, colonial orientalists and particularly the influential Asiatick Researches founded in the 18th century, later called The Asiatic Society, initially identified just two religions in India – Islam, and Hinduism. These orientalists included all Indian religions such as Buddhism as a subgroup of Hinduism in the 18th century. These texts called followers of Islam as "Mohamedans", and all others as "Hindus". The text, by the early 19th century, began dividing Hindus into separate groups, for chronology studies of the various beliefs. Among the earliest terms to emerge were "Seeks and their College" (later spelled Sikhs by Charles Wilkins), "Boudhism" (later spelled Buddhism), and in the 9th volume of Asiatick Researches report on religions in India, the term "Jainism" received notice.

According to Pennington, the terms Hindu and Hinduism were thus constructed for colonial studies of India. The various sub-divisions and separation of subgroup terms were assumed to be result of "communal conflict", and Hindu was constructed by these orientalists to imply people who adhered to "ancient default oppressive religious substratum of India", states Pennington. Followers of other Indian religions so identified were later referred Buddhists, Sikhs or Jains and distinguished from Hindus, in an antagonistic two-dimensional manner, with Hindus and Hinduism stereotyped as irrational traditional and others as rational reform religions. However, these mid-19th-century reports offered no indication of doctrinal or ritual differences between Hindu and Buddhist, or other newly constructed religious identities. These colonial studies, states Pennigton, "puzzled endlessly about the Hindus and intensely scrutinized them, but did not interrogate and avoided reporting the practices and religion of Mughal and Arabs in South Asia", and often relied on Muslim scholars to characterise Hindus.

In contemporary era, the term Hindus are individuals who identify with one or more aspects of Hinduism, whether they are practising or non-practicing or "Laissez-faire". The term does not include those who identify with other Indian religions such as Buddhism, Jainism, Sikhism or various animist tribal religions found in India such as "Sarnaism". The term Hindu, in contemporary parlance, includes people who accept themselves as culturally or ethnically Hindu rather than with a fixed set of religious beliefs within Hinduism. One need not be religious in the minimal sense, states Julius Lipner, to be accepted as Hindu by Hindus, or to describe oneself as Hindu.

Hindus subscribe to a diversity of ideas on spirituality and traditions, but have no ecclesiastical order, no unquestionable religious authorities, no governing body, nor a single founding prophet; Hindus can choose to be polytheistic, pantheistic, monotheistic, monistic, agnostic, atheistic or humanist. Because of the wide range of traditions and ideas covered by the term Hinduism, arriving at a comprehensive definition is difficult. The religion "defies our desire to define and categorize it". A Hindu may, by his or her choice, draw upon ideas of other Indian or non-Indian religious thought as a resource, follow or evolve his or her personal beliefs, and still identify as a Hindu.

In 1995, Chief Justice P. B. Gajendragadkar was quoted in an Indian Supreme Court ruling:

Although Hinduism contains a broad range of philosophies, Hindus share philosophical concepts, such as but not limiting to dharma, karma, kama, artha, moksha and samsara, even if each subscribes to a diversity of views. Hindus also have shared texts such as the Vedas with embedded Upanishads, and common ritual grammar (Sanskara (rite of passage)) such as rituals during a wedding or when a baby is born or cremation rituals. Some Hindus go on pilgrimage to shared sites they consider spiritually significant, practice one or more forms of bhakti or puja, celebrate mythology and epics, major festivals, love and respect for guru and family, and other cultural traditions. A Hindu could:

In the Constitution of India, the word "Hindu" has been used in some places to denote persons professing any of these religions: Hinduism, Jainism, Buddhism or Sikhism. This however has been challenged by the Sikhs and by neo-Buddhists who were formerly Hindus. According to Sheen and Boyle, Jains have not objected to being covered by personal laws termed under 'Hindu', but Indian courts have acknowledged that Jainism is a distinct religion.

The Republic of India is in the peculiar situation that the Supreme Court of India has repeatedly been called upon to define "Hinduism" because the Constitution of India, while it prohibits "discrimination of any citizen" on grounds of religion in article 15, article 30 foresees special rights for "All minorities, whether based on religion or language". As a consequence, religious groups have an interest in being recognised as distinct from the Hindu majority in order to qualify as a "religious minority". Thus, the Supreme Court was forced to consider the question whether Jainism is part of Hinduism in 2005 and 2006.

Starting after the 10th century and particularly after the 12th century Islamic invasion, states Sheldon Pollock, the political response fused with the Indic religious culture and doctrines. Temples dedicated to deity Rama were built from north to south India, and textual records as well as hagiographic inscriptions began comparing the Hindu epic of Ramayana to regional kings and their response to Islamic attacks. The Yadava king of Devagiri named "Ramacandra", for example states Pollock, is described in a 13th-century record as, "How is this Rama to be described.. who freed Varanasi from the "mleccha" (barbarian, Turk Muslim) horde, and built there a golden temple of Sarngadhara". Pollock notes that the Yadava king "Ramacandra" is described as a devotee of deity Shiva (Shaivism), yet his political achievements and temple construction sponsorship in Varanasi, far from his kingdom's location in the Deccan region, is described in the historical records in Vaishnavism terms of Rama, a deity Vishnu avatar. Pollock presents many such examples and suggests an emerging Hindu political identity that was grounded in the Hindu religious text of Ramayana, one that has continued into the modern times, and suggests that this historic process began with the arrival of Islam in India.

Brajadulal Chattopadhyaya has questioned the Pollock theory and presented textual and inscriptional evidence. According to Chattopadhyaya, the Hindu identity and religious response to Islamic invasion and wars developed in different kingdoms, such as wars between Islamic Sultanates and the Vijayanagara kingdom (Karnataka), and Islamic raids on the kingdoms in Tamil Nadu. These wars were described not just using the mythical story of Rama from Ramayana, states Chattopadhyaya, the medieval records used a wide range of religious symbolism and myths that are now considered as part of Hindu literature. This emergence of religious with political terminology began with the first Muslim invasion of Sindh in the 8th century CE, and intensified 13th century onwards. The 14th-century Sanskrit text, "Madhuravijayam", a memoir written by "Gangadevi", the wife of Vijayanagara prince, for example describes the consequences of war using religious terms,

The historiographic writings in Telugu language from the 13th- and 14th-century Kakatiya dynasty period presents a similar "alien other (Turk)" and "self-identity (Hindu)" contrast. Chattopadhyaya, and other scholars, state that the military and political campaign during the medieval era wars in Deccan peninsula of India, and in the north India, were no longer a quest for sovereignty, they embodied a political and religious animosity against the "otherness of Islam", and this began the historical process of Hindu identity formation.

Andrew Nicholson, in his review of scholarship on Hindu identity history, states that the vernacular literature of Bhakti movement sants from 15th to 17th century, such as Kabir, Anantadas, Eknath, Vidyapati, suggests that distinct religious identities, between Hindus and Turks (Muslims), had formed during these centuries. The poetry of this period contrasts Hindu and Islamic identities, states Nicholson, and the literature vilifies the Muslims coupled with a "distinct sense of a Hindu religious identity".

Scholars state that Hindu, Buddhist and Jain identities are retrospectively-introduced modern constructions. Inscriptional evidence from the 8th century onwards, in regions such as South India, suggests that medieval era India, at both elite and folk religious practices level, likely had a "shared religious culture", and their collective identities were "multiple, layered and fuzzy". Even among Hinduism denominations such as Shaivism and Vaishnavism, the Hindu identities, states Leslie Orr, lacked "firm definitions and clear boundaries".

Overlaps in Jain-Hindu identities have included Jains worshipping Hindu deities, intermarriages between Jains and Hindus, and medieval era Jain temples featuring Hindu religious icons and sculpture. Beyond India, on Java island of Indonesia, historical records attest to marriages between Hindus and Buddhists, medieval era temple architecture and sculptures that simultaneously incorporate Hindu and Buddhist themes, where Hinduism and Buddhism merged and functioned as "two separate paths within one overall system", according to Ann Kenney and other scholars. Similarly, there is an organic relation of Sikhs to Hindus, states Zaehner, both in religious thought and their communities, and virtually all Sikhs' ancestors were Hindus. Marriages between Sikhs and Hindus, particularly among "Khatris", were frequent. Some Hindu families brought up a son as a Sikh, and some Hindus view Sikhism as a tradition within Hinduism, even though the Sikh faith is a distinct religion.

Julius Lipner states that the custom of distinguishing between Hindus, Buddhists, Jains, and Sikhs is a modern phenomena, but one that is a convenient abstraction. Distinguishing Indian traditions is a fairly recent practice, states Lipner, and is the result of "not only Western preconceptions about the nature of religion in general and of religion in India in particular, but also with the political awareness that has arisen in India" in its people and a result of Western influence during its colonial history.

Scholars such as Fleming and Eck state that the post-Epic era literature from the 1st millennium CE amply demonstrate that there was a historic concept of the Indian subcontinent as a sacred geography, where the sacredness was a shared set of religious ideas. For example, the twelve "Jyotirlingas" of Shaivism and fifty-one "Shaktipithas" of Shaktism are described in the early medieval era Puranas as pilgrimage sites around a theme. This sacred geography and Shaiva temples with same iconography, shared themes, motifs and embedded legends are found across India, from the Himalayas to hills of South India, from Ellora Caves to Varanasi by about the middle of 1st millennium. Shakti temples, dated to a few centuries later, are verifiable across the subcontinent. Varanasi as a sacred pilgrimage site is documented in the "Varanasimahatmya" text embedded inside the "Skanda Purana", and the oldest versions of this text are dated to 6th to 8th-century CE.

The idea of twelve sacred sites in Shiva Hindu tradition spread across the Indian subcontinent appears not only in the medieval era temples but also in copper plate inscriptions and temple seals discovered in different sites. According to Bhardwaj, non-Hindu texts such as the memoirs of Chinese Buddhist and Persian Muslim travellers attest to the existence and significance of the pilgrimage to sacred geography among Hindus by later 1st millennium CE.

According to Fleming, those who question whether the term Hindu and Hinduism are a modern construction in a religious context present their arguments based on some texts that have survived into the modern era, either of Islamic courts or of literature published by Western missionaries or colonial-era Indologists aiming for a reasonable construction of history. However, the existence of non-textual evidence such as cave temples separated by thousands of kilometers, as well as lists of medieval era pilgrimage sites, is evidence of a shared sacred geography and existence of a community that was self-aware of shared religious premises and landscape. Further, it is a norm in evolving cultures that there is a gap between the "lived and historical realities" of a religious tradition and the emergence of related "textual authorities". The tradition and temples likely existed well before the medieval era Hindu manuscripts appeared that describe them and the sacred geography. This, states Fleming, is apparent given the sophistication of the architecture and the sacred sites along with the variance in the versions of the Puranic literature. According to Diana L. Eck and other Indologists such as André Wink, Muslim invaders were aware of Hindu sacred geography such as Mathura, Ujjain, and Varanasi by the 11th-century. These sites became a target of their serial attacks in the centuries that followed.

The Hindus have been persecuted during the medieval and modern era. The medieval persecution included waves of plunder, killing, destruction of temples and enslavement by Turk-Mongol Muslim armies from central Asia. This is documented in Islamic literature such as those relating to 8th century Muhammad bin-Qasim, 11th century Mahmud of Ghazni, the Persian traveler Al Biruni, the 14th century Islamic army invasion led by Timur, and various Sunni Islamic rulers of the Delhi Sultanate and Mughal Empire. There were occasional exceptions such as Akbar who stopped the persecution of Hindus, and occasional severe persecution such as under Aurangzeb, who destroyed temples, forcibly converted non-Muslims to Islam and banned the celebration of Hindu festivals such as Holi and Diwali.

Other recorded persecution of Hindus include those under the reign of 18th century Tipu Sultan in south India, and during the colonial era. In the modern era, religious persecution of Hindus have been reported outside India.

Christophe Jaffrelot states that modern Hindu nationalism was born in Maharashtra, in the 1920s, as a reaction to the Islamic Khilafat Movement wherein Indian Muslims championed and took the cause of the Turkish Ottoman sultan as the Caliph of all Muslims, at the end of the World War I. Hindus viewed this development as one of divided loyalties of Indian Muslim population, of pan-Islamic hegemony, and questioned whether Indian Muslims were a part of an inclusive anti-colonial Indian nationalism. The Hindu nationalism ideology that emerged, states Jeffrelot, was codified by Savarkar while he was a political prisoner of the British colonial empire.

Chris Bayly traces the roots of Hindu nationalism to the Hindu identity and political independence achieved by the Maratha confederacy, that overthrew the Islamic Mughal empire in large parts of India, allowing Hindus the freedom to pursue any of their diverse religious beliefs and restored Hindu holy places such as Varanasi. A few scholars view Hindu mobilisation and consequent nationalism to have emerged in the 19th century as a response to British colonialism by Indian nationalists and neo-Hinduism gurus. Jaffrelot states that the efforts of Christian missionaries and Islamic proselytizers, during the British colonial era, each of whom tried to gain new converts to their own religion, by stereotyping and stigmatising Hindus to an identity of being inferior and superstitious, contributed to Hindus re-asserting their spiritual heritage and counter cross examining Islam and Christianity, forming organisations such as the "Hindu Sabhas" (Hindu associations), and ultimately a Hindu-identity driven nationalism in the 1920s.

The colonial era Hindu revivalism and mobilisation, along with Hindu nationalism, states Peter van der Veer, was primarily a reaction to and competition with Muslim separatism and Muslim nationalism. The successes of each side fed the fears of the other, leading to the growth of Hindu nationalism and Muslim nationalism in the Indian subcontinent. In the 20th century, the sense of religious nationalism grew in India, states van der Veer, but only Muslim nationalism succeeded with the formation of the West and East Pakistan (later split into Pakistan and Bangladesh), as "an Islamic state" upon independence. Religious riots and social trauma followed as millions of Hindus, Jains, Buddhists and Sikhs moved out of the newly created Islamic states and resettled into the Hindu-majority post-British India. After the separation of India and Pakistan in 1947, the Hindu nationalism movement developed the concept of Hindutva in second half of the 20th century.

The Hindu nationalism movement has sought to reform Indian laws, that critics say attempts to impose Hindu values on India's Islamic minority. Gerald Larson states, for example, that Hindu nationalists have sought a uniform civil code, where all citizens are subject to the same laws, everyone has equal civil rights, and individual rights do not depend on the individual's religion. In contrast, opponents of Hindu nationalists remark that eliminating religious law from India poses a threat to the cultural identity and religious rights of Muslims, and people of Islamic faith have a constitutional right to Islamic shariah-based personal laws. A specific law, contentious between Hindu nationalists and their opponents in India, relates to the legal age of marriage for girls. Hindu nationalists seek that the legal age for marriage be eighteen that is universally applied to all girls regardless of their religion and that marriages be registered with local government to verify the age of marriage. Muslim clerics consider this proposal as unacceptable because under the shariah-derived personal law, a Muslim girl can be married at any age after she reaches puberty.

Hindu nationalism in India, states Katharine Adeney, is a controversial political subject, with no consensus about what it means or implies in terms of the form of government and religious rights of the minorities.

According to Pew Research, there are over 1 billion Hindus worldwide (15% of world's population). Along with Christians (31.5%), Muslims (23.2%) and Buddhists (7.1%), Hindus are one of the four major religious groups of the world.

Most Hindus are found in Asian countries. The countries with most Hindu residents and citizens include (in decreasing order) are India, Nepal, Bangladesh, Indonesia, Pakistan, Sri Lanka, United States, Malaysia, United Kingdom, Myanmar, Canada, Mauritius, Guyana, South Africa, Trinidad and Tobago, Fiji, Suriname.

The fertility rate, that is children per woman, for Hindus is 2.4, which is less than the world average of 2.5. Pew Research projects that there will be 1.161 billion Hindus by 2020.

In more ancient times, Hindu kingdoms arose and spread the religion and traditions across Southeast Asia, particularly Thailand, Nepal, Burma, Malaysia, Indonesia, Cambodia, Laos, Philippines, and what is now central Vietnam.

Over 3 million Hindus are found in Bali Indonesia, a culture whose origins trace back to ideas brought by Tamil Hindu traders to Indonesian islands in the 1st millennium CE. Their sacred texts are also the Vedas and the Upanishads. The Puranas and the Itihasa (mainly "Ramayana" and the "Mahabharata") are enduring traditions among Indonesian Hindus, expressed in community dances and shadow puppet ("wayang") performances. As in India, Indonesian Hindus recognises four paths of spirituality, calling it "Catur Marga". Similarly, like Hindus in India, Balinese Hindu believe that there are four proper goals of human life, calling it "Catur Purusartha" – dharma (pursuit of moral and ethical living), artha (pursuit of wealth and creative activity), kama (pursuit of joy and love) and moksha (pursuit of self-knowledge and liberation).




</doc>
<doc id="13678" url="https://en.wikipedia.org/wiki?curid=13678" title="Hernando de Alarcón">
Hernando de Alarcón

Hernando de Alarcón (born 1500) was a Spanish explorer and navigator of the 16th century, noted for having led an early expedition to the Baja California Peninsula, during which he became one of the first Europeans to ascend the Colorado River from its mouth and perhaps the first to reach Alta California.

Little is known about Alarcón's life outside of his exploits in New Spain. He was probably born in the town of Trujillo, in present-day Extremadura, Spain, in the first years of the 16th century and traveled to the Spanish colonies in the Americas as a young man.

By 1540, Mexico had been conquered and state-sponsored expeditions were being sent north in search of new wealth and the existence of a water passage between the Atlantic and Pacific oceans. Viceroy of New Spain Antonio de Mendoza commissioned Francisco Vázquez de Coronado to undertake a massive overland expedition with the purpose of finding the Seven Cities of Cibola, which were rumored to exist in the unexplored northern interior. The expedition was to be resupplied with stores and provisions delivered by ships traveling up the Sea of Cortés, the commander of which would be Alarcón.

Alarcón set sail from Acapulco with two ships, the "San Pedro" and the "Santa Catalina", on May 9, 1540, and was later joined by the "San Gabriel" at St. Jago de Buena Esperanza, in Colima. His orders from Mendoza were to await the arrival of Coronado's land expedition at a certain latitude along the coast. The meeting with Coronado was never effected, though Alarcón reached the appointed place and left letters, which were soon afterwards discovered by Melchior Diaz, another explorer.

Alarcón eventually sailed to the northern terminus of the Gulf of California and completed the explorations begun by Francisco de Ulloa the preceding year. During this voyage Alarcón proved to his satisfaction that no open-water passage existed between the Gulf of California and the South Sea. Subsequently, on September 26, he entered the mouth of the Colorado River, which he named the "Buena Guia". He was the first European to ascend the river for a distance considerable enough to make important observations. On a second voyage, he probably proceeded past the present-day site of Yuma, Arizona. A map drawn by one of Alarcón's pilots is the earliest accurately detailed representation of the Gulf of California and the lower course of the Colorado River.

Alarcón is almost unique among 16th-century "conquistadores" in that he reportedly treated the Indians he met humanely, as opposed to the often reckless and cruel behavior known from accounts of his contemporaries. Bernard de Voto, in his 1953 "Westward the Course of Empire", observed: "The Indians had an experience they were never to repeat: they were sorry to see these white men leave." Alarcón wrote of his contact with the Yuma-speaking Indians along the Colorado. The information he compiled consisted of their practices in warfare, religion, curing and even sexual customs.

California Historical Landmark No. 568, on the west bank of the Colorado River near Andrade in Imperial County, California, commemorates Alarcón's expedition having been the first non-Indians to sight land within the present-day state of California.




</doc>
<doc id="13679" url="https://en.wikipedia.org/wiki?curid=13679" title="Hakka cuisine">
Hakka cuisine

Hakka cuisine, or Kuh-chia cuisine, is the cooking style of the Hakka people, who may also be found in other parts of Taiwan and in countries with significant overseas Hakka communities. There are numerous restaurants in Taiwan, Hong Kong, Indonesia, Malaysia, Singapore and Thailand serving Hakka cuisine. Hakka cuisine was listed in 2014 on the first Hong Kong Inventory of Intangible Cultural Heritage.

The Hakka people have a marked cuisine and style of Chinese cooking which is little known outside the Hakka home. It concentrates on the texture of food – the hallmark of Hakka cuisine. Whereas preserved meats feature in Hakka delicacy, stewed, braised, roast meats – 'texturised' contributions to the Hakka palate – have a central place in their repertoire. Preserved vegetables (梅菜) are commonly used for steamed and braised dishes such as steamed minced pork with preserved vegetables and braised pork with salted vegetables. In fact, the raw materials for Hakka food are no different from raw materials for any other type of regional Chinese cuisine where what is cooked depends on what is available in the market. Hakka cuisine may be described as outwardly simple but tasty. The skill in Hakka cuisine lies in the ability to cook meat thoroughly without hardening it, and to naturally bring out the proteinous flavour (umami taste) of meat.

The Hakka who settled in the harbour and port areas of Hong Kong placed great emphasis on seafood cuisine. Hakka cuisine in Hong Kong is less dominated by expensive meats; instead, emphasis is placed on an abundance of vegetables. Pragmatic and simple, Hakka cuisine is garnished lightly with sparse or little flavouring. Modern Hakka cooking in Hong Kong favours offal, an example being deep-fried intestines (). Others include tofu with preservatives, along with their signature dish, salt baked chicken (). Another specialty is the poon choi (). While it may be difficult to prove these were the actual diets of the old Hakka community, it is at present a commonly accepted view. The above dishes and their variations are in fact found and consumed throughout China, including Guangdong Province, and are not particularly unique or confined to the Hakka population.

Besides meat as source of protein, there is a unique vegan dish called lei cha (). It comprises combinations of vegetables and beans. Although not specifically unique for all Hakka people but are definitely famous among the Hakka-Hopo families. This vegetable-based rice tea dish is gaining momentum in some multicultural countries like Malaysia. Cooking of this dish requires the help from other family members to complete all eight combinations. It helps foster the relationship between family members in return. 

Steamed bun (茶果) is a popular snack for Hakka people. It is mainly made from glutinous rice and is available in sweet or salty options. Sweet version consists of sweetened black-eyed pea pastes or peanuts. Salty version consists of preserved radish.

Hakka food also includes other traditional Taiwanese dishes, just as other Taiwanese ethnic groups do. Some of the more notable dishes in Hakka cuisine are listed as follow:

In India and other regions with significant Indian populations, the locally known "Hakka cuisine" is actually an Indian adaptation of original Hakka dishes. This variation of Hakka cuisine is in reality, mostly Indian Chinese cuisine. It is called "Hakka cuisine" because in India, many owners of restaurants who serve this cuisine are of Hakka origin. Typical dishes include 'chilli chicken' and 'Dongbei (northeastern) chow mein' (an Indianised version of real Northeastern Chinese cuisine), and these restaurants also serve traditional Indian dishes such as pakora. Being very popular in these areas, this style of cuisine is often mistakenly credited as being representative of Hakka cuisine in general, whereas the authentic style of Hakka cuisine is rarely known in these regions.

Outside of India, the premiere place to enjoy Indian-Chinese cuisine is in Toronto, Canada, due to the large amount of Chinese from India that have emigrated to the region and have chosen to open restaurants.

In Thailand, Bangkok's Chinatown is Yaowarat and including neighboring areas such as Sampheng, Charoen Chai, Charoen Krung, Suan Mali, Phlapphla Chai or Wong Wian Yi Sip Song Karakadakhom (July 22nd Circle). In the past, many Hakka restaurants are located in the Suan Mali near Bangkok Metropolitan Administration General Hospital. But now they had moved into many places, such as Talad Phlu, which is also one of the Chinatown as well.




</doc>
<doc id="13680" url="https://en.wikipedia.org/wiki?curid=13680" title="Hunan cuisine">
Hunan cuisine

Hunan cuisine, also known as Xiang cuisine, consists of the cuisines of the Xiang River region, Dongting Lake and western Hunan Province in China. It is one of the Eight Great Traditions of Chinese cuisine and is well known for its hot and spicy flavours, fresh aroma and deep colours. Common cooking techniques include stewing, frying, pot-roasting, braising and smoking. Due to the high agricultural output of the region, ingredients for Hunan dishes are many and varied.

The history of the cooking skills employed in Hunan cuisine dates back to the 17th century. During the course of its history, Hunan cuisine assimilated a variety of local forms, eventually evolving into its own style. Some well-known dishes include fried chicken with Sichuan spicy sauce () and smoked pork with dried long green beans ().

Hunan cuisine consists of three primary styles:

Known for its liberal use of chili peppers, shallots and garlic, Hunan cuisine is known for being "gan la" () or purely hot, as opposed to Sichuan cuisine, to which it is often compared. Sichuan cuisine is known for its distinctive "ma la" () seasoning and other complex flavour combinations, frequently employs Sichuan pepper along with chilies which are often dried. It also utilises more dried or preserved ingredients and condiments. Hunan cuisine, on the other hand, is often spicier by pure chili content and contains a larger variety of fresh ingredients. Both Hunan and Sichuan cuisine are perhaps significantly oilier than the other cuisines in China, but Sichuan dishes are generally oilier than Hunan dishes. Another characteristic distinguishing Hunan cuisine from Sichuan cuisine is that, in general, Hunan cuisine uses smoked and cured goods in its dishes much more frequently.
Another feature of Hunan cuisine is that the menu changes with the seasons. In a hot and humid summer, a meal will usually start with cold dishes or a platter holding a selection of cold meats with chilies for opening the pores and keeping cool in the summer. In winter, a popular choice is the hot pot, thought to heat the blood in the cold months. A special hot pot called "yuanyang huoguo" () is notable for splitting the pot into two sides – a spicy one and a mild one. One of the classic dishes in Hunan cuisine served in restaurants and at home is farmer pepper fried pork. It is made with several common ingredients: pork belly, green pepper, fermented black beans and other spices.

Chilies are an entire class of flavourings in Hunan cuisine.



</doc>
